<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[屏幕太“亮”看不清灰色部分]]></title>
    <url>%2F201907%2Fmisc%2Fscreen_too_bright.html</url>
    <content type="text"><![CDATA[双屏中的一屏（ThinkVision P24i-10），感觉太“亮”，看着很别扭，看不清灰色的部分。一直看下来，整个人觉得很累，怎么调整亮度和对比度都不对。参考 显示器白色部分太亮 导致白色与淡灰色分不出，在别的电脑上去可以。 在同等显卡的情况下，应该怎么调节？，认为有三种可能： 对比度 色阶 线的问题，换线 前两者调过很多次，问题依旧。考虑第三种方法，换线。确认问题屏的接线为 VGA 转 HDMI，没有问题的屏为 VGA - VGA，因此两者线互切，Bingo！两个屏幕都看得很舒服了！]]></content>
      <categories>
        <category>misc</category>
      </categories>
      <tags>
        <tag>misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elementary OS 使用记录]]></title>
    <url>%2F201903%2Flinux%2Felementaryos.html</url>
    <content type="text"><![CDATA[无法更换壁纸（wallpaper），killall -HUP gala]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>elementary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些常见的 git 命令备忘]]></title>
    <url>%2F201901%2Ftools%2Fgit_cmd.html</url>
    <content type="text"><![CDATA[本文首次编辑：2016-04-27。 查看 log，按 message 过滤、按 author 过滤、按日期过滤等。https://www.atlassian.com/git/tutorials/git-log。 灵活打 patch，https://www.jianshu.com/p/814fb6606734 第一次切换分支，git checkout -b xxx origin/xxx 后续切分支，git checkout xxx 删除本地分支，git branch -d xxx 删除远程分支，git push origin –delete xxx 查看当前分支，git branch -a | grep “*” git checkout到特定版本，git checkout upstream的前8位 git clone / push 的时候不用密码：git config --global credential.helper &#39;cache --timeout 7200&#39;，timeout 的单位为秒。 创建分支，git checkout -b newbranch 重命名分支，git branch -m oldBranch newBranch 提供本地分支到远程 repo（远程 repo 无此分支），git push origin newBranch or git push -u origin newBranch 强制推送本地修订，覆盖远程 repo。会覆盖此间别人的提交。git push --force-with-lease 打 patch 时，如何把 patch 中的 commit message 和 user 保持不变？git am xxx.patch，与 git format-patch 相对应 stage Q：多一个 stage 有什么优点？A：暂存空间。git add 后的文件放到 stage 区，再修改同样的文件，其修订不会体现在此次 commit，除非再 git add 一次。 git format-patch，已提交版本生成 patch git format-patch -&lt;n&gt; &lt;SHA1&gt;，输出从 SHA1 开始的 n 个提交 patch，会输出 10 个 patch git format-patch -10 HEAD --stdout &gt; 0001-last-10-commits.patch，输出最新前 10 次修订为一个 patch git log -p -1 &lt;commit&gt;，查看某次提交的具体修订 git diff sha1 sha2 &gt; mypatch.diff，输出 sha1 到 sha2 的所有修订，如果 sha1 比 sha2 早，则是修订 patch，如果晚，则是回退 patch。 git am -3 –ignore-space-change，只能使用 format-patch 的 patch git config core.editor vim git checkout file，可以让 file 从 staged 状态返回 untracked 状态 git checkout – file git reset HEAD file，让文件从 staged 返回 modified 状态 git clean -f -d，删除未被跟踪的任何文件/目录 .gitignore，忽略不需要跟踪的文件 git revert commitid，撤消某个修订并自动 commit git reset –soft，回退修订 基于某个 commitid 创建新分支 name git reset –hard commitid git branch name git merge，不推荐使用。可通过 git format 打 patch，优势是可以看到同步的每个修订。 git cherry-pick commitid，单独同步某次提交 git show commit git commit –amend，修改最后一次提交的 log git rebase，不推荐新手使用。 git reset –hard commitid, git push, 回退到某个特定版本 git remote -v，查看当前仓库的链接 git status –untracked-files=no，git status 只查看跟踪的文件，同 git status -uno 回退某个文件的到特定版本，git checkout c5f567 -- file1/to/restore file2/to/restore，详见 stackoverflow 删除未被跟踪的任何文件和目录注意：本操作会删除所有未加入 git 版本管理的文件。 在对应组件源码目录下，git clean -f -d -X，清除该目录中所有没有被跟踪的文件。 123456789101112131415161718192021222324252627282930313233343536373839NAME git-clean - Remove untracked files from the working treeSYNOPSIS git clean [-d] [-f] [-i] [-n] [-q] [-e &lt;pattern&gt;] [-x | -X] [--] &lt;path&gt;...DESCRIPTION Cleans the working tree by recursively removing files that are not under version control, starting from the current directory. Normally, only files unknown to Git are removed, but if the -x option is specified, ignored files are also removed. This can, for example, be useful to remove all build products. If any optional &lt;path&gt;... arguments are given, only those paths are affected.OPTIONS -d Remove untracked directories in addition to untracked files. If an untracked directory is managed by a different Git repository, it is not removed by default. Use -f option twice if you really want to remove such a directory. -f, --force If the Git configuration variable clean.requireForce is not set to false, git clean will refuse to run unless given -f, -n or -i. -i, --interactive Show what would be done and clean files interactively. See “Interactive mode” for details. -n, --dry-run Don’t actually remove anything, just show what would be done. -q, --quiet Be quiet, only report errors, but not the files that are successfully removed. -e &lt;pattern&gt;, --exclude=&lt;pattern&gt; In addition to those found in .gitignore (per directory) and $GIT_DIR/info/exclude, also consider these patterns to be in the set of the ignore rules in effect. -x Don’t use the standard ignore rules read from .gitignore (per directory) and $GIT_DIR/info/exclude, but do still use the ignore rules given with -e options. This allows removing all untracked files, including build products. This can be used (possibly in conjunction with git reset) to create a pristine working directory to test a clean build. -X Remove only files ignored by Git. This may be useful to rebuild everything from scratch, but keep manually created files. 样例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445jerome@compile:~/sb/src/libttoo$ git statusOn branch masterUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) .gitignore debian/files debian/libttoo-dbg.debhelper.log debian/libttoo-dbg.substvars debian/libttoo-dbg/ debian/libttoo-dev.debhelper.log debian/libttoo-dev.substvars debian/libttoo-dev/ debian/libttoo.debhelper.log debian/libttoo.postinst.debhelper debian/libttoo.postrm.debhelper debian/libttoo.substvars debian/libttoo/ debian/tmp/ include/ttoo_version.patch output/x86-tt/bin/nothing added to commit but untracked files present (use "git add" to track)jerome@compile:~/sb/src/libttoo$ git clean -dfRemoving .gitignoreRemoving debian/filesRemoving debian/libttoo-dbg.debhelper.logRemoving debian/libttoo-dbg.substvarsRemoving debian/libttoo-dbg/Removing debian/libttoo-dev.debhelper.logRemoving debian/libttoo-dev.substvarsRemoving debian/libttoo-dev/Removing debian/libttoo.debhelper.logRemoving debian/libttoo.postinst.debhelperRemoving debian/libttoo.postrm.debhelperRemoving debian/libttoo.substvarsRemoving debian/libttoo/Removing debian/tmp/Removing include/ttoo_version.patchRemoving output/x86-tt/bin/Removing output/x86-tt/objects/jerome@compile:~/sb/src/libttoo$ git statusOn branch masternothing to commit, working directory cleanjerome@compile:~/sb/src/libttoo$ git fork 一个仓库到本地后，同步远程仓库的修订详见： gitlab或github下fork后如何同步源的新更新内容？ 同步一个 fork Git远程操作详解 12345678910111213141516171819202122232425262728293031323334353637383940$ git clone http://192.168.199.32/sonic/libteam/ Cloning into 'libteam'...remote: Counting objects: 4985, done.remote: Compressing objects: 100% (1822/1822), done.remote: Total 4985 (delta 3089), reused 4985 (delta 3089)Receiving objects: 100% (4985/4985), 15.87 MiB | 0 bytes/s, done.Resolving deltas: 100% (3089/3089), done.Checking connectivity... done.$ cd libteam/$ git remote -vorigin http://192.168.199.32/sonic/libteam/ (fetch)origin http://192.168.199.32/sonic/libteam/ (push)$ git remote add upstream https://github.com/jpirko/libteam.git$ git remote -vorigin http://192.168.199.32/sonic/libteam/ (fetch)origin http://192.168.199.32/sonic/libteam/ (push)upstream https://github.com/jpirko/libteam.git (fetch)upstream https://github.com/jpirko/libteam.git (push)$ git fetch upstream remote: Counting objects: 4, done.remote: Total 4 (delta 3), reused 3 (delta 3), pack-reused 1Unpacking objects: 100% (4/4), done.From https://github.com/jpirko/libteam * [new branch] gh-pages -&gt; upstream/gh-pages * [new branch] master -&gt; upstream/master$ git merge upstream/master Updating 3ede1b2..789591cFast-forward man/teamd.conf.5 | 7 ++++++- 1 file changed, 6 insertions(+), 1 deletion(-)$ git push origin master Username for 'http://192.168.199.32': your_namePassword for 'http://your_name@192.168.199.32': Counting objects: 4, done.Delta compression using up to 24 threads.Compressing objects: 100% (4/4), done.Writing objects: 100% (4/4), 511 bytes | 0 bytes/s, done.Total 4 (delta 3), reused 0 (delta 0)To http://192.168.199.32/sonic/libteam/ 3ede1b2..789591c master -&gt; master 如果远程“父”仓库的有很多 tags 和 branches，如何同步到本地远程 repo？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475$ git remote add upstream https://github.com/opencomputeproject/SAI$ git remote -v origin http://192.168.199.32/sonic/SAI (fetch)origin http://192.168.199.32/sonic/SAI (push)upstream https://github.com/opencomputeproject/SAI (fetch)upstream https://github.com/opencomputeproject/SAI (push)$ git fetch upstreamremote: Counting objects: 190, done.remote: Compressing objects: 100% (6/6), done.remote: Total 190 (delta 119), reused 122 (delta 119), pack-reused 65Receiving objects: 100% (190/190), 291.31 KiB | 250.00 KiB/s, done.Resolving deltas: 100% (139/139), completed with 57 local objects.From https://github.com/opencomputeproject/SAI * [new branch] master -&gt; upstream/master * [new branch] revert-648-vlanigmpcontrol -&gt; upstream/revert-648-vlanigmpcontrol * [new branch] v0.9.1 -&gt; upstream/v0.9.1 * [new branch] v0.9.2 -&gt; upstream/v0.9.2 * [new branch] v0.9.4 -&gt; upstream/v0.9.4 * [new branch] v0.9.5 -&gt; upstream/v0.9.5 * [new branch] v0.9.6 -&gt; upstream/v0.9.6 * [new branch] v1.0 -&gt; upstream/v1.0 * [new branch] v1.1 -&gt; upstream/v1.1 * [new branch] v1.2 -&gt; upstream/v1.2 * [new tag] v1.2.1 -&gt; v1.2.1 * [new tag] v1.2.2 -&gt; v1.2.2 * [new tag] v1.2.3 -&gt; v1.2.3 * [new tag] v1.2.4 -&gt; v1.2.4 * [new tag] v1.3.0 -&gt; v1.3.0$ git push --mirror Username for 'http://192.168.199.32': your_namePassword for 'http://your_name@192.168.199.32': Counting objects: 200, done.Delta compression using up to 24 threads.Compressing objects: 100% (93/93), done.Writing objects: 100% (200/200), 351.49 KiB | 0 bytes/s, done.Total 200 (delta 161), reused 145 (delta 107)remote: Resolving deltas: 100% (161/161), completed with 60 local objects.To http://192.168.199.32/sonic/SAI - [deleted] revert-648-vlanigmpcontrol - [deleted] riotmac - [deleted] v0.9.1 - [deleted] v0.9.2 - [deleted] v0.9.4 - [deleted] v0.9.5 - [deleted] v0.9.6 - [deleted] v1.0 - [deleted] v1.1 - [deleted] v1.2 * [new branch] origin/HEAD -&gt; origin/HEAD * [new branch] origin/master -&gt; origin/master * [new branch] origin/revert-648-vlanigmpcontrol -&gt; origin/revert-648-vlanigmpcontrol * [new branch] origin/riotmac -&gt; origin/riotmac * [new branch] origin/v0.9.1 -&gt; origin/v0.9.1 * [new branch] origin/v0.9.2 -&gt; origin/v0.9.2 * [new branch] origin/v0.9.4 -&gt; origin/v0.9.4 * [new branch] origin/v0.9.5 -&gt; origin/v0.9.5 * [new branch] origin/v0.9.6 -&gt; origin/v0.9.6 * [new branch] origin/v1.0 -&gt; origin/v1.0 * [new branch] origin/v1.1 -&gt; origin/v1.1 * [new branch] origin/v1.2 -&gt; origin/v1.2 * [new branch] upstream/master -&gt; upstream/master * [new branch] upstream/revert-648-vlanigmpcontrol -&gt; upstream/revert-648-vlanigmpcontrol * [new branch] upstream/v0.9.1 -&gt; upstream/v0.9.1 * [new branch] upstream/v0.9.2 -&gt; upstream/v0.9.2 * [new branch] upstream/v0.9.4 -&gt; upstream/v0.9.4 * [new branch] upstream/v0.9.5 -&gt; upstream/v0.9.5 * [new branch] upstream/v0.9.6 -&gt; upstream/v0.9.6 * [new branch] upstream/v1.0 -&gt; upstream/v1.0 * [new branch] upstream/v1.1 -&gt; upstream/v1.1 * [new branch] upstream/v1.2 -&gt; upstream/v1.2 * [new tag] v1.2.1 -&gt; v1.2.1 * [new tag] v1.2.2 -&gt; v1.2.2 * [new tag] v1.2.3 -&gt; v1.2.3 * [new tag] v1.2.4 -&gt; v1.2.4 * [new tag] v1.3.0 -&gt; v1.3.0 合并多次本地提交 不喜欢默认编译器 nano，先配置一下默认编辑器为 vim：git config --global core.editor vim git rebase -i HEAD~2，合并前两次提交 123456789101112131415161718192021222324252627282930313233343536$ git logcommit 3d4729bc94a3a780afb2892c967ea23383933419Author: your_name &lt;your_name@your_company.com&gt;Date: Mon Apr 2 20:30:16 2018 +0800 [COMPILE] fix xxx issuescommit 19c2ee6f54ab1a860a54c38708024e69572a9358Author: your_name &lt;your_name@your_company.com&gt;Date: Mon Apr 2 19:49:11 2018 +0800 [Version Control] remove modules are not needed$ git rebase -i HEAD~2 GNU nano 2.5.3 File: /home/user/workshop/.git/rebase-merge/git-rebase-todo pick 19c2ee6 [Version Control] remove modules are not neededpick 3d4729b [COMPILE] fix xxx issues# Rebase 8572f84..3d4729b onto 8572f84 (2 command(s))## Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like "squash", but discard this commit's log message# x, exec = run command (the rest of the line) using shell# d, drop = remove commit## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.## Note that empty commits are commented out 改要保留的提交 log 为 pick，把要合并的提交改为 squash。如上文改为 12pick 19c2ee6 [Version Control] remove modules are not neededsquash 3d4729b [COMPILE] fix xxx issues 保存退出后看 git log： 12345678$ git logcommit 47c2b52a018680d314673fa11afd14d46a8841cfAuthor: your_name &lt;your_name@your_company.com&gt;Date: Mon Apr 2 19:49:11 2018 +0800 [Version Control] remove modules are not needed [COMPILE] fix xxx issues 处理 merge 冲突 git pull 发现有冲突 1234$ git pullAuto-merging .gitmodulesCONFLICT (content): Merge conflict in .gitmodulesAutomatic merge failed; fix conflicts and then commit the result. 打开冲突的文件 .gitmodules 12345678$ vi .gitmodules [submodule "src/repo"] path = src/repo&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD url = http://192.168.250.250/repog/repo======= url = http://192.168.250.250/repog/repo.git&gt;&gt;&gt;&gt;&gt;&gt;&gt; 19c2ee6f54ab1a860a54c38708024e69572a9358 fix 对应的冲突例如上文修订为： 123[submodule "src/repo"] path = src/repo url = http://192.168.250.250/repog/repo 提交 fix 的结果 123$ git add .gitmodules $ git commit -m "fix merge conflict"[your_branch ee31e1a] fix merge conflict 提交代码 12345678$ git push origin your_branchCounting objects: 34, done.Delta compression using up to 24 threads.Compressing objects: 100% (33/33), done.Writing objects: 100% (34/34), 3.49 KiB | 0 bytes/s, done.Total 34 (delta 25), reused 0 (delta 0)To http://192.168.250.250/repog/repox 19c2ee6..ee31e1a your_branch -&gt; your_branch 如何不留 log 的 revert？（强制提交本地 repo 内容）强制 revert 远程服务器的内容为本地 repo 内容。一般为 rebase 之后所需。 命令：git push --force-with-lease 但是如果不是洁癖，最好还是用 git revert，有记录地回退。 查看某个 commit id 属于哪个 tags 或 branch git branch -r --contains commitid git tag --contains commitid tag 相关操作 git tag -l 列出全部 tag git checkout &lt;tag_name&gt;，detach 到某个 tag git checkout tags/&lt;tag_name&gt; -b &lt;branch_name&gt;，根据某个 tag 创建分支 查看某个 commmitid 是否属于某个 tag git tag --contains commitid 如何 merge 其他 repo 中的某次提交？ 添加其他 repo，git remote add upstream your_repo_url 下载其他 repo 的代码：git fetch upstream 查看其他 repo 的 log：git log upstream/master 合并某次提交：git cherry-pick your_repo_commit_id git am 失败如何合代码类似这个链接：https://blog.csdn.net/sunnylgz/article/details/7660638。 出现问题时： git apply –reject xxx.patch 到对应目录，应可以看到有对应的 .rej 文件，打开一看就可以看出是哪段代码合不进去。 手动处理冲突 git add 对应文件 git am –continue 查看本地分支与远程分支的差异git status 的时候经常可以看到 Your branch is ahead of &#39;origin/xxx&#39; by 3 commits.，有时候可能不知道这个 ahead / behind 的 commits 分别是什么。可通过 git log origin/xxx..xxx 查看，xxx 指分支名，以 master 分支为例，git log origin/master..master。 git log 导入 excel stackoverflow，git log --pretty=format:%h,%an,%ae,%s &gt; /path/to/file.csv，然后导入 csv，以 “,” 为分隔符隔开。前面 git log 输出格式为（hash [abbreviated], author name, author email, subject）。 类似 svn log –stop-on-copy 功能，只取分支创建后的记录 本地 git checkout 目标分支和目标分支的父分支。 git log base_branch..target_branch --pretty=format:%h,%an,%ae,%s &gt; your.csv git add 提示 “error: insufficient permission for adding an object to repository database .git/objects” 原因：.git/objects 中的权限有问题 解决：见 https://stackoverflow.com/questions/6448242/git-push-error-insufficient-permission-for-adding-an-object-to-repository-datab, sudo chown yourname:yourgroup -R .git/objects/ 123456789101112131415161718192021222324252627282930313233$ git add openssh_7.9p1.orig.tar.gz.ascerror: insufficient permission for adding an object to repository database .git/objectserror: openssh_7.9p1.orig.tar.gz.asc: failed to insert into databaseerror: unable to index file openssh_7.9p1.orig.tar.gz.ascfatal: adding files failed$ ls -al .git/objects/total 236drwxrwxr-x 59 ubuntu ubuntu 4096 Mar 6 19:49 .drwxrwxr-x 8 ubuntu ubuntu 4096 Mar 6 20:14 ..drwxrwxr-x 2 ubuntu ubuntu 4096 Mar 6 19:49 01drwxrwxr-x 2 ubuntu ubuntu 4096 Dec 25 21:46 03drwxrwxr-x 2 ubuntu ubuntu 4096 Dec 25 21:46 06drwxrwxr-x 2 ubuntu ubuntu 4096 Dec 28 16:12 0cdrwxrwxr-x 2 ubuntu ubuntu 4096 Jan 17 09:29 1cdrwxrwxr-x 2 ubuntu ubuntu 4096 Dec 4 09:44 20drwxrwxr-x 2 ubuntu ubuntu 4096 Feb 19 09:39 29drwxr-xr-x 2 root root 4096 Jan 18 13:10 31...$ sudo chown ubuntu:ubuntu -R .git/objects/[sudo] password for ubuntu: $ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)Untracked files: (use "git add &lt;file&gt;..." to include in what will be committed) openssh_7.9p1.orig.tar.gz.ascnothing added to commit but untracked files present (use "git add" to track)$ git add openssh_7.9p1.orig.tar.gz.asc $]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>版本控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图解 rpc rpc_poll 和 rpc_streaming 的差异]]></title>
    <url>%2F201901%2Fnetworks%2Frpc.rpc_poll.rpc_streaming.html</url>
    <content type="text"><![CDATA[gif 截自 youtube 视频。]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>networks</tag>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kconfig-frontends 简介]]></title>
    <url>%2F201811%2Fprogrammer%2Ftools%2Fkconfig-frontends.html</url>
    <content type="text"><![CDATA[Kconfig + Kbuild 为内核编译的配置和编译框架。其中 Kconfig 作为一个典型的配置框架，被很多开发人员单独使用，典型的项目有 BuildRoot、uboot。 也有一些人将 Kconfig 的源码从内核中剥出，作为一个独立的组件。比如: Kconfiglib, A flexible Python 2/3 Kconfig implementation and library guillon/kconfig, 通过 kconfig/config.sh 脚本，实现 kconfig 编译和目标运行 kconfig-frontends，与内核一起发布，有点官方 standalone kconfig 的意思。需要编译、安装，之后通过 kconfig-conf 等命令运行。 这里介绍 Kconfig-frontend 从零到使用的过程。 下载编译 wget http://ymorin.is-a-geek.org/download/kconfig-frontends/kconfig-frontends-3.19.0.0.tar.xz tar xvf kconfig-frontends-3.19.0.0.tar.xz sudo apt-get install gperf ./configure –enable-conf –enable-mconf –disable-shared –enable-static make make install 使用记录类 make alldefconfig kconfig-conf --alldefconfig Kconfig，其中文件 Kconfig 为配置入口。 1234567891011121314151617jeromesun@kmcb0220:~/workshop/hello$ kconfig-conf --alldefconfig Kconfig ## configuration written to .config#jeromesun@kmcb0220:~/workshop/hello$ lsconfigs hello.c hello.d hello.o Kconfig lib Makefilejeromesun@kmcb0220:~/workshop/hello$ vi .config 1 # 2 # Automatically generated file; DO NOT EDIT. 3 # MYAPP Configuration 4 # 5 CONFIG_CROSS_COMPILE="" 6 CONFIG_ENABLE_LOGGING=y 7 CONFIG_DEFAULT_LOGLEVEL=3 8 CONFIG_LOGGING_TIME=y 9 # CONFIG_DEBUG_LIST is not set 10 # CONFIG_FOO is not set 类 make menuconfig kconfig-mconf Kconfig 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253jeromesun@kmcb0220:~/workshop/hello$ kconfig-mconf Kconfig .config - MYAPP Configuration ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ┌───────────────────────────────────────────── MYAPP Configuration ─────────────────────────────────────────────┐ │ Arrow keys navigate the menu. &lt;Enter&gt; selects submenus ---&gt; (or empty submenus ----). Highlighted letters │ │ are hotkeys. Pressing &lt;Y&gt; includes, &lt;N&gt; excludes, &lt;M&gt; modularizes features. Press &lt;Esc&gt;&lt;Esc&gt; to exit, &lt;?&gt; │ │ for Help, &lt;/&gt; for Search. Legend: [*] built-in [ ] excluded &lt;M&gt; module &lt; &gt; module capable │ │ │ │ ┌───────────────────────────────────────────────────────────────────────────────────────────────────────────┐ │ │ │ () Cross-compiler tool prefix │ │ │ │ [*] Enable log functions │ │ │ │ (3) Default message log level (1-4) │ │ │ │ [*] Show timing information on log functions │ │ │ │ [ ] Debug linked list manipulation │ │ │ │ [ ] Foo │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └───────────────────────────────────────────────────────────────────────────────────────────────────────────┘ │ ├───────────────────────────────────────────────────────────────────────────────────────────────────────────────┤ │ &lt;Select&gt; &lt; Exit &gt; &lt; Help &gt; &lt; Save &gt; &lt; Load &gt; │ └───────────────────────────────────────────────────────────────────────────────────────────────────────────────┘ configuration written to .config*** End of the configuration.*** Execute 'make' to start the build or try 'make help'.jeromesun@kmcb0220:~/workshop/hello$ cat .config## Automatically generated file; DO NOT EDIT.# MYAPP Configuration#CONFIG_CROSS_COMPILE=""CONFIG_ENABLE_LOGGING=yCONFIG_DEFAULT_LOGLEVEL=3CONFIG_LOGGING_TIME=y# CONFIG_DEBUG_LIST is not setCONFIG_FOO=yCONFIG_BAR=y 编译 log下载、解压123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128jeromesun@km:~/workshop$ wget http://ymorin.is-a-geek.org/download/kconfig-frontends/kconfig-frontends-3.19.0.0.tar.xz--2018-10-26 23:21:48-- http://ymorin.is-a-geek.org/download/kconfig-frontends/kconfig-frontends-3.19.0.0.tar.xzResolving ymorin.is-a-geek.org (ymorin.is-a-geek.org)... 90.76.108.19Connecting to ymorin.is-a-geek.org (ymorin.is-a-geek.org)|90.76.108.19|:80... connected.HTTP request sent, awaiting response... 200 OKLength: 370660 (362K) [application/octet-stream]Saving to: ‘kconfig-frontends-3.19.0.0.tar.xz’kconfig-frontends-3.19.0.0.tar.xz 100%[===============================================================&gt;] 361.97K 14.2KB/s in 17s 2018-10-26 23:22:06 (21.5 KB/s) - ‘kconfig-frontends-3.19.0.0.tar.xz’ saved [370660/370660]jeromesun@km:~/workshop$ jeromesun@km:~/workshop$ tar xvf kconfig-frontends-3.19.0.0.tar.xz kconfig-frontends-3.19.0.0/kconfig-frontends-3.19.0.0/frontends/kconfig-frontends-3.19.0.0/frontends/qconf/kconfig-frontends-3.19.0.0/frontends/qconf/Makefile.inkconfig-frontends-3.19.0.0/frontends/qconf/qconf.hkconfig-frontends-3.19.0.0/frontends/qconf/qconf.cc.patchkconfig-frontends-3.19.0.0/frontends/qconf/qconf.cckconfig-frontends-3.19.0.0/frontends/qconf/Makefile.amkconfig-frontends-3.19.0.0/frontends/conf/kconfig-frontends-3.19.0.0/frontends/conf/Makefile.inkconfig-frontends-3.19.0.0/frontends/conf/Makefile.amkconfig-frontends-3.19.0.0/frontends/conf/conf.ckconfig-frontends-3.19.0.0/frontends/Makefile.inkconfig-frontends-3.19.0.0/frontends/gconf/kconfig-frontends-3.19.0.0/frontends/gconf/Makefile.inkconfig-frontends-3.19.0.0/frontends/gconf/gconf.gladekconfig-frontends-3.19.0.0/frontends/gconf/gconf.ckconfig-frontends-3.19.0.0/frontends/gconf/gconf.c.patchkconfig-frontends-3.19.0.0/frontends/gconf/Makefile.amkconfig-frontends-3.19.0.0/frontends/mconf/kconfig-frontends-3.19.0.0/frontends/mconf/Makefile.inkconfig-frontends-3.19.0.0/frontends/mconf/mconf.ckconfig-frontends-3.19.0.0/frontends/mconf/Makefile.amkconfig-frontends-3.19.0.0/frontends/Makefile.amkconfig-frontends-3.19.0.0/frontends/nconf/kconfig-frontends-3.19.0.0/frontends/nconf/nconf.hkconfig-frontends-3.19.0.0/frontends/nconf/Makefile.inkconfig-frontends-3.19.0.0/frontends/nconf/nconf.ckconfig-frontends-3.19.0.0/frontends/nconf/Makefile.amkconfig-frontends-3.19.0.0/frontends/nconf/nconf.gui.ckconfig-frontends-3.19.0.0/INSTALLkconfig-frontends-3.19.0.0/utils/kconfig-frontends-3.19.0.0/utils/tweak.inkconfig-frontends-3.19.0.0/utils/Makefile.inkconfig-frontends-3.19.0.0/utils/mergekconfig-frontends-3.19.0.0/utils/gettext.ckconfig-frontends-3.19.0.0/utils/diffkconfig-frontends-3.19.0.0/utils/Makefile.amkconfig-frontends-3.19.0.0/utils/tweak.in.patchkconfig-frontends-3.19.0.0/READMEkconfig-frontends-3.19.0.0/Makefile.inkconfig-frontends-3.19.0.0/aclocal.m4kconfig-frontends-3.19.0.0/COPYINGkconfig-frontends-3.19.0.0/AUTHORSkconfig-frontends-3.19.0.0/libs/kconfig-frontends-3.19.0.0/libs/images/kconfig-frontends-3.19.0.0/libs/images/Makefile.inkconfig-frontends-3.19.0.0/libs/images/Makefile.amkconfig-frontends-3.19.0.0/libs/images/images.c_origkconfig-frontends-3.19.0.0/libs/Makefile.inkconfig-frontends-3.19.0.0/libs/lxdialog/kconfig-frontends-3.19.0.0/libs/lxdialog/util.ckconfig-frontends-3.19.0.0/libs/lxdialog/checklist.ckconfig-frontends-3.19.0.0/libs/lxdialog/yesno.ckconfig-frontends-3.19.0.0/libs/lxdialog/Makefile.inkconfig-frontends-3.19.0.0/libs/lxdialog/menubox.ckconfig-frontends-3.19.0.0/libs/lxdialog/dialog.hkconfig-frontends-3.19.0.0/libs/lxdialog/Makefile.amkconfig-frontends-3.19.0.0/libs/lxdialog/textbox.ckconfig-frontends-3.19.0.0/libs/lxdialog/inputbox.ckconfig-frontends-3.19.0.0/libs/Makefile.amkconfig-frontends-3.19.0.0/libs/parser/kconfig-frontends-3.19.0.0/libs/parser/util.ckconfig-frontends-3.19.0.0/libs/parser/yconf.ckconfig-frontends-3.19.0.0/libs/parser/yconf.y.patchkconfig-frontends-3.19.0.0/libs/parser/lkc_proto.hkconfig-frontends-3.19.0.0/libs/parser/confdata.ckconfig-frontends-3.19.0.0/libs/parser/symbol.ckconfig-frontends-3.19.0.0/libs/parser/Makefile.inkconfig-frontends-3.19.0.0/libs/parser/lkc.hkconfig-frontends-3.19.0.0/libs/parser/yconf.ykconfig-frontends-3.19.0.0/libs/parser/list.hkconfig-frontends-3.19.0.0/libs/parser/expr.ckconfig-frontends-3.19.0.0/libs/parser/menu.ckconfig-frontends-3.19.0.0/libs/parser/expr.hkconfig-frontends-3.19.0.0/libs/parser/hconf.gperfkconfig-frontends-3.19.0.0/libs/parser/lconf.lkconfig-frontends-3.19.0.0/libs/parser/Makefile.amkconfig-frontends-3.19.0.0/libs/parser/lconf.ckconfig-frontends-3.19.0.0/scripts/kconfig-frontends-3.19.0.0/scripts/version.shkconfig-frontends-3.19.0.0/scripts/Makefile.inkconfig-frontends-3.19.0.0/scripts/ksync.listkconfig-frontends-3.19.0.0/scripts/ksync.shkconfig-frontends-3.19.0.0/scripts/Makefile.amkconfig-frontends-3.19.0.0/scripts/.autostuff/kconfig-frontends-3.19.0.0/scripts/.autostuff/scripts/kconfig-frontends-3.19.0.0/scripts/.autostuff/scripts/missingkconfig-frontends-3.19.0.0/scripts/.autostuff/scripts/depcompkconfig-frontends-3.19.0.0/scripts/.autostuff/scripts/config.subkconfig-frontends-3.19.0.0/scripts/.autostuff/scripts/ar-libkconfig-frontends-3.19.0.0/scripts/.autostuff/scripts/ltmain.shkconfig-frontends-3.19.0.0/scripts/.autostuff/scripts/compilekconfig-frontends-3.19.0.0/scripts/.autostuff/scripts/config.guesskconfig-frontends-3.19.0.0/scripts/.autostuff/scripts/ylwrapkconfig-frontends-3.19.0.0/scripts/.autostuff/scripts/install-shkconfig-frontends-3.19.0.0/scripts/.autostuff/m4/kconfig-frontends-3.19.0.0/scripts/.autostuff/m4/lt~obsolete.m4kconfig-frontends-3.19.0.0/scripts/.autostuff/m4/ltoptions.m4kconfig-frontends-3.19.0.0/scripts/.autostuff/m4/libtool.m4kconfig-frontends-3.19.0.0/scripts/.autostuff/m4/ltversion.m4kconfig-frontends-3.19.0.0/scripts/.autostuff/m4/ltsugar.m4kconfig-frontends-3.19.0.0/scripts/.autostuff/config.h.inkconfig-frontends-3.19.0.0/bootstrapkconfig-frontends-3.19.0.0/.versionkconfig-frontends-3.19.0.0/Makefile.amkconfig-frontends-3.19.0.0/configurekconfig-frontends-3.19.0.0/configure.ackconfig-frontends-3.19.0.0/docs/kconfig-frontends-3.19.0.0/docs/kconfig-language.txtkconfig-frontends-3.19.0.0/docs/kconfig.txtkconfig-frontends-3.19.0.0/docs/Makefile.inkconfig-frontends-3.19.0.0/docs/Makefile.amjeromesun@km:~/workshop$ cd kconfig-frontends-3.19.0.0/ 配置如果没安装 gperf 会提示 configure: error: can not find gperf。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311jeromesun@km:~/workshop/kconfig-frontends-3.19.0.0$ ./configure --help`configure' configures kconfig-frontends 3.19.0.0 to adapt to many kinds of systems.Usage: ./configure [OPTION]... [VAR=VALUE]...To assign environment variables (e.g., CC, CFLAGS...), specify them asVAR=VALUE. See below for descriptions of some of the useful variables.Defaults for the options are specified in brackets.Configuration: -h, --help display this help and exit --help=short display options specific to this package --help=recursive display the short help of all the included packages -V, --version display version information and exit -q, --quiet, --silent do not print `checking ...' messages --cache-file=FILE cache test results in FILE [disabled] -C, --config-cache alias for `--cache-file=config.cache' -n, --no-create do not create output files --srcdir=DIR find the sources in DIR [configure dir or `..']Installation directories: --prefix=PREFIX install architecture-independent files in PREFIX [/usr/local] --exec-prefix=EPREFIX install architecture-dependent files in EPREFIX [PREFIX]By default, `make install' will install all the files in`/usr/local/bin', `/usr/local/lib' etc. You can specifyan installation prefix other than `/usr/local' using `--prefix',for instance `--prefix=$HOME'.For better control, use the options below.Fine tuning of the installation directories: --bindir=DIR user executables [EPREFIX/bin] --sbindir=DIR system admin executables [EPREFIX/sbin] --libexecdir=DIR program executables [EPREFIX/libexec] --sysconfdir=DIR read-only single-machine data [PREFIX/etc] --sharedstatedir=DIR modifiable architecture-independent data [PREFIX/com] --localstatedir=DIR modifiable single-machine data [PREFIX/var] --runstatedir=DIR modifiable per-process data [LOCALSTATEDIR/run] --libdir=DIR object code libraries [EPREFIX/lib] --includedir=DIR C header files [PREFIX/include] --oldincludedir=DIR C header files for non-gcc [/usr/include] --datarootdir=DIR read-only arch.-independent data root [PREFIX/share] --datadir=DIR read-only architecture-independent data [DATAROOTDIR] --infodir=DIR info documentation [DATAROOTDIR/info] --localedir=DIR locale-dependent data [DATAROOTDIR/locale] --mandir=DIR man documentation [DATAROOTDIR/man] --docdir=DIR documentation root [DATAROOTDIR/doc/kconfig-frontends] --htmldir=DIR html documentation [DOCDIR] --dvidir=DIR dvi documentation [DOCDIR] --pdfdir=DIR pdf documentation [DOCDIR] --psdir=DIR ps documentation [DOCDIR]Program names: --program-prefix=PREFIX prepend PREFIX to installed program names --program-suffix=SUFFIX append SUFFIX to installed program names --program-transform-name=PROGRAM run sed PROGRAM on installed program namesSystem types: --build=BUILD configure for building on BUILD [guessed] --host=HOST cross-compile to build programs to run on HOST [BUILD]Optional Features: --disable-option-checking ignore unrecognized --enable/--with options --disable-FEATURE do not include FEATURE (same as --enable-FEATURE=no) --enable-FEATURE[=ARG] include FEATURE [ARG=yes] --enable-silent-rules less verbose build output (undo: "make V=1") --disable-silent-rules verbose build output (undo: "make V=0") --enable-dependency-tracking do not reject slow dependency extractors --disable-dependency-tracking speeds up one-time build --enable-static[=PKGS] build static libraries [default=no] --enable-shared[=PKGS] build shared libraries [default=yes] --enable-fast-install[=PKGS] optimize for fast installation [default=yes] --disable-libtool-lock avoid locking (might break parallel builds) --disable-wall build with -Wall (default=yes) --enable-werror build with -Werror (default=no) --enable-root-menu-prompt=PROMPT set the root-menu prompt (default=Configuration) --enable-config-prefix=PREFIX the prefix to the config option (default=CONFIG_) --disable-utils install utilities to manage .config files (default=yes) --disable-L10n enable localisation (L10n) (default=auto) --disable-conf conf, the stdin-based frontend (default=auto) --disable-mconf mconf, the traditional ncurses-based frontend (default=auto) --disable-nconf nconf, the modern ncurses-based frontend (default=auto) --disable-gconf gconf, the GTK-based frontend (default=auto) --disable-qconf qconf, the QT-based frontend (default=auto) --enable-frontends=list enables only the set of frontends in comma-separated 'list' (default: auto selection), takes precedence over all --enable-*conf, aboveOptional Packages: --with-PACKAGE[=ARG] use PACKAGE [ARG=yes] --without-PACKAGE do not use PACKAGE (same as --with-PACKAGE=no) --with-pic[=PKGS] try to use only PIC/non-PIC objects [default=use both] --with-aix-soname=aix|svr4|both shared library versioning (aka "SONAME") variant to provide on AIX, [default=aix]. --with-gnu-ld assume the C compiler uses GNU ld [default=no] --with-sysroot[=DIR] Search for dependent libraries within DIR (or the compiler's sysroot if not specified).Some influential environment variables: CC C compiler command CFLAGS C compiler flags LDFLAGS linker flags, e.g. -L&lt;lib dir&gt; if you have libraries in a nonstandard directory &lt;lib dir&gt; LIBS libraries to pass to the linker, e.g. -l&lt;library&gt; CPPFLAGS (Objective) C/C++ preprocessor flags, e.g. -I&lt;include dir&gt; if you have headers in a nonstandard directory &lt;include dir&gt; LT_SYS_LIBRARY_PATH User-defined run-time library search path. CPP C preprocessor CXX C++ compiler command CXXFLAGS C++ compiler flags CXXCPP C++ preprocessor PKG_CONFIG path to pkg-config utility PKG_CONFIG_PATH directories to add to pkg-config's search path PKG_CONFIG_LIBDIR path overriding pkg-config's built-in search path YACC The `Yet Another Compiler Compiler' implementation to use. Defaults to the first program found out of: `bison -y', `byacc', `yacc'. YFLAGS The list of arguments that will be passed by default to $YACC. This script will default YFLAGS to the empty string to avoid a default value of `-d' given by some make applications. gtk_CFLAGS C compiler flags for gtk, overriding pkg-config gtk_LIBS linker flags for gtk, overriding pkg-config qt4_CFLAGS C compiler flags for qt4, overriding pkg-config qt4_LIBS linker flags for qt4, overriding pkg-config MOC Qt meta object compiler (moc) command conf_EXTRA_LIBS Extra libraries to build the conf frontend gconf_EXTRA_LIBS Extra libraries to build the gconf frontend mconf_EXTRA_LIBS Extra libraries to build the mconf frontend nconf_EXTRA_LIBS Extra libraries to build the nconf frontend qconf_EXTRA_LIBS Extra libraries to build the qconf frontendUse these variables to override the choices made by `configure' or to helpit to find libraries and programs with nonstandard names/locations.Report bugs to &lt;yann.morin.1998@free.fr&gt;.jeromesun@km:~/workshop/kconfig-frontends-3.19.0.0$ ./configure --enable-conf --enable-mconf --disable-shared --enable-staticchecking for a BSD-compatible install... /usr/bin/install -cchecking whether build environment is sane... yeschecking for a thread-safe mkdir -p... /bin/mkdir -pchecking for gawk... nochecking for mawk... mawkchecking whether make sets $(MAKE)... yeschecking whether make supports nested variables... yeschecking whether make supports nested variables... (cached) yeschecking for style of include used by make... GNUchecking for gcc... gccchecking whether the C compiler works... yeschecking for C compiler default output file name... a.outchecking for suffix of executables... checking whether we are cross compiling... nochecking for suffix of object files... ochecking whether we are using the GNU C compiler... yeschecking whether gcc accepts -g... yeschecking for gcc option to accept ISO C89... none neededchecking whether gcc understands -c and -o together... yeschecking dependency style of gcc... gcc3checking for ar... archecking the archiver (ar) interface... archecking build system type... x86_64-pc-linux-gnuchecking host system type... x86_64-pc-linux-gnuchecking how to print strings... printfchecking for a sed that does not truncate output... /bin/sedchecking for grep that handles long lines and -e... /bin/grepchecking for egrep... /bin/grep -Echecking for fgrep... /bin/grep -Fchecking for ld used by gcc... /usr/bin/ldchecking if the linker (/usr/bin/ld) is GNU ld... yeschecking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -Bchecking the name lister (/usr/bin/nm -B) interface... BSD nmchecking whether ln -s works... yeschecking the maximum length of command line arguments... 1572864checking how to convert x86_64-pc-linux-gnu file names to x86_64-pc-linux-gnu format... func_convert_file_noopchecking how to convert x86_64-pc-linux-gnu file names to toolchain format... func_convert_file_noopchecking for /usr/bin/ld option to reload object files... -rchecking for objdump... objdumpchecking how to recognize dependent libraries... pass_allchecking for dlltool... nochecking how to associate runtime and link libraries... printf %s\nchecking for archiver @FILE support... @checking for strip... stripchecking for ranlib... ranlibchecking command to parse /usr/bin/nm -B output from gcc object... okchecking for sysroot... nochecking for a working dd... /bin/ddchecking how to truncate binary pipes... /bin/dd bs=4096 count=1checking for mt... mtchecking if mt is a manifest tool... nochecking how to run the C preprocessor... gcc -Echecking for ANSI C header files... yeschecking for sys/types.h... yeschecking for sys/stat.h... yeschecking for stdlib.h... yeschecking for string.h... yeschecking for memory.h... yeschecking for strings.h... yeschecking for inttypes.h... yeschecking for stdint.h... yeschecking for unistd.h... yeschecking for dlfcn.h... yeschecking for objdir... .libschecking if gcc supports -fno-rtti -fno-exceptions... nochecking for gcc option to produce PIC... -fPIC -DPICchecking if gcc PIC flag -fPIC -DPIC works... yeschecking if gcc static flag -static works... yeschecking if gcc supports -c -o file.o... yeschecking if gcc supports -c -o file.o... (cached) yeschecking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yeschecking dynamic linker characteristics... GNU/Linux ld.sochecking how to hardcode library paths into programs... immediatechecking whether stripping libraries is possible... yeschecking if libtool supports shared libraries... yeschecking whether to build shared libraries... nochecking whether to build static libraries... yeschecking for gcc... (cached) gccchecking whether we are using the GNU C compiler... (cached) yeschecking whether gcc accepts -g... (cached) yeschecking for gcc option to accept ISO C89... (cached) none neededchecking whether gcc understands -c and -o together... (cached) yeschecking dependency style of gcc... (cached) gcc3checking for g++... g++checking whether we are using the GNU C++ compiler... yeschecking whether g++ accepts -g... yeschecking dependency style of g++... gcc3checking how to run the C++ preprocessor... g++ -Echecking for ld used by g++... /usr/bin/ld -m elf_x86_64checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yeschecking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yeschecking for g++ option to produce PIC... -fPIC -DPICchecking if g++ PIC flag -fPIC -DPIC works... yeschecking if g++ static flag -static works... yeschecking if g++ supports -c -o file.o... yeschecking if g++ supports -c -o file.o... (cached) yeschecking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yeschecking dynamic linker characteristics... (cached) GNU/Linux ld.sochecking how to hardcode library paths into programs... immediatechecking for inline... inlinechecking whether make sets $(MAKE)... (cached) yeschecking for gperf... gperfchecking for pkg-config... /usr/bin/pkg-configchecking pkg-config is at least version 0.9.0... yeschecking for flex... flexchecking lex output file root... lex.yychecking lex library... -lflchecking whether yytext is a pointer... yeschecking for bison... bison -ychecking libintl.h usability... yeschecking libintl.h presence... yeschecking for libintl.h... yeschecking whether gettext is declared... yeschecking for library containing gettext... none requiredchecking ncursesw/curses.h usability... yeschecking ncursesw/curses.h presence... yeschecking for ncursesw/curses.h... yeschecking for library containing setupterm... -ltinfochecking for library containing initscr... -lncurseswchecking for library containing new_panel... -lpanelwchecking for library containing menu_init... -lmenuwchecking for gtk... nochecking for qt4... nochecking that generated files are newer than configure... doneconfigure: creating ./config.statusconfig.status: creating Makefileconfig.status: creating docs/Makefileconfig.status: creating libs/Makefileconfig.status: creating libs/images/Makefileconfig.status: creating libs/lxdialog/Makefileconfig.status: creating libs/parser/Makefileconfig.status: creating frontends/Makefileconfig.status: creating frontends/conf/Makefileconfig.status: creating frontends/mconf/Makefileconfig.status: creating frontends/nconf/Makefileconfig.status: creating frontends/gconf/Makefileconfig.status: creating frontends/qconf/Makefileconfig.status: creating utils/Makefileconfig.status: creating scripts/Makefileconfig.status: creating scripts/.autostuff/config.hconfig.status: executing depfiles commandsconfig.status: executing libtool commandsconfigure: configure: Configured with:configure: - parser library : staticconfigure: - root-menu prompt : Configurationconfigure: - config prefix : CONFIG_configure: - frontends : conf mconf nconfconfigure: - transform name : s&amp;^&amp;kconfig-&amp;configure: - localised : yesconfigure: - install utilities : yesconfigure: - CFLAGS CXXFLAGS : -Wall 编译、安装12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091jeromesun@km:~/workshop/kconfig-frontends-3.19.0.0$ makeMaking all in docsMaking all in libsMaking all in parser GPERF hconf.c CC libkconfig_parser_la-yconf.lo CCLD libkconfig-parser.laar: `u' modifier ignored since `D' is the default (see `U')Making all in lxdialog CC libkconfig_lxdialog_a-checklist.o CC libkconfig_lxdialog_a-inputbox.o CC libkconfig_lxdialog_a-menubox.o CC libkconfig_lxdialog_a-textbox.o CC libkconfig_lxdialog_a-util.o CC libkconfig_lxdialog_a-yesno.o AR libkconfig-lxdialog.aar: `u' modifier ignored since `D' is the default (see `U')Making all in frontendsMaking all in conf CC conf-conf.o CCLD confMaking all in mconf CC mconf-mconf.o CCLD mconfMaking all in nconf CC nconf-nconf.o CC nconf-nconf.gui.o CCLD nconfMaking all in scriptsMaking all in utils CC gettext-gettext.o CCLD gettext GEN tweakjeromesun@km:~/workshop/kconfig-frontends-3.19.0.0$ sudo make installMaking install in docs /bin/mkdir -p '/usr/local/share/doc/kconfig-frontends' /usr/bin/install -c -m 644 kconfig-language.txt kconfig.txt '/usr/local/share/doc/kconfig-frontends'Making install in libsMaking install in parser /bin/mkdir -p '/usr/local/lib' /bin/bash ../../libtool --mode=install /usr/bin/install -c libkconfig-parser.la '/usr/local/lib'libtool: install: /usr/bin/install -c .libs/libkconfig-parser.lai /usr/local/lib/libkconfig-parser.lalibtool: install: /usr/bin/install -c .libs/libkconfig-parser.a /usr/local/lib/libkconfig-parser.alibtool: install: chmod 644 /usr/local/lib/libkconfig-parser.alibtool: install: ranlib /usr/local/lib/libkconfig-parser.alibtool: finish: PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin" ldconfig -n /usr/local/lib----------------------------------------------------------------------Libraries have been installed in: /usr/local/libIf you ever happen to want to link against installed librariesin a given directory, LIBDIR, you must either use libtool, andspecify the full pathname of the library, or use the '-LLIBDIR'flag during linking and do at least one of the following: - add LIBDIR to the 'LD_LIBRARY_PATH' environment variable during execution - add LIBDIR to the 'LD_RUN_PATH' environment variable during linking - use the '-Wl,-rpath -Wl,LIBDIR' linker flag - have your system administrator add LIBDIR to '/etc/ld.so.conf'See any operating system documentation about shared libraries formore information, such as the ld(1) and ld.so(8) manual pages.---------------------------------------------------------------------- /bin/mkdir -p '/usr/local/include/kconfig' /usr/bin/install -c -m 644 list.h lkc.h expr.h lkc_proto.h '/usr/local/include/kconfig'Making install in lxdialogMaking install in frontendsMaking install in conf /bin/mkdir -p '/usr/local/bin' /bin/bash ../../libtool --mode=install /usr/bin/install -c conf '/usr/local/bin/./kconfig-conf'libtool: install: /usr/bin/install -c conf /usr/local/bin/./kconfig-confMaking install in mconf /bin/mkdir -p '/usr/local/bin' /bin/bash ../../libtool --mode=install /usr/bin/install -c mconf '/usr/local/bin/./kconfig-mconf'libtool: install: /usr/bin/install -c mconf /usr/local/bin/./kconfig-mconfMaking install in nconf /bin/mkdir -p '/usr/local/bin' /bin/bash ../../libtool --mode=install /usr/bin/install -c nconf '/usr/local/bin/./kconfig-nconf'libtool: install: /usr/bin/install -c nconf /usr/local/bin/./kconfig-nconfMaking install in scriptsMaking install in utils /bin/mkdir -p '/usr/local/bin' /bin/bash ../libtool --mode=install /usr/bin/install -c gettext '/usr/local/bin/./kconfig-gettext'libtool: install: /usr/bin/install -c gettext /usr/local/bin/./kconfig-gettext /bin/mkdir -p '/usr/local/bin' /usr/bin/install -c tweak '/usr/local/bin/./kconfig-tweak' /bin/mkdir -p '/usr/local/bin' /usr/bin/install -c diff '/usr/local/bin/./kconfig-diff' /usr/bin/install -c merge '/usr/local/bin/./kconfig-merge'jeromesun@km:~/workshop/kconfig-frontends-3.19.0.0$]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>kconfig</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SecureCRT 使用记录]]></title>
    <url>%2F201811%2Fprogrammer%2Ftools%2Fscrt_note.html</url>
    <content type="text"><![CDATA[快捷键 切换 tab，alt + 1/2/3/4...，其中 1 / 2 / 3 / 4 /… 为对应 tab 的位置。]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>SecureCRT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux telnet 服务器调研]]></title>
    <url>%2F201810%2Fnetworks%2Ftelnet.html</url>
    <content type="text"><![CDATA[linux telnetd 分析Linux 发行版本视 telnet 为不安全工具，对 telnet 的支持比较差。目前发行版主要使用 inetd (internet “super-server”) + telnetd 的形式，并没有独立的 telnet 服务器。一般只有在嵌入式系统中才有 telnet standalone 服务器。 telnetd, 源码隶属 netkit-telnet xinetd + telnetd openbsd-inetd + tcpd + telnetd standalone telnetd: utelnetd, https://wiki.gentoo.org/wiki/Utelnetd, 代码https://public.pengutronix.de/software/utelnetd/, 用于 optware/gentoo 等。 busybox telnetd 优缺点分析： inetd + telnetd 目前各大发行版本支持 正常情况下，可直接安装使用。目前在 ubuntu 上验证，即装即可用，但是在 debian jessie 上，不可用。下文详细介绍 fix 过程，fix 后 openbsd-inetd (debian 默认 inetd) + telnetd 可用。 不方便维护，除 telnetd，还需要引进 inetd，多一个故障点 多一个 inetd，多一个代码维护点 standalone telnetd 代码少，以 utelnetd 来讲，空行算进去，总的也才 600 多行。 相比 inetd + telnetd 方式，部署简单，方便维护。 busybox 的 telnetd 在整个 busybox 框架下，如果单独剥离出来，需要一定工作量。相比之下，utelnetd 很方便。 关于 inetd网上推荐使用 xinetd，redhat 系用 xinetd 比较多。debian 系支持的比较少，像 update-inetd 就明确安装时就说明不完全支持 xinetd。 inetd listens for connections on certain internet sockets. When a connection is found on one of its sockets, it decides what service the socket corresponds to, and invokes a program to service the request. After the program is finished, it continues to listen on the socket (except in some cases which will be described below). Essentially, inetd allows running one daemon to invoke several others, reducing load on the system. utelnetd 验证验证可用。 验证 log: 123456789101112131415161718192021222324252627a@xxx:~$ sudo lsof -i:23 -na@xxx:~$ sudo utelnetd -dtelnetd: starting port: 23; interface: any; login program: /bin/logina@xxx:~$ a@xxx:~$ sudo lsof -i:23 -nCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEutelnetd 27898 root 3u IPv4 120819 0t0 TCP *:telnet (LISTEN)a@xxx:~$ a@xxx:~$ telnet localhost Trying 127.0.0.1...Connected to localhost.Escape character is '^]'.Debian GNU/Linux 8xxx login: aPassword: Last login: Fri Oct 26 22:46:25 CST 2018 on pts/11Linux xxx 3.16.0-5-amd64 #1 SMP Debian 3.16.51-3+deb8u1 (2018-01-08) x86_64Unauthorized access and/or use are prohibited.All access and/or use are subject to monitoring.a@xxx:~$ lslibperl4-corelibs-perl_0.003-1_all.deb tcpd utelnetdlsof_4.86+dfsg-1_amd64.deb telnetd_0.17-41_amd64.deba@xxx:~$ logoutConnection closed by foreign host. 编译记录123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051jeromesun@km:~/workshop$ tar xvf utelnetd-0.1.11.tar.gz utelnetd-0.1.11/utelnetd-0.1.11/utelnetd.cutelnetd-0.1.11/LICENSEutelnetd-0.1.11/Makefileutelnetd-0.1.11/ChangeLogutelnetd-0.1.11/READMEjeromesun@km:~/workshop$ cd utelnetd-0.1.11/jeromesun@km:~/workshop/utelnetd-0.1.11$ makegcc -I. -pipe -DSHELLPATH=\"/bin/login\" -Wall -fomit-frame-pointer -c -o utelnetd.o utelnetd.cutelnetd.c: In function ‘perror_msg_and_die’:utelnetd.c:160:2: warning: format not a string literal and no format arguments [-Wformat-security] fprintf(stderr,text); ^utelnetd.c: In function ‘make_new_session’:utelnetd.c:264:10: warning: variable ‘t2’ set but not used [-Wunused-but-set-variable] int t1, t2; ^utelnetd.c:264:6: warning: variable ‘t1’ set but not used [-Wunused-but-set-variable] int t1, t2; ^utelnetd.c: In function ‘main’:utelnetd.c:561:7: warning: pointer targets in passing argument 3 of ‘accept’ differ in signedness [-Wpointer-sign] &amp;salen)) &lt; 0) &#123; ^In file included from utelnetd.c:45:0:/usr/include/x86_64-linux-gnu/sys/socket.h:243:12: note: expected ‘socklen_t * restrict &#123;aka unsigned int * restrict&#125;’ but argument is of type ‘int *’ extern int accept (int __fd, __SOCKADDR_ARG __addr, ^utelnetd.c:597:23: warning: pointer targets in passing argument 1 of ‘remove_iacs’ differ in signedness [-Wpointer-sign] ptr = remove_iacs(ts-&gt;buf1 + ts-&gt;wridx1, maxlen, ^utelnetd.c:190:1: note: expected ‘unsigned char *’ but argument is of type ‘char *’ remove_iacs(unsigned char *bf, int len, int *processed, int *num_totty) &#123; ^gcc -I. -pipe -DSHELLPATH=\"/bin/login\" -Wall -fomit-frame-pointer utelnetd.o -o utelnetdstrip --remove-section=.comment --remove-section=.note utelnetdjeromesun@km:~/workshop/utelnetd-0.1.11$ lsChangeLog LICENSE Makefile README utelnetd utelnetd.c utelnetd.ojeromesun@km:~/workshop/utelnetd-0.1.11$ ls -altotal 96drwxr-xr-x 2 jeromesun jeromesun 4096 10月 26 14:10 .drwxrwxr-x 17 jeromesun jeromesun 4096 10月 26 14:10 ..-rw-r--r-- 1 jeromesun jeromesun 2545 8月 11 2008 ChangeLog-rw-r--r-- 1 jeromesun jeromesun 17982 3月 6 2000 LICENSE-rw-r--r-- 1 jeromesun jeromesun 1120 8月 11 2008 Makefile-rw-r--r-- 1 jeromesun jeromesun 532 8月 8 2003 README-rwxrwxr-x 1 jeromesun jeromesun 18912 10月 26 14:10 utelnetd-rw-r--r-- 1 jeromesun jeromesun 16430 8月 6 2003 utelnetd.c-rw-rw-r-- 1 jeromesun jeromesun 14600 10月 26 14:10 utelnetd.ojeromesun@km:~/workshop/utelnetd-0.1.11$ openbsd-inetd + telnetd 验证在 debian jessie 上验证。虽然不用，但是存档。 问题分析问题现象：telnet 客户端在几秒钟后自行退出。 123456[20181026-091148.403]a@xxx:~$ telnet localhost[20181026-091148.436]Trying 127.0.0.1...[20181026-091148.443]Connected to localhost.[20181026-091148.444]Escape character is '^]'.[20181026-091149.726][20181026-091153.446]Connection closed by foreign host. log 分析: 12Oct 26 18:17:42 xxx in.telnetd[4140]: connect from 127.0.0.1 (127.0.0.1)Oct 26 18:17:42 xxx in.telnetd[4140]: error: cannot execute : No such file or directory 下载 telnetd 源码，grep 并没有发现文件有 cannot execute 的字样。进一步下载 tcp-wrapper 和 openbsd-inetd 源码，发现该 log 在 tcp-wrappers/tcpd.c 中。应该是入参有问题， 1234567891011121314151617181920212223242526272829303132333435...main(argc, argv)int argc;char **argv;&#123; struct request_info request; char path[MAXPATHNAMELEN]; /* Attempt to prevent the creation of world-writable files. */#ifdef DAEMON_UMASK umask(DAEMON_UMASK);#endif /* * If argv[0] is an absolute path name, ignore REAL_DAEMON_DIR, and strip * argv[0] to its basename. */ if (argv[0][0] == '/') &#123; strcpy(path, argv[0]); argv[0] = strrchr(argv[0], '/') + 1; &#125; else &#123; sprintf(path, "%s/%s", REAL_DAEMON_DIR, argv[0]); &#125;... /* Report request and invoke the real daemon program. */ syslog(allow_severity, "connect from %s", eval_client(&amp;request)); closelog(); (void) execv(path, argv); syslog(LOG_ERR, "error: cannot execute %s: %m", path); &lt;---- 这时异常退出，关于 %m The ‘%m’ conversion prints the string corresponding to the error code in errno. https://stackoverflow.com/questions/20577557/whats-the-meaning-of-the-m-formatting-specifier . clean_exit(&amp;request); /* NOTREACHED */&#125; 改下代码，把所有的 argv 打出来: 1234Oct 26 18:17:42 xxx in.telnetd[4140]: argc 0Oct 26 18:17:42 xxx in.telnetd[4140]: 0: argv in.telnetdOct 26 18:17:42 xxx in.telnetd[4140]: connect from 127.0.0.1 (127.0.0.1)Oct 26 18:17:42 xxx in.telnetd[4140]: error: cannot execute : No such file or directory 发现入参是 in.telnetd，不是 /etc/inetd.conf 中写的 /usr/sbin/in.telnetd。 1telnet stream tcp nowait telnetd /usr/sbin/tcpd /usr/sbin/in.telnetd 有点奇怪: openbsd-inetd 执行 telnet 服务时，执行的是什么命令 即使 openbsd-inetd 执行时，以 in.telnetd 直接传入，REAL_DAEMON_DIR 在编译时也有定义，应该有值才对。 1cc -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -DFACILITY=LOG_DAEMON -DHOSTS_ACCESS -DNETGROUP -DDAEMON_UMASK=022 -DREAL_DAEMON_DIR=\"/usr/sbin\" -DPROCESS_OPTIONS -DACLEXEC -DKILL_IP_OPTIONS -DSEVERITY=LOG_INFO -DRFC931_TIMEOUT=10 -DHOSTS_DENY=\"/etc/hosts.deny\" -DHOSTS_ALLOW=\"/etc/hosts.allow\" -DSYS_ERRLIST_DEFINED -DHAVE_STRERROR -DHAVE_WEAKSYMS -DINET6=1 -Dss_family=__ss_family -Dss_len=__ss_len -o tcpd.o -c tcpd.c 先不管了，直接改 tcpd.c 的代码，将所有 telnet 服务的入参强制变成 /usr/sbin/in.telnet: 12345678910111213141516171819202122232425262728--- &lt;unnamed&gt;+++ &lt;unnamed&gt;@@ -77,6 +77,11 @@ (void) openlog(argv[0], LOG_PID); #endif + int i;+ syslog(LOG_ERR, "argc %d", i);+ for (i = 0; i &lt; argc; i++) &#123;+ syslog(LOG_ERR, "%d: argv %s", i, argv[i]);+ &#125; /* * Find out the endpoint addresses of this conversation. Host name * lookups and double checks will be done on demand.@@ -125,6 +130,13 @@ eval_client(&amp;request), eval_hostaddr(request.client)); #else syslog(allow_severity, "connect from %s", eval_client(&amp;request));+#endif+ if (strcmp(argv[0], "in.telnetd") == 0) &#123;+ syslog(LOG_ERR, "path before change: path %s, argv %s", path, argv[0]);+ strcpy(path, "/usr/sbin/in.telnetd");+ syslog(LOG_ERR, "path after change: path %s, argv %s", path, argv[0]);+ &#125;+ closelog(); (void) execv(path, argv); syslog(LOG_ERR, "error: cannot execute %s: %m", path); 修改后正常: 1234567891011121314151617181920212223242526[20181026-142113.815][jeromesun@64 ~]$ telnet 192.168.3.31[20181026-142113.815]Trying 192.168.3.31...[20181026-142113.816]Connected to 192.168.3.31.[20181026-142113.817]Escape character is '^]'.[20181026-142122.726][20181026-142133.853]Debian GNU/Linux 8 &lt;---- 过了 20 秒才进来，看这个时间很像进行 dns 解析 timeout 了[20181026-142133.892][20181026-142137.023]xxx login: a[20181026-142137.352]Password: [20181026-142137.368]Last login: Fri Oct 26 19:46:52 CST 2018 from 11.1.1.99 on pts/10[20181026-142137.698]Linux xxx 3.16.0-5-amd64 #1 SMP Debian 3.16.51-3+deb8u1 (2018-01-08) x86_64[20181026-142137.700]Unauthorized access and/or use are prohibited.[20181026-142137.700]All access and/or use are subject to monitoring.[20181026-142137.700][20181026-142138.494]a@xxx:~$ [20181026-142200.714]a@xxx:~$ show version[20181026-142201.869]Distribution: Debian 8.11[20181026-142201.869]Kernel: 3.16.0-5-amd64[20181026-142201.870]Build commit: 62a9f38[20181026-142201.870]Build date: Thu Oct 25 20:56:07 CST 2018...[20181026-142202.045][20181026-142202.575]a@xxx:~$ [20181026-142203.202]telnet&gt; q[20181026-142203.203]Connection closed.[20181026-142203.579][jeromesun@64 ~]$ 编译记录在源码根目录，执行 dpkg-buildpackage -rfakeroot -b -us -uc -nc --as-root -Tbinary 进行编译。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162jeromesun@km:~/tcp-wrappers-7.6.q$ rm tcpdjeromesun@km:~/tcp-wrappers-7.6.q$ rm tcpd.o jeromesun@km:~/tcp-wrappers-7.6.q$ rm debian/.stamp-build jeromesun@km:~/tcp-wrappers-7.6.q$ dpkg-buildpackage -rfakeroot -b -us -uc -nc --as-root -Tbinarydpkg-buildpackage: source package tcp-wrappersdpkg-buildpackage: source version 7.6.q-25dpkg-buildpackage: source distribution unstabledpkg-buildpackage: source changed by Marco d'Itri &lt;md@linux.it&gt;dpkg-buildpackage: host architecture amd64 fakeroot debian/rules binarydh_testdir/usr/bin/make COPTS="-g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2" LDOPTS="-Wl,-Bsymbolic-functions -Wl,-z,relro" linuxmake[1]: Entering directory '/home/jeromesun/tcp-wrappers-7.6.q'make[2]: Entering directory '/home/jeromesun/tcp-wrappers-7.6.q'cc -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -DFACILITY=LOG_DAEMON -DHOSTS_ACCESS -DNETGROUP -DDAEMON_UMASK=022 -DREAL_DAEMON_DIR=\"/usr/sbin\" -DPROCESS_OPTIONS -DACLEXEC -DKILL_IP_OPTIONS -DSEVERITY=LOG_INFO -DRFC931_TIMEOUT=10 -DHOSTS_DENY=\"/etc/hosts.deny\" -DHOSTS_ALLOW=\"/etc/hosts.allow\" -DSYS_ERRLIST_DEFINED -DHAVE_STRERROR -DHAVE_WEAKSYMS -DINET6=1 -Dss_family=__ss_family -Dss_len=__ss_len -o tcpd.o -c tcpd.ctcpd.c:44:1: warning: return type defaults to ‘int’ [-Wimplicit-int] main(argc, argv) ^tcpd.c: In function ‘main’:tcpd.c:112:5: warning: implicit declaration of function ‘fix_options’ [-Wimplicit-function-declaration] fix_options(&amp;request); ^tcpd.c:141:12: warning: implicit declaration of function ‘execv’ [-Wimplicit-function-declaration] (void) execv(path, argv); ^cc -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -DFACILITY=LOG_DAEMON -DHOSTS_ACCESS -DNETGROUP -DDAEMON_UMASK=022 -DREAL_DAEMON_DIR=\"/usr/sbin\" -DPROCESS_OPTIONS -DACLEXEC -DKILL_IP_OPTIONS -DSEVERITY=LOG_INFO -DRFC931_TIMEOUT=10 -DHOSTS_DENY=\"/etc/hosts.deny\" -DHOSTS_ALLOW=\"/etc/hosts.allow\" -DSYS_ERRLIST_DEFINED -DHAVE_STRERROR -DHAVE_WEAKSYMS -DINET6=1 -Dss_family=__ss_family -Dss_len=__ss_len -Wl,-Bsymbolic-functions -Wl,-z,relro -o tcpd tcpd.o -Lshared -lwrapmake[2]: Leaving directory '/home/jeromesun/tcp-wrappers-7.6.q'make[1]: Leaving directory '/home/jeromesun/tcp-wrappers-7.6.q'touch debian/.stamp-buildtest root = "`whoami`"dh_testdirdh_prepdh_installdirsdh_installdh_installdocs --link-doc=libwrap0dh_installdocs -p libwrap0 READMEdh_installchangelogs CHANGESdh_installman -p tcpd *.8dh_installman -p libwrap0 *.5dh_installman -p libwrap0-dev *.3dh_linkmkdir -p /home/jeromesun/tcp-wrappers-7.6.q/debian/libwrap0/lib/x86_64-linux-gnu/ /home/jeromesun/tcp-wrappers-7.6.q/debian/libwrap0-dev/usr/lib/x86_64-linux-gnu/cp shared/libwrap.so.0.7.6 /home/jeromesun/tcp-wrappers-7.6.q/debian/libwrap0/lib/x86_64-linux-gnu/ln -s libwrap.so.0.7.6 /home/jeromesun/tcp-wrappers-7.6.q/debian/libwrap0/lib/x86_64-linux-gnu/libwrap.so.0ln -s /lib/x86_64-linux-gnu/libwrap.so.0 \ /home/jeromesun/tcp-wrappers-7.6.q/debian/libwrap0-dev/usr/lib/x86_64-linux-gnu/libwrap.somv /home/jeromesun/tcp-wrappers-7.6.q/debian/libwrap0-dev/usr/lib/libwrap.a /home/jeromesun/tcp-wrappers-7.6.q/debian/libwrap0-dev/usr/lib/x86_64-linux-gnu/dh_linkdh_stripdh_compressdh_fixpermsdh_installdebconfdh_makeshlibs -- -c4dh_installdebdh_shlibdepsdh_gencontroldh_md5sumsdh_builddebdpkg-deb: building package 'tcpd' in '../tcpd_7.6.q-25_amd64.deb'.dpkg-deb: building package 'libwrap0' in '../libwrap0_7.6.q-25_amd64.deb'.dpkg-deb: building package 'libwrap0-dev' in '../libwrap0-dev_7.6.q-25_amd64.deb'.jeromesun@km:~/tcp-wrappers-7.6.q$ xinetd + telnetd在 debian jessie 上验证。未成功。]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>networks</tag>
        <tag>telnet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux shell 字符串处理]]></title>
    <url>%2F201810%2Fshell%2Fstring.html</url>
    <content type="text"><![CDATA[首字母大写：b=$(s^) 截取几个字符：${i:0:2} 判断字符串子集Shell判断字符串包含关系的几种方法: 通过 grep 判断 通过 if [ A =~ B ] 判断 A 包含 B。]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redhat 系发行版本使用笔记]]></title>
    <url>%2F201810%2Flinux%2Fredhat_note.html</url>
    <content type="text"><![CDATA[包管理 安装本地包，rpm -i xxx.rpm 网络相关配置文件，/etc/sysconfig/network-scripts 123456[root@TENCENT64 /etc/sysconfig/network-scripts]# lseth1 ifcfg-eth4 ifdown-eth ifdown-ppp ifup-aliases ifup-isdn ifup-routes network-functionsifcfg-eth0 ifcfg-eth5 ifdown-ippp ifdown-routes ifup-bnep ifup-plip ifup-sit network-functions-ipv6ifcfg-eth1 ifcfg-lo ifdown-ipv6 ifdown-sit ifup-eth ifup-plusb ifup-tunnel route-eth1ifcfg-eth2 ifdown ifdown-isdn ifdown-tunnel ifup-ippp ifup-post ifup-wireless setdefaultgw-tlinuxifcfg-eth3 ifdown-bnep ifdown-post ifup ifup-ipv6 ifup-ppp init.ipv6-global 重启网络服务，# service network restart 网卡配置， 123456789[root@TENCENT64 /etc/sysconfig/network-scripts]# cat ifcfg-eth0#IP Config for eth0:DEVICE='eth0'HWADDR=6c:92:bf:85:4c:eeNM_CONTROLLED='yes'ONBOOT='yes'IPADDR='10.6.188.99'NETMASK='255.255.255.0'GATEWAY='10.6.188.1' Misc sudo 组不存在，添加 sudo 组，groupadd sudo，否则提示 useradd: group &#39;sudo&#39; does not exist 添加用户，useradd -G sudo,docker jeromesun -m -s /bin/bash 添加用户到 sudoers file，在 root 用户下，visudo，添加一行 jeromesun ALL=(ALL) ALL。否则出现 jeromesun is not in the sudoers file. This incident will be reported.。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>redhat</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 简单文件服务器]]></title>
    <url>%2F201810%2Fadministrator%2Fnginx_file_server.html</url>
    <content type="text"><![CDATA[安装 nginx，sudo apt-get install nginx 创建 file server 配置文件 /etc/nginx/conf.d/file_server.conf，在这里配置： 监听的端口号 服务器名称，可以是 IP 文件服务器的根目录 重启 nginx 服务，sudo service nginx restart /etc/nginx/conf.d/file_server.conf， 1234567891011server &#123; listen 80; server_name 192.168.1.2; charset utf-8; root /your/dir/to/share; location / &#123; autoindex on; autoindex_exact_size on; autoindex_localtime on; &#125;&#125;]]></content>
      <categories>
        <category>administrator</category>
      </categories>
      <tags>
        <tag>administrator</tag>
        <tag>debian</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ARP 代理]]></title>
    <url>%2F201810%2Fnetworks%2Fproxy_arp.html</url>
    <content type="text"><![CDATA[Linux 配置 ARP 代理123bridge# echo 1 &gt; /proc/sys/net/ipv4/conf/eth4/proxy_arpbridge# echo 1 &gt; /proc/sys/net/ipv4/conf/eth4/proxy_arp_pvlanbridge# echo 1 &gt; /proc/sys/net/ipv4/ip_forward 参考材料 http://linux-ip.net/html/ether-arp-proxy.html https://wiki.debian.org/BridgeNetworkConnectionsProxyArp]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>networks</tag>
        <tag>ARP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip 使用记录]]></title>
    <url>%2F201810%2Fprogrammer%2Fpython%2Fpip.html</url>
    <content type="text"><![CDATA[替换源 全局替换 参考 http://mirrors.ustc.edu.cn/help/pypi.html, Unix 环境: $HOME/.config/pip/pip.conf: 123[global]index-url = https://mirrors.ustc.edu.cn/pypi/web/simpleformat = columns 如果源不支持 https，需要再加一行：trusted-host = xxx.com 使用 pip 时如果出现 configparser.MissingSectionHeaderError: File contains no section headers., 说明你的 pip.conf 忘记加上 [global] 这一行了。 pip install 带参数替换 12PIP_OPTIONS="--index-url=http://xxx.com/pypi/web/simple/ --trusted-host=xxx.com"sudo LANG=C chroot $FILESYSTEM_ROOT pip install $PIP_OPTIONS 'scapy' Dockerfile 中替换在 Dockerfile 中加一条命令： 1RUN mkdir -p ~/.pip &amp;&amp; echo "[global]\nindex-url = https://mirrors.ustc.edu.cn/pypi/web/simple/\ntrusted-host = mirrors.ustc.edu.cn" &gt; ~/.pip/pip.conf 安装本地 whl 包需要带全路径安装：pip install /full/path/to/xxx.whl]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows 串口共享工具 comfoolery 简介]]></title>
    <url>%2F201809%2Ftools%2Fcomfoolery.html</url>
    <content type="text"><![CDATA[本工具来自brianpoe, 目前该网站跳转至poehome.com/comfoolery，不过后者无响应。现已移到 github 上保存，详见：https://github.com/sunnogo/comfoolery。 功能描述通过TCP共享串口，可多人共享，含读共享、读写共享功能。 使用方法 点击ComfoolerySetup.exe安装Comfoolery 配置Comfoolery，详见“菜单说明”一节 通告串口服务器IP、端口号 客户端telnet连接串口服务器 菜单说明 File，仅含退出选项，一般用不到 Edit，含Com Settings和TCP Settings两个选项 Com Settings，配置要共享的串口信息 Com Port，待共享的串口号 Baud Rate，波特率 Parity，一般选择“None” Data bits，一般选择“8” Stop bits，一般选择“1” Flow Control，一般选择“None” TCP Settings，配置共享服务器端口 Read-only port number，当客户端连接此端口号时，只能读串口输出的信息，不能对串口进行写操作 Read/write port number，当客户端连接此端口号时，不但能读串口输出的信息，还可对串口进行写操作 Help，一般用不到 客户端连接说明使用telnet工具，按服务器的IP加共享的端口号即可连接。注意使用时，需要为telnet工具配置“Force character at a time mode”，否则telnet工具敲回车会多回显一次本次输入，且无法使用方向键等，使用效果不佳。 SecureCRT，右击标签，选择“Session Options”，点击左侧“Category”-&gt;“Connection”-&gt;”Telnet”，在右侧勾选“Force character at a time mode”，保存退出。 Linux命令行，”telnet 服务器IP 端口号”，敲ctrl + ]，执行mode character，就可以进入单字符模式（”character at a time” mode）。 其他说明打开多个Comfoolery实例可实现多串口共享。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>serialport</tag>
        <tag>串口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sshd 配置]]></title>
    <url>%2F201807%2Flinux%2Fsshd_config.html</url>
    <content type="text"><![CDATA[sshd_config 相关配置配置超时timeout = ClientAliveCountMax * ClientAliveInterval ClientAliveCountMax Sets the number of client alive messages which may be sent without sshd(8) receiving any messages back from the client. If this threshold is reached while client alive messages are being sent, sshd will disconnect the client, terminating the session. It is important to note that the use of client alive messages is very different from TCPKeepAlive. The client alive messages are sent through the encrypted channel and therefore will not be spoofable. The TCP keepalive option enabled by TCPKeepAlive is spoofable. The client alive mechanism is valuable when the client or server depend on knowing when a connection has become inactive. The default value is 3. If ClientAliveInterval is set to 15, and ClientAliveCountMax is left at the default, unresponsive SSH clients will be disconnected after approximately 45 seconds. ClientAliveInterval Sets a timeout interval in seconds after which if no data has been received from the client, sshd(8) will send a message through the encrypted channel to request a response from the client. The default is 0, indicating that these messages will not be sent to the client. This option applies to protocol version 2 only. sessions 相关MaxSessions Specifies the maximum number of open sessions permitted per network connection. The default is 10. 这个参数为 per network connection 的会话数限制，并不能限制总量。 MaxStartups Specifies the maximum number of concurrent unauthenticated connections to the SSH daemon. Additional connections will be dropped until authentication succeeds or the LoginGraceTime expires for a connection. The default is 10. Alternatively, random early drop can be enabled by specifying the three colon separated values ‘’start:rate:full’’ (e.g. “10:30:60”). sshd(8) will refuse connection attempts with a probability of ‘’rate/100’’ (30%) if there are currently ‘’start’’ (10) unauthenticated connections. The probability increases linearly and all connection attempts are refused if the number of unauthenticated connections reaches ‘’full’’ (60). 此参数用于控制还未登录成功的会话数。并不能限制登录成功的会话数。 Linux 相关配置NO-OP 超时踢掉会话TMOUT，用于配置 bash 无操作（no-op）超时时间，即超过 TMOUT 秒未操作会话，则退出登录。只要会话含此变量即可，因此可将该配置放在 /etc/profile 或 /etc/bash.bashrc。 12TMOUT=180export TMOUT 样例： 123456789101112[144134.041]jeromesun@xxx-12:~&gt; ssh a@16.3.3.31[144135.789]a@16.3.3.31's password: [144135.802]You are on[144135.803]...[144135.804]Unauthorized access and/or use are prohibited.[144135.804]All access and/or use are subject to monitoring.[144135.804][144135.805]Last login: Wed Jul 18 22:37:28 2018 from 192.168.1.92[144136.252]a@xxx-yyy:~$ [144136.437]a@xxx-yyy:~$ [144436.444]a@xxx-yyy:~$ timed out waiting for input: auto-logout[144436.464]Connection to 16.3.3.31 closed. 限制登录会话数maxlogins / maxsyslogins，配置文件在 /etc/security/limits.conf 或 /etc/security/limits.d/*.conf，配置样例如下。 1234567891011121314# Some of the lines in this sample might conflict and overwrite each other# The whole range is included to illustrate the possibilities#limit users in the users group to two logins each@users - maxlogins 2#limit all users to three logins each* - maxlogins 3#limit all users except root to 20 simultaneous logins in total* - maxsyslogins 20#limit in the users group to 5 logins in total%users - maxlogins 2#limit all users with a GID &gt;= 1000 to two logins each1000: - maxlogins 2#limit user johndoe to one loginjohndoe - maxlogins 2 运行样例（超出配置的限制数）： 123456789jeromesun@xxx-12:~&gt; ssh a@16.3.3.31a@16.3.3.31's password: You are on...Too many logins for 'a'.Last login: Wed Jul 18 22:37:34 2018 from 192.168.1.92Connection to 16.3.3.31 closed.jeromesun@xxx-12:~&gt; 参考链接 https://gitlab.com/gitlab-com/infrastructure/issues/1104 https://stackoverflow.com/questions/31114690/difference-between-maxstartups-and-maxsessions-in-sshd-config http://www.361way.com/ssh-autologout/4679.html https://linux.die.net/man/5/sshd_config]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>sshd</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 学习笔记]]></title>
    <url>%2F201806%2Fprogrammer%2Fpython%2Fnote.html</url>
    <content type="text"><![CDATA[运算符详见 菜鸟教程 python 运算符 这里只列出与 C 语言有差异的地方。 算术运算符 运算符 描述 实例 ** 幂 - 返回x的y次幂 a**b 为10的20次方， 输出结果 100000000000000000000 // 取整除 - 返回商的整数部分 9//2 输出结果 4 , 9.0//2.0 输出结果 4.0 比较运算符，没有 || &amp;&amp;，换为 and / or / not 运算符 描述 实例 &lt;&gt; 不等于 - 比较两个对象是否不相等 (a &lt;&gt; b) 返回 true。这个运算符类似 != 。 赋值运算符 运算符 描述 实例 += 加法赋值运算符 c += a 等效于 c = c + a -= 减法赋值运算符 c -= a 等效于 c = c - a *= 乘法赋值运算符 c = a 等效于 c = c a /= 除法赋值运算符 c /= a 等效于 c = c / a %= 取模赋值运算符 c %= a 等效于 c = c % a **= 幂赋值运算符 c = a 等效于 c = c a //= 取整除赋值运算符 c //= a 等效于 c = c // a 位运算符 运算符 描述 实例 ^ 按位异或运算符：当两对应的二进位相异时，结果为1 (a ^ b) 输出结果 49 ，二进制解释： 0011 0001 ~ 按位取反运算符：对数据的每个二进制位取反,即把1变为0,把0变为1 。~x 类似于 -x-1 (~a ) 输出结果 -61 ，二进制解释： 1100 0011，在一个有符号二进制数的补码形式。 &lt;&lt; 左移动运算符：运算数的各二进位全部左移若干位，由 &lt;&lt; 右边的数字指定了移动的位数，高位丢弃，低位补0。 a &lt;&lt; 2 输出结果 240 ，二进制解释： 1111 0000 &gt;&gt; 右移动运算符：把”&gt;&gt;”左边的运算数的各二进位全部右移若干位，&gt;&gt; 右边的数字指定了移动的位数 a &gt;&gt; 2 输出结果 15 ，二进制解释： 逻辑运算符 运算符 逻辑表达式 描述 实例 and x and y 布尔”与” - 如果 x 为 False，x and y 返回 False，否则它返回 y 的计算值。 (a and b) 返回 20。 or x or y 布尔”或” - 如果 x 是非 0，它返回 x 的值，否则它返回 y 的计算值。 (a or b) 返回 10。 not not x 布尔”非” - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 not(a and b) 返回 False 成员运算符 除了以上的一些运算符之外，Python还支持成员运算符，测试实例中包含了一系列的成员，包括字符串，列表或元组。 运算符 描述 实例 in 如果在指定的序列中找到值返回 True，否则返回 False。 x 在 y 序列中 , 如果 x 在 y 序列中返回 True。 not in 如果在指定的序列中没有找到值返回 True，否则返回 False。 x 不在 y 序列中 , 如果 x 不在 y 序列中返回 True 身份运算符 运算符 描述 实例 is is 是判断两个标识符是不是引用自一个对象 x is y, 类似 id(x) == id(y) , 如果引用的是同一个对象则返回 True，否则返回 False is not is not 是判断两个标识符是不是引用自不同对象 x is not y ， 类似 id(a) != id(b)。如果引用的不是同一个对象则返回结果 True，否则返回 False。 语法条件语句123456if condition: statementelif condition: statementelse statement 全局变量 global全局变量一般不建议使用，但是写小脚本的时候可能用到。全局变量定义只需要在最外层定义即可，在函数内使用时，用 global 指定变量为外层定义的全局变量。 样例： 123456789c = 0 # global variabledef add(): global c c = c + 2 # increment by 2 print("Inside add():", c)add()print("In main:", c) 运行结果： 12Inside add(): 2In main: 2 数据结构list遍历列表见 Python 列表(List) 的三种遍历(序号和值)方法，这里贴一下原作者 痞子泰 的代码备忘， 123456789101112131415161718192021222324#!/usr/bin/env python# -*- coding: utf-8 -*-if __name__ == '__main__': list = ['html', 'js', 'css', 'python'] # 方法1 print '遍历列表方法1：' for i in list: print ("序号：%s 值：%s" % (list.index(i) + 1, i)) print '\n遍历列表方法2：' # 方法2 for i in range(len(list)): print ("序号：%s 值：%s" % (i + 1, list[i])) # 方法3 print '\n遍历列表方法3：' for i, val in enumerate(list): print ("序号：%s 值：%s" % (i + 1, val)) # 方法3 print '\n遍历列表方法3 （设置遍历开始初始位置，只改变了起始序号）：' for i, val in enumerate(list, 2): print ("序号：%s 值：%s" % (i + 1, val)) 列表比较python 2.7 直接使用 cmp() 函数比较，0 表示相等。 列表排序详见 菜鸟教程， 1list.sort(cmp=None, key=None, reverse=False) key 表示要比较的元素，贴一下样例代码： 123456789101112131415#!/usr/bin/python# -*- coding: UTF-8 -*- # 获取列表的第二个元素def takeSecond(elem): return elem[1] # 列表random = [(2, 2), (3, 4), (4, 1), (1, 3)] # 指定第二个元素排序random.sort(key=takeSecond) # 输出类别print '排序列表：', random 输出结果： 1排序列表：[(4, 1), (2, 2), (1, 3), (3, 4)] dict赋值： 123456myDict = &#123;&#125;myDict['test'] = "Value"Python3:myDict[b'test'] = "Value" 如果使用不当时，key 找不到，会出现 KeyError。此时通过 myDict.get(b’test’, None)，判断返回值是否为 None，再进行进一步的操作。 copy 赋值、浅复制和深复制的差异http://www.runoob.com/w3cnote/python-understanding-dict-copy-shallow-or-deep.html 集合（set）集合，内置函数，set([&#39;a&#39;, &#39;b&#39;])，可将列表的数据转换为集合，也是列表格式。 12345678$ pythonPython 2.7.12 (default, Nov 20 2017, 18:23:56) [GCC 5.4.0 20160609] on linux2Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; a = [1, 2 ,3, 4, 1, 1, 2, 2, 3]&gt;&gt;&gt; b = set(a)&gt;&gt;&gt; print bset([1, 2, 3, 4]) 多线程处理这里先只讨论 python 2.7 的。线程和锁都隶属 threading 库。 threading 库包含几种 objects： Thread，创建、启动线程 Lock，普通锁，不支持嵌套 Rlock，嵌套锁 Condition，条件锁 Semaphore，信号量 Timer，定时器 Event Thread在 with 语句中使用 locks, conditions, and semaphoreslogprint两种格式化方法： 使用 format，print &#39;{name} {test}&#39;format(name=&#39;yyy&#39;, test=&#39;zzz&#39;) 原生，print &#39;%s %s&#39;%(&#39;yyy&#39;, &#39;zzz&#39;) syslog相比 logging，syslog 比较简单易入手，不过没有 logging 灵活。 1syslog.syslog('%%Hello: %s'%('your_name')) logging个人觉得比 syslog 好用，可以同时输出到 console 和文件中。注意 logging 比较复杂，比如在 class 中用，和在 main 函数中用，写法有很多差异。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364jeromesun@km:~/workshop/python$ python test_logging.py 2018-10-23 08:58:41,998 - spam_application - INFO - creating an instance of auxiliary_module.Auxiliary2018-10-23 08:58:42,000 - spam_application.auxiliary.Auxiliary - INFO - creating an instance of Auxiliary2018-10-23 08:58:42,000 - spam_application - INFO - created an instance of auxiliary_module.Auxiliary2018-10-23 08:58:42,001 - spam_application - INFO - calling auxiliary_module.Auxiliary.do_something2018-10-23 08:58:42,001 - spam_application.auxiliary.Auxiliary - INFO - doing something2018-10-23 08:58:42,001 - spam_application.auxiliary.Auxiliary - INFO - done doing something2018-10-23 08:58:42,001 - spam_application - INFO - finished auxiliary_module.Auxiliary.do_something2018-10-23 08:58:42,001 - spam_application - INFO - calling auxiliary_module.some_function()2018-10-23 08:58:42,001 - spam_application - INFO - done with auxiliary_module.some_function()jeromesun@km:~/workshop/python$ cat test_logging.py import loggingclass hello: def __init__(self): self.logger = logging.getLogger('spam_application.auxiliary.Auxiliary') self.logger.info('creating an instance of Auxiliary') def do_something(self): self.logger.info('doing something') a = 1 + 1 self.logger.info('done doing something')def main(): # create logger with 'spam_application' logger = logging.getLogger('spam_application') logger.setLevel(logging.DEBUG) # create file handler which logs even debug messages fh = logging.FileHandler('spam.log') fh.setLevel(logging.DEBUG) # create console handler with a higher log level ch = logging.StreamHandler() ch.setLevel(logging.DEBUG) # create formatter and add it to the handlers formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') fh.setFormatter(formatter) ch.setFormatter(formatter) # add the handlers to the logger logger.addHandler(fh) logger.addHandler(ch) logger.info('creating an instance of auxiliary_module.Auxiliary') a = hello() logger.info('created an instance of auxiliary_module.Auxiliary') logger.info('calling auxiliary_module.Auxiliary.do_something') a.do_something() logger.info('finished auxiliary_module.Auxiliary.do_something') logger.info('calling auxiliary_module.some_function()') logger.info('done with auxiliary_module.some_function()')if __name__ == '__main__': main()jeromesun@km:~/workshop/python$ tail -n 10 spam.log 2018-10-22 10:24:27,924 - spam_application - INFO - done with auxiliary_module.some_function()2018-10-23 08:58:41,998 - spam_application - INFO - creating an instance of auxiliary_module.Auxiliary2018-10-23 08:58:42,000 - spam_application.auxiliary.Auxiliary - INFO - creating an instance of Auxiliary2018-10-23 08:58:42,000 - spam_application - INFO - created an instance of auxiliary_module.Auxiliary2018-10-23 08:58:42,001 - spam_application - INFO - calling auxiliary_module.Auxiliary.do_something2018-10-23 08:58:42,001 - spam_application.auxiliary.Auxiliary - INFO - doing something2018-10-23 08:58:42,001 - spam_application.auxiliary.Auxiliary - INFO - done doing something2018-10-23 08:58:42,001 - spam_application - INFO - finished auxiliary_module.Auxiliary.do_something2018-10-23 08:58:42,001 - spam_application - INFO - calling auxiliary_module.some_function()2018-10-23 08:58:42,001 - spam_application - INFO - done with auxiliary_module.some_function()jeromesun@km:~/workshop/python$ 常用工具延迟几秒123import timetime.sleep(5) 字符串对比if a == &#39;abcdefg&#39; 常见 errorTypeError: &#39;NoneType&#39; object is not iterable in Python遍历时，对应的 list 或 dict 为空。详见 https://stackoverflow.com/questions/3887381/typeerror-nonetype-object-is-not-iterable-in-python。可通过 or [] 或 or {} 规避。 1for i in data or []: RuntimeError: dictionary changed size during iteration字典 items() 和 iteritems() 的差异，都是遍历。前者能遍历中删除的原因是，拷贝内存处理。iteritems 使用时，不能变动字典的大小，即不能增删成员。 12345678910111213141516171819202122232425jeromesun@km:~/workshop$ python test_copy.py k 1 &lt;type 'str'&gt; v 1k 3 &lt;type 'str'&gt; v 3k 2 &lt;type 'str'&gt; v 2k 4 &lt;type 'str'&gt; v 4k 1 &lt;type 'str'&gt; v 1Traceback (most recent call last): File "test_copy.py", line 10, in &lt;module&gt; for (k,v) in b.iteritems() or &#123;&#125;:RuntimeError: dictionary changed size during iterationjeromesun@km:~/workshop$ jeromesun@km:~/workshop$ cat test_copy.py import copya = &#123;'1':1, '2':2, '3':3, '4':4&#125;for (k,v) in a.items() or &#123;&#125;: print "k &#123;&#125; &#123;&#125; v &#123;&#125;".format(k,type(k), v) del a[k]a = &#123;'1':1, '2':2, '3':3, '4':4&#125;b = copy.copy(a)for (k,v) in b.iteritems() or &#123;&#125;: print "k &#123;&#125; &#123;&#125; v &#123;&#125;".format(k,type(k), v) #del a[k] b['5'] = 5 items 遍历的性能，在元素多的情况下，差很多： 1234567891011121314151617181920212223242526272829303132333435jeromesun@km:~/workshop$ python test_copy.py len 1000 item 0.000249 a.k.a 4016064.25703 pps, iteritem 0.000116 a.k.a 8620689.65517 ppslen 10000 item 0.002774 a.k.a 3604902.66763 pps, iteritem 0.001042 a.k.a 9596928.98273 ppslen 100000 item 0.040658 a.k.a 2459540.55782 pps, iteritem 0.013075 a.k.a 7648183.55641 ppslen 1000000 item 0.724924 a.k.a 1379454.94976 pps, iteritem 0.176209 a.k.a 5675079.02548 ppslen 10000000 item 9.40743 a.k.a 1062989.57314 pps, iteritem 2.154777 a.k.a 4640851.4663 ppsjeromesun@km:~/workshop$ cat test_copy.py import copyimport datetimedef test_perf(size): a = &#123;&#125; for i in range(0, size): a[str(i)] = i item_start = datetime.datetime.now() for (k,v) in a.items() or &#123;&#125;: a[k] += 1 item_end = datetime.datetime.now() iter_start = datetime.datetime.now() for (k,v) in a.iteritems() or &#123;&#125;: a[k] -= 1 iter_end = datetime.datetime.now() titem = (item_end - item_start).total_seconds() titer = (iter_end - iter_start).total_seconds() print "len &#123;&#125; item &#123;&#125; a.k.a &#123;&#125; pps, iteritem &#123;&#125; a.k.a &#123;&#125; pps".\ format(len(a), titem, size / titem, titer, size / titer)test_perf(1000)test_perf(10000)test_perf(100000)test_perf(1000000)test_perf(10000000) 问题多线程 python 程序运行时无法 ctrl + c 退出how-to-exit-the-entire-application-from-a-python-thread 提到了几种解法，但是经过验证，发现 signal 的方法可行性最高。 作为代码搬运工，找到了一个样例代码：How to terminate running Python threads using signals 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import timeimport threadingimport signal class Job(threading.Thread): def __init__(self): threading.Thread.__init__(self) # The shutdown_flag is a threading.Event object that # indicates whether the thread should be terminated. self.shutdown_flag = threading.Event() # ... Other thread setup code here ... def run(self): print('Thread #%s started' % self.ident) while not self.shutdown_flag.is_set(): # ... Job code here ... time.sleep(0.5) # ... Clean shutdown code here ... print('Thread #%s stopped' % self.ident) class ServiceExit(Exception): """ Custom exception which is used to trigger the clean exit of all running threads and the main program. """ pass def service_shutdown(signum, frame): print('Caught signal %d' % signum) raise ServiceExit def main(): # Register the signal handlers signal.signal(signal.SIGTERM, service_shutdown) signal.signal(signal.SIGINT, service_shutdown) print('Starting main program') # Start the job threads try: j1 = Job() j2 = Job() j1.start() j2.start() # Keep the main thread running, otherwise signals are ignored. while True: time.sleep(0.5) except ServiceExit: # Terminate the running threads. # Set the shutdown flag on each thread to trigger a clean shutdown of each thread. j1.shutdown_flag.set() j2.shutdown_flag.set() # Wait for the threads to close... j1.join() j2.join() print('Exiting main program') if __name__ == '__main__': main() 运行结果： 123456789jeromesun@km:~/workshop/python$ python thread_signal.py Starting main programThread #139858881009408 started Thread #139858872616704 started^CCaught signal 2Thread #139858881009408 stoppedThread #139858872616704 stoppedExiting main programjeromesun@km:~/workshop/python$ 想保密，如何发布 Python 组件？docker 中的 pyc 无法直接运行docker 中的 pyc 无法 import]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux arp]]></title>
    <url>%2F201805%2Fnetworks%2Flinux_arp.html</url>
    <content type="text"><![CDATA[详见： cumulus linux 文档：https://support.cumulusnetworks.com/hc/en-us/articles/202012933-Changing-ARP-timers-in-Cumulus-Linux arp man 文档：https://linux.die.net/man/7/arp Linux ARP 的配置基于端口，但是有默认配置，位置详见 /proc/sys/net/ipv4/neigh/default/* ARP 老化时间默认 base_reachable_time 为 1800 秒，即老化时间为 900s 到 2700s 的随机值（15分钟-45分钟）。 ARP 老化时间由 base_reachable_time 决定，当内核软转没有使用到这个 ARP 一段时间后（between base_reachable_time/2 and 3*base_reachable_time/2），将这个 ARP 从 reachable 状态置为 stale 状态。后由 gc（garbage collector）回收。 判断 ARP 是否为 stale 状态的周期为 gc_stale_time（默认 60 秒），gc 运行的间隔为 gc_interval（默认 30 秒）。 base_reachable_time (since Linux 2.2) Once a neighbor has been found, the entry is considered to be valid for at least a random value between base_reachable_time/2 and 3*base_reachable_time/2. An entry’s validity will be extended if it receives positive feedback from higher level protocols. Defaults to 30 seconds. This file is now obsolete in favor of base_reachable_time_ms. base_reachable_time_ms (since Linux 2.6.12) As for base_reachable_time, but measures time in milliseconds. Defaults to 30000 milliseconds. ARP 容量目前默认配置为 512。 gc_thresh1，如果 ARP cache 小于这个数，gc 不会运行。 gc_thresh2，ARP cache 的 soft 最大值。gc 允许 ARP cache 超过这个数 5 秒，5 秒后运行 gc。 gc_thresh3，ARP cache 的 hard 最大值。一旦 ARP cache 超过这个数，gc 会一直运行。 gc_thresh1 (since Linux 2.2) The minimum number of entries to keep in the ARP cache. The garbage collector will not run if there are fewer than this number of entries in the cache. Defaults to 128. gc_thresh2 (since Linux 2.2) The soft maximum number of entries to keep in the ARP cache. The garbage collector will allow the number of entries to exceed this for 5 seconds before collection will be performed. Defaults to 512. gc_thresh3 (since Linux 2.2) The hard maximum number of entries to keep in the ARP cache. The garbage collector will always run if there are more than this number of entries in the cache. Defaults to 1024.]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>arp</tag>
        <tag>networks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行 - grep]]></title>
    <url>%2F201805%2Fshell%2Fgrep.html</url>
    <content type="text"><![CDATA[匹配整个单词，grep -w world 匹配多个单词，grep -E &#39;(hello|world)&#39;，或 grep -e &#39;\(hello\|world\)&#39;]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[终端工具使用记录]]></title>
    <url>%2F201805%2Fprogrammer%2Ftools%2Fterminal.html</url>
    <content type="text"><![CDATA[ConEmussh Linux 系统后，vim 卡住 原因：不明 规避：在 .bashrc 中 export TERM=xterm，默认 TERM 值为 linux 文本选取去空格Settings -&gt; Keys &amp; Macro -&gt; Mark/Copy -&gt; Text selection，反选 Detect line ends，勾选 Trim trailing spaces tmux色彩问题 tmux -2 在 .bashrc 中添加 alias tmux=&quot;tmux -2&quot; 解决 vim 背景色问题见 256 color support for vim background in tmux。 .bashrc 配置： 12345678910111213if [[ -z $TMUX ]]; then if [ -e /usr/share/terminfo/x/xterm+256color ]; then # may be xterm-256 depending on your distro export TERM='xterm-256color' else export TERM='xterm' fielse if [ -e /usr/share/terminfo/s/screen-256color-s ]; then export TERM='screen-256color' else export TERM='screen' fifi 如何翻页看 log （scroll 功能）见 How do I scroll in tmux? screenSolve screen error “Cannot open your terminal ‘/dev/pts/0’ - please check”原因：用 ssh 登一个账户，su - xxx 到另一个账户，再用 screen。 Solve screen error “Cannot open your terminal ‘/dev/pts/0’ - please check” 解决screen Cannot open your terminal ‘/dev/pts/1’问题，有详细原因分析，ssh userA，系统分配的 tty 给 userA，如果 su - userB，userB 还是用的 userA 的 tty，只可读，不可写。]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>terminal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux shell 脚本]]></title>
    <url>%2F201804%2Fshell%2Fbash_script.html</url>
    <content type="text"><![CDATA[函数12345678910111213141516# Function: wait until ifindex okwait_ifindex() &#123; while true; do if [ -e /sys/class/net/$1/ifindex ]; then IFINDEX=$(cat /sys/class/net/$1/ifindex) echo "Get interface $&#123;1&#125; ifindex $&#123;IFINDEX&#125;" if [ "$IFINDEX"x != "0"x ]; then break; fi fi echo "Wait for interface $&#123;1&#125; ifindex OK for 1 second..." sleep 1 done&#125;wait_ifindex eth0 输出： 12~$ ./test.sh Get interface eth0 ifindex 2 返回值$# 返回上一个命令的执行结果。 123456~$ ls /bin dev initrd.img lib64 mnt root snap sys varboot etc initrd.img.old lost+found opt run sonic tmp vmlinuzcdrom home lib media proc sbin srv usr vmlinuz.old~$ echo $#0]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下载命令 - wget]]></title>
    <url>%2F201804%2Fshell%2Fwget.html</url>
    <content type="text"><![CDATA[常用选项： -r : 遍历所有子目录 -np : 不到上一层子目录去 -nH : 不要将文件保存到主机名文件夹 -R index.html, 不下载 index.html 文件 -o logfile, 即 –output-file=logfile, 保存 log 到 logfile -A acclist, 即 –accept acclist, 下载的白名单，例如，-A deb,log,gz,ko，表示下载后续为 .deb / .log / .gz / .ko 的文件。如果使用通配符，则不再视为后缀 -R rejlist, 下载的黑名单 –no-use-server-timestamps, -l depth, 即 –level=depth，递归下载的深度]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux kernel 杂录]]></title>
    <url>%2F201804%2Fprogrammer%2Flinux%2Fkernel_misc.html</url>
    <content type="text"><![CDATA[实时输出 dmesg详见 Terminal with real time dmesg output。 cat /proc/kmsg]]></content>
      <categories>
        <category>kernel</category>
      </categories>
      <tags>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络相关命令入门]]></title>
    <url>%2F201804%2Fnetworks%2Fcommand.html</url>
    <content type="text"><![CDATA[FAQtcpdump命令执行很慢 / 报文没显示，但是已抓到 / 报文抓得不全 / …Linux 网络相关命令，如果执行起来很慢，尝试一下 -n 选项。没了 ip 地址、L4 port 解析成名称，速度杠杠的。 -n Don’t convert addresses (i.e., host addresses, port numbers, etc.) to names. 1234567891011121314151617181920212223242526272829admin@sonic:~$ sudo tcpdump -i Ethernet52tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on Ethernet52, link-type EN10MB (Ethernet), capture size 262144 bytes^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^Z[1]+ Stopped sudo tcpdump -i Ethernet52admin@sonic:~$admin@sonic:~$ sudo tcpdump -i Ethernet52 -ntcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on Ethernet52, link-type EN10MB (Ethernet), capture size 262144 bytes08:07:35.175472 IP 20.0.0.2 &gt; 20.0.0.1: ICMP echo request, id 32684, seq 89, length 6408:07:35.175557 IP 20.0.0.1 &gt; 20.0.0.2: ICMP echo reply, id 32684, seq 89, length 6408:07:36.175431 IP 20.0.0.2 &gt; 20.0.0.1: ICMP echo request, id 32684, seq 90, length 6408:07:36.175520 IP 20.0.0.1 &gt; 20.0.0.2: ICMP echo reply, id 32684, seq 90, length 6408:07:37.175374 IP 20.0.0.2 &gt; 20.0.0.1: ICMP echo request, id 32684, seq 91, length 6408:07:37.175463 IP 20.0.0.1 &gt; 20.0.0.2: ICMP echo reply, id 32684, seq 91, length 6408:07:38.175297 IP 20.0.0.2 &gt; 20.0.0.1: ICMP echo request, id 32684, seq 92, length 6408:07:38.175377 IP 20.0.0.1 &gt; 20.0.0.2: ICMP echo reply, id 32684, seq 92, length 6408:07:39.175221 IP 20.0.0.2 &gt; 20.0.0.1: ICMP echo request, id 32684, seq 93, length 6408:07:39.175317 IP 20.0.0.1 &gt; 20.0.0.2: ICMP echo reply, id 32684, seq 93, length 64^C10 packets captured10 packets received by filter0 packets dropped by kernel 如何看 tag?tcpdump 带 -e 选项。 1-e Print the link-level header on each dump line. This can be used, for example, to print MAC layer addresses for protocols such as Ethernet and IEEE 802.11. 如何看 raw data?带 -x、-xx、-X、-XX 12345678910-x When parsing and printing, in addition to printing the headers of each packet, print the data of each packet (minus its link level header) in hex. The smaller of the entire packet or snaplen bytes will be printed. Note that this is the entire link-layer packet, so for link layers that pad (e.g. Ethernet), the padding bytes will also be printed when the higher layer packet is shorter than the required padding.-xx When parsing and printing, in addition to printing the headers of each packet, print the data of each packet, including its link level header, in hex.-X When parsing and printing, in addition to printing the headers of each packet, print the data of each packet (minus its link level header) in hex and ASCII. This is very handy for analysing new protocols.-XX When parsing and printing, in addition to printing the headers of each packet, print the data of each packet, including its link level header, in hex and ASCII.]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux export 变量]]></title>
    <url>%2F201804%2Fshell%2Fexport_environment.html</url>
    <content type="text"><![CDATA[export 命令用于声明一个变量。变量的声明同样有工作域一说。例如： 如果在 terminal 中执行 export ABC=abc，则只在本终端中生效； 如果在 ~/.bashrc 中写入 export ABC=abc，则在本用户生效； 如果在 /etc/profile 或 /etc/bash.bashrc 中写入 export ABC=abc，则全局生效。 注意 /etc/rc.local 中使用 export 命令，并不生效。具体原因不明。]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 串口相关]]></title>
    <url>%2F201803%2Fprogrammer%2Flinux%2Fserialport.html</url>
    <content type="text"><![CDATA[可学习一下 TTY的那些事儿 开机自启动，通过串口输出grub 的配置文件中修改相应行： 123GRUB_CMDLINE_LINUX='console=tty0 console=ttyS1,19200n8'GRUB_TERMINAL=serialGRUB_SERIAL_COMMAND="serial --speed=19200 --unit=1 --word=8 --parity=no --stop=1" 运行时修改串口配置使用 stty 命令。详见 man tty 描述。 stty -F /dev/ttyS0 speed 115200，修改 ttyS0 波特率为 115200 共享串口可使用 ser2net 共享串口，详见之前整理的 ser2net 用法。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>serialport</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux时间相关]]></title>
    <url>%2F201803%2Fshell%2Ftime.html</url>
    <content type="text"><![CDATA[配置系统时间 配置硬件时钟，hwclock --set --date=&quot;03/29/2018 15:31&quot; 同步硬件时钟到系统时间，hwclock --hctosys 同步系统时间到硬件时钟，hwclock --systohc 查看硬件时钟，hwclock -r 查看系统时间，date]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>time</tag>
        <tag>clock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deb debug package]]></title>
    <url>%2F201802%2Flinux%2Fdebian_debug_package.html</url>
    <content type="text"><![CDATA[标准的 debian / ubuntu 打 deb 包，通过将可执行文件的符号表通过剥离成独立的 dbg 包，称为 debug package。引用官方对 debug package 的描述： Debug packages contain debug symbols and usually are named -dbg. They are useful if program crashes and you want to generate stack trace which contains information about functions where it crashed. 因此如果你的系统使用标准 debian / ubuntu 编译、打包，则一般情况下编译结果会生成一个 _version.deb 和一个 -dbg_version.deb。正常情况下 -dbg.deb 不会安装。如果运行这个包里的可执行文件时 crash 生成 core dump，则 gdb 看不到符号表信息。解决方法： 找到与 _version.deb 同时间编译的 -dbg_version.deb，注意，如果是经常自己编译，version 可能是一样的，没有改，需要人工确认两个包是同一次编译生成的。 安装 -dbg_version.deb 到目标系统 gdb your_core_file your_elf 调试 core file，bt full 即可看到对应的符号表。 安装 orchagent dbg 包前，提示 no debugging symbols found： 1234567891011121314151617181920212223242526272829303132root@sonic:~/core# gdb orchagent -dbg orchagent.1516015456.30.core gdb: unrecognized option '-dbg'Use `gdb --help' for a complete list of options.root@sonic:~/core# gdb orchagent orchagent.1516015456.30.core GNU gdb (Debian 7.7.1+dfsg-5) 7.7.1Copyright (C) 2014 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-linux-gnu".Type "show configuration" for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type "help".Type "apropos word" to search for commands related to "word"...Reading symbols from orchagent...(no debugging symbols found)...done.[New LWP 40][New LWP 112][New LWP 30][New LWP 39][Thread debugging using libthread_db enabled]Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".Core was generated by `/usr/bin/orchagent -d /var/log/swss -b 8192 -m 00:xx:xx:xx:xx:xx'.Program terminated with signal SIGABRT, Aborted.#0 0x00007fbc29d25067 in raise () from /lib/x86_64-linux-gnu/libc.so.6(gdb) bt full#0 0x00007fbc29d25067 in raise () from /lib/x86_64-linux-gnu/libc.so.6No symbol table info available.#1 0x00007fbc29d26448 in abort () from /lib/x86_64-linux-gnu/libc.so.6 安装 orchagent dbg 包后： 1234567891011121314151617181920212223242526root@sonic:~/core# gdb orchagent orchagent.1516015456.30.core GNU gdb (Debian 7.7.1+dfsg-5) 7.7.1Copyright (C) 2014 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-linux-gnu".Type "show configuration" for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type "help".Type "apropos word" to search for commands related to "word"...Reading symbols from orchagent...Reading symbols from /usr/lib/debug/.build-id/80/83abbc9424f44c6361452396c75e47249c006b.debug...done.done.[New LWP 40][New LWP 112][New LWP 30][New LWP 39][Thread debugging using libthread_db enabled]Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".Core was generated by `/usr/bin/orchagent -d /var/log/swss -b 8192 -m 00:xx:xx:xx:xx:xx'.Program terminated with signal SIGABRT, Aborted.#0 0x00007fbc29d25067 in raise () from /lib/x86_64-linux-gnu/libc.so.6 新版本（debhelper/9.20151219 or newer in Debian）的 debhelper 已经把 -dbg.deb 改为 -dbgsym.deb，详情请见 DebugPackage。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>deb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 聚合口 team & libteam 简介]]></title>
    <url>%2F201802%2Fprogrammer%2Flinux%2Flibteam.html</url>
    <content type="text"><![CDATA[详见： libteam 项目 wiki libteam ppt 架构目标：替代 bonding 功能，最终干掉 bonding。 内核中的代码尽可能少。把内核当成是 puppet 控制逻辑在用户空间实现，puppeteer 整个项目称为 team project，其中用户空间的代码项目为 libteam，含 libteam 库、teamd daemon、teamd-utils 三个组件。 teamdev driver从 Linux 内核版本 3.3 开始支持。teamdev driver 遵循以下原则，只做报文的 rx/tx 处理，本身无业务逻辑。 If something can be done in userspace, do it in userspace. fast-path （1.4KLOC） netlink 通信（0.6KLOC） user space 配置、改变 teamdev 驱动的行为 user space 从驱动获取端口状态变化等事件 Team 模式 一种 mode 一个内核模块 activebackup broadcast loadbalance random roundrobin 一般称为 teamdev，接口名为 team0 等。 libteam lib使用 libnl，封装 Team Netlink 通信。用户无需知道任何 Netlink API 相关的信息。所有消息都来自 driver，并缓存在用户空间，使用者不需要发任何消息就能获取到请求的数据。 同时封装 RT Netlink，用于使用者添加、删除 Teamdev 实例，或添加删除 port，或获取、设置网络接口的硬件 IP 等。 libteam teamd即 Team daemon，为 libteam 项目的一部分，使用 libteam lib。teamd 跑在后台，一个实例对应一个 Team softdev，用于支持多种多样的逻辑 Team 行为。比如 基础的 round-robin，或更复杂的 active-backup、load-balancing。这些逻辑在 teamd 中称为 runner，每个 Team softdev 只能运行一种 runner。 Team Netlink有两种类型的消息：Port list 和 option list。 Port list 消息只存在 driver -&gt; lib 方向，只读数据。schema： port item interface index changed flag，指明该端口任何状态是否有变化。 removed flag，指明端口被删除了 linkup，直接从 ethtool 获取 link 状态 speed，直接从 ethtool 获取 Mbps duplex，直接从 ethtool 获取 duplex port item … port item … Option list 消息可能存在两个方向。driver -&gt; lib 方向，暴露并传输 driver 数据到 userspace。 lib-&gt; driver 方向，用于通告 driver 哪个 option 的值应变化，应怎么变化。schema 如下： option item name，option 名 changed flag removed flag type，指明以面 data 域的类型 data，动态类型 port interface index。如果 option 是 per-port 的，那么这个值为对应接口 index。 array index，如果 option 是 array。 option item … option item … 存在以下消息： lib 请求 port list lib 请求 option list lib 请求 option 值变化 driver port 状态变化事件。net core 通知 dirver 哪些端口状态变化或被删除。 driver option 值变化事件。 第4、5点，使用 netlink multicast facility，用于支撑多用户空间实例。 teamnl，使用 libteam，并封装 Team device Netlink 通信。 Driver通过 ip 工具集即可添加、删除 team 设备。 12# ip link add name team0 type team# ip link delete team0 创建 team 设备时，如果未指定硬件地址，将生成一个随机的。 同样通过 ip 工具集添加、移除端口。 12# ip link set eth0 master team0# ip link set eth0 nomaster Team softdev 驱动使用 netdevice 通告机制获取 port 上面的事件，比如 link 状态变化、port 丢失等。当一个 team 设备实例创建时（例如 team0），它就与其他网络设备无异，用户可像普通网络设备那样配置 team0，比如配置 IP 地址、应用 iptables 规则等。不同的地方是它自己不能从收发 skb，它使用其他网络设备（物理端口）。 发送 skb 时，team softdev 通过 port 选择算法选出一个 port，然后使用该 port 的 netdevice 发送 skb。 接收端，team softdev 使用 net core rx 步骤的 rx_handle 钩子拦截报文。bonding、bridging、macvlan 和 openvswitch 使用同样的钩子。通过这个钩子，报文看起来就像是从 teamdev 中接收的。然后 Net 核心代码就将报文视为从 teamdev 中接收的，进行下一步处理。 问题的重点在于如何达到最好的性能，因此 fast path（skb 发送、接收 paths）都是无锁的，只使用 RCU。同时将数据存到内存中，实现最大的局部性和最小的指针解引用。 Options【TBD】 Modes每个 mode 实现成一个 module。Team core 代码使用用户空间应用配置的 mode 字符串，调用对应 mode 实现的 handler。这些 handler 定义以下行为： init，在选择模式后调用，与通常的 init 函数一样，用于分配内存和注册 mode 特有的 option。 exit，反选 mode 后调用。 receive，由接收钩子调用，这个 handler 允许 mode 查看收到的 skb，并可修改 skb。 transmit，由 Team core 发送函数调用。在这里决策发送端口。 port_enter，当一个端口加入 teamdev 时调用 port_leave，当一个端口移除时调用 port_change_mac，当检测到硬件地址发生变化时调用。 目前实现五种模式： broadcast，Basic mode。将报文发送给所有可能的端口。 roundrobin，Basic mode。一种很简单的端口选择算法，基于端口列表，逐个循环选择端口。这是唯一一种可以不需要用户空间交互就可正常 运行的模式。 random，Basic mode。随机选择端口。 activebackup，在这种模式，只有一个端口处于 active 状态，该端口处理 skb 收发。其他端口都处于 backup 状态。用户空间通过 activeport 选项指定 active 端口。 loadbalance，一个复杂的模式。比如用于 LACP 和用户空间控制收发均衡。使用 hash 识别相同的 skb。Hash 长度 8 比特，所以总共有 256 种类型的 skb。hash 使用 BPF (Berkeley Packet Filter) 机制计算。这个模式使用以下选项： bpf_hash_func，一个二进制 option，包含 BPF 函数，用于从 skb 计算 hash 值。应用空间可组合和配置 hash 计算函数。例如源、目的 IP 地址、MAC 地址等。 lb_hash_stats 和 lb_port_stats，只读数组选项。暴露 256 种可能的 skb 类型的收发计算器，以及每个端口的收发计算器。用户空间程序可使用这个统计值判断端口的均衡程序，如果均衡程度不够，再进行 hash 算法调整。 lb_stats_refresh_interval，下发统计值到用户空间的频率。 lb_tx_hash_to_port_mapping，用于 hash-to-port 映射的数组选项。允许用户空间应用程序告诉驱动程序某个特定 hash 值的 skb 应选择哪个端口发送。 lb_tx_method，字符串选择，有两个值。 hash，告诉驱动使用 hash 值获取发送端口 hash_to_port_mapping，使能 hash_to_port_mapping 功能，并从先前的数组选项获取发送端口。 teamdlibteam 项目的重要部分。如果可能，最好在 teamd 实现功能，而非 Team softdev Linux 驱动。把 teamdev 视为木偶，则 teamd 是操纵 teamdev 的傀儡师。 teamd 的详细命令行参数见 man 8 teamd。 teamd 负责 teamdev 的创建与删除。teamdev 在 teamd 启动的时候创建，在 teamd 退出前删除。teamdev 的名字（比如 team0）通过配置文件指定。 Teamd 主要负责： 配置文件解析 后台 forking 以及诸如 PID 创建、信号处理等相关的事情。在运行 systemd 的系统中不需要，但是 teamd 也需要运行在其他系统。 Team softdev Linux driver 实例的创建与删除。 Libteam 库通信初始化 提供主循环框架，用于 fd 或定时器等的监控与处理。 初始化事件机 端口添加、删除事件处理 初始化链路状态监控器（watcher） 初始化 runner 初始化 D-Bus 接口 添加端口到 teamdev teamd 被设计成单进程、单线程应用，目前不需要多线程，这样代码会更简单。所有的运行时工作都在主循环中完成。所以如果 runner 或 watcher 需要做自己的事情（比如定时工作或 socker 数据接收等），则它们必须在主循环的框架中自己实现。 link-watcherLink 监测器实现链路状态检测，可使用不同的方法检测某个端口是否有报文传输能力，即判断端口是否 Up。 目前实现的方式有： ethtool，使用 libteam lib 获取端口 ethtool 状态变化 arp_ping，通过某端口发送 ARP 请求，如果有收到 ARP 请求，则认为链路为 up 状态。目标 IP 地址、发送时间间隔和其他选项都可以在 teamd 中配置。 nsna_ping，类似 arp_ping，但是使用 IPv6 邻居请求（NS，neighbor solicitation）和邻居发现机制（NA，neighbor advertisement）。用于纯 IPv6 环境。 可全局配置，亦可每端口配置 link-watch。用户也可以为一次配置多个 link-watcher，只有当所有的 link-watcher 报告的状态都为 up，链路才是 up。 runnerRunner 决定 Team 设备的行为。他们使用想要的内核 team 模式进行操作。Runner 监测端口 link 状态变化（使用所选择的 link-watch 监测结果），并进行相应的操作。Runner 可能还实现其他功能。 有以下 Runners 可使用（Team softdev Linux 驱动模式见以下括号）： broadcast (broadcast)，几乎没做啥，只是将 teamdev 的模式置为 broadcast 模式。 roundrobin (roundrobin)，几乎没做啥，只是将 teamdev 的模式置为 roundrobin 模式。 random (random)，几乎没做啥，只是将 teamdev 的模式置为 random 模式。 activebackup (broadcast)，监测链路变化，并选择 active 端口做报文传输。每个端口可配置自己的优先级，以及是否 sticky。sticky 的含义为即使有更高优先级的端口 Link，该端口也不会被停用。 loadbalance (loadbalance)，为了做被动的负载平衡，runner 只设置 BPF 散列函数，它将确定 skb 传输的端口。为了执行主动负载平衡，runner 将不同哈希值映射到不同的以达到完美平衡。lb_hash_stats 数组选项用于获取统计信息。lb_tx_hash_to_port_mapping 数组选项用于将散列映射到 TX 端口。 lacp (loadbalance)，实现 802.3ad LACP 协议。可使用 hash 或 loadbalance runner。 teamd control APITeamd 提供 control API 供用户控制。通过 D-Bus 和 Unix socket 实现。 teamd 启动时默认使用 Unix domain socket API，如果有带 -D 选项，则使用 D-Bus API，创建 D-Bus 服务 org.libteam.teamd.[teamdevname]。 支持以下方法： ConfigDump()，返回 teamd 所有 JSON 配置。 ConfigDumpActual()，返回所有 teamd JSON 配置，但是只包含在线端口的配置，过滤所有非在线端口。 StateDump()，返回 teamd 的状态以及其 JSON 中的子配置。 PortAdd(String port_devname)，添加端口到 teamdev。 PortRemove PortConfigUpdate PortConfigDump StateItemValueGet(String state_item_path)，在 state 树中查找 state 条目，并返回其值。 StateItemValueSet(String state_item_path, String value) 有计划在将来用更多的方法扩展这个接口。还有一个想法是扩展 API，以便能够将一个 runner 作为一个外部应用程序通过 control API 与 teamd 通信。 teamdctlteamdctl 提供 control API 的封装，用来运行时监控和配置 teamd。1:1 封装 API。 teamdctl 命令更详细的描述和命令行参数，详见 manpage （man 8 teamdctl）。 Configteamd 使用 JSON 配置文件配置，通过命令行或 .JSON 格式的的文件传递给 teamd。选择 JSON 格式的原因是它可以轻松指定（和解析）分层配置。 teamd 配置样例（teamd1.conf）： 12345678910111213141516171819202122232425262728293031&#123; "device": "team0", "hwaddr": "10:22:33:44:55:66", "runner": &#123;"name": "activebackup"&#125;, "link_watch": &#123; "name": "nsna_ping", "interval": 200, "missed_max": 15, "target_host": "fe80::210:18ff:feaa:bbcc" &#125;, "ports": &#123; "eth0": &#123; "prio": -10, "sticky": true &#125;, "eth1": &#123; "prio": 100, "link_watch": &#123;"name": "ethtool"&#125; &#125;, "eth2": &#123; "link_watch": &#123; "name": "arp_ping", "interval": 100, "missed_max": 30, "source_host": "192.168.23.2", "target_host": "192.168.23.1" &#125; &#125;, "eth3": &#123;&#125; &#125;&#125; 配置几乎不言自明。只有 link_watch 部分可能看起来有点混乱。所以在这个例子中，默认 link-watcher 是 nsna_ping，设置为每 200 毫秒发送 NAs（邻居通告）。丢失答复的最大数量为 15 个。如果丢失更多答复，link 将被视为关闭。 端口 eth1 和 eth2 指定他们自己的 link-watcher。 另一个 teamd 配置样例（teamd2.conf）： 1234567891011&#123; "device": "team0", "runner": &#123; "name": "lacp", "active": true, "fast_rate": true, "tx_hash": ["eth", "ipv4", "ipv6"] &#125;, "link_watch": &#123;"name": "ethtool"&#125;, "ports": &#123;"eth1": &#123;&#125;, "eth2": &#123;&#125;&#125;&#125; 在这个样例中，tx_hash 一节值得一提。它指明使用 skb 哪些部分计算 hash。 更多详细内容见 manpage（man 8 teamd.conf）。 样例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue state UNKNOWN mode DEFAULT link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT qlen 1000 link/ether 52:54:00:b2:a7:f1 brd ff:ff:ff:ff:ff:ff3: eth3: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT qlen 1000 link/ether 00:07:e9:11:22:33 brd ff:ff:ff:ff:ff:ff4: eth1: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT qlen 1000 link/ether 52:54:00:3d:c7:6d brd ff:ff:ff:ff:ff:ff5: eth2: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT qlen 1000 link/ether 52:54:00:73:15:c2 brd ff:ff:ff:ff:ff:ff# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 52:54:00:b2:a7:f1 brd ff:ff:ff:ff:ff:ff inet 192.168.122.182/24 brd 192.168.122.255 scope global eth0 inet6 fe80::5054:ff:feb2:a7f1/64 scope link valid_lft forever preferred_lft forever3: eth3: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN qlen 1000 link/ether 00:07:e9:11:22:33 brd ff:ff:ff:ff:ff:ff4: eth1: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN qlen 1000 link/ether 52:54:00:3d:c7:6d brd ff:ff:ff:ff:ff:ff5: eth2: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN qlen 1000 link/ether 52:54:00:73:15:c2 brd ff:ff:ff:ff:ff:ff# teamd -f teamd2.conf -d# ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue state UNKNOWN mode DEFAULT link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT qlen 1000 link/ether 52:54:00:b2:a7:f1 brd ff:ff:ff:ff:ff:ff3: eth3: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT qlen 1000 link/ether 00:07:e9:11:22:33 brd ff:ff:ff:ff:ff:ff4: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master team0 state UP mode DEFAULT qlen 1000 link/ether fa:29:06:7a:81:b8 brd ff:ff:ff:ff:ff:ff5: eth2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master team0 state UP mode DEFAULT qlen 1000 link/ether fa:29:06:7a:81:b8 brd ff:ff:ff:ff:ff:ff6: team0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT link/ether fa:29:06:7a:81:b8 brd ff:ff:ff:ff:ff:ff# tail /var/log/messagesMay 24 10:56:02 test1 kernel: [ 36.351762] team0: Port device eth1 addedMay 24 10:56:02 test1 kernel: [ 36.357303] 8139cp 0000:00:08.0: eth2: link up, 100Mbps, full-duplex, lpa 0x05E1May 24 10:56:02 test1 kernel: [ 36.359975] team0: Port device eth2 addedMay 24 10:56:02 test1 teamd[883]: 0.1 sucessfully started.May 24 10:56:03 test1 teamd[883]: eth1: Using link_watch "ethtool".May 24 10:56:03 test1 teamd[883]: eth1: Changed port state: "disabled" -&gt; "expired"May 24 10:56:03 test1 teamd[883]: eth2: Using link_watch "ethtool".May 24 10:56:03 test1 teamd[883]: eth2: Changed port state: "disabled" -&gt; "expired"May 24 10:56:03 test1 teamd[883]: eth1: Changed port state: "expired" -&gt; "current"May 24 10:56:03 test1 teamd[883]: eth2: Changed port state: "expired" -&gt; "current"# ip addr add 192.168.24.2/24 dev team0 # ping 192.168.24.1 -c 10 -i0.1PING 192.168.24.1 (192.168.24.1) 56(84) bytes of data.64 bytes from 192.168.24.1: icmp_req=1 ttl=64 time=0.511 ms64 bytes from 192.168.24.1: icmp_req=2 ttl=64 time=0.862 ms64 bytes from 192.168.24.1: icmp_req=3 ttl=64 time=0.927 ms64 bytes from 192.168.24.1: icmp_req=4 ttl=64 time=0.917 ms64 bytes from 192.168.24.1: icmp_req=5 ttl=64 time=0.966 ms64 bytes from 192.168.24.1: icmp_req=6 ttl=64 time=0.829 ms64 bytes from 192.168.24.1: icmp_req=7 ttl=64 time=0.916 ms64 bytes from 192.168.24.1: icmp_req=8 ttl=64 time=0.861 ms64 bytes from 192.168.24.1: icmp_req=9 ttl=64 time=0.866 ms64 bytes from 192.168.24.1: icmp_req=10 ttl=64 time=0.884 ms--- 192.168.24.1 ping statistics ---10 packets transmitted, 10 received, 0% packet loss, time 910msrtt min/avg/max/mdev = 0.511/0.853/0.966/0.126 ms# teamd -f teamd2.conf -k# ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue state UNKNOWN mode DEFAULT link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT qlen 1000 link/ether 52:54:00:b2:a7:f1 brd ff:ff:ff:ff:ff:ff3: eth3: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT qlen 1000 link/ether 00:07:e9:11:22:33 brd ff:ff:ff:ff:ff:ff4: eth1: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc pfifo_fast state DOWN mode DEFAULT qlen 1000 link/ether 52:54:00:3d:c7:6d brd ff:ff:ff:ff:ff:ff5: eth2: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc pfifo_fast state DOWN mode DEFAULT qlen 1000 link/ether 52:54:00:73:15:c2 brd ff:ff:ff:ff:ff:ff Bonding v.s. team features来源： https://github.com/jpirko/libteam/wiki/Bonding-vs.-Team-featuresFeature Bonding Teambroadcast TX policyYesYesround-robin TX policyYesYesactive-backup TX policyYesYesLACP (802.3ad) supportYesYesHash-based TX policyYesYesHighly customizable hash function setup NoYesTX load-balancing support (TLB)YesYesRX load-balancing support (ALB)YesPlannedRX load-balancing support (ALB) in bridge or openvswitch No PlannedLACP hash port selectYesYesload-balancing for LACP support NoYesEthtool link monitoringYesYesARP link monitoringYesYesNS/NA (IPV6) link monitoring NoYesports up/down delaysYesYesport priorities and stickiness (“primary” option enhancement) NoYesseparate per-port link monitoring setup NoYesmultiple link monitoring setup LimitedYeslockless TX/RX path No(rwlock)Yes(RCU)VLAN supportYesYesuser-space runtime control Limited FullLogic in user-space NoYesExtensibility Hard EasyModular design NoYesPerformance overhead Low Very LowD-Bus interface NoYesØMQ interface NoYesmultiple device stackingYesYeszero config using LLDP No Planned manman teamd12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879js@js-vbox:~/sonic-buildimage/src/sonic-swss$ man teamdTEAMD(8) Team daemon TEAMD(8)NAME teamd — team network device control daemonSYNOPSIS teamd -k [-p pid_file] [-g] teamd -e [-p pid_file] [-g] teamd -c config_text [-p pid_file] [-gdrD] [-Z address] teamd -f config_file [-p pid_file] [-gdrD] [-Z address] teamd -h|-VDESCRIPTION teamd is a daemon to control a given team network device, during runtime, as a puppeteer controls a puppet. It uses libteam to communicate with the kernel team device instance via Netlink sockets. The behaviour depends on the selected runner and its configuration. This daemon is part of the libteam project.OPTIONS -h, --help Print help text to console and exit. -V, --version Print version information to console and exit. -d, --daemonize Daemonize after startup. -k, --kill Kill running daemon instance. -e, --check Return 0 if a daemon is already running. -f filename, --config-file filename Load the specified configuration file. -c text, --config text Use given JSON format configuration string. If this option is present then -f option will be ignored. -p filename, --pid-file filename Use the specified PID file. -g, --debug Turns on debugging messages. Repeating the option increases verbosity. -r, --force-recreate Force team device recreation in case it already exists. -o, --take-over Take over the device if it already exists. -N, --no-quit-destroy This option also ensures that the team device is not removed after teamd finishes. -t devicename, --team-dev devicename Use the specified team device name (overrides "device" key in the configuration). -n, --no-ports Start without ports, even if they are listed in the configuration. -D, --dbus-enable Enable D-Bus interface. -Z address, --zmq-enable address Enable ZMQ interface. Possible address formats are "tcp://ip:port", "ipc://path" and others. Detailed description of ZMQ library is in page http://zguide.zeromq.org/page:all. -U, --usock-enable Enable UNIX domain socket interface. This is enabled by default. -u, --usock-disable Disable UNIX domain socket interface.SEE ALSO teamdctl(8), teamd.conf(5), teamnl(8), bond2team(1)AUTHOR Jiri Pirko is the original author and current maintainer of libteam.libteam 2013-07-10 TEAMD(8) man teamd.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397js@js-vbox:~/sonic-buildimage/src/sonic-swss$ man teamd.confTEAMD.CONF(5) Team daemon configuration TEAMD.CONF(5)NAME teamd.conf — libteam daemon configuration fileDESCRIPTION teamd uses JSON format configuration.OPTIONS device (string) Desired name of new team device. debug_level (int) Level of debug messages. The higher it is the more debug messages will be printed. It is the same as adding "-g" command line options. Default: 0 (disabled) hwaddr (string) Desired hardware address of new team device. Usual MAC address format is accepted. runner.name (string) Name of team device. The following runners are available: broadcast — Simple runner which directs the team device to transmit packets via all ports. roundrobin — Simple runner which directs the team device to transmits packets in a round-robin fashion. activebackup — Watches for link changes and selects active port to be used for data transfers. loadbalance — To do passive load balancing, runner only sets up BPF hash function which will determine port for packet transmit. To do active load balancing, runner moves hashes among available ports trying to reach perfect balance. lacp — Implements 802.3ad LACP protocol. Can use same Tx port selection possibilities as loadbalance runner. notify_peers.count (int) Number of bursts of unsolicited NAs and gratuitous ARP packets sent after port is enabled or disabled. Default: 0 (disabled) Default for activebackup runner: 1 notify_peers.interval (int) Value is positive number in milliseconds. Specifies an interval between bursts of notify-peer packets. Default: 0 mcast_rejoin.count (int) Number of bursts of multicast group rejoin requests sent after port is enabled or disabled. Default: 0 (disabled) Default for activebackup runner: 1 mcast_rejoin.interval (int) Value is positive number in milliseconds. Specifies an interval between bursts of multicast group rejoin requests. Default: 0 link_watch.name | ports.PORTIFNAME.link_watch.name (string) Name of link watcher to be used. The following link watchers are available: ethtool — Uses Libteam lib to get port ethtool state changes. arp_ping — ARP requests are sent through a port. If an ARP reply is received, the link is considered to be up. nsna_ping — Similar to the previous, except that it uses IPv6 Neighbor Solicitation / Neighbor Advertisement mechanism. This is an alternative to arp_ping and becomes handy in pure- IPv6 environments. ports (object) List of ports, network devices, to be used in a team device. See examples for more information. ports.PORTIFNAME.queue_id (int) ID of queue which this port should be mapped to. Default: NoneACTIVE-BACKUP RUNNER SPECIFIC OPTIONS runner.hwaddr_policy (string) This defines the policy of how hardware addresses of team device and port devices should be set during the team lifetime. The following are available: same_all — All ports will always have the same hardware address as the associated team device. by_active — Team device adopts the hardware address of the currently active port. This is useful when the port device is not able to change its hardware address. only_active — Only the active port adopts the hardware address of the team device. The others have their own. Default: same_all ports.PORTIFNAME.prio (int) Port priority. The higher number means higher priority. Default: 0 ports.PORTIFNAME.sticky (bool) Flag which indicates if the port is sticky. If set, it means the port does not get unselected if another port with higher priority or better parameters becomes available. Default: falseLOAD BALANCE RUNNER SPECIFIC OPTIONS runner.tx_hash (array) List of fragment types (strings) which should be used for packet Tx hash computation. The following are available: eth — Uses source and destination MAC addresses. vlan — Uses VLAN id. ipv4 — Uses source and destination IPv4 addresses. ipv6 — Uses source and destination IPv6 addresses. ip — Uses source and destination IPv4 and IPv6 addresses. l3 — Uses source and destination IPv4 and IPv6 addresses. tcp — Uses source and destination TCP ports. udp — Uses source and destination UDP ports. sctp — Uses source and destination SCTP ports. l4 — Uses source and destination TCP and UDP and SCTP ports. runner.tx_balancer.name (string) Name of active Tx balancer. Active Tx balancing is disabled by default. The only value available is basic. Default: None runner.tx_balancer.balancing_interval (int) In tenths of a second. Periodic interval between rebalancing. Default: 50LACP RUNNER SPECIFIC OPTIONS runner.active (bool) If active is true LACPDU frames are sent along the configured links periodically. If not, it acts as "speak when spoken to". Default: true runner.fast_rate (bool) Option specifies the rate at which our link partner is asked to transmit LACPDU packets. If this is true then packets will be sent once per second. Otherwise they will be sent every 30 seconds. runner.tx_hash (array) Same as for load balance runner. runner.tx_balancer.name (string) Same as for load balance runner. runner.tx_balancer.balancing_interval (int) Same as for load balance runner. runner.sys_prio (int) System priority, value can be 0 – 65535. Default: 255 runner.min_ports (int) Specifies the minimum number of ports that must be active before asserting carrier in the master interface, value can be 1 – 255. 成员口大于等于此值时，LACP 才会 Up，否则 Carrier down。 Default: 0 runner.agg_select_policy (string) This selects the policy of how the aggregators will be selected. The following are available: lacp_prio — Aggregator with highest priority according to LACP standard will be selected. Aggregator priority is affected by per-port option lacp_prio. lacp_prio_stable — Same as previous one, except do not replace selected aggregator if it is still usable. bandwidth — Select aggregator with highest total bandwidth. count — Select aggregator with highest number of ports. port_options — Aggregator with highest priority according to per-port options prio and sticky will be selected. This means that the aggregator containing the port with the highest priority will be selected unless at least one of the ports in the currently selected aggregator is sticky. Default: lacp_prio ports.PORTIFNAME.lacp_prio (int) Port priority according to LACP standard. The lower number means higher priority. ports.PORTIFNAME.lacp_key (int) Port key according to LACP standard. It is only possible to aggregate ports with the same key. Default: 0ETHTOOL LINK WATCH SPECIFIC OPTIONS link_watch.delay_up | ports.PORTIFNAME.link_watch.delay_up (int) Value is a positive number in milliseconds. It is the delay between the link coming up and the runner being notified about it. Default: 0 link_watch.delay_down | ports.PORTIFNAME.link_watch.delay_down (int) Value is a positive number in milliseconds. It is the delay between the link going down and the runner being notified about it. Default: 0ARP PING LINK WATCH SPECIFIC OPTIONS link_watch.interval | ports.PORTIFNAME.link_watch.interval (int) Value is a positive number in milliseconds. It is the interval between ARP requests being sent. link_watch.init_wait | ports.PORTIFNAME.link_watch.init_wait (int) Value is a positive number in milliseconds. It is the delay between link watch initialization and the first ARP request being sent. Default: 0 link_watch.missed_max | ports.PORTIFNAME.link_watch.missed_max (int) Maximum number of missed ARP replies. If this number is exceeded, link is reported as down. Default: 3 link_watch.source_host | ports.PORTIFNAME.link_watch.source_host (hostname) Hostname to be converted to IP address which will be filled into ARP request as source address. Default: 0.0.0.0 link_watch.target_host | ports.PORTIFNAME.link_watch.target_host (hostname) Hostname to be converted to IP address which will be filled into ARP request as destination address. link_watch.validate_active | ports.PORTIFNAME.link_watch.validate_active (bool) Validate received ARP packets on active ports. If this is not set, all incoming ARP packets will be considered as a good reply. Default: false link_watch.validate_inactive | ports.PORTIFNAME.link_watch.validate_inactive (bool) Validate received ARP packets on inactive ports. If this is not set, all incoming ARP packets will be considered as a good reply. Default: false link_watch.send_always | ports.PORTIFNAME.link_watch.send_always (bool) By default, ARP requests are sent on active ports only. This option allows sending even on inactive ports. Default: falseNS/NA PING LINK WATCH SPECIFIC OPTIONS link_watch.interval | ports.PORTIFNAME.link_watch.interval (int) Value is a positive number in milliseconds. It is the interval between sending NS packets. link_watch.init_wait | ports.PORTIFNAME.link_watch.init_wait (int) Value is a positive number in milliseconds. It is the delay between link watch initialization and the first NS packet being sent. link_watch.missed_max | ports.PORTIFNAME.link_watch.missed_max (int) Maximum number of missed NA reply packets. If this number is exceeded, link is reported as down. Default: 3 link_watch.target_host | ports.PORTIFNAME.link_watch.target_host (hostname) Hostname to be converted to IPv6 address which will be filled into NS packet as target address.EXAMPLES &#123; "device": "team0", "runner": &#123;"name": "roundrobin"&#125;, "ports": &#123;"eth1": &#123;&#125;, "eth2": &#123;&#125;&#125; &#125; Very basic configuration. &#123; "device": "team0", "runner": &#123;"name": "activebackup"&#125;, "link_watch": &#123;"name": "ethtool"&#125;, "ports": &#123; "eth1": &#123; "prio": -10, "sticky": true &#125;, "eth2": &#123; "prio": 100 &#125; &#125; &#125; This configuration uses active-backup runner with ethtool link watcher. Port eth2 has higher priority, but the sticky flag ensures that if eth1 becomes active, it stays active while the link remains up. &#123; "device": "team0", "runner": &#123;"name": "activebackup"&#125;, "link_watch": &#123; "name": "ethtool", "delay_up": 2500, "delay_down": 1000 &#125;, "ports": &#123; "eth1": &#123; "prio": -10, "sticky": true &#125;, "eth2": &#123; "prio": 100 &#125; &#125; &#125; Similar to the previous one. Only difference is that link changes are not propagated to the runner immediately, but delays are applied. &#123; "device": "team0", "runner": &#123;"name": "activebackup"&#125;, "link_watch": &#123; "name": "arp_ping", "interval": 100, "missed_max": 30, "target_host": "192.168.23.1" &#125;, "ports": &#123; "eth1": &#123; "prio": -10, "sticky": true &#125;, "eth2": &#123; "prio": 100 &#125; &#125; &#125; This configuration uses ARP ping link watch. &#123; "device": "team0", "runner": &#123;"name": "activebackup"&#125;, "link_watch": [ &#123; "name": "arp_ping", "interval": 100, "missed_max": 30, "target_host": "192.168.23.1" &#125;, &#123; "name": "arp_ping", "interval": 50, "missed_max": 20, "target_host": "192.168.24.1" &#125; ], "ports": &#123; "eth1": &#123; "prio": -10, "sticky": true &#125;, "eth2": &#123; "prio": 100 &#125; &#125; &#125; Similar to the previous one, only this time two link watchers are used at the same time. &#123; "device": "team0", "runner": &#123; "name": "loadbalance", "tx_hash": ["eth", "ipv4", "ipv6"] &#125;, "ports": &#123;"eth1": &#123;&#125;, "eth2": &#123;&#125;&#125; &#125; Configuration for hash-based passive Tx load balancing. &#123; "device": "team0", "runner": &#123; "name": "loadbalance", "tx_hash": ["eth", "ipv4", "ipv6"], "tx_balancer": &#123; "name": "basic" &#125; &#125;, "ports": &#123;"eth1": &#123;&#125;, "eth2": &#123;&#125;&#125; &#125; Configuration for active Tx load balancing using basic load balancer. &#123; "device": "team0", "runner": &#123; "name": "lacp", "active": true, "fast_rate": true, "tx_hash": ["eth", "ipv4", "ipv6"] &#125;, "link_watch": &#123;"name": "ethtool"&#125;, "ports": &#123;"eth1": &#123;&#125;, "eth2": &#123;&#125;&#125; &#125; Configuration for connection to LACP capable counterpart.SEE ALSO teamd(8), teamdctl(8), teamnl(8), bond2team(1)AUTHOR Jiri Pirko is the original author and current maintainer of libteam.libteam 2013-07-09 TEAMD.CONF(5) man teamdctl1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283js@js-vbox:~/sonic-buildimage/src/sonic-swss$ man teamdctlTEAMDCTL(8) teamd control TEAMDCTL(8)NAME teamdctl — team daemon control toolSYNOPSIS teamdctl [options] team_device command [command_args...] teamdctl -hDESCRIPTION teamdctl is a tool that allows a user to interact with a running teamd instance. It defaults to using Unix Domain Sockets, but will fall back to using the D-Bus API, to ensure reliable operation in all environments.OPTIONS -h, --help Print help text to console and exit. -v, --verbosity Increase output verbosity. -o, --oneline Force output to one line if possible. -D, --force-dbus Force to use D-Bus interface. -Z address, --force-zmq address Force to use ZMQ interface. Possible address formats are "tcp://ip:port", "ipc://path" and others. Detailed description of ZMQ library is in page http://zguide.zeromq.org/page:all. -U, --force-usock Force to use UNIX domain socket interface. This is the default behavior.COMMAND config dump Dumps teamd JSON config. config dump noports Dumps teamd JSON configuration without "ports" section included. config dump actual Dumps teamd actual JSON configuration. It includes ports which are currently present. state dump | state Dumps teamd JSON state document. state view Prints out state of teamd parsed from JSON state document. state item get state_item_path Finds state item in JSON state document and returns its value. state item set state_item_path value Finds state item in JSON state document and sets its value by value parameter. This is available only for a limited number of paths: setup.debug_level — User can set debug level. Higher level is more verbose. ports.PORTIFNAME.runner.aggregator.selected — This is available for lacp runner. User can manually select the aggregator. runner.active_port — This is available for activebackup runner. User can manually select the active port. port add portdev Takes port device name as argument. Adds port device into team. port remove portdev Takes port device name as argument. Removes port device from team. port present portdev Takes port device name as argument. Checks if the port device is present in team. port config update portdev portconfig-string Takes port device name as the first argument and JSON format configuration string as the second argument. Updates port device configuration. port config dump portdev Takes port device name as the first argument. Dumps port device JSON configuration to standard output.SEE ALSO teamd(8), teamnl(8), teamd.conf(5)AUTHOR Jiri Pirko is the original author and current maintainer of libteam.libteam 2013-05-24 TEAMDCTL(8)]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>libteam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无网络下安装常用 deb 包]]></title>
    <url>%2F201802%2Flinux%2Fdeb_without_network.html</url>
    <content type="text"><![CDATA[安装方法：到官网下载对应软件 ubuntu / debian 的 deb 包。 例如 openssh-server，以 ubuntu 16.04 为例，下载路径，在页面底部，选择对应的硬件架构（arch），比如 amd64。 openssh-server安装顺序： openssh-client openssh-sftp-server openssh-server 在 ubuntu 16.04 上验证过。 gdb安装顺序： libpython2.7 gdb 在 debian jessie 上验证过。 iptables安装顺序： libnfnetlink0 libxtables10，新版本可能是 libxtables11 iptables 在 debian jessie 上验证过。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>deb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apt&deb 工具使用记录]]></title>
    <url>%2F201801%2Flinux%2Fapt%26deb.html</url>
    <content type="text"><![CDATA[查看 deb 包内容 查看 .deb 文件包含的内容，dpkg-deb -c packageName.deb 查看已安装 deb 包的内容，dpkg -L packageName 查看包是否已安装 dpkg -s packageName 解压 deb 包 dpkg -x xxx.deb your_dir apt 卸载命令http://blog.csdn.net/get_set/article/details/51276609 apt-get purge / apt-get –purge remove删除已安装包（不保留配置文件)。如软件包a，依赖软件包b，则执行该命令会删除a，而且不保留配置文件 apt-get autoremove删除为了满足依赖而安装的，但现在不再需要的软件包（包括已安装包），保留配置文件。 apt-get remove删除已安装的软件包（保留配置文件），不会删除依赖软件包，且保留配置文件。 apt-get autocleanAPT的底层包是dpkg, 而dpkg 安装Package时, 会将 *.deb 放在 /var/cache/apt/archives/中，apt-get autoclean 只会删除 /var/cache/apt/archives/ 已经过期的deb。 apt-get clean使用 apt-get clean 会将 /var/cache/apt/archives/ 的 所有 deb 删掉，可以理解为 rm /var/cache/apt/archives/*.deb。 apt-get install -y对所有的提示执行 y（yes）. install 和 build-dep 差异The short version. apt-get installinstalls a new package, automatically resolving and downloading dependent packages. If package is installed then try to upgrade to latest version. apt-get build-depCauses apt-get to install/remove packages in an attempt to satisfy the build dependencies for a source package. The command sudo apt-get build-dep packagename means to install all dependencies for ‘packagename’ so that I can build it”. So build-dep is an apt-get command just like install, remove, update, etc. The build-dep command searches the local repositories in the system and install the build dependencies for package. If the package does not exists in the local repository it will return an error code. For installing matplotlib see To Install matplotlib on Ubuntu 清除多余的 kernel image问题：apt-get install 的时候出错，提示 update-initramfs 做 gzip 时没有空间。根本原因为 /boot 分区没空间。解决：通过 apt-get remove --purge 清除多余的 kernel image。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259$ df -hFilesystem Size Used Avail Use% Mounted onudev 63G 0 63G 0% /devtmpfs 13G 34M 13G 1% /run/dev/mapper/ubuntu--vg-root 1.6T 392G 1.2T 26% /tmpfs 63G 176K 63G 1% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 63G 0 63G 0% /sys/fs/cgroup/dev/sda1 472M 404M 44M 91% /boot~$ apt-file search arpThe program 'apt-file' is currently not installed. You can install it by typing:sudo apt install apt-filenetadmin@kmc-b0230:~/sb.0509$ sudo apt-get install apt-file[sudo] password for netadmin: Reading package lists... DoneBuilding dependency tree Reading state information... DoneThe following packages were automatically installed and are no longer required: linux-headers-4.13.0-37 linux-headers-4.13.0-37-generic linux-headers-4.13.0-38 linux-headers-4.13.0-38-generic linux-headers-4.13.0-39 linux-headers-4.13.0-39-generic linux-image-4.13.0-37-generic linux-image-4.13.0-38-generic linux-image-4.13.0-39-generic linux-image-4.4.0-119-generic linux-image-4.4.0-121-generic linux-image-4.4.0-124-generic linux-image-extra-4.13.0-37-generic linux-image-extra-4.13.0-38-generic linux-image-extra-4.13.0-39-generic linux-image-extra-4.4.0-119-generic linux-image-extra-4.4.0-121-generic linux-image-extra-4.4.0-124-genericUse 'sudo apt autoremove' to remove them.The following additional packages will be installed: libconfig-file-perl libregexp-assemble-perlThe following NEW packages will be installed: apt-file libconfig-file-perl libregexp-assemble-perl0 upgraded, 3 newly installed, 0 to remove and 212 not upgraded.13 not fully installed or removed.Need to get 109 kB of archives.After this operation, 349 kB of additional disk space will be used.Do you want to continue? [Y/n] yGet:1 http://cn.archive.ubuntu.com/ubuntu xenial/universe amd64 libconfig-file-perl all 1.50-3 [9,722 B]Get:2 http://cn.archive.ubuntu.com/ubuntu xenial/universe amd64 libregexp-assemble-perl all 0.36-1 [77.5 kB]Get:3 http://cn.archive.ubuntu.com/ubuntu xenial/universe amd64 apt-file all 2.5.5ubuntu1 [21.6 kB]Fetched 109 kB in 2s (42.7 kB/s) Selecting previously unselected package libconfig-file-perl.(Reading database ... 382259 files and directories currently installed.)Preparing to unpack .../libconfig-file-perl_1.50-3_all.deb ...Unpacking libconfig-file-perl (1.50-3) ...Selecting previously unselected package libregexp-assemble-perl.Preparing to unpack .../libregexp-assemble-perl_0.36-1_all.deb ...Unpacking libregexp-assemble-perl (0.36-1) ...Selecting previously unselected package apt-file.Preparing to unpack .../apt-file_2.5.5ubuntu1_all.deb ...Unpacking apt-file (2.5.5ubuntu1) ...Processing triggers for man-db (2.7.5-1) ...Setting up initramfs-tools (0.122ubuntu8.8) ...update-initramfs: deferring update (trigger activated)Setting up linux-firmware (1.157.18) ...update-initramfs: Generating /boot/initrd.img-4.13.0-41-genericgzip: stdout: No space left on deviceE: mkinitramfs failure find 141 cpio 141 gzip 1update-initramfs: failed for /boot/initrd.img-4.13.0-41-generic with 1.dpkg: error processing package linux-firmware (--configure): subprocess installed post-installation script returned error exit status 1Setting up linux-image-4.13.0-43-generic (4.13.0-43.48~16.04.1) ...Running depmod.update-initramfs: deferring update (hook will be called later)The link /initrd.img is a dangling linkto /boot/initrd.img-4.4.0-127-genericExamining /etc/kernel/postinst.d.run-parts: executing /etc/kernel/postinst.d/apt-auto-removal 4.13.0-43-generic /boot/vmlinuz-4.13.0-43-genericrun-parts: executing /etc/kernel/postinst.d/initramfs-tools 4.13.0-43-generic /boot/vmlinuz-4.13.0-43-genericupdate-initramfs: Generating /boot/initrd.img-4.13.0-43-genericgzip: stdout: No space left on deviceE: mkinitramfs failure find 141 cpio 141 gzip 1update-initramfs: failed for /boot/initrd.img-4.13.0-43-generic with 1.run-parts: /etc/kernel/postinst.d/initramfs-tools exited with return code 1Failed to process /etc/kernel/postinst.d at /var/lib/dpkg/info/linux-image-4.13.0-43-generic.postinst line 1052.dpkg: error processing package linux-image-4.13.0-43-generic (--configure): subprocess installed post-installation script returned error exit status 2dpkg: dependency problems prevent configuration of linux-image-extra-4.13.0-43-generic: linux-image-extra-4.13.0-43-generic depends on linux-image-4.13.0-43-generic; however: Package linux-image-4.13.0-43-generic is not configured yet.dpkg: error processing package linux-image-extra-4.13.0-43-generic (--configure): dependency problems - leaving unconfiguredNo apport report written because the error message indicates its a followup error from a previous failure. dpkg: dependency problems prevent configuration of linux-image-generic-hwe-16.04: linux-image-generic-hwe-16.04 depends on linux-image-4.13.0-43-generic; however: Package linux-image-4.13.0-43-generic is not configured yet. linux-image-generic-hwe-16.04 depends on linux-image-extra-4.13.0-43-generic; however: Package linux-image-extra-4.13.0-43-generic is not configured yet. linux-image-generic-hwe-16.04 depends on linux-firmware; however: Package linux-firmware is not configured yet.dpkg: error processing package linux-image-generic-hwe-16.04 (--configure): dependency problems - leaving unconfiguredNo apport report written because MaxReports is reached already dpkg: dependency problems prevent configuration of linux-generic-hwe-16.04: linux-generic-hwe-16.04 depends on linux-image-generic-hwe-16.04 (= 4.13.0.43.62); however: Package linux-image-generic-hwe-16.04 is not configured yet.dpkg: error processing package linux-generic-hwe-16.04 (--configure): dependency problems - leaving unconfiguredNo apport report written because MaxReports is reached already Setting up linux-image-4.4.0-124-generic (4.4.0-124.148) ...Running depmod.update-initramfs: deferring update (hook will be called later)The link /initrd.img is a dangling linkto /boot/initrd.img-4.13.0-43-genericExamining /etc/kernel/postinst.d.run-parts: executing /etc/kernel/postinst.d/apt-auto-removal 4.4.0-124-generic /boot/vmlinuz-4.4.0-124-genericrun-parts: executing /etc/kernel/postinst.d/initramfs-tools 4.4.0-124-generic /boot/vmlinuz-4.4.0-124-genericupdate-initramfs: Generating /boot/initrd.img-4.4.0-124-genericgzip: stdout: No space left on deviceE: mkinitramfs failure find 141 cpio 141 gzip 1update-initramfs: failed for /boot/initrd.img-4.4.0-124-generic with 1.run-parts: /etc/kernel/postinst.d/initramfs-tools exited with return code 1Failed to process /etc/kernel/postinst.d at /var/lib/dpkg/info/linux-image-4.4.0-124-generic.postinst line 1052.dpkg: error processing package linux-image-4.4.0-124-generic (--configure): subprocess installed post-installation script returned error exit status 2No apport report written because MaxReports is reached already Setting up linux-image-4.4.0-127-generic (4.4.0-127.153) ...Running depmod.update-initramfs: deferring update (hook will be called later)The link /initrd.img is a dangling linkto /boot/initrd.img-4.4.0-124-genericExamining /etc/kernel/postinst.d.run-parts: executing /etc/kernel/postinst.d/apt-auto-removal 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-genericrun-parts: executing /etc/kernel/postinst.d/initramfs-tools 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-genericupdate-initramfs: Generating /boot/initrd.img-4.4.0-127-genericgzip: stdout: No space left on deviceE: mkinitramfs failure find 141 cpio 141 gzip 1update-initramfs: failed for /boot/initrd.img-4.4.0-127-generic with 1.run-parts: /etc/kernel/postinst.d/initramfs-tools exited with return code 1Failed to process /etc/kernel/postinst.d at /var/lib/dpkg/info/linux-image-4.4.0-127-generic.postinst line 1052.dpkg: error processing package linux-image-4.4.0-127-generic (--configure): subprocess installed post-installation script returned error exit status 2No apport report written because MaxReports is reached already Setting up linux-image-extra-4.13.0-41-generic (4.13.0-41.46~16.04.1) ...run-parts: executing /etc/kernel/postinst.d/apt-auto-removal 4.13.0-41-generic /boot/vmlinuz-4.13.0-41-genericrun-parts: executing /etc/kernel/postinst.d/initramfs-tools 4.13.0-41-generic /boot/vmlinuz-4.13.0-41-genericupdate-initramfs: Generating /boot/initrd.img-4.13.0-41-generic gzip: stdout: No space left on deviceE: mkinitramfs failure find 141 cpio 141 gzip 1update-initramfs: failed for /boot/initrd.img-4.13.0-41-generic with 1.run-parts: /etc/kernel/postinst.d/initramfs-tools exited with return code 1dpkg: error processing package linux-image-extra-4.13.0-41-generic (--configure): subprocess installed post-installation script returned error exit status 1No apport report written because MaxReports is reached already dpkg: dependency problems prevent configuration of linux-image-extra-4.4.0-124-generic: linux-image-extra-4.4.0-124-generic depends on linux-image-4.4.0-124-generic; however: Package linux-image-4.4.0-124-generic is not configured yet.dpkg: error processing package linux-image-extra-4.4.0-124-generic (--configure): dependency problems - leaving unconfiguredNo apport report written because MaxReports is reached already dpkg: dependency problems prevent configuration of linux-image-extra-4.4.0-127-generic: linux-image-extra-4.4.0-127-generic depends on linux-image-4.4.0-127-generic; however: Package linux-image-4.4.0-127-generic is not configured yet.dpkg: error processing package linux-image-extra-4.4.0-127-generic (--configure): dependency problems - leaving unconfiguredNo apport report written because MaxReports is reached already dpkg: dependency problems prevent configuration of linux-image-generic: linux-image-generic depends on linux-image-4.4.0-127-generic; however: Package linux-image-4.4.0-127-generic is not configured yet. linux-image-generic depends on linux-image-extra-4.4.0-127-generic; however: Package linux-image-extra-4.4.0-127-generic is not configured yet. linux-image-generic depends on linux-firmware; however: Package linux-firmware is not configured yet.dpkg: error processing package linux-image-generic (--configure): dependency problems - leaving unconfiguredNo apport report written because MaxReports is reached already dpkg: dependency problems prevent configuration of linux-image-extra-virtual: linux-image-extra-virtual depends on linux-image-generic (= 4.4.0.127.133); however: Package linux-image-generic is not configured yet.dpkg: error processing package linux-image-extra-virtual (--configure): dependency problems - leaving unconfiguredNo apport report written because MaxReports is reached already Setting up libconfig-file-perl (1.50-3) ...Setting up libregexp-assemble-perl (0.36-1) ...Setting up apt-file (2.5.5ubuntu1) ...The system-wide cache is empty. You may want to run 'apt-file update'as root to update the cache. You can also run 'apt-file update' asnormal user to use a cache in the user's home directory.Processing triggers for initramfs-tools (0.122ubuntu8.8) ...update-initramfs: Generating /boot/initrd.img-4.13.0-41-genericgzip: stdout: No space left on deviceE: mkinitramfs failure find 141 cpio 141 gzip 1update-initramfs: failed for /boot/initrd.img-4.13.0-41-generic with 1.dpkg: error processing package initramfs-tools (--configure): subprocess installed post-installation script returned error exit status 1No apport report written because MaxReports is reached already Errors were encountered while processing: linux-firmware linux-image-4.13.0-43-generic linux-image-extra-4.13.0-43-generic linux-image-generic-hwe-16.04 linux-generic-hwe-16.04 linux-image-4.4.0-124-generic linux-image-4.4.0-127-generic linux-image-extra-4.13.0-41-generic linux-image-extra-4.4.0-124-generic linux-image-extra-4.4.0-127-generic linux-image-generic linux-image-extra-virtual initramfs-toolsE: Sub-process /usr/bin/dpkg returned an error code (1)t$ sudo apt remove --purge linux-image-4.4.0-127-generic linux-image-extra-4.4.0-127-generic Reading package lists... DoneBuilding dependency tree Reading state information... DoneThe following packages will be REMOVED: linux-image-4.4.0-127-generic* linux-image-extra-4.4.0-127-generic* linux-image-extra-virtual* linux-image-generic*0 upgraded, 0 newly installed, 4 to remove and 212 not upgraded.4 not fully installed or removed.After this operation, 224 MB disk space will be freed.Do you want to continue? [Y/n] y(Reading database ... 260557 files and directories currently installed.)Removing linux-image-extra-virtual (4.4.0.127.133) ...Removing linux-image-generic (4.4.0.127.133) ...Removing linux-image-extra-4.4.0-127-generic (4.4.0-127.153) ...depmod: FATAL: could not load /boot/System.map-4.4.0-127-generic: No such file or directoryrun-parts: executing /etc/kernel/postinst.d/apt-auto-removal 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-genericrun-parts: executing /etc/kernel/postinst.d/initramfs-tools 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-genericupdate-initramfs: Generating /boot/initrd.img-4.4.0-127-genericrun-parts: executing /etc/kernel/postinst.d/pm-utils 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-genericrun-parts: executing /etc/kernel/postinst.d/unattended-upgrades 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-genericrun-parts: executing /etc/kernel/postinst.d/update-notifier 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-genericrun-parts: executing /etc/kernel/postinst.d/zz-update-grub 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-genericGenerating grub configuration file ...Warning: Setting GRUB_TIMEOUT to a non-zero value when GRUB_HIDDEN_TIMEOUT is set is no longer supported.Found linux image: /boot/vmlinuz-4.13.0-43-genericFound initrd image: /boot/initrd.img-4.13.0-43-genericFound linux image: /boot/vmlinuz-4.13.0-41-genericFound initrd image: /boot/initrd.img-4.13.0-41-genericFound memtest86+ image: /memtest86+.elfFound memtest86+ image: /memtest86+.bindonePurging configuration files for linux-image-extra-4.4.0-127-generic (4.4.0-127.153) ...Removing linux-image-4.4.0-127-generic (4.4.0-127.153) ...Examining /etc/kernel/postrm.d .run-parts: executing /etc/kernel/postrm.d/initramfs-tools 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-genericupdate-initramfs: Deleting /boot/initrd.img-4.4.0-127-genericrun-parts: executing /etc/kernel/postrm.d/zz-update-grub 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-genericGenerating grub configuration file ...Warning: Setting GRUB_TIMEOUT to a non-zero value when GRUB_HIDDEN_TIMEOUT is set is no longer supported.Found linux image: /boot/vmlinuz-4.13.0-43-genericFound initrd image: /boot/initrd.img-4.13.0-43-genericFound linux image: /boot/vmlinuz-4.13.0-41-genericFound initrd image: /boot/initrd.img-4.13.0-41-genericFound memtest86+ image: /memtest86+.elfFound memtest86+ image: /memtest86+.bindonePurging configuration files for linux-image-4.4.0-127-generic (4.4.0-127.153) ...Examining /etc/kernel/postrm.d .run-parts: executing /etc/kernel/postrm.d/initramfs-tools 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-genericrun-parts: executing /etc/kernel/postrm.d/zz-update-grub 4.4.0-127-generic /boot/vmlinuz-4.4.0-127-generic]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>deb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地 mirror debian]]></title>
    <url>%2F201801%2Fadministrator%2Fdebian-mirror.html</url>
    <content type="text"><![CDATA[需求为快速编译，本地镜像 debian。 镜像工具 ftpsync，debian 官方推荐 apt-mirror，实测速率太慢 debmirror，未测 一开始使用 apt-mirror，在 ubuntu 中 apt-get install 的 apt-mirror 并不能做 debian 镜像，出现各种提示错误。所以如果要用 apt-mirror，ubuntu 做 ubuntu 的，debian 上做 debian的。如果想在 ubuntu 上做 debian 镜像，那就搞一个 debian docker 吧。 ftpsync 使用记录官方对做 mirror 的说明，详见https://www.debian.org/mirror/ftpmirror。 ftpsync 的获取方式： tar 包 from https://ftp-master.debian.org/ftpsync.tar.gz git repository: git clone https://anonscm.debian.org/git/mirror/archvsync.git (see https://anonscm.debian.org/cgit/mirror/archvsync.git/) 使用说明见：https://anonscm.debian.org/cgit/mirror/archvsync.git/tree/README.md，相对简单。 快速入门： 建议创建一个特定的用户用于整个镜像源制作（我未做） 建议创建一个独立的目录用于整个镜像源制作，上一步创建的用户有写权限。（这一步肯定有必要） 将 ftpsync 脚本放在 $HOME/bin 或者 $HOME 下（我觉得这是为什么要创建特定用户的原因，保证这个目录只用于做镜像源用，其他用户也不会烦要在 /home/xxx 目录下有这种业务脚本） 将 ftpsync.conf.sample 重命名为 ftpsync.conf 放到 $HOME/etc 中，并根据你自己的需要做配置。至少你得改 TO= 和 RSYNC_HOST 两行。 TO= 指明下载的结果存放在本地哪个路径 RSYNC_HOST 指明上级镜像源，即你将从哪个服务器下载 创建 $HOME/log 目录，或者在 $LOGDIR 中指定 执行 ftpsync，等下载结束了！ 还有另一处方式，由上级镜像源触发更新操作，则需要做其他处理： If only you receive an update trigger, Setup the .ssh/authorized_keys for the mirror user and place the public key of your upstream mirror into it. Preface it with no-port-forwarding,no-X11-forwarding,no-agent-forwarding,no-pty,command=&quot;~/bin/ftpsync&quot;,from=&quot;IPADDRESS&quot; and replace $IPADDRESS with that of your upstream mirror. arch 配置项，有两个互斥的选项，ARCH_INCLUDE 和 ARCH_EXCLUDE，相当于要下载的白名单和黑名单。查看 bin/ftpsync 脚本的源码，可以看出两个选项只能配置一个。建议直接配置 ARCH_INCLUDE，因为 ARCH_EXCLUDE 容易有漏网之鱼。 12345678910111213141516171819202122232425262728293031# Learn which archs to include/exclude based on ARCH_EXCLUDE and ARCH_INCLUDE# settings.# Sets EXCLUDE (which might also have --include statements# followed by a --exclude *_*.&lt;things&gt;.set_exclude_include_archs() &#123; if [[ -n "$&#123;ARCH_EXCLUDE&#125;" ]] &amp;&amp; [[ -n "$&#123;ARCH_INCLUDE&#125;" ]]; then echo &gt;&amp;2 "ARCH_EXCLUDE and ARCH_INCLUDE are mutually exclusive. Set only one." exit 1 fi if [[ -n "$&#123;ARCH_EXCLUDE&#125;" ]]; then for ARCH in $&#123;ARCH_EXCLUDE&#125;; do arch_exclude $&#123;ARCH&#125; done arch_include '*' arch_include source elif [[ -n "$&#123;ARCH_INCLUDE&#125;" ]]; then local include_arch_all=false for ARCH in $&#123;ARCH_INCLUDE&#125;; do arch_include $&#123;ARCH&#125; if [[ $&#123;ARCH&#125; != source ]]; then include_arch_all=true fi done if [[ true = $&#123;include_arch_all&#125; ]]; then arch_include all fi arch_exclude '*' arch_exclude source fi&#125; 配置文件$HOME/etc/ftpsync.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344################################################################################################################################################## This is a sample configuration file for the ftpsync mirror script. #### Only options most users may need are included. For documentation #### and all available options see ftpsync.conf(5). ##################################################################################################################################################MIRRORNAME=`hostname -f`TO="/home/mirror/mirror/debian"MAILTO="$LOGNAME"# HUB=false########################################################################## Connection options########################################################################RSYNC_HOST="ftp.cn.debian.org"RSYNC_PATH="debian"# RSYNC_USER=# RSYNC_PASSWORD=########################################################################## Mirror information options######################################################################### INFO_MAINTAINER="Admins &lt;admins@example.com&gt;, Person &lt;person@example.com&gt;"# INFO_SPONSOR="Example &lt;https://example.com&gt;"# INFO_COUNTRY=DE# INFO_LOCATION="Example"# INFO_THROUGHPUT=10Gb########################################################################## Include and exclude options########################################################################ARCH_INCLUDE="amd64 source"# ARCH_EXCLUDE=########################################################################## Log option######################################################################### LOGDIR= $HOME/etc/ftpsync-security.conf此配置只下载 amd64 和 source，其他架构忽略。RSYNC_HOST 尝试 ftp.cn.debian.org 和 mirrors.ustc.edu.cn&quot;，都不行，只能用 security.debian.org。目前还没有搞懂，感觉很奇怪，这两个源都有 debian-security 目录。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647################################################################################################################################################## This is a sample configuration file for the ftpsync mirror script. #### Only options most users may need are included. For documentation #### and all available options see ftpsync.conf(5). ################################################################################################################################################### MIRRORNAME=`hostname -f`# TO="/srv/mirrors/debian/"# MAILTO="$LOGNAME"# HUB=falseMIRRORNAME=`hostname -f`TO="/home/mirror/mirror/debian-security"MAILTO="$LOGNAME"########################################################################## Connection options########################################################################RSYNC_HOST="security.debian.org"RSYNC_PATH="debian-security"# RSYNC_USER=# RSYNC_PASSWORD=########################################################################## Mirror information options######################################################################### INFO_MAINTAINER="Admins &lt;admins@example.com&gt;, Person &lt;person@example.com&gt;"# INFO_SPONSOR="Example &lt;https://example.com&gt;"# INFO_COUNTRY=DE# INFO_LOCATION="Example"# INFO_THROUGHPUT=10Gb########################################################################## Include and exclude options########################################################################ARCH_INCLUDE="amd64 source"# ARCH_EXCLUDE=########################################################################## Log option######################################################################### LOGDIR= 做 debian-security 镜像源配置文件如上所示，执行的命令为 ./bin/ftpsync sync:archive:security，注意字符串的一致，这里 security 要和配置文件 ftpsync-security.conf 中的 security 保持一致。 cron 每天定时 sync1234567$ cat /etc/cron.d/ftpsyncSHELL=/bin/bashPATH=/home/mirror/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin#minute hour day_of_month month day_of_week user command0 2 * * * mirror ftpsync sync:archive:security0 2 * * * mirror ftpsync log如果下载失败，中间过程可见 LOGDIR 中的 log 进行排查。例如先前排查 debian-security 下载失败的问题。 ftpsync.log，ftpsync 脚本的 log rsync-ftpsync.log，rsync 的正常 log，很多。。 rsync-ftpsync.error，rsync 的异常 log，出问题看这里，可以看到 rsync 的 error code 及出现这个 error code 的原因。 12345678910111213141516171819$ ls log/ftpsync.log ftpsync-security.log rsync-ftpsync.error.1 rsync-ftpsync.log.1 rsync-ftpsync-security.error.1ftpsync.log.0 ftpsync-security.log.0 rsync-ftpsync.error.2 rsync-ftpsync.log.2 rsync-ftpsync-security.logftpsync.log.1 ftpsync-security.log.1 rsync-ftpsync.error.3 rsync-ftpsync.log.3 rsync-ftpsync-security.log.0ftpsync.log.2 rsync-ftpsync.error rsync-ftpsync.log rsync-ftpsync-security.error rsync-ftpsync-security.log.1ftpsync.log.3 rsync-ftpsync.error.0 rsync-ftpsync.log.0 rsync-ftpsync-security.error.0$ cat log/ftpsync-security.log.0 1月 10 19:38:10 hostname ftpsync-security[12253]: Mirrorsync start1月 10 19:38:10 hostname ftpsync-security[12253]: We got pushed from 10.13.70.861月 10 19:38:10 hostname ftpsync-security[12253]: Running mirrorsync, update is required, /home/mirror-user/mirrors/debian-security//Archive-Update-Required-hostname exists1月 10 19:38:10 hostname ftpsync-security[12253]: Running stage1: rsync --filter=exclude_/Archive-Update-in-Progress-hostname --filter=protect_/Archive-Update-in-Progress-hostname --filter=exclude_/Archive-Update-Required-hostname --filter=protect_/Archive-Update-Required-hostname --filter=exclude_/project/trace/hostname --filter=protect_/project/trace/hostname --filter=exclude_/project/trace/hostname-stage1 --filter=protect_/project/trace/hostname-stage1 --filter=exclude_/project/trace/_hierarchy --filter=protect_/project/trace/_hierarchy --filter=exclude_/project/trace/_traces --filter=protect_/project/trace/_traces --filter=include_/project/ --filter=protect_/project/ --filter=include_/project/trace/ --filter=protect_/project/trace/ --filter=include_/project/trace/* --exclude=.~tmp~/ --filter=exclude_/dists/**/binary-alpha/ --filter=exclude_/dists/**/installer-alpha/ --filter=exclude_/dists/**/Contents-alpha.gz --filter=exclude_/dists/**/Contents-udeb-alpha.gz --filter=exclude_/dists/**/Contents-alpha.diff/ --filter=exclude_/indices/**/arch-alpha.files --filter=exclude_/indices/**/arch-alpha.list.gz --filter=exclude_/pool/**/*_alpha.deb --filter=exclude_/pool/**/*_alpha.udeb --filter=exclude_/pool/**/*_alpha.changes --filter=exclude_/dists/**/binary-arm/ --filter=exclude_/dists/**/installer-arm/ --filter=exclude_/dists/**/Contents-arm.gz --filter=exclude_/dists/**/Contents-udeb-arm.gz --filter=exclude_/dists/**/Contents-arm.diff/ --filter=exclude_/indices/**/arch-arm.files --filter=exclude_/indices/**/arch-arm.list.gz --filter=exclude_/pool/**/*_arm.deb --filter=exclude_/pool/**/*_arm.udeb --filter=exclude_/pool/**/*_arm.changes --filter=exclude_/dists/**/binary-armel/ --filter=exclude_/dists/**/installer-armel/ --filter=exclude_/dists/**/Contents-armel.gz --filter=exclude_/dists/**/Contents-udeb-armel.gz --filter=exclude_/dists/**/Contents-armel.diff/ --filter=exclude_/indices/**/arch-armel.files --filter=exclude_/indices/**/arch-armel.list.gz --filter=exclude_/pool/**/*_armel.deb --filter=exclude_/pool/**/*_armel.udeb --filter=exclude_/pool/**/*_armel.changes --filter=exclude_/dists/**/binary-armhf/ --filter=exclude_/dists/**/installer-armhf/ --filter=exclude_/dists/**/Contents-armhf.gz --filter=exclude_/dists/**/Contents-udeb-armhf.gz --filter=exclude_/dists/**/Contents-armhf.diff/ --filter=exclude_/indices/**/arch-armhf.files --filter=exclude_/indices/**/arch-armhf.list.gz --filter=exclude_/pool/**/*_armhf.deb --filter=exclude_/pool/**/*_armhf.udeb --filter=exclude_/pool/**/*_armhf.changes --filter=exclude_/dists/**/binary-hppa/ --filter=exclude_/dists/**/installer-hppa/ --filter=exclude_/dists/**/Contents-hppa.gz --filter=exclude_/dists/**/Contents-udeb-hppa.gz --filter=exclude_/dists/**/Contents-hppa.diff/ --filter=exclude_/indices/**/arch-hppa.files --filter=exclude_/indices/**/arch-hppa.list.gz --filter=exclude_/pool/**/*_hppa.deb --filter=exclude_/pool/**/*_hppa.udeb --filter=exclude_/pool/**/*_hppa.changes --filter=exclude_/dists/**/binary-hurd-i386/ --filter=exclude_/dists/**/installer-hurd-i386/ --filter=exclude_/dists/**/Contents-hurd-i386.gz --filter=exclude_/dists/**/Contents-udeb-hurd-i386.gz --filter=exclude_/dists/**/Contents-hurd-i386.diff/ --filter=exclude_/indices/**/arch-hurd-i386.files --filter=exclude_/indices/**/arch-hurd-i386.list.gz --filter=exclude_/pool/**/*_hurd-i386.deb --filter=exclude_/pool/**/*_hurd-i386.udeb --filter=exclude_/pool/**/*_hurd-i386.changes --filter=exclude_/dists/**/binary-i386/ --filter=exclude_/dists/**/installer-i386/ --filter=exclude_/dists/**/Contents-i386.gz --filter=exclude_/dists/**/Contents-udeb-i386.gz --filter=exclude_/dists/**/Contents-i386.diff/ --filter=exclude_/indices/**/arch-i386.files --filter=exclude_/indices/**/arch-i386.list.gz --filter=exclude_/pool/**/*_i386.deb --filter=exclude_/pool/**/*_i386.udeb --filter=exclude_/pool/**/*_i386.changes --filter=exclude_/dists/**/binary-ia64/ --filter=exclude_/dists/**/installer-ia64/ --filter=exclude_/dists/**/Contents-ia64.gz --filter=exclude_/dists/**/Contents-udeb-ia64.gz --filter=exclude_/dists/**/Contents-ia64.diff/ --filter=exclude_/indices/**/arch-ia64.files --filter=exclude_/indices/**/arch-ia64.list.gz --filter=exclude_/pool/**/*_ia64.deb --filter=exclude_/pool/**/*_ia64.udeb --filter=exclude_/pool/**/*_ia64.changes --filter=exclude_/dists/**/binary-kfreebsd-amd64/ --filter=exclude_/dists/**/installer-kfreebsd-amd64/ --filter=exclude_/dists/**/Contents-kfreebsd-amd64.gz --filter=exclude_/dists/**/Contents-udeb-kfreebsd-amd64.gz --filter=exclude_/dists/**/Contents-kfreebsd-amd64.diff/ --filter=exclude_/indices/**/arch-kfreebsd-amd64.files --filter=exclude_/indices/**/arch-kfreebsd-amd64.list.gz --filter=exclude_/pool/**/*_kfreebsd-amd64.deb --filter=exclude_/pool/**/*_kfreebsd-amd64.udeb --filter=exclude_/pool/**/*_kfreebsd-amd64.changes --filter=exclude_/dists/**/binary-kfreebsd-i386/ --filter=exclude_/dists/**/installer-kfreebsd-i386/ --filter=exclude_/dists/**/Contents-kfreebsd-i386.gz --filter=exclude_/dists/**/Contents-udeb-kfreebsd-i386.gz --filter=exclude_/dists/**/Contents-kfreebsd-i386.diff/ --filter=exclude_/indices/**/arch-kfreebsd-i386.files --filter=exclude_/indices/**/arch-kfreebsd-i386.list.gz --filter=exclude_/pool/**/*_kfreebsd-i386.deb --filter=exclude_/pool/**/*_kfreebsd-i386.udeb --filter=exclude_/pool/**/*_kfreebsd-i386.changes --filter=exclude_/dists/**/binary-m68k/ --filter=exclude_/dists/**/installer-m68k/ --filter=exclude_/dists/**/Contents-m68k.gz --filter=exclude_/dists/**/Contents-udeb-m68k.gz --filter=exclude_/dists/**/Contents-m68k.diff/ --filter=exclude_/indices/**/arch-m68k.files --filter=exclude_/indices/**/arch-m68k.list.gz --filter=exclude_/pool/**/*_m68k.deb --filter=exclude_/pool/**/*_m68k.udeb --filter=exclude_/pool/**/*_m68k.changes --filter=exclude_/dists/**/binary-mipsel/ --filter=exclude_/dists/**/installer-mipsel/ --filter=exclude_/dists/**/Contents-mipsel.gz --filter=exclude_/dists/**/Contents-udeb-mipsel.gz --filter=exclude_/dists/**/Contents-mipsel.diff/ --filter=exclude_/indices/**/arch-mipsel.files --filter=exclude_/indices/**/arch-mipsel.list.gz --filter=exclude_/pool/**/*_mipsel.deb --filter=exclude_/pool/**/*_mipsel.udeb --filter=exclude_/pool/**/*_mipsel.changes --filter=exclude_/dists/**/binary-mips/ --filter=exclude_/dists/**/installer-mips/ --filter=exclude_/dists/**/Contents-mips.gz --filter=exclude_/dists/**/Contents-udeb-mips.gz --filter=exclude_/dists/**/Contents-mips.diff/ --filter=exclude_/indices/**/arch-mips.files --filter=exclude_/indices/**/arch-mips.list.gz --filter=exclude_/pool/**/*_mips.deb --filter=exclude_/pool/**/*_mips.udeb --filter=exclude_/pool/**/*_mips.changes --filter=exclude_/dists/**/binary-powerpc/ --filter=exclude_/dists/**/installer-powerpc/ --filter=exclude_/dists/**/Contents-powerpc.gz --filter=exclude_/dists/**/Contents-udeb-powerpc.gz --filter=exclude_/dists/**/Contents-powerpc.diff/ --filter=exclude_/indices/**/arch-powerpc.files --filter=exclude_/indices/**/arch-powerpc.list.gz --filter=exclude_/pool/**/*_powerpc.deb --filter=exclude_/pool/**/*_powerpc.udeb --filter=exclude_/pool/**/*_powerpc.changes --filter=exclude_/dists/**/binary-s390/ --filter=exclude_/dists/**/installer-s390/ --filter=exclude_/dists/**/Contents-s390.gz --filter=exclude_/dists/**/Contents-udeb-s390.gz --filter=exclude_/dists/**/Contents-s390.diff/ --filter=exclude_/indices/**/arch-s390.files --filter=exclude_/indices/**/arch-s390.list.gz --filter=exclude_/pool/**/*_s390.deb --filter=exclude_/pool/**/*_s390.udeb --filter=exclude_/pool/**/*_s390.changes --filter=exclude_/dists/**/binary-s390x/ --filter=exclude_/dists/**/installer-s390x/ --filter=exclude_/dists/**/Contents-s390x.gz --filter=exclude_/dists/**/Contents-udeb-s390x.gz --filter=exclude_/dists/**/Contents-s390x.diff/ --filter=exclude_/indices/**/arch-s390x.files --filter=exclude_/indices/**/arch-s390x.list.gz --filter=exclude_/pool/**/*_s390x.deb --filter=exclude_/pool/**/*_s390x.udeb --filter=exclude_/pool/**/*_s390x.changes --filter=exclude_/dists/**/binary-sh/ --filter=exclude_/dists/**/installer-sh/ --filter=exclude_/dists/**/Contents-sh.gz --filter=exclude_/dists/**/Contents-udeb-sh.gz --filter=exclude_/dists/**/Contents-sh.diff/ --filter=exclude_/indices/**/arch-sh.files --filter=exclude_/indices/**/arch-sh.list.gz --filter=exclude_/pool/**/*_sh.deb --filter=exclude_/pool/**/*_sh.udeb --filter=exclude_/pool/**/*_sh.changes --filter=exclude_/dists/**/binary-sparc/ --filter=exclude_/dists/**/installer-sparc/ --filter=exclude_/dists/**/Contents-sparc.gz --filter=exclude_/dists/**/Contents-udeb-sparc.gz --filter=exclude_/dists/**/Contents-sparc.diff/ --filter=exclude_/indices/**/arch-sparc.files --filter=exclude_/indices/**/arch-sparc.list.gz --filter=exclude_/pool/**/*_sparc.deb --filter=exclude_/pool/**/*_sparc.udeb --filter=exclude_/pool/**/*_sparc.changes --filter=include_/dists/**/binary-*/ --filter=include_/dists/**/installer-*/ --filter=include_/dists/**/Contents-*.gz --filter=include_/dists/**/Contents-udeb-*.gz --filter=include_/dists/**/Contents-*.diff/ --filter=include_/indices/**/arch-*.files --filter=include_/indices/**/arch-*.list.gz --filter=include_/pool/**/*_*.deb --filter=include_/pool/**/*_*.udeb --filter=include_/pool/**/*_*.changes --filter=include_/dists/**/source/ --filter=include_/pool/**/*.tar.* --filter=include_/pool/**/*.diff.* --filter=include_/pool/**/*.dsc mirrors.ustc.edu.cn::debian-security /home/mirror-user/mirrors/debian-security/ --bwlimit=0 -prltvHSB8192 --safe-links --chmod=D755,F644 --timeout 3600 --stats --no-human-readable --include=*.diff/ --exclude=*.diff/Index --exclude=Packages* --exclude=Sources* --exclude=Release* --exclude=InRelease --include=i18n/by-hash --exclude=i18n/* --exclude=ls-lR*1月 10 19:38:11 hostname ftpsync-security[12253]: Back from rsync with returncode 51月 10 19:38:11 hostname ftpsync-security[12253]: ERROR: Sync step 1 went wrong, got errorcode 5. Logfile: /home/mirror-user/log/ftpsync-security.log1月 10 19:39:12 hostname ftpsync-security[12253]: Mirrorsync done$ cat log/rsync-ftpsync-security.error.0@ERROR: Unknown module 'debian-security'rsync error: error starting client-server protocol (code 5) at main.c(1653) [Receiver=3.1.1] 镜像总大小详见官方的镜像大小记录，每日更新，https://www.debian.org/mirror/size。 如果要减少镜像的大小，需要配置 ARCH_INCLUDE=，ARCH_EXCLUDE 要排除太多东西。 1234mirror$ du -hd 135G ./debian-security487G ./debian522G . 设置本地 mirror搭建局域网镜像源服务器见 (http://www.cnblogs.com/beynol/p/nginx-simple-file-server.html) 该链已失效。。 安装 nginx, sudo apt-get install nginx 配置 /etc/nginx/conf.d/files_server.conf 重启 nginx 服务，sudo service nginx restart 12345678910111213cat /etc/nginx/conf.d/files_server.confserver &#123; listen 80; server_name 192.168.250.250; charset utf-8; root /home/mirror/mirror; location / &#123; autoindex on; autoindex_exact_size on; autoindex_localtime on; &#125;&#125; debian OS 中的 sources.list 配置 sources.list 123456deb [trusted=yes] http://192.168.250.250/debian jessie main contrib non-freedeb-src [trusted=yes] http://192.168.250.250/debian jessie main contrib non-freedeb [trusted=yes] http://192.168.250.250/debian jessie-updates maindeb-src [trusted=yes] http://192.168.250.250/debian jessie-updates maindeb [trusted=yes] http://192.168.250.250/debian-security jessie/updates main contrib non-freedeb-src [trusted=yes] http://192.168.250.250/debian-security jessie/updates main contrib non-free apt-get update 1234567891011121314151617181920212223242526$ docker run -it debian:jessie bashroot@bc80cd6b79e9:/# cd /etc/apt/root@bc80cd6b79e9:/etc/apt# apt-get updateIgn http://192.168.250.250 jessie InReleaseGet:1 http://192.168.250.250 jessie-updates InRelease [145 kB]Get:2 http://192.168.250.250 jessie/updates InRelease [94.4 kB]Get:3 http://192.168.250.250 jessie Release.gpg [2434 B]Get:4 http://192.168.250.250 jessie Release [148 kB]Get:5 http://192.168.250.250 jessie-updates/main Sources [20.8 kB]Get:6 http://192.168.250.250 jessie-updates/main amd64 Packages [23.1 kB]Get:7 http://192.168.250.250 jessie/updates/main Sources [279 kB]Get:8 http://192.168.250.250 jessie/updates/contrib Sources [1298 B]Get:9 http://192.168.250.250 jessie/updates/non-free Sources [20 B]Get:10 http://192.168.250.250 jessie/updates/main amd64 Packages [644 kB]Get:11 http://192.168.250.250 jessie/updates/contrib amd64 Packages [2366 B]Get:12 http://192.168.250.250 jessie/updates/non-free amd64 Packages [20 B]Get:13 http://192.168.250.250 jessie/main Sources [9167 kB]Get:14 http://192.168.250.250 jessie/contrib Sources [58.9 kB]Get:15 http://192.168.250.250 jessie/non-free Sources [119 kB]Get:16 http://192.168.250.250 jessie/main amd64 Packages [9064 kB]Get:17 http://192.168.250.250 jessie/contrib amd64 Packages [59.2 kB]Get:18 http://192.168.250.250 jessie/non-free amd64 Packages [101 kB]Fetched 19.9 MB in 4s (4019 kB/s)Reading package lists...Reading package lists... Doneroot@bc80cd6b79e9:/etc/apt# 问题记录Update 失败。原因：ftpsync 可能不是一次性能能完成下载，需要下载比较久。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455root@b58bb3484992:/# cat etc/apt/sources.listdeb http://192.168.250.250/debian stretch maindeb http://192.168.250.250/debian stretch-updates maindeb http://192.168.250.250/debian-security stretch/updates mainroot@b58bb3484992:/# cat etc/apt/sources.listdeb http://192.168.250.250/debian stretch maindeb http://192.168.250.250/debian stretch-updates maindeb http://192.168.250.250/debian-security stretch/updates mainroot@b58bb3484992:/# root@b58bb3484992:/# apt-get updateIgn:1 http://192.168.250.250/debian stretch InReleaseIgn:2 http://192.168.250.250/debian stretch-updates InReleaseGet:3 http://192.168.250.250/debian-security stretch/updates InRelease [63.0 kB]Ign:4 http://192.168.250.250/debian stretch ReleaseIgn:5 http://192.168.250.250/debian stretch-updates ReleaseIgn:6 http://192.168.250.250/debian stretch/main all PackagesIgn:7 http://192.168.250.250/debian stretch/main amd64 PackagesIgn:8 http://192.168.250.250/debian stretch-updates/main amd64 PackagesIgn:9 http://192.168.250.250/debian stretch-updates/main all PackagesIgn:6 http://192.168.250.250/debian stretch/main all PackagesIgn:7 http://192.168.250.250/debian stretch/main amd64 PackagesIgn:8 http://192.168.250.250/debian stretch-updates/main amd64 PackagesIgn:9 http://192.168.250.250/debian stretch-updates/main all PackagesIgn:6 http://192.168.250.250/debian stretch/main all PackagesIgn:7 http://192.168.250.250/debian stretch/main amd64 PackagesIgn:8 http://192.168.250.250/debian stretch-updates/main amd64 PackagesIgn:9 http://192.168.250.250/debian stretch-updates/main all PackagesIgn:6 http://192.168.250.250/debian stretch/main all PackagesIgn:7 http://192.168.250.250/debian stretch/main amd64 PackagesIgn:8 http://192.168.250.250/debian stretch-updates/main amd64 PackagesIgn:9 http://192.168.250.250/debian stretch-updates/main all PackagesIgn:6 http://192.168.250.250/debian stretch/main all PackagesIgn:7 http://192.168.250.250/debian stretch/main amd64 PackagesIgn:8 http://192.168.250.250/debian stretch-updates/main amd64 PackagesIgn:9 http://192.168.250.250/debian stretch-updates/main all PackagesIgn:6 http://192.168.250.250/debian stretch/main all PackagesErr:7 http://192.168.250.250/debian stretch/main amd64 Packages 404 Not FoundErr:8 http://192.168.250.250/debian stretch-updates/main amd64 Packages 404 Not FoundIgn:9 http://192.168.250.250/debian stretch-updates/main all PackagesGet:10 http://192.168.250.250/debian-security stretch/updates/main amd64 Packages [333 kB]Fetched 396 kB in 0s (1023 kB/s) Reading package lists... DoneW: The repository 'http://192.168.250.250/debian stretch Release' does not have a Release file.N: Data from such a repository can't be authenticated and is therefore potentially dangerous to use.N: See apt-secure(8) manpage for repository creation and user configuration details.W: The repository 'http://192.168.250.250/debian stretch-updates Release' does not have a Release file.N: Data from such a repository can't be authenticated and is therefore potentially dangerous to use.N: See apt-secure(8) manpage for repository creation and user configuration details.E: Failed to fetch http://192.168.250.250/debian/dists/stretch/main/binary-amd64/Packages 404 Not FoundE: Failed to fetch http://192.168.250.250/debian/dists/stretch-updates/main/binary-amd64/Packages 404 Not FoundE: Some index files failed to download. They have been ignored, or old ones used instead.root@b58bb3484992:/# 使用 apt-mirror 出现的问题以下贴出 USTC 同学的邮件往来记录，谢谢 USTC LUG！ 发现问题： 12345678910111213141516因本地开发网与外网隔离，想做一个本地镜像站，但是发出使用 apt-mirror 做镜像时，通常下载一小会儿的时候就会 connection refused，此时正常使用也使用不了。请问是否 USTC mirror 对使用者的下载有限制，如果有限制，我应该如何做自己的本地镜像站？Need to get 136 kB of source archives.Err http://ftp.cn.debian.org/debian/ jessie/main tcp-wrappers 7.6.q-25 (dsc) Could not connect to mirrors.ustc.edu.cn:80 (202.141.160.110). - connect (111: Connection refused) [IP: 202.141.160.110 80]Err http://ftp.cn.debian.org/debian/ jessie/main tcp-wrappers 7.6.q-25 (tar) Unable to connect to mirrors.ustc.edu.cn:http: [IP: 202.141.160.110 80]Err http://ftp.cn.debian.org/debian/ jessie/main tcp-wrappers 7.6.q-25 (diff) Unable to connect to mirrors.ustc.edu.cn:http: [IP: 202.141.160.110 80]E: Failed to fetch http://ftp.cn.debian.org/debian/pool/main/t/tcp-wrappers/tcp-wrappers_7.6.q-25.dsc Could not connect to mirrors.ustc.edu.cn:80 (202.141.160.110). - connect (111: Connection refused) [IP: 202.141.160.110 80]E: Failed to fetch http://ftp.cn.debian.org/debian/pool/main/t/tcp-wrappers/tcp-wrappers_7.6.q.orig.tar.gz Unable to connect to mirrors.ustc.edu.cn:http: [IP: 202.141.160.110 80]E: Failed to fetch http://ftp.cn.debian.org/debian/pool/main/t/tcp-wrappers/tcp-wrappers_7.6.q-25.debian.tar.xz Unable to connect to mirrors.ustc.edu.cn:http: [IP: 202.141.160.110 80]E: Failed to fetch some archives. Request more log 1请您尝试重现这个故障， 并在故障发生时执行 curl -vvLI http://mirrors.ustc.edu.cn/debian/README12请反馈该命令的完整输出。 Reply more log 123456789101112131415161718192021222324252627282930313233Log 如下所示$ curl -vvLI http://mirrors.ustc.edu.cn/debian/README* Trying 202.38.95.110...* connect to 202.38.95.110 port 80 failed: Connection refused* Trying 202.141.160.110...* connect to 202.141.160.110 port 80 failed: Connection refused* Trying 2001:da8:d800:95::110...* Immediate connect fail for 2001:da8:d800:95::110: Network is unreachable* Trying 2001:da8:d800:95::110...* Immediate connect fail for 2001:da8:d800:95::110: Network is unreachable* Failed to connect to mirrors.ustc.edu.cn port 80: Connection refused* Closing connection 0curl: (7) Failed to connect to mirrors.ustc.edu.cn port 80: Connection refused$ ping mirrors.ustc.edu.cnPING mirrors.ustc.edu.cn (202.141.160.110) 56(84) bytes of data.64 bytes from 202.141.160.110: icmp_seq=1 ttl=52 time=26.4 ms64 bytes from 202.141.160.110: icmp_seq=2 ttl=52 time=25.5 ms^C--- mirrors.ustc.edu.cn ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1001msrtt min/avg/max/mdev = 25.533/25.994/26.455/0.461 ms$ ping 202.38.95.110PING 202.38.95.110 (202.38.95.110) 56(84) bytes of data.64 bytes from 202.38.95.110: icmp_seq=1 ttl=46 time=80.9 ms64 bytes from 202.38.95.110: icmp_seq=2 ttl=46 time=76.6 ms^C--- 202.38.95.110 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1001msrtt min/avg/max/mdev = 76.614/78.759/80.905/2.163 ms 反馈 123456789101112131415161718你好！目前mirrors有两类流控措施：1. TCP并发连接数限制2. HTTP请求频率限制根据您的反馈，我认为可能是触发了连接数限制。 目前HTTP/HTTPS类请求的连接数限制为11。第12个http连接将返回tcp reset。请议尝试降低apt-mirror的并发线程数量，然后重试一次。我们不推荐使用apt-mirorr执行大量同步，这是由于HTTP协议有较大的额外开销，会显著增加服务器负载。建议您使用rsync协议同步软件仓库，这也是debian官方向下游镜像分发软件包的协议。不仅传输速度更快，而且不需要繁琐的apt-mirror配置。可以使用debian官方制作的ftpsync脚本（虽然叫ftpsync，但实际上是rsync命令的包装），ftpsync能很好得解决当上游正在更新时，下游同步结果不一致的问题。也可以直接调用rsync命令，参考指令如下：rsync -avH --progress rsync.mirrors.ustc.edu.cn::debian/ path/to/local/storage/如果任何疑问，欢迎来信交流。祝好 确认问题原因 12345678谢谢你的回复！apt-mirror 的默认并连接数为 20 个，超过 11 个了。好的，接下来我尝试用 ftpsync 做。非常感谢！Regards,sunnogo]]></content>
      <categories>
        <category>administrator</category>
      </categories>
      <tags>
        <tag>administrator</tag>
        <tag>debian</tag>
        <tag>mirror</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线缆和端口形态总结]]></title>
    <url>%2F201712%2Fnetworks%2Fcables_and_ports.html</url>
    <content type="text"><![CDATA[详见 数据中心线缆基础架构。 Serdes 10G NRZ 25G NRZ 50G NRZ… 50G PAM4 100G PAM4 端口形态10G25G40G100G线缆CATCAT5CAT6CAT7AOC, DAC, ACC, 2 Transceivers with Structured Cabling Active Optical Cable，AOC，译为有源光缆。将 2 只光模块与光缆封装在一起，这种线缆都不可更换模块。 Passive Direct Attach Cable，DAC, 这种线缆都不可更换端口，模块头和铜缆不能分离。重、短。 Active Direct Attach Cable, 也有称 Active Copper Cables, ACC。与 DAC 相似，但是在 transceiver connectors 中加入微处理器和一些电路放大信号（也称“线性放大芯片”）。 详见 4 ADVANTAGES OF DIRECT ATTACH CABLING (DAC)。 。 光模块Transceivers MAU GBIC SFP XENPAK X2 XFP SFP+ QSFP CFP GBIC，高速以太网路界面转换器（英文：Gigabit Interface Converter，简称GBIC） SFP，小封装热插拔收发器（SFP, Small form-factor pluggable transceiver），mini GBIC，1Gbps SFP+，10Gbps SFP28，25Gbps QSFP，Quad SFP，4x1Gbps QSFP+，4x10Gbps QSFP28，4x25Gbps QSFP56，4x50Gbps QSFPDD，4x2x25Gbps，或者4x2x50Gbps 连接器类型https://en.wikipedia.org/wiki/Optical_fiber_connector LC MPO 其他 Number of Lanes: 1, 2, 4, 8, 16 Number of PMDs: KR, CR, SR, PSM, CWDM, LR, ER Number of FECs: KR, RS(528,514), RS(544, 514) IEEE 命名： xxxBASEmRn PMD]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>cable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Path MTU 概述]]></title>
    <url>%2F201712%2Fnetworks%2Fpath_mtu.html</url>
    <content type="text"><![CDATA[结论 概念 PMTU，Path MTU，以路由为单位，作为路由表的属性信息缓存于路由表。 PMTU发现机制，若网络设备收到超MTU IP报文且该IP报文不允许分片，则返回一个ICMP type 3 code 4报文（The datagram is too big. Packet fragmentation is required but the &#39;don&#39;t fragment&#39; (DF) flag is on.），将网络设备支持的MTU大小附在ICMP报文中，返回给报文源主机，由报文源主机调整该路径的PMTU。该机制利用IP头部flags中的Don&#39;t fragment位，为1时表示不允许分片。 影响。在GRE IP隧道叠加网中，报文将在IP头部后添加上24字节GRE IP头部。以默认IP MTU为1500字节为例，原先一个1514字节大小的报文（IP头部 + 数据刚好为IP MTU 1500字节）在公网上可以正常传输，若此时将路径切换到GRE IP隧道叠加网，则报文长度将变成1528字节（IP头部 + 数据 = 1524字节），将超过默认IP MTU。详见 H3C 文章 看招MTU!!!——高端路由器GRE组网中需要注意的问题。 如果分片发生在旁挂设备，则将导致GRE IP报文被分片，无法在隧道终结处重组，因为第二个分片不带GRE头部。 IP报文不允许分片 对于TCP报文 将通过PMTU发现机制，调整主机PMTU 通过快速重传机制，迅速恢复 主机调整TCP报文大小，以适应PMTU 对于UDP报文 将通过PMTU发现机制，调整主机PMTU 丢弃该报文 后续传输时，对超过PMTU的报文，在主机处主动进行分片。 若有需要，超时重传、调整报文大小的机制由UDP的上层协议支持。 对于其他IP报文（以ping报文为例） 将通过PMTU发现机制，调整主机PMTU 丢弃该报文 后续传输时，在主机处主动分片（以Linux为例） IP报文允许分片 如果业务开始前，主机已经调整PMTU，则分片在主机进行，业务可正常运行。 如果主机未调整PMTU，则分片在旁挂设备进行，将导致业务中断。此问题将影响整个方案。 规避手段 规避目标：将分片的行为转移至主机上，不允许旁挂设备上进行任何分片行为。 方案：对所有超IP MTU送旁挂设备CPU的报文，皆返回ICMP type 3 code 4。需验证此规避对允许分片IP报文的影响。 风险：对控制面和管理面的影响待评估。 分析 Linux PMTU发现机制默认为IP_PMTUDISC_WANT，如果报文不超过PMTU，默认开启PMTU发现机制，如果报文超过PMTU，则主动在终端进行分片处理。（will fragment a datagram if needed according to the path MTU, or will set the don’t-fragment flag otherwise.） Windows TCP报文，默认不允许分片 其他报文，默认允许分片 对允许分片的报文，如果报文长度超过PMTU，则主动在终端处进行分片 不能假定网络上的所有的TCP报文都不允许分片（如新浪网，默认TCP报文允许分片） 实验结果 系统 协议 默认是否加DF 默认对超PMTU的处理 Linux TCP 是 调整TCP段长度 Linux UDP 是 不做处理，用户程序处理 Linux RTSP（UDP） 是 丢掉ICMP packet too big的那几个包，后续分片 Linux TFTP（UDP） 是 等不到ACK，timeout退出 Linux ping 是 不重传报文，主机提示From 3.3.3.3 icmp_seq=93 Frag needed and DF set (mtu = 0)，后开始在主机对ping报文进行分片，分片后的报文DF=0；如果强制设置DF：-M = do，则提示ping: local error: Message too long, mtu=552 Linux TCP(自己构造) 否 默认在交换机中送CPU分片，如果此时有一个ICMP packet too big返回至主机（比如由ping触发），则会转在主机分片 Windows TCP 是 调整TCP段长度 Windows UDP 否 被路由器分片或被主机分片 Windows ping 否 无处理，在交换机中分片，如果此时有ICMP packet too big（如TCP触发），则会主动在终端分片。如果强制设置DF：-f，则提示Packet needs to be fragmented but DF set. 如上实验结果，得出以下结论： Linux下，TCP/UDP报文默认都置上DF位； Windows下，TCP报文默认置上DF位，UDP报文默认不置DF位； Linux下，UDP的对ICMP packet too big报文的处理取决于用户，Linux内核不进行处理 不管Linux还是Windows下，如果要发出的UDP报文大于PMTU，则会主动在HOST端进行分片。 PMTU以路由（SIP + DIP + TOS）为单位影响系统，UDP虽然没有主动调整数据报的大小，但是因UDP报文返回的ICMP packet too big报文会影响对应路由的PMTU。 标准 RFC 1191 Path MTU Discovery RFC 4821 Packetization Layer Path MTU Discovery 按RFC 1191的定义，PMTU发现机制为Packetization Protocol服务，TCP是这种可调节报文大小的协议，因此可直接使用；而UDP协议需要靠上层协议来实现报文大小调整。 RFC 1191 第6章“Host Implementation”讲述PMTU Discovery对终端的建议（仅仅是suggestion，不是specification）： 在哪个或哪些层次实现PMTU发现机制； 由IP以上层次决定报文要发多大； Pakcetization Protocol必须能影响PMTU变化，含更新报文大小、控制DF位。（IP层不控制DF位） PMTU信息缓存在哪； 把PMTU做为路由表项的一个属性成员。 对于UDP这种无连接的报文，若返回ICMP packet too big，需要其上层协议通过超时重传机制，重传被dropped的报文。 旧PMTU信息如何被老化； PMTU如何上涨； Linux的处理Linux Kernel的实现参考：man 7 ip 中关于IP_MTU_DISCOVER的描述。 IP_MTU_DISCOVER (since Linux 2.2)Set or receive the Path MTU Discovery setting for a socket. When enabled, Linux will perform Path MTU Discovery as defined in RFC 1191 on SOCK_STREAM sockets. For non-SOCK_STREAM sockets, IP_PMTUDISC_DO forces the don’t-fragment flag to be set on all outgoing packets. It is the user’s responsibility to packetize the data in MTU-sized chunks and to do the retransmits if necessary. The kernel will reject (with EMSGSIZE) datagrams that are bigger than the known path MTU. IP_PMTUDISC_WANT will fragment a datagram if needed according to the path MTU, or will set the don’t-fragment flag otherwise. The system-wide default can be toggled between IP_PMTUDISC_WANT and IP_PMTUDISC_DONT by writing (respectively, zero and nonzero values) to the /proc/sys/net/ipv4/ip_no_pmtu_disc file. When PMTU discovery is enabled, the kernel automatically keeps track of the path MTU per destination host. When it is connected to a specific peer with connect(2), the currently known path MTU can be retrieved conveniently using the IP_MTU socket option (e.g., after an EMSGSIZE error occurred). The path MTU may change over time. For connectionless sockets with many destinations, the new MTU for a given destination can also be accessed using the error queue (see IP_RECVERR). A new error will be queued for every incoming MTU update. While MTU discovery is in progress, initial packets from datagram sockets may be dropped. Applications using UDP should be aware of this and not take it into account for their packet retransmit strategy. To bootstrap the path MTU discovery process on unconnected sockets, it is possible to start with a big datagram size (up to 64K-headers bytes long) and let it shrink by updates of the path MTU. To get an initial estimate of the path MTU, connect a datagram socket to the destination address using connect(2) and retrieve the MTU by calling getsockopt(2) with the IP_MTU option. It is possible to implement RFC 4821 MTU probing with SOCK_DGRAM or SOCK_RAW sockets by setting a value of IP_PMTUDISC_PROBE (available since Linux 2.6.22). This is also particularly useful for diagnostic tools such as tracepath(8) that wish to deliberately send probe packets larger than the observed Path MTU.]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>packet</tag>
        <tag>MTU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核源码处理ICMP packet too big与DF]]></title>
    <url>%2F201712%2Fnetworks%2Fkernel_handle_rfc1191.html</url>
    <content type="text"><![CDATA[RFC 1191 man 7 ip 结论 ICMP packet too big对ICMP packet too big的处理，TCP/UDP最终都对对应路由条目进行MTU更新。而TCP的MTU、MSS、窗口大小和最终段大小的关系比较复杂，目前没有看明白。 Don’t fragmentDF位的默认配置，受系统配置控制，Ubuntu 14.04默认开启MTU发现功能。推断结果：UDP大报文默认未置上，而TCP大报文默认置上。 Linux内核如何处理ICMP Packet too bigICMP流程报文类型：1223 #define ICMP_DEST_UNREACH 3 /* Destination Unreachable */43 #define ICMP_FRAG_NEEDED 4 /* Fragmentation Needed/DF set */ icmp_rcv(struct sk_buff *skb)，根据ICMP类型处理skb：1icmp_pointers[icmph-&gt;type].handler(skb); icmp_pointers的定义显示，ICMP_DEST_UNRAECH的handler为icmp_unreach，后者获取出ICMP头部的mtu后，投递给icmp_socket_deliver(skb, mtu)。icmp_socket_deliver最终将skb和mtu值投递给ipprot-&gt;err_handler(skb, info); TCP流程tcp_v4_err(skb, info)，调用tcp_v4_mtu_reduced(struct sock *sk) 更新路由的MTU，inet_csk_update_pmtu(struct sock *sk, u32 mtu)找到路由inet_csk_rebuild_route(sk, &amp;inet-&gt;cork.fl);更新路由MTUdst-&gt;ops-&gt;update_pmtu(dst, sk, NULL, mtu); tcp_v4_err，如果MTU变小，且可分片，则会tcp_sync_mss(struct sock *sk, u32 pmtu)。关于TCP的MSS与MTU相关的内容很多： 123456789101112131415161718192021221274 /* This function synchronize snd mss to current pmtu/exthdr set.1275 1276 tp-&gt;rx_opt.user_mss is mss set by user by TCP_MAXSEG. It does NOT counts1277 for TCP options, but includes only bare TCP header.1278 1279 tp-&gt;rx_opt.mss_clamp is mss negotiated at connection setup.1280 It is minimum of user_mss and mss received with SYN.1281 It also does not include TCP options.1282 1283 inet_csk(sk)-&gt;icsk_pmtu_cookie is last pmtu, seen by this function.1284 1285 tp-&gt;mss_cache is current effective sending mss, including1286 all tcp options except for SACKs. It is evaluated,1287 taking into account current pmtu, but never exceeds1288 tp-&gt;rx_opt.mss_clamp.1289 1290 NOTE1. rfc1122 clearly states that advertised MSS1291 DOES NOT include either tcp or ip options.1292 1293 NOTE2. inet_csk(sk)-&gt;icsk_pmtu_cookie and tp-&gt;mss_cache1294 are READ ONLY outside this function. --ANK (980731)1295 */ 处理TCP MSS未看懂。 UDP流程__udp4_lib_err(struct sk_buff skb, u32 info, struct udp_table udptable)ipv4_sk_update_pmtu(struct sk_buff skb, struct sock sk, u32 mtu)，也是基于路由更新MTU。__ip_rt_update_pmtu ping报文的处理也是类似，见ping_err。 Linux内核对DF的默认处理经阅读代码，发现控制DF标志的地方主要有两处： inet_sock.pmtudisc sk_buff.local_df 以关键字pmtudisc和local_df做全局字符串搜索，发现对pmtudisc和local_df有赋值的地方很少。如下各小节分析。 另附：IP MTU DISCOVER相关宏1234590 /* IP_MTU_DISCOVER values */91 #define IP_PMTUDISC_DONT 0 /* Never send DF frames */92 #define IP_PMTUDISC_WANT 1 /* Use per route hints */93 #define IP_PMTUDISC_DO 2 /* Always DF */94 #define IP_PMTUDISC_PROBE 3 /* Ignore dst pmtu */ IP报文发送出口源代码：ip_queue_xmit和__ip_make_skb，后者用于UDP。 1234567891011382 if (ip_dont_fragment(sk, &amp;rt-&gt;dst) &amp;&amp; !skb-&gt;local_df)383 iph-&gt;frag_off = htons(IP_DF);384 else385 iph-&gt;frag_off = 0;248 int ip_dont_fragment(struct sock *sk, struct dst_entry *dst)249 &#123;250 return inet_sk(sk)-&gt;pmtudisc == IP_PMTUDISC_DO ||251 (inet_sk(sk)-&gt;pmtudisc == IP_PMTUDISC_WANT &amp;&amp;252 !(dst_metric_locked(dst, RTAX_MTU)));253 &#125; AF_INET协议族inet_create，依赖ipv4_config配置。该配置体现在/proc/sys/net/ipv4/ip_no_pmtu_disc，目前Ubuntu 14.04上默认ip_no_pmtu_disc=0，即由每个路由确定。 1234374 if (ipv4_config.no_pmtu_disc)375 inet-&gt;pmtudisc = IP_PMTUDISC_DONT;376 else377 inet-&gt;pmtudisc = IP_PMTUDISC_WANT; 系统配置可用sysctl命令配置，或通过/etc/sysctl.conf配置文件配置ip_no_pmtu_disc值，最终体现在/proc/sys/net/ipv4/ip_no_pmtu_disc。源码链接。 ICMP报文默认创建ICMP sk时，不发送DF报文。icmp_sk_init(struct net *net)。 PS：ICMP报文不超过576字节的限制在icmp_send接口中有体现。]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>packet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建 gitlab 服务器]]></title>
    <url>%2F201712%2Fadministrator%2Fgitlab.html</url>
    <content type="text"><![CDATA[apt-get install gitlab-ce 失败问题 log: gem devise-two-factor 的依赖关系得不到满足。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859Setting up ruby-paranoia (2.1.3-1) ...Setting up gitlab (8.5.8+dfsg-5) ...Creating/updating gitlab user account...adduser: Warning: The home directory `/var/lib/gitlab' does not belong to the user you are currently creating.Creating runtime directories for gitlab...Updating file permissions...Configuring hostname and email...Registering /etc/gitlab/gitlab.yml via ucfCreating config file /etc/gitlab/gitlab.yml with new versionRegistering /etc/gitlab/gitlab-debian.conf via ucfCreating config file /etc/gitlab/gitlab-debian.conf with new versionCreating config file /etc/nginx/sites-available/localhost with new versionReloading nginx configuration...Create database if not presentpsql: FATAL: database "gitlab_production" does not existpsql: FATAL: role "gitlab" does not existCreate gitlab user with create database privillege...CREATE ROLEMake gitlab user owner of gitlab_production database...ALTER DATABASEGrant all privileges to gitlab user...GRANTVerifying we have all required libraries...Could not find gem 'devise-two-factor (~&gt; 2.0.0)' in any of the gem sourceslisted in your Gemfile or available on this machine.dpkg: error processing package gitlab (--configure): subprocess installed post-installation script returned error exit status 7Setting up ruby-debug-inspector (0.0.2-1.1build3) ...Setting up ruby-binding-of-caller (0.7.2+debian1-3) ...Setting up ruby-bson (1.10.0-2) ...Setting up ruby-bson-ext (1.10.0-2build5) ...Setting up ruby-columnize (0.9.0-1) ...Setting up ruby-byebug (5.0.0-1build3) ...Setting up ruby2.3-dev:amd64 (2.3.1-2~16.04.2) ...Setting up ruby-dev:amd64 (1:2.3.0+1) ...Setting up ruby-ffi (1.9.10debian-1build2) ...Setting up ruby-jbuilder (2.3.1-1) ...Setting up ruby-libvirt (0.5.1-3build5) ...Setting up ruby-rb-inotify (0.9.7-1) ...Setting up ruby-listen (3.0.3-3) ...Setting up ruby-msgpack (0.6.2-1build4) ...Setting up ruby-rabl (0.11.4-2) ...Setting up ruby-rabl-rails (0.4.1-1) ...Setting up ruby-sdoc (0.4.1-1) ...Setting up ruby-spring (1.3.6-2) ...Setting up ruby-sqlite3 (1.3.11-2build1) ...Setting up ruby-web-console (2.2.1-2) ...Processing triggers for libc-bin (2.23-0ubuntu9) ...Processing triggers for systemd (229-4ubuntu19) ...Processing triggers for ureadahead (0.100.0-19) ...Processing triggers for ufw (0.35-0ubuntu2) ...Errors were encountered while processing: gitlabE: Sub-process /usr/bin/dpkg returned an error code (1)netadmin@kmc-b0232:~$ 改用官方最新的 deb 包详见 https://packages.gitlab.com/gitlab/gitlab-ce/install， curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash sudo apt-get install gitlab-ce 123456789101112netadmin@kmc-b0232:~$ curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bashDetected operating system as Ubuntu/xenial.Checking for curl...Detected curl...Running apt-get update... done.Installing apt-transport-https... done.Installing /etc/apt/sources.list.d/gitlab_gitlab-ce.list...done.Importing packagecloud gpg key... done.Running apt-get update... done.The repository is setup! You can now install packages.netadmin@kmc-b0232:~$ 配置目前还未配置邮件发送。 nginxgitlab 默认使用 nginx。安装完后 nginx sites-enabled 有两个，我把 default 直接删了。然后把另一个的 server_name 改成自己的 ip。修改完记得 sudo service nginx restart。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667netadmin@kmc-b0232:/etc/nginx/sites-available$ ls ../sites-enabled/ -altotal 8drwxr-xr-x 2 root root 4096 12月 13 19:42 .drwxr-xr-x 6 root root 4096 12月 13 19:40 ..lrwxrwxrwx 1 root root 36 12月 13 14:23 gitlab -&gt; /etc/nginx/sites-available/localhostnetadmin@kmc-b0232:/etc/nginx/sites-available$ cat gitlab## GitLab#### Lines starting with two hashes (##) are comments with information.## Lines starting with one hash (#) are configuration parameters that can be uncommented.###################################### CONTRIBUTING ######################################## If you change this file in a Merge Request, please also create## a Merge Request on https://gitlab.com/gitlab-org/omnibus-gitlab/merge_requests####################################### configuration ######################################### See installation.md#using-https for additional HTTPS configuration details.upstream gitlab-workhorse &#123; server unix:/run/gitlab/gitlab-workhorse.socket fail_timeout=0;&#125;## Normal HTTP hostserver &#123; ## Either remove "default_server" from the listen line below, ## or delete the /etc/nginx/sites-enabled/default file. This will cause gitlab ## to be served if you visit any address that your server responds to, eg. ## the ip address of the server (http://x.x.x.x/)n 0.0.0.0:80 default_server; listen 0.0.0.0:80; listen [::]:80; server_name your_url_or_your_ip; ## Replace this with something like gitlab.example.com server_tokens off; ## Don't show the nginx version number, a security best practice root /usr/share/gitlab/public; ## See app/controllers/application_controller.rb for headers set ## Individual nginx logs for this GitLab vhost access_log /var/log/nginx/gitlab_access.log; error_log /var/log/nginx/gitlab_error.log; location / &#123; client_max_body_size 0; gzip off; ## https://github.com/gitlabhq/gitlabhq/issues/694 ## Some requests take more than 30 seconds. proxy_read_timeout 300; proxy_connect_timeout 300; proxy_redirect off; proxy_http_version 1.1; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_pass http://gitlab-workhorse; &#125;&#125;netadmin@kmc-b0232:/etc/nginx/sites-available$ gitlab 配置在 /etc/gitlab 目录下，将以下两个文件各一处配置改成你的本机 IP。（我目前只想在局域网内访问 gitlab 服务器） gitlab.rb:external_url ‘http://your_url_or_your_ip&#39; gitlab.yml: host: your_ip 修改完后 sudo gitlab-ctl restart （还不清楚与 sudo gitlab-ctl reconfigure 的差异），即可通过 IP 访问到本地 gitlab 服务器。 备份备份功能官方说明文档，详见 https://docs.gitlab.com/omnibus/settings/backups.html。这里只讲直接运行在 host 主机上的模式，docker 模式见链接里的说明。 备份命令，sudo gitlab-rake gitlab:backup:create 备份路径配置 配置文件路径 /etc/gitlab/gitlab.rb 配置内容，修改 manage_backup_path 为 true，backup_path 为你所需要的路径，默认情况这两项都被注释，默认路径为 /var/opt/gitlab/backups 配置生效，需要执行命令 sudo gitlab-ctl reconfigure 备份过程： 123456789101112131415161718192021222324252627282930313233usernamexxx@hostnameyyy:~$ sudo gitlab-rake gitlab:backup:create [sudo] password for usernamexxx: Dumping database ... Dumping PostgreSQL database gitlabhq_production ... [DONE]doneDumping repositories ... * abc/wtf_proxy ... [DONE] * abc/wtf_proxy.wiki ... [SKIPPED]doneDumping uploads ... doneDumping builds ... doneDumping artifacts ... doneDumping pages ... doneDumping lfs objects ... doneDumping container registry images ... [DISABLED]Creating backup archive: 1515588043_2018_01_10_10.2.4_gitlab_backup.tar ... doneUploading backup archive to remote storage ... skippedDeleting tmp directories ... donedonedonedonedonedonedonedoneDeleting old backups ... skippingusernamexxx@hostnameyyy:~$ 备份后大小： 123456usernamexxx@hostnameyyy:~$ sudo ls -ahl /var/opt/gitlab/backups/total 938Mdrwx------ 2 git root 4.0K 1月 10 20:40 .drwxr-xr-x 18 root root 4.0K 12月 13 19:37 ..-rw------- 1 git git 469M 1月 10 14:46 1515566815_2018_01_10_10.2.4_gitlab_backup.tar-rw------- 1 git git 469M 1月 10 20:40 1515588043_2018_01_10_10.2.4_gitlab_backup.tar 备份文件路径配置： 1234usernamexxx@hostnameyyy:~$ sudo cat /etc/gitlab/gitlab.rb | grep backup###! Docs: https://docs.gitlab.com/omnibus/settings/backups.html# gitlab_rails['manage_backup_path'] = true# gitlab_rails['backup_path'] = "/var/opt/gitlab/backups" 这只是备份到本地，建议把 tar 包备份到其他主机。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>版本控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mirror 旧 git 仓库到新的 git 仓库（保留所有提交 / 分支 / tags）]]></title>
    <url>%2F201712%2Ftools%2Fgit_mirror_to_new_repo.html</url>
    <content type="text"><![CDATA[需求感谢 GFW，在编译 SONiC 开源项目的时候碰到很多源码下载不下来。因此有必要本地保存一份源码。而且，有的源码下载下来，需要切换分支，因此需要完整保存该源码的镜像，包含所有的提交、分支和 tags。 本文以自建的 gitlab ce 服务器为例。目标：mirror https://anonscm.debian.org/cgit/pkg-dhcp/isc-dhcp.git 到本地的 gitlab 服务器。 方法一：命令行很明显，这是一个很常见的需求，git 可以很快地做这个活。详见 Import an existing git project into GitLab? 在 gitlab ce 服务器上添加对应的仓库，比如 http://your_gitlab_url/sonic/isc-dhcp.git 下载 isc-dhcp 的源码到本地，git clone https://anonscm.debian.org/cgit/pkg-dhcp/isc-dhcp.git --mirror 进入 isc-dhcp 源码根目录，执行以下两个命令： git remote add gitlab http://your_gitlab_url/sonic/isc-dhcp.git git push gitlab –mirror Bingo!! 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495netadmin@kmc-b0230:~$ git clone https://anonscm.debian.org/cgit/pkg-dhcp/isc-dhcp.git --mirrorCloning into bare repository 'isc-dhcp.git'...remote: Counting objects: 3435, done.remote: Compressing objects: 100% (1702/1702), done.remote: Total 3435 (delta 2428), reused 2488 (delta 1670)Receiving objects: 100% (3435/3435), 64.05 MiB | 62.00 KiB/s, done.Resolving deltas: 100% (2428/2428), done.Checking connectivity... done.netadmin@kmc-b0230:~/isc-dhcp$ git remote add gitlab http://your_gitlab_url/sonic/isc-dhcp.gitnetadmin@kmc-b0230:~/isc-dhcp$ git push gitlab --mirrorUsername for 'http://your_gitlab_url': jeromesunPassword for 'http://jeromesun@your_gitlab_url':Counting objects: 3435, done.Delta compression using up to 24 threads.Compressing objects: 100% (944/944), done.Writing objects: 100% (3435/3435), 64.05 MiB | 79.66 MiB/s, done.Total 3435 (delta 2428), reused 3435 (delta 2428)remote: Resolving deltas: 100% (2428/2428), done.To http://your_gitlab_url/sonic/isc-dhcp.git * [new branch] experimental -&gt; experimental * [new branch] master -&gt; master * [new branch] pristine-tar -&gt; pristine-tar * [new branch] upstream -&gt; upstream * [new tag] debian/4.1.0-1 -&gt; debian/4.1.0-1 * [new tag] debian/4.1.1-1 -&gt; debian/4.1.1-1 * [new tag] debian/4.1.1-2 -&gt; debian/4.1.1-2 * [new tag] debian/4.1.1-P1-10 -&gt; debian/4.1.1-P1-10 * [new tag] debian/4.1.1-P1-11 -&gt; debian/4.1.1-P1-11 * [new tag] debian/4.1.1-P1-12 -&gt; debian/4.1.1-P1-12 * [new tag] debian/4.1.1-P1-13 -&gt; debian/4.1.1-P1-13 * [new tag] debian/4.1.1-P1-14 -&gt; debian/4.1.1-P1-14 * [new tag] debian/4.1.1-P1-15 -&gt; debian/4.1.1-P1-15 * [new tag] debian/4.1.1-P1-16 -&gt; debian/4.1.1-P1-16 * [new tag] debian/4.1.1-P1-16.1 -&gt; debian/4.1.1-P1-16.1 * [new tag] debian/4.1.1-P1-17 -&gt; debian/4.1.1-P1-17 * [new tag] debian/4.1.1-P1-4 -&gt; debian/4.1.1-P1-4 * [new tag] debian/4.1.1-P1-5 -&gt; debian/4.1.1-P1-5 * [new tag] debian/4.1.1-P1-6 -&gt; debian/4.1.1-P1-6 * [new tag] debian/4.1.1-P1-7 -&gt; debian/4.1.1-P1-7 * [new tag] debian/4.1.1-P1-8 -&gt; debian/4.1.1-P1-8 * [new tag] debian/4.1.1-P1-9 -&gt; debian/4.1.1-P1-9 * [new tag] debian/4.2.2-1 -&gt; debian/4.2.2-1 * [new tag] debian/4.2.2-2 -&gt; debian/4.2.2-2 * [new tag] debian/4.2.2.dfsg.1-3 -&gt; debian/4.2.2.dfsg.1-3 * [new tag] debian/4.2.2.dfsg.1-4 -&gt; debian/4.2.2.dfsg.1-4 * [new tag] debian/4.2.2.dfsg.1-5 -&gt; debian/4.2.2.dfsg.1-5 * [new tag] debian/4.2.4-1 -&gt; debian/4.2.4-1 * [new tag] debian/4.2.4-2 -&gt; debian/4.2.4-2 * [new tag] debian/4.2.4-3 -&gt; debian/4.2.4-3 * [new tag] debian/4.2.4-4 -&gt; debian/4.2.4-4 * [new tag] debian/4.2.4-5 -&gt; debian/4.2.4-5 * [new tag] debian/4.2.4-6 -&gt; debian/4.2.4-6 * [new tag] debian/4.2.4-7 -&gt; debian/4.2.4-7 * [new tag] debian/4.3.0+dfsg-1 -&gt; debian/4.3.0+dfsg-1 * [new tag] debian/4.3.0+dfsg-2 -&gt; debian/4.3.0+dfsg-2 * [new tag] debian/4.3.0a1-1 -&gt; debian/4.3.0a1-1 * [new tag] debian/4.3.0a1-2 -&gt; debian/4.3.0a1-2 * [new tag] debian/4.3.1-1 -&gt; debian/4.3.1-1 * [new tag] debian/4.3.1-2 -&gt; debian/4.3.1-2 * [new tag] debian/4.3.1-3 -&gt; debian/4.3.1-3 * [new tag] debian/4.3.1-4 -&gt; debian/4.3.1-4 * [new tag] debian/4.3.1-5 -&gt; debian/4.3.1-5 * [new tag] debian/4.3.1-6 -&gt; debian/4.3.1-6 * [new tag] debian/4.3.1_b1 -&gt; debian/4.3.1_b1 * [new tag] debian/4.3.2-1 -&gt; debian/4.3.2-1 * [new tag] debian/4.3.3-1 -&gt; debian/4.3.3-1 * [new tag] debian/4.3.3-2 -&gt; debian/4.3.3-2 * [new tag] debian/4.3.3-3 -&gt; debian/4.3.3-3 * [new tag] debian/4.3.3-5 -&gt; debian/4.3.3-5 * [new tag] debian/4.3.3-6 -&gt; debian/4.3.3-6 * [new tag] debian/4.3.3-7 -&gt; debian/4.3.3-7 * [new tag] debian/4.3.3-8 -&gt; debian/4.3.3-8 * [new tag] debian/4.3.3-9 -&gt; debian/4.3.3-9 * [new tag] debian/4.3.4-1 -&gt; debian/4.3.4-1 * [new tag] debian/4.3.5-1 -&gt; debian/4.3.5-1 * [new tag] debian/4.3.5-2 -&gt; debian/4.3.5-2 * [new tag] debian/4.3.5-3 -&gt; debian/4.3.5-3 * [new tag] debian/4.3.5_b1-1 -&gt; debian/4.3.5_b1-1 * [new tag] debin/4.2.2.dfsg.1-4 -&gt; debin/4.2.2.dfsg.1-4 * [new tag] upstream/4.1.0 -&gt; upstream/4.1.0 * [new tag] upstream/4.1.1 -&gt; upstream/4.1.1 * [new tag] upstream/4.1.1-P1 -&gt; upstream/4.1.1-P1 * [new tag] upstream/4.2.2 -&gt; upstream/4.2.2 * [new tag] upstream/4.2.4 -&gt; upstream/4.2.4 * [new tag] upstream/4.2.5-P1 -&gt; upstream/4.2.5-P1 * [new tag] upstream/4.3.0 -&gt; upstream/4.3.0 * [new tag] upstream/4.3.0a1 -&gt; upstream/4.3.0a1 * [new tag] upstream/4.3.1 -&gt; upstream/4.3.1 * [new tag] upstream/4.3.2 -&gt; upstream/4.3.2 * [new tag] upstream/4.3.3 -&gt; upstream/4.3.3 * [new tag] upstream/4.3.4 -&gt; upstream/4.3.4 * [new tag] upstream/4.3.4_b1 -&gt; upstream/4.3.4_b1 * [new tag] upstream/4.3.5 -&gt; upstream/4.3.5 * [new tag] upstream/4.3.5_b1 -&gt; upstream/4.3.5_b1netadmin@kmc-b0230:~/isc-dhcp$ 方法二：gitlab 使用 import project 创建新项目详见 gitlab 图形界面，支持从 github / bitbucket / google code 等网站直接 import，也支持通过 URL 指定要 import 的 git 仓库。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>版本控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apt-deb 相关问题记录]]></title>
    <url>%2F201712%2Flinux%2Fapt_deb_issues.html</url>
    <content type="text"><![CDATA[修改源查看依赖关系 编译依赖，apt-rdepends --build-depends package_name 问题记录apt-get -y build-dep linux 失败log： 12345root@c60c282d2d76:/# apt-get -y build-dep linuxReading package lists... DoneBuilding dependency tree Reading state information... DoneE: Build-Depends dependency for linux cannot be satisfied because candidate version of package debhelper can't satisfy version requirements 分析：debhelper 的版本满足不了编译 linux 的依赖。 通过 apt-rdepends --build-depends linux &gt; linux.build-depends.txt 查看 linux 的编译依赖。linux 的编译依赖好多，要等很长时间。 通过 cat linux.build-depends.txt | grep debhelper 确认对 debhelper 的版本依赖发现有软件对其的版本依赖 &gt;= 10，而 debian jessie 的默认 debhelper 版本为 9.20xxx，在 repo 中可以看到 debhelper 当前最新版本为 10.10.9。 1234567891011121314root@c60c282d2d76:/# cat linux.build-depends.txt | grep "&gt;= 10" Build-Depends: debhelper (&gt;= 10~) Build-Depends: debhelper (&gt;= 10) Build-Depends: debhelper (&gt;= 10) Build-Depends: debhelper (&gt;= 10) Build-Depends: debhelper (&gt;= 10) Build-Depends: debhelper (&gt;= 10) Build-Depends: debhelper (&gt;= 10) Build-Depends: debhelper (&gt;= 10) Build-Depends: debhelper (&gt;= 10) Build-Depends: debhelper (&gt;= 10~) Build-Depends: debhelper (&gt;= 10~) Build-Depends: debhelper (&gt;= 10) Build-Depends: debhelper (&gt;= 10) 查看 debhelper 所有版本 通过 apt-cache madison debhelper 查看 debhelper 的所有版本 1234567root@c60c282d2d76:/# apt-cache madison debhelper debhelper | 10.2.5~bpo8+1 | http://ftp.cn.debian.org/debian/ jessie-backports/main amd64 Packages debhelper | 9.20150101+deb8u2 | http://ftp.cn.debian.org/debian/ jessie/main amd64 Packages debhelper | 9.20150101+deb8u2 | http://security.debian.org/ jessie/updates/main amd64 Packages debhelper | 9.20150101+deb8u2 | http://ftp.cn.debian.org/debian/ jessie/main Sources debhelper | 10.2.5~bpo8+1 | http://ftp.cn.debian.org/debian/ jessie-backports/main Sources debhelper | 9.20150101+deb8u2 | http://security.debian.org/ jessie/updates/main Sources 尝试安装 debhelper 版本 10.2.5~bp08+1，发现有新的依赖关系问题： 123456789101112131415root@c60c282d2d76:/# apt-get install debhelper=10.2.5~bpo8+1Reading package lists... DoneBuilding dependency tree Reading state information... DoneSome packages could not be installed. This may mean that you haverequested an impossible situation or if you are using the unstabledistribution that some required packages have not yet been createdor been moved out of Incoming.The following information may help to resolve the situation:The following packages have unmet dependencies: debhelper : Depends: dh-autoreconf (&gt;= 12~) but 10 is to be installed Depends: dh-strip-nondeterminism (&gt;= 0.028~) but 0.003-1 is to be installedE: Unable to correct problems, you have held broken packages.root@c60c282d2d76:/# 发现比较高版本的包都是来自 jessie-backports: Backports: Backports are recompiled packages from testing (mostly) and unstable (in a few cases only, e.g. security updates), so they will run without new libraries (wherever it is possible) on a stable Debian distribution. It is recommended to pick out single backports which fit your needs, and not to use all backports available. 即，Backports 存放的软件为不稳定或仅用于测试目的的编译结果。 1234567891011root@c60c282d2d76:/# apt-cache madison dh-autoreconf dh-autoreconf | 12~bpo8+1 | http://ftp.cn.debian.org/debian/ jessie-backports/main amd64 Packagesdh-autoreconf | 10 | http://ftp.cn.debian.org/debian/ jessie/main amd64 Packagesdh-autoreconf | 10 | http://ftp.cn.debian.org/debian/ jessie/main Sourcesdh-autoreconf | 12~bpo8+1 | http://ftp.cn.debian.org/debian/ jessie-backports/main Sourcesroot@c60c282d2d76:/# apt-cache madison dh-strip-nondeterminism dh-strip-nondeterminism | 0.034-1~bpo8+1 | http://ftp.cn.debian.org/debian/ jessie-backports/main amd64 Packagesdh-strip-nondeterminism | 0.003-1 | http://ftp.cn.debian.org/debian/ jessie/main amd64 Packagesstrip-nondeterminism | 0.003-1 | http://ftp.cn.debian.org/debian/ jessie/main Sourcesstrip-nondeterminism | 0.034-1~bpo8+1 | http://ftp.cn.debian.org/debian/ jessie-backports/main Sourcesroot@c60c282d2d76:/# OK，是时候把 Backports 的源踢掉了。 故障时的源，被 163 的 Debian镜像使用帮助误导了。 12345678deb http://mirrors.163.com/debian/ jessie main non-free contribdeb http://mirrors.163.com/debian/ jessie-updates main non-free contribdeb http://mirrors.163.com/debian/ jessie-backports main non-free contribdeb-src http://mirrors.163.com/debian/ jessie main non-free contribdeb-src http://mirrors.163.com/debian/ jessie-updates main non-free contribdeb-src http://mirrors.163.com/debian/ jessie-backports main non-free contribdeb http://mirrors.163.com/debian-security/ jessie/updates main non-free contribdeb-src http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib 在调试的时候，一开始已注意到可能是源的问题，但是还是一遍一遍傻逼式地试不同的源，比如上面的 debian 官方中国源 ftp.cn.debian.org。 烂习惯。。。。。调东西还是乱试一通，没去找根本原因。。。教训是一个下午没了，正常已经半个小时就可以发现根本原因了。 /boot 目录满了，无法增删内核 image如果 /boot 目录满了，无法正常地 apt-get intall / remove / purge 等操作。解决方法如下，来自： https://gist.github.com/ipbastola/2760cfc28be62a5ee10036851c654600 https://askubuntu.com/questions/585736/cant-clean-a-full-boot-because-of-unmet-dependencies, msa 的回答 解决步骤: sudo apt autoremove –purge sudo apt autoremove sudo apt-get -f install 异常 log： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118jeromesun@km:~$ df -hFilesystem Size Used Avail Use% Mounted on.../dev/sda1 472M 468M 0 100% /boot...jeromesun@km:~$ jeromesun@kmc-b0232:~$ sudo apt-get autoremove [sudo] password for jeromesun: Reading package lists... DoneBuilding dependency tree Reading state information... DoneYou might want to run 'apt-get -f install' to correct these.The following packages have unmet dependencies: linux-image-extra-4.13.0-37-generic : Depends: linux-image-4.13.0-37-generic but it is not installed linux-image-generic-hwe-16.04 : Depends: linux-image-4.13.0-37-generic but it is not installedE: Unmet dependencies. Try using -f.jeromesun@km:~$ sudo apt-get -fE: Command line option 'f' [from -f] is not understood in combination with the other options.jeromesun@km:~$ jeromesun@km:~$ sudo apt-get -f installReading package lists... DoneBuilding dependency tree Reading state information... DoneCorrecting dependencies... DoneThe following packages were automatically installed and are no longer required:... linux-headers-4.10.0-37 linux-headers-4.10.0-37-generic linux-headers-4.10.0-40 linux-headers-4.10.0-40-generic linux-headers-4.10.0-42 linux-headers-4.10.0-42-generic linux-headers-4.13.0-26 linux-headers-4.13.0-26-generic linux-headers-4.13.0-31 linux-headers-4.13.0-31-generic linux-image-4.10.0-37-generic linux-image-4.10.0-40-generic linux-image-4.10.0-42-generic linux-image-4.13.0-26-generic linux-image-4.13.0-31-generic linux-image-extra-4.10.0-37-generic linux-image-extra-4.10.0-40-generic linux-image-extra-4.10.0-42-generic linux-image-extra-4.13.0-26-generic linux-image-extra-4.13.0-31-generic ... Use 'sudo apt autoremove' to remove them.The following additional packages will be installed: linux-image-4.13.0-37-genericSuggested packages: fdutils linux-toolsThe following NEW packages will be installed: linux-image-4.13.0-37-generic0 upgraded, 1 newly installed, 0 to remove and 205 not upgraded.9 not fully installed or removed.Need to get 0 B/20.9 MB of archives.After this operation, 72.6 MB of additional disk space will be used.Do you want to continue? [Y/n] y(Reading database ... 574107 files and directories currently installed.)Preparing to unpack .../linux-image-4.13.0-37-generic_4.13.0-37.42~16.04.1_amd64.deb ...Done.Unpacking linux-image-4.13.0-37-generic (4.13.0-37.42~16.04.1) ...dpkg: error processing archive /var/cache/apt/archives/linux-image-4.13.0-37-generic_4.13.0-37.42~16.04.1_amd64.deb (--unpack): cannot copy extracted data for './boot/vmlinuz-4.13.0-37-generic' to '/boot/vmlinuz-4.13.0-37-generic.dpkg-new': failed to write (No space left on device)No apport report written because the error message indicates a disk full error dpkg-deb: error: subprocess paste was killed by signal (Broken pipe)Examining /etc/kernel/postrm.d .run-parts: executing /etc/kernel/postrm.d/initramfs-tools 4.13.0-37-generic /boot/vmlinuz-4.13.0-37-genericrun-parts: executing /etc/kernel/postrm.d/zz-update-grub 4.13.0-37-generic /boot/vmlinuz-4.13.0-37-genericErrors were encountered while processing: /var/cache/apt/archives/linux-image-4.13.0-37-generic_4.13.0-37.42~16.04.1_amd64.debE: Sub-process /usr/bin/dpkg returned an error code (1)jeromesun@km:~$ jeromesun@km:~$ uname -aLinux km 4.10.0-38-generic #42~16.04.1-Ubuntu SMP Tue Oct 10 16:32:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linuxjeromesun@km:~$ sudo dpkg --list 'linux-image*'|awk '&#123; if ($1=="ii") print $2&#125;'|grep -v `uname -r`linux-image-4.10.0-37-genericlinux-image-4.10.0-40-genericlinux-image-4.10.0-42-genericlinux-image-4.13.0-26-genericlinux-image-4.13.0-31-genericlinux-image-4.13.0-32-genericlinux-image-4.13.0-36-genericlinux-image-extra-4.10.0-37-genericlinux-image-extra-4.10.0-40-genericlinux-image-extra-4.10.0-42-genericlinux-image-extra-4.13.0-26-genericlinux-image-extra-4.13.0-31-genericlinux-image-extra-4.13.0-32-genericjeromesun@km:~$ jeromesun@km:~$ sudo apt-get purge linux-image-4.10.0-37-genericReading package lists... DoneBuilding dependency tree Reading state information... DoneYou might want to run 'apt-get -f install' to correct these:The following packages have unmet dependencies: linux-image-extra-4.10.0-37-generic : Depends: linux-image-4.10.0-37-generic but it is not going to be installed linux-image-extra-4.13.0-37-generic : Depends: linux-image-4.13.0-37-generic but it is not going to be installed linux-image-generic-hwe-16.04 : Depends: linux-image-4.13.0-37-generic but it is not going to be installedE: Unmet dependencies. Try 'apt-get -f install' with no packages (or specify a solution).jeromesun@km:~$ sudo dpkg --force-all -P linux-image-4.10.0-37-genericdpkg: linux-image-4.10.0-37-generic: dependency problems, but removing anyway as you requested: linux-image-extra-4.10.0-37-generic depends on linux-image-4.10.0-37-generic.(Reading database ... 574105 files and directories currently installed.)Removing linux-image-4.10.0-37-generic (4.10.0-37.41~16.04.1) ...Examining /etc/kernel/postrm.d .run-parts: executing /etc/kernel/postrm.d/initramfs-tools 4.10.0-37-generic /boot/vmlinuz-4.10.0-37-genericupdate-initramfs: Deleting /boot/initrd.img-4.10.0-37-genericrun-parts: executing /etc/kernel/postrm.d/zz-update-grub 4.10.0-37-generic /boot/vmlinuz-4.10.0-37-genericGenerating grub configuration file ...Warning: Setting GRUB_TIMEOUT to a non-zero value when GRUB_HIDDEN_TIMEOUT is set is no longer supported.Found linux image: /boot/vmlinuz-4.13.0-36-genericFound initrd image: /boot/initrd.img-4.13.0-36-genericFound linux image: /boot/vmlinuz-4.13.0-32-genericFound initrd image: /boot/initrd.img-4.13.0-32-genericFound linux image: /boot/vmlinuz-4.13.0-31-genericFound initrd image: /boot/initrd.img-4.13.0-31-genericFound linux image: /boot/vmlinuz-4.13.0-26-genericFound initrd image: /boot/initrd.img-4.13.0-26-genericFound linux image: /boot/vmlinuz-4.10.0-42-genericFound initrd image: /boot/initrd.img-4.10.0-42-genericFound linux image: /boot/vmlinuz-4.10.0-40-genericFound initrd image: /boot/initrd.img-4.10.0-40-genericFound linux image: /boot/vmlinuz-4.10.0-38-genericFound initrd image: /boot/initrd.img-4.10.0-38-genericFound memtest86+ image: /memtest86+.elfFound memtest86+ image: /memtest86+.bindonePurging configuration files for linux-image-4.10.0-37-generic (4.10.0-37.41~16.04.1) ...Examining /etc/kernel/postrm.d .run-parts: executing /etc/kernel/postrm.d/initramfs-tools 4.10.0-37-generic /boot/vmlinuz-4.10.0-37-genericrun-parts: executing /etc/kernel/postrm.d/zz-update-grub 4.10.0-37-generic /boot/vmlinuz-4.10.0-37-genericjeromesun@km:~$]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>deb</tag>
        <tag>apt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行 - sed]]></title>
    <url>%2F201712%2Fshell%2Fsed.html</url>
    <content type="text"><![CDATA[-e，不写入文件 -i，写入文件 s，替换 s/xxx/yyy/g s;xxx;yyy; 所有 subdir.mk 替换 “$(CC) $(BUILD_CFLAGS)” 为 “$(CC) $(BUILD_CFLAGS) -fPIC”，find . -name &quot;subdir.mk&quot; -exec sed -i &#39;s;$(CC) $(BUILD_CFLAGS);$(CC) $(BUILD_CFLAGS) -fPIC;&#39; &#39;{}&#39; \; 使用 find 结果替换时，加个 -type f，只处理 regular file，否则处理完后，可能有文件类型发生变动，git status 有 typechange: your_file 所有 .c 文件首行添加 “#include &lt;asm-generic/io.h&gt;”，find . -name &quot;*.c&quot; -exec sed -i &#39;1 i#include &lt;asm-generic/io.h&gt;&#39; &quot;{}&quot; \; 行首，行尾加字符，例如 # 号：s/^/\#/g，s/$/\#/g sed 替换匹配行的某个字符，例如还是行首加 # 号：sed -i &#39;/your_pattern/s/^/\#/g&#39; sed 匹配多个字符串，sed -n &#39;/hello\|world/p&#39; 或 &#39;/hello/p; /world/p&#39; 完全匹配字符串，\&lt;your_world\&gt; 问题汇总记录一次二次展开的惨案人生苦短，请用 Python…sb 了，这个搞了一个晚上，刚才才想起来，要用 ; … 1234jeromesun@km:~/workshop/bash$ echo "abcdefghijk" | sed "s/abcd/fghi`pwd`/"sed: -e expression #1, char 13: unknown option to `s'jeromesun@km:~/workshop/bash$ echo "abcdefghijk" | sed "s;abcd;fghi`pwd`;"fghi/home/jeromesun/workshop/bashefghijk]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[p4 语言简介]]></title>
    <url>%2F201708%2Fnetworks%2Fp4%2Fp4lang_intro.html</url>
    <content type="text"><![CDATA[简述P4 语言为一种领域语言，用于网络转发平面（数据平面）报文处理流水线的描述。 P4 是一种类 C 的专用语言，用于描述数据平面转发流水线。P4 语言源自 SIGCOMM 2014 CCR 论文“Programming Protocol-Independent Packet Processors”，P4 就是这几个单词的缩写。 简单地，可将 P4 语言与 C 语言进行对比。 C 语言程序代码 – gcc 或其他编译器 –&gt; 可执行文件，运行在 x86 CPU / ARM / 51单片机等目标上。 P4 语言代码 – P4 编译器–&gt; 固件或其他形式输出，运行在通过 CPU / NPU / FPGA / ASIC 等目标上。 P4 语言的目标： 设备无关。P4 语言被设计成与具体实现无关，可以编译到不同的执行机器（亦称为 P4 targets），比如通用 CPU、FPGA、ASIC、NPU 等。厂家提供 P4 target 时，必须同时提供一个后端编译器，将 P4 源码映射到目标交换机模型。 协议无关。这意味着 P4 语言不会原生支持任何协议，即便是通用协议，比如 Ethernet、IP、TCP、VxLAN 等。P4 语言描述报文头部格式以及程序中需要的协议字段。 可重配置。协议独立性和抽象语言模型允许可重新配置，P4目标应该能够在部署后更改其处理数据包的方式（可能多次）。 这种能力传统上只有通用 CPU 或 NPU 支持，而固定功能 ASIC 不支持。 P4 语言抽象P4 语言规格目前存在两种并行的语言规格，包含 P4-14 和 P4-16 两种，详见 p4-spec。P4-16 相比 P4-14 的改进在于， P4 语言代码样例P4 样例代码，simple router。 其他网络编程语言目前常见开放的数据平面编程语言除 P4 外，还有 PoF，不过后者自 2014 年来已基本无更新。二者的对比详见文章 P4和POF的对比。]]></content>
      <categories>
        <category>p4</category>
      </categories>
      <tags>
        <tag>p4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[包管理工具依赖关系管理]]></title>
    <url>%2F201706%2Flinux%2Fdeb_dependency.html</url>
    <content type="text"><![CDATA[因产品的无法按 app 升级，发现产品中的组件已按包管理工具打包，但是却没有用上包管理工具的核心——依赖关系管理。本文研究包管理工具的依赖关系管理。 通常依赖关系管理分为安装时/运行时依赖和构建时依赖。这里主要讲安装时/运行时依赖。我所理解的安装时依赖即运行时依赖。常见的包管理工具有 deb / rpm / pip / npm / rake 等，这里以 deb 为例。 详见 How to make a “Basic” .deb。为验证安装时依赖关系管理，创建 mydep_2.24-1。helloworld_1.0-1 依赖 mydep_2.24-1。 目录架构 helloworld 软件包目录架构 12345678sunyongfeng@ubuntu:~/workshop/test$ tree helloworld_1.0-1helloworld_1.0-1├── DEBIAN│ └── control└── usr └── local └── bin └── helloworld mydep 软件包目录架构 12345678910114 directories, 2 filessunyongfeng@ubuntu:~/workshop/test$ tree mydep_2.24-1mydep_2.24-1├── DEBIAN│ └── control└── usr └── local └── bin └── mydep4 directories, 2 files 控制文件该实验主要用到两个字段： Version，本 package 版本号 Depends，本 package 依赖哪些软件包，及依赖的版本号是多少 helloworld 控制文件 1234567891011sunyongfeng@ubuntu:~/workshop/test$ cat helloworld_1.0-1/DEBIAN/control Package: helloworldVersion: 1.0-1Section: basePriority: optionalArchitecture: amd64Depends: mydep (&gt;= 2.24)Maintainer: Your Name &lt;you@email.com&gt;Description: Hello World When you need some sunshine, just run this small program! mydep 控制文件 12345678910sunyongfeng@ubuntu:~/workshop/test$ cat mydep_2.24-1/DEBIAN/control Package: mydepVersion: 2.24-1Section: basePriority: optionalArchitecture: amd64Maintainer: Your Name &lt;you@email.com&gt;Description: Hello World my dep When you need some sunshine my dep, just run this small program! 打包通过命令 dpkg-deb --build dir 打包。 1234sunyongfeng@ubuntu:~/workshop/test$ dpkg-deb --build helloworld_1.0-1/dpkg-deb: building package 'helloworld' in 'helloworld_1.0-1.deb'.sunyongfeng@ubuntu:~/workshop/test$ dpkg-deb --build mydep_2.24-1/dpkg-deb: building package 'mydep' in 'mydep_2.24-1.deb' 安装依赖关系不成立，安装失败如果先安装 helloworld，提示依赖的 mydep 未安装，失败。 123456789101112sunyongfeng@ubuntu:~/workshop/test$ sudo dpkg -i helloworld_1.0-1.deb (Reading database ... 325288 files and directories currently installed.)Preparing to unpack helloworld_1.0-1.deb ...Unpacking helloworld (1.0-1) over (1.0-1) ...dpkg: dependency problems prevent configuration of helloworld: helloworld depends on mydep (&gt;= 2.24); however: Package mydep is not installed.dpkg: error processing package helloworld (--install): dependency problems - leaving unconfiguredErrors were encountered while processing: helloworld 依赖关系成立，安装成功先安装 mydep。 123456sunyongfeng@ubuntu:~/workshop/test$ sudo dpkg -i mydep_2.24-1.deb Selecting previously unselected package mydep.(Reading database ... 325288 files and directories currently installed.)Preparing to unpack mydep_2.24-1.deb ...Unpacking mydep (2.24-1) ...Setting up mydep (2.24-1) ... 再安装 helloworld 12345sunyongfeng@ubuntu:~/workshop/test$ sudo dpkg -i helloworld_1.0-1.deb (Reading database ... 325289 files and directories currently installed.)Preparing to unpack helloworld_1.0-1.deb ...Unpacking helloworld (1.0-1) over (1.0-1) ...Setting up helloworld (1.0-1) ... 卸载软件如果先删除 mydep，会一般把依赖 mydep 的软件包都删除。 12345678910111213sunyongfeng@ubuntu:~/workshop/test$ sudo apt-get remove mydepReading package lists... DoneBuilding dependency tree Reading state information... DoneThe following packages will be REMOVED: helloworld mydep0 upgraded, 0 newly installed, 2 to remove and 278 not upgraded.After this operation, 0 B of additional disk space will be used.Do you want to continue? [Y/n] y(Reading database ... 325288 files and directories currently installed.)Removing helloworld (1.0-1) ...Removing mydep (2.24-1) ...dpkg: warning: while removing mydep, directory '/usr/local/bin' not empty so not removed 依赖关系数据库deb 软件依赖关系数据库存放于 /var/lib/dpkg/status，纯文本文件。比如 mydep 和 helloworld 的信息如下。 123456789101112131415161718192021222324sunyongfeng@ubuntu:~/workshop/test$ sudo vi /var/lib/dpkg/status37582 Package: mydep 37583 Status: install ok installed 37584 Priority: optional 37585 Section: base 37586 Maintainer: Your Name &lt;you@email.com&gt; 37587 Architecture: amd64 37588 Version: 2.24-1 37589 Description: Hello World my dep 37590 When you need some sunshine my dep, just run this 37591 small program! 42473 Package: helloworld 42474 Status: install ok installed 42475 Priority: optional 42476 Section: base 42477 Maintainer: Your Name &lt;you@email.com&gt; 42478 Architecture: amd64 42479 Version: 1.0-1 42480 Depends: mydep (&gt;= 2.24) 42481 Description: Hello World 42482 When you need some sunshine, just run this 42483 small program! hack 依赖关系数据库由于没有看源码确认，通过删除依赖关系数据库中 helloworld 依赖 mydep 的 Depends 行 42480 Depends: mydep (&gt;= 2.24)。通过删除 mydep 包，看 helloworld 会不会被连带删除确认依赖关系数据库是否生效。经验证，此时卸载 mydep 包，不会卸载 helloworld 包，与预期的相符。 123456789101112131415161718192021222324sunyongfeng@ubuntu:~/workshop/test$ sudo vi /var/lib/dpkg/status42462 Package: helloworld 42463 Status: install ok installed 42464 Priority: optional 42465 Section: base 42466 Maintainer: Your Name &lt;you@email.com&gt; 42467 Architecture: amd64 42468 Version: 1.0-1 42469 Description: Hello World 42470 When you need some sunshine, just run this 42471 small program! sunyongfeng@ubuntu:~/workshop/test$ sudo apt-get remove mydepReading package lists... DoneBuilding dependency tree Reading state information... DoneThe following packages will be REMOVED: mydep0 upgraded, 0 newly installed, 1 to remove and 278 not upgraded.After this operation, 0 B of additional disk space will be used.Do you want to continue? [Y/n] y(Reading database ... 325288 files and directories currently installed.)Removing mydep (2.24-1) ... 升级 mydep 版本，会不会提醒依赖它的 helloworld答案是不会。 将 helloworld 的控制文件 Depends 行改为 42480 Depends: mydep (= 2.24)，升级 mydep 为版本 2.25-1，此时不会提醒 helloworld。但是重新安装 helloworld 会进一步提醒。 因此对被依赖的软件包，如果升级为不向前兼容的版本，只能以“死给你看”的形式“通知”依赖它的软件包。 1234567891011121314151617181920212223242526272829303132333435363738394041sunyongfeng@ubuntu:~/workshop/test$ vi helloworld_1.0-1/DEBIAN/controlsunyongfeng@ubuntu:~/workshop/test$ rm helloworld_1.0-1.deb sunyongfeng@ubuntu:~/workshop/test$ dpkg-deb --build helloworld_1.0-1/dpkg-deb: building package 'helloworld' in 'helloworld_1.0-1.deb'.sunyongfeng@ubuntu:~/workshop/test$ sudo apt-get remove helloworld Reading package lists... DoneBuilding dependency tree Reading state information... DoneThe following packages will be REMOVED: helloworld0 upgraded, 0 newly installed, 1 to remove and 278 not upgraded.1 not fully installed or removed.After this operation, 0 B of additional disk space will be used.Do you want to continue? [Y/n] y(Reading database ... 325288 files and directories currently installed.)Removing helloworld (1.0-1) ...sunyongfeng@ubuntu:~/workshop/test$ sudo dpkg -i helloworld_1.0-1.deb Selecting previously unselected package helloworld.(Reading database ... 325288 files and directories currently installed.)Preparing to unpack helloworld_1.0-1.deb ...Unpacking helloworld (1.0-1) ...Setting up helloworld (1.0-1) ...sunyongfeng@ubuntu:~/workshop/test$ sudo dpkg -i mydep_2.24-1.deb dpkg: warning: downgrading mydep from 2.25-1 to 2.24-1(Reading database ... 325288 files and directories currently installed.)Preparing to unpack mydep_2.24-1.deb ...Unpacking mydep (2.24-1) over (2.25-1) ...Setting up mydep (2.24-1) ...sunyongfeng@ubuntu:~/workshop/test$ sudo dpkg -i helloworld_1.0-1.deb (Reading database ... 325289 files and directories currently installed.)Preparing to unpack helloworld_1.0-1.deb ...Unpacking helloworld (1.0-1) over (1.0-1) ...dpkg: dependency problems prevent configuration of helloworld: helloworld depends on mydep (= 2.24-1); however: Version of mydep on system is 2.25-1.dpkg: error processing package helloworld (--install): dependency problems - leaving unconfiguredErrors were encountered while processing: helloworld 参考资料 http://tldp.org/HOWTO/html_single/Debian-Binary-Package-Building-HOWTO/ https://www.debian.org/doc/manuals/debian-faq/ch-pkg_basics.en.html Written with StackEdit.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>deb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux kernel module 依赖相关]]></title>
    <url>%2F201706%2Fprogrammer%2Flinux%2Fkernel_module_dep.html</url>
    <content type="text"><![CDATA[查看依赖关系问题背景：从专有系统移植某个特定功能的内核模块到 Linux 发行版，确认该模块的依赖关系。包含“我依赖谁”、“谁依赖我”两种情况。详见How to check kernel module dependencies on Linux lsmod 如下，vboxdrv.ko 依赖 vboxnetadp.ko、vboxnetflt.ko、vboxpci.ko。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107sunyongfeng@ubuntu:~$ lsmodModule Size Used bytipc 127285 0pci_stub 12622 1vboxpci 23116 0vboxnetadp 25813 0vboxnetflt 27947 0vboxdrv 455053 3 vboxnetadp,vboxnetflt,vboxpcixt_CHECKSUM 12549 1iptable_mangle 12734 1ipt_REJECT 12541 2nf_reject_ipv4 13183 1 ipt_REJECTebtable_filter 12827 0ebtables 35359 1 ebtable_filterip6table_filter 12815 0ip6_tables 27504 1 ip6table_filterkvm_intel 154139 0binfmt_misc 18163 1cfg80211 551242 0sch_netem 17419 0vxlan 41123 0ip6_udp_tunnel 12755 1 vxlanudp_tunnel 13187 1 vxlansch_htb 22429 0xt_nat 12726 0xt_tcpudp 12924 6btrfs 968059 0xor 21411 1 btrfsraid6_pq 97812 1 btrfsufs 75315 0qnx4 13394 0hfsplus 103788 0hfs 54819 0minix 36454 0ntfs 101958 0msdos 17332 0jfs 186807 0xfs 937845 0veth 13376 0ipt_MASQUERADE 12678 4nf_nat_masquerade_ipv4 13412 1 ipt_MASQUERADExfrm_user 36115 1xfrm_algo 15394 1 xfrm_useriptable_nat 12875 1nf_conntrack_ipv4 18953 3nf_defrag_ipv4 12758 1 nf_conntrack_ipv4nf_nat_ipv4 14267 1 iptable_natxt_addrtype 12713 2iptable_filter 12810 1ip_tables 27718 3 iptable_filter,iptable_mangle,iptable_natxt_conntrack 12760 2x_tables 34103 13 ip6table_filter,xt_CHECKSUM,ip_tables,xt_tcpudp,ipt_MASQUERADE,xt_conntrack,xt_nat,iptable_filter,ebtables,ipt_REJECT,iptable_mangle,ip6_tables,xt_addrtypenf_nat 26308 3 nf_nat_ipv4,xt_nat,nf_nat_masquerade_ipv4nf_conntrack 105683 5 nf_nat,nf_nat_ipv4,xt_conntrack,nf_nat_masquerade_ipv4,nf_conntrack_ipv4br_netfilter 18017 0bridge 114479 1 br_netfilterstp 12976 1 bridgellc 14441 2 stp,bridgeoverlay 42380 0openvswitch 85378 0libcrc32c 12644 2 xfs,openvswitchsnd_hda_codec_realtek 80584 1snd_hda_codec_generic 70069 1 snd_hda_codec_realteksnd_hda_intel 30775 6dell_wmi 13132 0snd_hda_controller 35493 1 snd_hda_intelsparse_keymap 13890 1 dell_wmigpio_ich 13636 0snd_hda_codec 144641 4 snd_hda_codec_realtek,snd_hda_codec_generic,snd_hda_intel,snd_hda_controllersnd_hwdep 17709 1 snd_hda_codeccoretemp 13638 0snd_pcm 106401 3 snd_hda_codec,snd_hda_intel,snd_hda_controllersnd_seq_midi 13564 0snd_seq_midi_event 14899 1 snd_seq_midikvm 480880 1 kvm_intelsnd_rawmidi 31148 1 snd_seq_midisnd_seq 63540 2 snd_seq_midi_event,snd_seq_midisnd_seq_device 14875 3 snd_seq,snd_rawmidi,snd_seq_midisnd_timer 30069 2 snd_pcm,snd_seqdcdbas 15017 0lpc_ich 21176 0snd 83976 22 snd_hda_codec_realtek,snd_hwdep,snd_timer,snd_pcm,snd_seq,snd_rawmidi,snd_hda_codec_generic,snd_hda_codec,snd_hda_intel,snd_seq_deviceserio_raw 13434 0soundcore 15091 2 snd,snd_hda_codec8250_fintek 12924 0shpchp 37216 0mac_hid 13275 0parport_pc 32909 1ppdev 17711 0lp 17799 0parport 42432 3 lp,ppdev,parport_pcautofs4 39306 2hid_generic 12559 0psmouse 118539 0broadcom 17339 0i915 1087204 3pata_acpi 13053 0usbhid 53106 0hid 110883 2 hid_generic,usbhidwmi 19379 1 dell_wmivideo 24803 1 i915i2c_algo_bit 13564 1 i915drm_kms_helper 123797 1 i915tg3 179117 0ptp 19534 1 tg3pps_core 19332 1 ptpdrm 341489 5 i915,drm_kms_helper cat modules.dep，几乎与 lsmod 一样，但是包含未加载的内核模块依赖关系，ubuntu 默认有很多很多！ 123456789101112131415161718sunyongfeng@ubuntu:~$ cat /lib/modules/`uname -r`/modules.depkernel/arch/x86/kernel/cpu/mcheck/mce-inject.ko:kernel/arch/x86/kernel/msr.ko:kernel/arch/x86/kernel/cpuid.ko:kernel/arch/x86/kernel/iosf_mbi.ko:kernel/arch/x86/crypto/glue_helper.ko:kernel/arch/x86/crypto/aes-x86_64.ko:kernel/arch/x86/crypto/des3_ede-x86_64.ko: kernel/crypto/des_generic.kokernel/arch/x86/crypto/camellia-x86_64.ko: kernel/crypto/xts.ko kernel/crypto/lrw.ko kernel/crypto/gf128mul.ko kernel/arch/x86/crypto/glue_helper.kokernel/arch/x86/crypto/blowfish-x86_64.ko: kernel/crypto/blowfish_common.kokernel/arch/x86/crypto/twofish-x86_64.ko: kernel/crypto/twofish_common.kokernel/arch/x86/crypto/twofish-x86_64-3way.ko: kernel/arch/x86/crypto/twofish-x86_64.ko kernel/crypto/twofish_common.ko kernel/crypto/xts.ko kernel/crypto/lrw.ko kernel/crypto/gf128mul.ko kernel/arch/x86/crypto/glue_helper.kokernel/arch/x86/crypto/salsa20-x86_64.ko:kernel/arch/x86/crypto/serpent-sse2-x86_64.ko: kernel/crypto/xts.ko kernel/crypto/serpent_generic.ko kernel/crypto/lrw.ko kernel/crypto/gf128mul.ko kernel/arch/x86/crypto/glue_helper.ko kernel/crypto/ablk_helper.ko kernel/crypto/cryptd.kokernel/arch/x86/crypto/aesni-intel.ko: kernel/arch/x86/crypto/aes-x86_64.ko kernel/crypto/lrw.ko kernel/crypto/gf128mul.ko kernel/arch/x86/crypto/glue_helper.ko kernel/crypto/ablk_helper.ko kernel/crypto/cryptd.kokernel/arch/x86/crypto/ghash-clmulni-intel.ko: kernel/crypto/cryptd.kokernel/arch/x86/crypto/sha1-ssse3.ko:... 此处省略几千行 modprobe --show-dependency xxx.ko，以 lsmod 不同的是，该命令显示谁依赖 xxx.ko。 1234sunyongfeng@ubuntu:~$ modprobe --show-depends -n iptable_filterinsmod /lib/modules/3.19.8-031908-generic/kernel/net/netfilter/x_tables.ko insmod /lib/modules/3.19.8-031908-generic/kernel/net/ipv4/netfilter/ip_tables.ko insmod /lib/modules/3.19.8-031908-generic/kernel/net/ipv4/netfilter/iptable_filter.ko depmod，生成 modules.dep 和 map 文件 依赖相关的问题提示 “modprobe: ERROR: ../libkmod/libkmod.c:5”可能出现的原因: 内核版本不一致 modules.dep.bin 受损 参考: “Could not open moddep file ‘/lib/modules/3.XX-generic/modules.dep.bin’” when mounting using a loop 使用循环进行挂载时的modprobe”无法打开moddep文件’/lib/modules/3.XX generic/modules.dep.bin’” 解决:（思路，重新生成 modules.dep.bin，或干脆重新替换内核） depmod uname -r, apt-get install --reinstall linux-image-&#39;uname -r 的结果&#39; 一个样例，发现 docker 服务起不来，通过 systemd 的 log 查看（sudo journalctl -u systemd-modules-load.service -b）是 modprobe 其他模块失败，导致 docker 服务退出。 123456789101112Nov 09 11:07:18 hostnamexxx systemd[1]: Starting Docker Application Container Engine...Nov 09 11:07:18 hostnamexxx docker[1019]: time="2018-11-09T11:07:18.725826063+08:00" level=info msg="New containerd process, pid: 1024\n"Nov 09 11:07:19 hostnamexxx docker[1019]: time="2018-11-09T11:07:19.800079405+08:00" level=info msg="Graph migration to content-addressability took 0.00 seconds"Nov 09 11:07:19 hostnamexxx docker[1019]: time="2018-11-09T11:07:19.801535791+08:00" level=warning msg="Running modprobe bridge br_netfilter failed with message: modprobe: ERROR: ../libkmod/libkmod.c:557 kmod_search_moddep() could not open moddep file '/lib/modules/3.16.0-5-amd64/modules.dep.bin'\nmodprobe: ERROR: ../libkmod/libkmod.c:557 kmod_search_moddep() could not open moddep file '/lib/modules/3.16.0-5-amd64/modules.dep.bin'\n, error: exit status 1"Nov 09 11:07:19 hostnamexxx docker[1019]: time="2018-11-09T11:07:19.802736912+08:00" level=warning msg="Running modprobe nf_nat failed with message: `modprobe: ERROR: ../libkmod/libkmod.c:557 kmod_search_moddep() could not open moddep file '/lib/modules/3.16.0-5-amd64/modules.dep.bin'`, error: exit status 1"Nov 09 11:07:19 hostnamexxx docker[1019]: time="2018-11-09T11:07:19.803828391+08:00" level=warning msg="Running modprobe xt_conntrack failed with message: `modprobe: ERROR: ../libkmod/libkmod.c:557 kmod_search_moddep() could not open moddep file '/lib/modules/3.16.0-5-amd64/modules.dep.bin'`, error: exit status 1"Nov 09 11:07:19 hostnamexxx docker[1019]: time="2018-11-09T11:07:19.805611702+08:00" level=info msg="Firewalld running: false"Nov 09 11:07:19 hostnamexxx docker[1019]: time="2018-11-09T11:07:19.904012372+08:00" level=fatal msg="Error starting daemon: Error initializing network controller: Error creating default \"bridge\" network: package not installed"Nov 09 11:07:19 hostnamexxx systemd[1]: docker.service: main process exited, code=exited, status=1/FAILURENov 09 11:07:19 hostnamexxx docker[1019]: time="2018-11-09T11:07:19+08:00" level=info msg="stopping containerd after receiving terminated"Nov 09 11:07:20 hostnamexxx systemd[1]: Failed to start Docker Application Container Engine.Nov 09 11:07:20 hostnamexxx systemd[1]: Unit docker.service entered failed state. 运行一下 sudo depmod，pass。]]></content>
      <categories>
        <category>kernel</category>
      </categories>
      <tags>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[交换机的三个平面简介——管理平面、控制平面、数据平面]]></title>
    <url>%2F201706%2Fnetworks%2Fswitch%2Fthree_panel.html</url>
    <content type="text"><![CDATA[http://www.ruijie.com.cn/special/wzwn/download/pdf/s.pdf 数据平面：物理口 物理口，芯片转发数据。 控制平面：物理口 CPU 口，协议报文从物理口 upcall 到 CPU 处理，所有网络协议处理。 管理平面：CPU 口 CPU 口，CLI/SNMP/TELNET/WEB/SSH/RMON 等控制方式，配置控制平面相关协议，管理协议，管理交换机设备状态等。 设备架构的不同，导致三个平面的实现方式也不同。 box chassis - fullmesh chassis - clos]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>交换机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[octeon mips64 上使用 gprof 记录]]></title>
    <url>%2F201706%2Fprogrammer%2Ftools%2Fgprof_mips64.html</url>
    <content type="text"><![CDATA[为何使用 gprof对 mips64 设备上某业务进行性能调优，由于 Linux 系统为深度定制系统且 mips CPU 的限制，valgrind / 内核 perf 工具都有法使用（尚未研究 OProfile）。strace 只能 trace system calls and signals，因此考虑使用 gprof 进行性能调优。 gprof 使用注意事项 编译和链接都需要使用-pg选项。若链接时没使用该选项，会输出空数据 gmon.out。 12~ # ls -al gmon.out-rw-r--r-- 1 root root 20 Jun 8 21:54 gmon.out 查看 octeon mips64 app 生成的 gmon.out 嵌入式设备上没有 gprof 程序 把 gmon.out 传到 x86 PC 通过交叉编译工具链中的 mips64-octeon-linux-gnu-gprof 查看 123456789101112131415sunyongfeng@openswitch-OptiPlex-380:~/workshop/test$mips64-octeon-linux-gnu-gprof ./rtxx -QFlat profile:Each sample counts as 0.01 seconds. % cumulative self self total time seconds seconds calls ms/call ms/call name 23.64 0.13 0.13 79992 0.00 0.00 s_lookup 3.64 0.15 0.02 553816 0.00 0.00 e_dump_prefix 3.64 0.17 0.02 396896 0.00 0.00 db_get_key 3.64 0.19 0.02 99999 0.00 0.00 e_dump_nsmmsg 3.64 0.21 0.02 99999 0.00 0.01 e_handle 3.64 0.23 0.02 79992 0.00 0.00 create_info 3.64 0.25 0.02 79992 0.00 0.00 e_lkup_find_entry 3.64 0.27 0.02 79991 0.00 0.00 e_proc... 如何在不退出的业务中使用 gprof详见 Saving gmon.out before killing a process。 gprof 通过 atexit 注册函数 _mcleanup，因此只要在退出前调用该函数即可。使用 SIGUSR1 信号，在信号处理函数中调用 _mcleanup 和 _exit。可正常运行！代码如下。 1234567891011121314151617181920#include &lt;dlfcn.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;void sigUsr1Handler(int sig)&#123; fprintf(stderr, "Exiting on SIGUSR1\n"); void (*_mcleanup)(void); _mcleanup = (void (*)(void))dlsym(RTLD_DEFAULT, "_mcleanup"); if (_mcleanup == NULL) fprintf(stderr, "Unable to find gprof exit hook\n"); else _mcleanup(); _exit(0);&#125;int main(int argc, char* argv[])&#123; signal(SIGUSR1, sigUsr1Handler); neverReturningLibraryFunction();&#125; SIGUSR1 十进制值是多少？不同的 arch 对 signal 的值定义不一样。在 x86 中的定义一般为 10，但是在 octeon mips 中就不一样了，详见 arch/mips/include/asm/signal.h： 12#define SIGUSR1 16 /* User-defined signal 1 (POSIX). */ #define SIGUSR2 17 /* User-defined signal 2 (POSIX). */ 所以，此时我只要 kill -16 my_proc 就会生成 gmon.out 了。 编译提示 Undefined reference to ‘dlsym’链接参数加上 -ldl 即可。据说 C++ 的链接参数是 -Wl,--no-as-needed -ldl -pg。 多线程使用 gprofgprof 默认不支持多线程，通过 http://sam.zoy.org/writings/programming/gprof.html 提供的 gprof-helper 包装 pthread_create 函数，注入钩子后即可。 源代码如下。 通过 gcc -shared -fPIC gprof-helper.c -o gprof-helper.so -lpthread -ldl 编译该文件为共享库 通过 LD_PRELOAD=./gprof-helper.so your_program 应用该共享库 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119/* gprof-helper.c -- preload library to profile pthread-enabled programs * * Authors: Sam Hocevar &lt;sam at zoy dot org&gt; * Daniel J枚nsson &lt;danieljo at fagotten dot org&gt; * * This program is free software; you can redistribute it and/or * modify it under the terms of the Do What The Fuck You Want To * Public License as published by Banlu Kemiyatorn. See * http://sam.zoy.org/projects/COPYING.WTFPL for more details. * * Compilation example: * gcc -shared -fPIC gprof-helper.c -o gprof-helper.so -lpthread -ldl * * Usage example: * LD_PRELOAD=./gprof-helper.so your_program */#define _GNU_SOURCE#include &lt;sys/time.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;dlfcn.h&gt;#include &lt;pthread.h&gt;static void * wrapper_routine(void *);/* Original pthread function */static int (*pthread_create_orig)(pthread_t *__restrict, __const pthread_attr_t *__restrict, void *(*)(void *), void *__restrict) = NULL;/* Library initialization function */void wooinit(void) __attribute__((constructor));void wooinit(void)&#123; pthread_create_orig = dlsym(RTLD_NEXT, "pthread_create"); fprintf(stderr, "pthreads: using profiling hooks for gprof\n"); if(pthread_create_orig == NULL) &#123; char *error = dlerror(); if(error == NULL) &#123; error = "pthread_create is NULL"; &#125; fprintf(stderr, "%s\n", error); exit(EXIT_FAILURE); &#125;&#125;/* Our data structure passed to the wrapper */typedef struct wrapper_s&#123; void * (*start_routine)(void *); void * arg; pthread_mutex_t lock; pthread_cond_t wait; struct itimerval itimer;&#125; wrapper_t;/* The wrapper function in charge for setting the itimer value */static void * wrapper_routine(void * data)&#123; /* Put user data in thread-local variables */ void * (*start_routine)(void *) = ((wrapper_t*)data)-&gt;start_routine; void * arg = ((wrapper_t*)data)-&gt;arg; /* Set the profile timer value */ setitimer(ITIMER_PROF, &amp;((wrapper_t*)data)-&gt;itimer, NULL); /* Tell the calling thread that we don't need its data anymore */ pthread_mutex_lock(&amp;((wrapper_t*)data)-&gt;lock); pthread_cond_signal(&amp;((wrapper_t*)data)-&gt;wait); pthread_mutex_unlock(&amp;((wrapper_t*)data)-&gt;lock); /* Call the real function */ return start_routine(arg);&#125;/* Our wrapper function for the real pthread_create() */int pthread_create(pthread_t *__restrict thread, __const pthread_attr_t *__restrict attr, void * (*start_routine)(void *), void *__restrict arg)&#123; wrapper_t wrapper_data; int i_return; /* Initialize the wrapper structure */ wrapper_data.start_routine = start_routine; wrapper_data.arg = arg; getitimer(ITIMER_PROF, &amp;wrapper_data.itimer); pthread_cond_init(&amp;wrapper_data.wait, NULL); pthread_mutex_init(&amp;wrapper_data.lock, NULL); pthread_mutex_lock(&amp;wrapper_data.lock); /* The real pthread_create call */ i_return = pthread_create_orig(thread, attr, &amp;wrapper_routine, &amp;wrapper_data); /* If the thread was successfully spawned, wait for the data * to be released */ if(i_return == 0) &#123; pthread_cond_wait(&amp;wrapper_data.wait, &amp;wrapper_data.lock); &#125; pthread_mutex_unlock(&amp;wrapper_data.lock); pthread_mutex_destroy(&amp;wrapper_data.lock); pthread_cond_destroy(&amp;wrapper_data.wait); return i_return;&#125; 参考资料 Saving gmon.out before killing a process Undefined reference to ‘dlsym’ Linux性能评测工具之一：gprof篇]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>profiling</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux c 查看当前进程内存使用值]]></title>
    <url>%2F201706%2Fprogrammer%2Fc%2Fget_rss.html</url>
    <content type="text"><![CDATA[问题背景排查大进程的内存使用率过高问题。在初始化阶段排查每个业务初始化前后内存占用情况，对在初始化阶段动态分配内存的情况有效，对运行时动态分配内存无效。 思路 获取进程 pid 查看 /proc/[pid]/status，获取 VmRSS 值 截取 VmRSS 行，打印 VmRSS 值 通过 sed/awk 获取打印值，并进行计算，确认哪个业务初始化消耗太多内存 /proc/[pid]/status详见 man 5 proc。 VmRSS: Resident set size. Note that the value here is the sum of RssAnon, RssFile, and RssShmem. 样例： 123456789101112131415161718192021222324252627282930313233343536373839404142 sunyongfeng  ~  cat /proc/1610/status Name: upstart-udev-brState: S (sleeping)Tgid: 1610Ngid: 0Pid: 1610PPid: 1524TracerPid: 0Uid: 1003 1003 1003 1003Gid: 1003 1003 1003 1003FDSize: 64Groups: 27 999 1003 VmPeak: 34596 kBVmSize: 34596 kBVmLck: 0 kBVmPin: 0 kBVmHWM: 1916 kBVmRSS: 1788 kBVmData: 240 kBVmStk: 136 kBVmExe: 80 kBVmLib: 4760 kBVmPTE: 76 kBVmSwap: 204 kBThreads: 1SigQ: 1/15283SigPnd: 0000000000000000ShdPnd: 0000000000000000SigBlk: 0000000000000000SigIgn: 0000000000000001SigCgt: 0000000180014000CapInh: 0000000000000000CapPrm: 0000000000000000CapEff: 0000000000000000CapBnd: 0000003fffffffffSeccomp: 0Cpus_allowed: ffCpus_allowed_list: 0-7Mems_allowed: 00000000,00000001Mems_allowed_list: 0voluntary_ctxt_switches: 2212nonvoluntary_ctxt_switches: 30 代码12345678910111213141516171819202122232425const char data_mem[] = "VmRSS:"; /* 打印当前消耗内存 */void print_mem(int pid, char *func_name)&#123; FILE *stream; char cache[256]; char mem_info[64]; printf("after func:[%-30s]\t", func_name); sprintf(mem_info, "/proc/%d/status", pid); stream = fopen(mem_info, "r"); if (stream == NULL) &#123; return; &#125; while(fscanf(stream, "%s", cache) != EOF) &#123; if (strncmp(cache, data_mem, sizeof(data_mem)) == 0) &#123; if (fscanf(stream, "%s", cache) != EOF) &#123; printf("hw memory[%s]&lt;=======\n", cache); break; &#125; &#125; &#125;&#125; 调用： 1print_mem(getpid(), your_func_name);]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 查看进程信息]]></title>
    <url>%2F201706%2Fshell%2Fprocess.html</url>
    <content type="text"><![CDATA[查看 CPU 使用率查看当前正在使用哪个 CPU coretop 命令中，f 命令添加域，选择 j 添加一列 P，显示上次使用的 SMP。J: P = Last used cpu (SMP)。域前面有 “*” 表示已选中。 查看前 123456789101112131415~ # toptop - 13:12:34 up 1:23, 0 users, load average: 11.37, 11.21, 11.10Tasks: 105 total, 3 running, 102 sleeping, 0 stopped, 0 zombieCpu(s): 23.3%us, 76.0%sy, 0.0%ni, 0.7%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%stMem: 995508k total, 508256k used, 487252k free, 0k buffersSwap: 0k total, 0k used, 0k free, 61552k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1546 root 20 0 456m 9592 3536 S 188 1.0 160:05.60 d 888 root 20 0 0 0 0 R 100 0.0 83:36.19 m 1781 root 20 0 0 0 0 R 100 0.0 83:16.54 c 1537 root 20 0 1481m 140m 37m S 8 14.4 4:57.15 a 1979 root 20 0 2848 1164 892 R 2 0.1 0:00.04 top 1 root 20 0 2004 696 592 S 0 0.1 0:02.49 init 2 root 20 0 0 0 0 S 0 0.0 0:00.00 kthreadd f 123456789101112131415161718192021222324Current Fields: AEHIOQTWKNMbcdfgJplrsuvyzX for window 1:DefToggle fields via field letter, type any other key to return * A: PID = Process Id u: nFLT = Page Fault count* E: USER = User Name v: nDRT = Dirty Pages count* H: PR = Priority y: WCHAN = Sleeping in Function* I: NI = Nice value z: Flags = Task Flags &lt;sched.h&gt;* O: VIRT = Virtual Image (kb) * X: COMMAND = Command name/line* Q: RES = Resident size (kb)* T: SHR = Shared Mem size (kb) Flags field:* W: S = Process Status 0x00000001 PF_ALIGNWARN* K: %CPU = CPU usage 0x00000002 PF_STARTING* N: %MEM = Memory usage (RES) 0x00000004 PF_EXITING* M: TIME+ = CPU Time, hundredths 0x00000040 PF_FORKNOEXEC b: PPID = Parent Process Pid 0x00000100 PF_SUPERPRIV c: RUSER = Real user name 0x00000200 PF_DUMPCORE d: UID = User Id 0x00000400 PF_SIGNALED f: GROUP = Group Name 0x00000800 PF_MEMALLOC g: TTY = Controlling Tty 0x00002000 PF_FREE_PAGES (2.5)* J: P = Last used cpu (SMP) 0x00008000 debug flag (2.5) p: SWAP = Swapped size (kb) 0x00024000 special threads (2.5) l: TIME = CPU Time 0x001D0000 special states (2.5) r: CODE = Code size (kb) 0x00100000 PF_USEDFPU (thru 2.4) s: DATA = Data+Stack size (kb) 查看 1234567891011121314top - 13:12:30 up 1:23, 0 users, load average: 11.40, 11.21, 11.10Tasks: 105 total, 4 running, 101 sleeping, 0 stopped, 0 zombieCpu(s): 25.6%us, 74.4%sy, 0.0%ni, 0.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%stMem: 995508k total, 508256k used, 487252k free, 0k buffersSwap: 0k total, 0k used, 0k free, 61552k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ P COMMAND 1546 root 20 0 456m 9592 3536 S 174 1.0 159:57.14 0 d 888 root 20 0 0 0 0 R 100 0.0 83:31.86 2 m 1781 root 20 0 0 0 0 R 100 0.0 83:12.20 3 c 1537 root 20 0 1481m 140m 37m S 16 14.4 4:56.98 1 a 1978 root 20 0 2912 1260 984 R 11 0.1 0:00.08 1 top 1 root 20 0 2004 696 592 S 0 0.1 0:02.49 0 init 2 root 20 0 0 0 0 S 0 0.0 0:00.00 1 kthreadd 跟踪系统调用和信号 - strace strace -p xxx -c，ctrl + c 退出后列出运行期间的所有调用情况统计 strace -p xxx，实时显示系统调用信息]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[p4 simple_switch_CLI 使用说明]]></title>
    <url>%2F201705%2Fnetworks%2Fp4%2Fsimple_switch_CLI.html</url>
    <content type="text"><![CDATA[help在 simple_switch_CLI 提示符下，执行 help，即可显示帮助。以 p4app 下的 simple_switch_CLI 为例。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples/bras.p4app$ docker exec -t -i a070609fbb24 simple_switch_CLIObtaining JSON from switch...DoneControl utility for runtime P4 table manipulationRuntimeCmd: help Documented commands (type help &lt;topic&gt;):========================================act_prof_add_member_to_group set_crc16_parameters act_prof_create_group set_crc32_parameters act_prof_create_member set_queue_depth act_prof_delete_group set_queue_rate act_prof_delete_member shell act_prof_dump show_actions act_prof_dump_group show_ports act_prof_dump_member show_tables act_prof_modify_member swap_configs act_prof_remove_member_from_group switch_info counter_read table_add counter_reset table_delete get_time_elapsed table_dump get_time_since_epoch table_dump_entry help table_dump_entry_from_key load_new_config_file table_dump_group mc_dump table_dump_member mc_mgrp_create table_indirect_add mc_mgrp_destroy table_indirect_add_member_to_group mc_node_associate table_indirect_add_with_group mc_node_create table_indirect_create_group mc_node_destroy table_indirect_create_member mc_node_dissociate table_indirect_delete mc_node_update table_indirect_delete_group mc_set_lag_membership table_indirect_delete_member meter_array_set_rates table_indirect_modify_member meter_get_rates table_indirect_remove_member_from_groupmeter_set_rates table_indirect_set_default mirroring_add table_indirect_set_default_with_group mirroring_delete table_info port_add table_modify port_remove table_num_entries register_read table_set_default register_reset table_set_timeout register_write table_show_actions reset_state write_config_to_file serialize_state Undocumented commands:======================EOF greetRuntimeCmd: 如果想查看每个命令的用法，以添加表项为例，执行 help table_add。 123RuntimeCmd: help table_addAdd entry to a match table: table_add &lt;table name&gt; &lt;action name&gt; &lt;match fields&gt; =&gt; &lt;action parameters&gt; [priority]RuntimeCmd: 表操作 查看本 switch 所有表，show_tables 查看某张表的描述，table_info 表名 查看某张表的信息，table_show 表名 添加表项，table_add 表名 action名 key值 =&gt; 字段1值 字段2值 字段3值]]></content>
      <categories>
        <category>p4</category>
      </categories>
      <tags>
        <tag>p4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NAT 知识汇总]]></title>
    <url>%2F201705%2Fnetworks%2Fnat.html</url>
    <content type="text"><![CDATA[由于全球 IP 地址的耗尽，电信级 NAT 应运而生，有人就被电信内网了，电信终于对我下此毒手了…该死的NAT转换。被电信内网了的最显著效果是，没经过特殊处理，外部无法访问你的服务器。因此就涉及到 NAT 转换和 NAT 穿越的概念。 NAT NAPT CGN / NAT44 TODO…]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>networks</tag>
        <tag>nat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[p4app 仓库 —— 用于快速验证 P4 程序]]></title>
    <url>%2F201705%2Fnetworks%2Fp4%2Frepo_p4app.html</url>
    <content type="text"><![CDATA[本文译自 p4app README，对内容结构进行少量调整，并附上运行 log。 简介p4app 仓库创建于 2017-02-23，是一种构建、运行、调试和测试 P4 程序的工具。哲学是“简单的东西应尽可能简单”，旨在使小而简单的 P4 程序易于编写、易于与他人分享。 p4factory 或 switch 等 P4 样例依赖安装步骤复杂、编译时间超长。p4app 可很好地解决此问题，降低 P4 入门门槛。与预期的相符，p4app 将 bmv2 等基础组件整合成一个 docker image。 安装 下载 p4app 1git clone https://github.com/p4lang/p4app Bug fix. p4app bug: pull request 17，docker 镜像名已由 p4lang/p4app:stable 改为 p4lang/p4app:latest。修改 p4app L16 为: 1-P4APP_IMAGE=$&#123;P4APP_IMAGE:-p4lang/p4app:latest&#125; 如果没有安装 docker ，需先安装。一键搞定：wget -qO- https://get.docker.com/ | sh。 为方便，建议把 p4app 脚本拷贝到 PATH 路径，例如： 1sudo cp p4app /usr/local/bin 程序安装到此结束！ 使用p4app 运行以 .p4app 为后缀的目录，称 p4app 包。p4app 仓库中包含多个样例，例如 simple_router.p4app，运行方法： 1p4app run examples/simple_router.p4app 此样例最终进入 mininet 命令行，在此之前，p4app 进行如下处理： 【首次运行 p4app 命令时】自动下载 docker 镜像 p4lang/p4app:latest，该镜像包含 P4 编译器、抓包工具 tshark、发包工具 scapy、net-tools 和 nmap 套件等工具 编译 simper_router.p4 设置并启动一个容器做为软件交换机 设置并启动 mininet 模拟实验网络 p4app 命令参数 run，运行 p4app，可带 target 参数。 pack，压缩 p4app 包为单独文件，便于分享。使用 gzip 压缩 unpack，解压上述压缩包 update，更新 p4app 本地缓存的 P4 编译器和相关工具到最新版本。p4app 在本地缓存P4编译器和工具，因此不必每次都重新下载。 123456789101112sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app$ ./p4app -hUsage: p4app run &lt;program.p4app&gt; Run a p4app. p4app run &lt;program.p4app&gt; &lt;target&gt; Run a p4app, specifying a target. p4app pack &lt;program.p4app&gt; Compress a p4app directory into a single file, in-place. p4app unpack &lt;program.p4app&gt; Expand a p4app file into a directory, in-place. p4app update Update the toolchain to the newest version. target 与 backendp4app 包最终将怎么运行，由配置文件 manifest file p4app.json 的参数targets 指定。目前支持有多种运行方式，例如仅编译成 bmv2 目标、进行 stf 测试、mininet 单交换机测试、mininet 多交换机测试等。本文将这些运行方式称为 backend，一个 p4app 包可以有多个 target，每个 target 必须指定其 backend。 通过在 p4app run 时指定 target 运行非默认 target，例如运行 simple_counter.p4app 的 debug target： 1p4app run examples/simple_couter.p4app debug 如果有多个 target，且使用者没有通过名字指定默认 target，则 p4app 随机运行其中一个。可使用 default-target 选项，设置默认 backend。例如： 12345678910&#123; "program": "my_program.p4", "language": "p4-14", "default-target": "debug", "targets": &#123; "debug": &#123; "use": "mininet", "num-hosts": 2 &#125;, "test1": &#123; "use": "stf", "test": "test1.stf" &#125;, "test2": &#123; "use": "stf", "test": "test2.stf" &#125;, &#125;&#125; 这里定义一个名为 “debug” 的 mininet backend，以及两个 STF backend，分别名为 “test1” 和 “test2”。&quot;user&quot;:&quot;mininet&quot; 用于指明每个 target 使用哪个 backend，如果不使用 user 字段，则 target 名同时被认定为 backend 名。这也是为什么，在之前的样例中，不需要指明&quot;use&quot;: &quot;mininet&quot; ，因为 target 名就已经是 mininet，如果直接被用成 backend 名，p4app 也可以识别。 目前支持以下几种 backend，具体见后文详述。 mininet multiswitch custom stf compile-bmv2 创建一个 p4app 包p4app 包的目录结构一般为： 1234567my_program.p4app | |- p4app.json | |- my_program.p4 | |- ...other files... p4app.json 是这个包的 manifest 文件，说明如何构建和运行 p4 程序，功能有点像 Makefile 文件。样例： 12345678910&#123; "program": "my_program.p4", "language": "p4-14", "targets": &#123; "mininet": &#123; "num-hosts": 2, "switch-config": "my_program.config" &#125; &#125;&#125; 样例 manifest 告诉 p4app 应该运行 my_program.p4，该 p4 程序使用 p4-14 编写（同样也可以用 p4-16，P4-16 版本）。该样例定义一个 target，该 target 的 backend 为 mininet，同时提供一些 mininet 配置选项：测试网络有两个 host，一个模拟交换机，该交换机启机默认加载 my_program.config 中的配置。如果你在 p4app.json 中引用像 my_program.config 时，则需要将 my_program.config 文件包在 p4app 包中，p4app 将确保相应工具可找到它。 Backendmininet该后端编译 p4 程序，并加载到 BMv2 simple_switch，然后创建 mininet 实验环境。 支持以下配置值（皆为可选）： 1234"mininet": &#123; "num-hosts": 2, "switch-config": "file.config"&#125; mininet 将创建星形拓扑网络，并创建 num-hosts 个数的 host，通过不同端口连接到模拟交换机。 模拟交换机的启机默认配置可通过 switch-config 配置。配置的文件是一系列 BMV2 simple_switch_CLI 命令。 在启机过程中，有信息提示网络配置信息以及如何使用 logging 和 debugging 工具。 BMV2 debugger 很方便，这里 阅读如何使用。 该 backend 还支持compile-bmv2 配置编译选项，详见下文相应章节。 multiswitch和 mininet 一样，这个 target 包含 P4 程序，并运行在 mininet 环境。但是这个 backend 支持配置多个交换机、自定义拓扑并在 host 上执行自定义命令。这些交换机默认自动配置 l2/l3 规则，用于所有 host 之间的互通，即假设 P4 程序有 ipv4_lpm、send_frame 和 forward 表，详见 simple_router.p4。 配置样例： 12345678910111213141516171819202122"multiswitch": &#123; "links": [ ["h1", "s1"], ["s1", "s2"], ["s2", "h2", 50] ], "hosts": &#123; "h1": &#123; "cmd": "python echo_server.py $port", "startup_sleep": 0.2, "wait": false &#125;, "h2": &#123; "cmd": "python echo_client.py h1 $port $echo_msg", "wait": true &#125; &#125;, "parameters": &#123; "port": 8000, "echo_msg": "foobar" &#125;&#125; 该配置创建以下拓扑： 1h1 &lt;---&gt; s1 &lt;---&gt; s2 &lt;---&gt; h2 其中 s2-h2 链路人工配置 50ms 的延迟。host 配置选项： cmd - 在 host 上运行的命令 wait - 等待命令执行结束。如果配置成 false，表示在后台运行此命令。 startup_sleep - 启动命令后应等待的时间（以秒为单位）。 latency - 主机与交换机之间的延迟。配置值是数字（解释为秒）或具有时间单位的字符串（例如50ms或1s）。该配置将覆盖“links”对象中设置的延迟。 通过将主机名（例如 “h1”）替换为相应的 IP 地址来格式化该命令。 目标中指定的参数将作为环境变量（即$后跟变量名称）可用于命令，详见 multiswitch 样例。 限制目前每个 host 最多只能连一个 switch。 指定每个交换机表项路由表（ipv4_lpm，send_frame 和 forward）在本 target 中自动下发。使用者可根据自己的需要下发表项到每个交换机中，形式为包含一个命令文件或命令数组。这些自定义的表项优先级比路由表的自动生成的高。例如： 123456789101112131415"multiswitch": &#123; "links": [ ... ], "hosts": &#123; ... &#125;, "switches": &#123; "s1": &#123; "entries": "s1_commands.txt" &#125;, "s2": &#123; "entries": [ "table_add ipv4_lpm set_nhop 10.0.1.10/32 =&gt; 10.0.1.10 1", "table_add ipv4_lpm set_nhop 10.0.2.10/32 =&gt; 10.0.2.10 2" ] &#125; &#125;&#125; 如果上述 s2 表项与自动生成的表项一样（例如自动生成的表项 set_nhop 10.0.1.10 / 32），这些自定义表项将具有更高的优先权，在下发表项时将警告表项重复。 自定义拓扑类通过 topo_module 选项指定自己的 mininet 拓扑类。例如： 12345"multiswitch": &#123; ... "topo_module": "mytopo" ...&#125; 这将 import mytopo 模块 mytopo.py，该文件应与 manifest 文件（p4app.json）放在同一目录下，同时应实现 CustomAppTopo 类。可 extend 默认的 topo 类 apptopo.AppTopo。例如： 12345678# mytopo.pyfrom apptopo import AppTopoclass CustomAppTopo(AppTopo): def __init__(self, *args, **kwargs): AppTopo.__init__(self, *args, **kwargs) print self.links() 详见样例 customtopo.p4app。 自定义控制器类似 topo_module 选项，通过 controller_module 选项自定义控制器。该模块应实现 CustomAppController 类。默认的控制器类为 appcontroller.AppController，可直接对该类进行扩展。详见样例 customtopo.p4app。 Logging当本 target 运行时，host 上的临时目录 /tmp/p4app_log 将加载到 guest 的 /tmp/p4app_log。运行 p4app 后， host 上保存有所有的 log。 host 命令的标准输出 stdout 将保存在该目录，如果需要保存某个命令的 log，将可以将其输出到该目录。 设置 &quot;bmv2_log&quot;:true，保存 P4 交换机的调试 log。设置 &quot;pcap_dump&quot;:true，抓取所有交换机的报文，交保存为 PCAP 格式。 以上文件将被保存到 /tmp/p4app_log。详见样例 broadcast.p4app Cleanup commands运行 target 后（在 mininet stop 之前），如果需要在 docker 容器内执行命令，可使用 after 选项，其后必须包含 cmd，可以是一个或多个命令，例如： 12345678910"multiswitch": &#123; "links": [ ... ], "hosts": &#123; ... &#125;, "after": &#123; "cmd": [ "echo register_read my_register 1 | simple_switch_CLI --json p4src/my_router.p4.json", "echo register_read my_register 2 | simple_switch_CLI --json p4src/my_router.p4.json" ] &#125;&#125; custom该 backend 允许使用者指定 python program，该 program 使用 Mininet python API 指定网络拓扑和配置。例如： 123456789&#123; "program": "source_routing.p4", "language": "p4-14", "targets": &#123; "custom": &#123; "program": "topo.py" &#125; &#125;&#125; 该 target 在启动 Mninet 时运行 topy.py 脚本。将使用以下参数调用 program： 参数 说明 –behavioral-exe switch 可执行文件 –json P4 程序编译结果 –cli switch_CLI 命令 样例： 1234PYTHONPATH=$PYTHONPATH:/scripts/mininet/ python2 topo.py \ --behavioral-exe simple_switch \ --json SOME_FILE \ --cli simple_switch_CLI 同时可以指定其他参数传递给自定义拓扑程序，方法是将它们包含在 program 定义中，如下所示： 123456789&#123; "program": "source_routing.p4", "language": "p4-14", "targets": &#123; "custom": &#123; "program": "topo.py --num-hosts 2 --switch-config simple_router.config" &#125; &#125;&#125; program 可通过 HOSTNAME 变量获取 docker 容器 ID。 1234import oscontainer = os.environ['HOSTNAME']print 'Run the switch CLI as follows:'print ' docker exec -t -i %s %s' % (container, args.cli) stfstf 后端编译给定的 p4 程序，并运行 stf 测试用例。 stf，simple testing framework，一种模拟网络测试框架。 “simple testing framework”, which can help you test small P4 programs and ensure they behave the way you expect. simple_counter.p4app 样例使用 stf 测试框架，运行该样例： 1p4app run examples/simple_counter.p4app 运行后，p4app 启动 docker 容器，并在容器中： 自动编译 simple_counter.p4 运行 simple_switch 交换机 stf 下发默认表项 stf 发送定义在 simple_counter.stf 中的报文，并验证 simple_switch 是否转发出预期的报文 和 mininet 不一样的是， stf 最终直接退出。 simple_counter.p4app stf 配置 p4app.json 配置 1234567891011121314&#123; "program": "simple_counter.p4", "language": "p4-14", "targets": &#123; "stf": &#123; "test": "simple_counter.stf" &#125;, "debug": &#123; "use": "mininet", "num-hosts": 2, "switch-config": "simple_counter.config" &#125; &#125;&#125; stf 文件 simple_counter.stf 配置 1234567891011121314add test1 data.f1:0x01010101 c1_2(val1:0x01, val2:0x02)add test1 data.f1:0x02020202 c1_2(val1:0x10, val2:0x20)add test2 data.f2:0x03030303 c3_4(val3:0x03, val4:0x04, port:1)add test2 data.f2:0x04040404 c3_4(val3:0x30, val4:0x40, port:2)expect 1 01010101 03030303 01 02 03 04packet 0 01010101 03030303 55 66 77 88expect 2 01010101 04040404 01 02 30 40packet 0 01010101 04040404 55 66 77 88expect 1 02020202 03030303 10 20 03 04packet 0 02020202 03030303 99 88 77 66expect 2 02020202 04040404 10 20 30 40packet 0 02020202 04040404 14 25 36 47 必须使用 stf 格式编写 stf target 指定的配置文件，目前还没有该格式的说明文档。（如果您想反向工程并提供一些文档，请提交PR！）请参阅 p4app 相关样例，参考其中的基本用法。 此后端还支持 compile-bmv2 target 的配置值。 compile-bmv2一个简单的后端，将 p4 程序编译成 BMV2 目标。 支持以下可选配置值： 12345"compile-bmv2": &#123; "compiler-flags": ["-v", "-E"], "run-before-compile": ["date"], "run-after-compile": ["date"]&#125; 高级功能指定 docker image如果想使用自定义的 P4 工具链或 p4app，可通过 P4APP_IMAGE 环境变量配置 Docker image，替代标准 p4lang image。例如： 1P4APP_IMAGE=me/my_p4app_image:latest p4app run examples/simple_router.p4app 指定 manifest 文件默认情况下，p4app 使用 app 目录下一个名为 p4app.json 的 manifest 文件。如果你的 manifest 文件名称不是 p4app.json，则可通过 --manifest 选项指定 manifest 文件。例如： 1p4app run myapp.p4app --manifest testing.p4app 指定 log 目录默认情况下，p4app 挂载 host 目录 /tmp/p4app_logs 到 docker 容器 guest 目录 /tmp/p4app_logs。bmv2 以及其他程序的输出将保存在此目录。可通过 $P4APP_LOGDIR 环境变量指定其他目录为 log 目录，例如： 1P4APP_LOGDIR=./out p4app run myapp.p4app 运行 log 汇总运行 simple_router.p4app123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app$ sudo cp p4app /usr/local/bin/sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app$ p4app run examples/simple_router.p4app/Unable to find image 'p4lang/p4app:latest' locallylatest: Pulling from p4lang/p4appc62795f78da9: Already exists d4fceeeb758e: Already exists 5c9125a401ae: Already exists 0062f774e994: Already exists 6b33fd031fac: Already exists c0bc589d658e: Pull complete d304998c3f88: Pull complete 9a10b2f1580d: Pull complete 0f3b81cccf80: Pull complete d32e2c3a5556: Pull complete 421d6ade42fb: Pull complete ed336ba6d94a: Pull complete 15d9b8c3dfdb: Pull complete d7df888c0624: Pull complete 09b889a34f73: Pull complete 8e46ef6cc28e: Pull complete 53625fe57a43: Pull complete a1cfe7751ecf: Pull complete 098b357129cf: Pull complete ecb46f207e83: Pull complete 25df5d0fdf2a: Pull complete a2592a836f76: Pull complete ba5f1dc63b79: Pull complete d8fe27124ef4: Pull complete b6c4e12d947a: Pull complete 24342178e654: Pull complete 21146199f8e0: Pull complete 41e02212e6ab: Pull complete 885ba0b6073a: Pull complete 28805cf1e6e6: Pull complete d5f002ec605e: Pull complete 07b6dd17ef27: Pull complete b91909b6c11f: Pull complete f0f07a64cc7e: Pull complete 202436ed05da: Pull complete Digest: sha256:7d8a140c7160992f693b9d5fab08f7aeaacdb448050d17da81c4ae05dd5465d0Status: Downloaded newer image for p4lang/p4app:latestEntering build directory.Extracting package.Reading package manifest.&gt; p4c-bm2-ss --p4v 16 "simple_router.p4" -o "simple_router.p4.json"&gt; python2 "/scripts/mininet/single_switch_mininet.py" --log-file "/var/log/simple_router.p4.log" --cli-message "mininet_message.txt" --num-hosts 2 --switch-config "simple_router.config" --behavioral-exe "simple_switch" --json "simple_router.p4.json"Adding host h1Adding host h2*** Error setting resource limits. Mininet's performance may be affected.*** Creating network*** Adding hosts:h1 h2 *** Adding switches:s1 *** Adding links:(h1, s1) (h2, s1) *** Configuring hostsh1 h2 *** Starting controller*** Starting 1 switchess1 Starting P4 switch s1.simple_switch -i 1@s1-eth1 -i 2@s1-eth2 --thrift-port 9090 --nanolog ipc:///tmp/bm-0-log.ipc --device-id 0 simple_router.p4.json --debugger --log-consoleP4 switch s1 has been started.**********Network configuration for: h1Default interface: h1-eth0 10.0.0.10 00:04:00:00:00:00Default route to switch: 10.0.0.1 (00:aa:bb:00:00:00)********************Network configuration for: h2Default interface: h2-eth0 10.0.1.10 00:04:00:00:00:01Default route to switch: 10.0.1.1 (00:aa:bb:00:00:01)**********Reading switch configuration script: simple_router.configConfiguring switch...Obtaining JSON from switch...DoneControl utility for runtime P4 table manipulationRuntimeCmd: Setting default action of send_frameaction: _dropruntime data: RuntimeCmd: Setting default action of forwardaction: _dropruntime data: RuntimeCmd: Setting default action of ipv4_lpmaction: _dropruntime data: RuntimeCmd: Adding entry to exact match table send_framematch key: EXACT-00:01action: rewrite_macruntime data: 00:aa:bb:00:00:00Entry has been added with handle 0RuntimeCmd: Adding entry to exact match table send_framematch key: EXACT-00:02action: rewrite_macruntime data: 00:aa:bb:00:00:01Entry has been added with handle 1RuntimeCmd: Adding entry to exact match table forwardmatch key: EXACT-0a:00:00:0aaction: set_dmacruntime data: 00:04:00:00:00:00Entry has been added with handle 0RuntimeCmd: Adding entry to exact match table forwardmatch key: EXACT-0a:00:01:0aaction: set_dmacruntime data: 00:04:00:00:00:01Entry has been added with handle 1RuntimeCmd: Adding entry to lpm match table ipv4_lpmmatch key: LPM-0a:00:00:0a/32action: set_nhopruntime data: 0a:00:00:0a 00:01Entry has been added with handle 0RuntimeCmd: Adding entry to lpm match table ipv4_lpmmatch key: LPM-0a:00:01:0a/32action: set_nhopruntime data: 0a:00:01:0a 00:02Entry has been added with handle 1RuntimeCmd: Configuration complete.Ready !======================================================================Welcome to the BMV2 Mininet CLI!======================================================================Your P4 program is installed into the BMV2 software switchand your initial configuration is loaded. You can interactwith the network using the mininet CLI below.To inspect or change the switch configuration, connect toits CLI from your host operating system using this command: docker exec -t -i 66d97e58a61f simple_switch_CLITo view the switch log, run this command from your host OS: docker exec -t -i 66d97e58a61f tail -f /var/log/simple_router.p4.logTo run the switch debugger, run this command from your host OS: docker exec -t -i 66d97e58a61f bm_p4dbg*** Starting CLI:mininet&gt; h1 ping h2PING 10.0.1.10 (10.0.1.10) 56(84) bytes of data.64 bytes from 10.0.1.10: icmp_seq=1 ttl=63 time=1.42 ms64 bytes from 10.0.1.10: icmp_seq=2 ttl=63 time=1.65 ms^C--- 10.0.1.10 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1000msrtt min/avg/max/mdev = 1.421/1.540/1.659/0.119 msmininet&gt; mininet&gt; mininet&gt; exit*** Stopping 0 controllers*** Stopping 2 links..*** Stopping 1 switchess1 *** Stopping 2 hostsh1 h2 *** Done 运行 simple_counter.p4app1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app$ p4app run examples/simple_counter.p4app/Entering build directory.Extracting package.Reading package manifest.&gt; p4c-bm2-ss --p4v 14 "simple_counter.p4" -o "simple_counter.p4.json"warning: cnt: Direct counter not used; ignoring&gt; python2 "/scripts/stf/bmv2stf.py" -v /tmp/simple_counter.p4.json /tmp/simple_counter.stfWARNING: No route found for IPv6 destination :: (no default route?)Running modelRunning simple_switch --log-file switch.log --log-flush --use-files 0 --thrift-port 9232 --device-id 142 -i 0@pcap0 -i 1@pcap1 -i 2@pcap2 /tmp/simple_counter.p4.jsonCalling target program-options parserAdding interface pcap0 as port 0 (files)Adding interface pcap1 as port 1 (files)Adding interface pcap2 as port 2 (files)Running simple_switch_CLI --thrift-port 9232Thrift server was startedSTF Command: STF Command: add test1 data.f1:0x01010101 c1_2(val1:0x01, val2:0x02)table_add test1 c1_2 0x01010101 =&gt; 0x01 0x02STF Command: add test1 data.f1:0x02020202 c1_2(val1:0x10, val2:0x20)table_add test1 c1_2 0x02020202 =&gt; 0x10 0x20STF Command: STF Command: add test2 data.f2:0x03030303 c3_4(val3:0x03, val4:0x04, port:1)table_add test2 c3_4 0x03030303 =&gt; 0x03 0x04 1STF Command: add test2 data.f2:0x04040404 c3_4(val3:0x30, val4:0x40, port:2)table_add test2 c3_4 0x04040404 =&gt; 0x30 0x40 2STF Command: STF Command: expect 1 01010101 03030303 01 02 03 04STF Command: packet 0 01010101 03030303 55 66 77 88Obtaining JSON from switch...DoneControl utility for runtime P4 table manipulationRuntimeCmd: Adding entry to exact match table test1match key: EXACT-01:01:01:01action: c1_2runtime data: 01 02Entry has been added with handle 0RuntimeCmd: Adding entry to exact match table test1match key: EXACT-02:02:02:02action: c1_2runtime data: 10 20Entry has been added with handle 1RuntimeCmd: Adding entry to exact match table test2match key: EXACT-03:03:03:03action: c3_4runtime data: 03 04 00:01Entry has been added with handle 0RuntimeCmd: Adding entry to exact match table test2match key: EXACT-04:04:04:04action: c3_4runtime data: 30 40 00:02Entry has been added with handle 1STF Command: expect 2 01010101 04040404 01 02 30 40STF Command: packet 0 01010101 04040404 55 66 77 88STF Command: expect 1 02020202 03030303 10 20 03 04STF Command: packet 0 02020202 03030303 99 88 77 66STF Command: expect 2 02020202 04040404 10 20 30 40STF Command: packet 0 02020202 04040404 14 25 36 47RuntimeCmd: simple_switch exit code -15Execution completedComparing outputsWARNING: PcapReader: unknown LL type [0]/[0x0]. Using Raw packetsWARNING: PcapReader: unknown LL type [0]/[0x0]. Using Raw packetsSUCCESS pack &amp; unpack 样例 log1234567891011sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples$ ls multiswitch.p4app/echo_client.py echo_server.py header.p4 p4app.json parser.p4 simple_router.p4sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples$ p4app pack multiswitch.p4app/ sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples$ lsbroadcast.p4app customtopo.p4app multiswitch.p4app simple_counter.p4app source_routing.p4appcompile_only.p4app multi_iface.p4app paxos_acceptor.p4app simple_router.p4appsunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples$ file multiswitch.p4app multiswitch.p4app: gzip compressed data, last modified: Mon May 29 08:25:21 2017, from Unixsunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples$ p4app unpack multiswitch.p4app sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples$ ls multiswitch.p4app/echo_client.py echo_server.py header.p4 p4app.json parser.p4 simple_router.p4 compile-bmv2 backend 样例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app$ p4app run examples/compile_only.p4app/Entering build directory.Extracting package.Reading package manifest.&gt; p4c-bm2-ss --p4v 14 -v --p4runtime-file out.bin --p4runtime-as-json "compile_only.p4" -o "compile_only.p4.json"error: Unknown option --p4runtime-as-jsonp4c-bm2-ss: Compile a P4 program--help Print this help message--version Print compiler version-I path Specify include path (passed to preprocessor)-D arg=value Define macro (passed to preprocessor)-U arg Undefine macro (passed to preprocessor)-E Preprocess only, do not compile (prints program on stdout)--nocpp Skip preprocess, assume input file is already preprocessed.--p4v &#123;14|16&#125; Specify language version to compile--target target Compile for the specified target--pp file Pretty-print the program in the specified file.--toJSON file Dump IR to JSON in the specified file.--testJson Dump and undump the IR--p4runtime-file file Write a P4Runtime control plane API description to the specified file.--p4runtime-format &#123;binary,json,text&#125; Choose output format for the P4Runtime API description (default is binary).-o outfile Write output to outfile--Werror Treat all warnings as errors-T loglevel [Compiler debugging] Adjust logging level per file (see below)-v [Compiler debugging] Increase verbosity level (can be repeated)--top4 pass1[,pass2] [Compiler debugging] Dump the P4 representation after passes whose name contains one of `passX' substrings. When '-v' is used this will include the compiler IR.--dump folder [Compiler debugging] Folder where P4 programs are dumpedloglevel format is: sourceFile:level,...,sourceFile:levelwhere 'sourceFile' is a compiler source file and'level' is the verbosity level for LOG messages in that file&gt; cat out.bincat: out.bin: No such file or directoryCompile failed.sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app$ vi examples/compile_only.p4app/p4app.jsonsunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app$ sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app$ p4app run examples/compile_only.p4app/Entering build directory.Extracting package.Reading package manifest.&gt; p4c-bm2-ss --p4v 14 -v --p4runtime-file out.bin --p4runtime-format json "compile_only.p4" -o "compile_only.p4.json"Invoking preprocessor cpp -C -undef -nostdinc -D__TARGET_BMV2__ -I/usr/local/share/p4c/p4_14include compile_only.p4Invoking preprocessor cpp -C -undef -nostdinc -I/usr/local/share/p4c/p4include /usr/local/share/p4c/p4include/v1model.p4Parsing P4-16 program /usr/local/share/p4c/p4include/v1model.p4Parsing P4-14 program compile_only.p4Converting to P4-16Converter_0_DoConstantFoldingConverter_1_CheckHeaderTypesConverter_2_TypeCheckConverter_3_DiscoverStructureConverter_4_ComputeCallGraphConverter_5_RewriterConverter_6_FixExtractsFrontEnd_0_PrettyPrintFrontEnd_1_ValidateParsedProgramFrontEnd_2_CreateBuiltinsFrontEnd_3_ResolveReferencesFrontEnd_4_ConstantFoldingFrontEnd_5_InstantiateDirectCallsFrontEnd_6_ResolveReferencesFrontEnd_7_TypeInferenceFrontEnd_8_BindTypeVariablesFrontEnd_9_ClearTypeMapFrontEnd_10_TableKeyNamesFrontEnd_11_ConstantFoldingFrontEnd_12_StrengthReductionFrontEnd_13_UselessCastsFrontEnd_14_SimplifyControlFlowFrontEnd_15_FrontEndDumpFrontEnd_16_RemoveAllUnusedDeclarationsFrontEnd_17_SimplifyParsersFrontEnd_18_ResetHeadersFrontEnd_19_UniqueNamesFrontEnd_20_MoveDeclarationsFrontEnd_21_MoveInitializersFrontEnd_22_SideEffectOrderingFrontEnd_23_SetHeadersFrontEnd_24_SimplifyControlFlowFrontEnd_25_MoveDeclarationsFrontEnd_26_SimplifyDefUseFrontEnd_27_UniqueParametersFrontEnd_28_SimplifyControlFlowFrontEnd_29_SpecializeAllFrontEnd_30_RemoveParserControlFlowFrontEnd_31_FrontEndLastMidEnd_0_ConvertEnumsMidEnd_1_VisitFunctorMidEnd_2_RemoveReturnsMidEnd_3_MoveConstructorsMidEnd_4_RemoveAllUnusedDeclarationsMidEnd_5_ClearTypeMapMidEnd_6_EvaluatorMidEnd_7_VisitFunctorMidEnd_8_InlineMidEnd_9_InlineActionsMidEnd_10_LocalizeAllActionsMidEnd_11_UniqueNamesMidEnd_12_UniqueParametersMidEnd_13_SimplifyControlFlowMidEnd_14_RemoveActionParametersMidEnd_15_SimplifyKeyMidEnd_16_ConstantFoldingMidEnd_17_StrengthReductionMidEnd_18_SimplifySelectCasesMidEnd_19_ExpandLookaheadMidEnd_20_SimplifyParsersMidEnd_21_StrengthReductionMidEnd_22_EliminateTuplesMidEnd_23_CopyStructuresMidEnd_24_NestedStructsMidEnd_25_SimplifySelectListMidEnd_26_RemoveSelectBooleansMidEnd_27_PredicationMidEnd_28_MoveDeclarationsMidEnd_29_ConstantFoldingMidEnd_30_LocalCopyPropagationMidEnd_31_ConstantFoldingMidEnd_32_MoveDeclarationsMidEnd_33_ValidateTablePropertiesMidEnd_34_SimplifyControlFlowMidEnd_35_CompileTimeOperationsMidEnd_36_TableHitMidEnd_37_SynthesizeActionsMidEnd_38_MoveActionsToTablesMidEnd_39_TypeCheckingMidEnd_40_SimplifyControlFlowMidEnd_41_RemoveLeftSlicesMidEnd_42_TypeCheckingMidEnd_43_LowerExpressionsMidEnd_44_ConstantFoldingMidEnd_45_TypeCheckingMidEnd_46_RemoveComplexExpressionsMidEnd_47_FixupChecksumMidEnd_48_SimplifyControlFlowMidEnd_49_RemoveAllUnusedDeclarationsMidEnd_50_EvaluatorMidEnd_51_VisitFunctorMidEnd_52_MidEndLast&gt; cat out.bin&#123; "tables": [ &#123; "preamble": &#123; "id": 33588198, "name": "t1", "alias": "t1" &#125;, "actionRefs": [ &#123; "id": 16792110 &#125;, &#123; "id": 16800567, "annotations": [ "@default_only()" ] &#125; ], "size": "1024" &#125; ], "actions": [ &#123; "preamble": &#123; "id": 16800567, "name": "NoAction", "alias": "NoAction" &#125; &#125;, &#123; "preamble": &#123; "id": 16792110, "name": "a1", "alias": "a1" &#125;, "params": [ &#123; "id": 1, "name": "port", "bitwidth": 9 &#125; ] &#125; ]&#125;sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app$ logging 功能样例运行样例 bcast_router.p4app，虽然运行后有提示错误，但是不影响 logging 样例展示。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples$ p4app run broadcast.p4app/Entering build directory.Extracting package.Reading package manifest.&gt; p4c-bm2-ss --p4v 16 "bcast_router.p4" -o "bcast_router.p4.json"&gt; python2 "/scripts/mininet/multi_switch_mininet.py" --log-dir "/tmp/p4app_logs" --manifest "./p4app.json" --target "multiswitch" --auto-control-plane --behavioral-exe "simple_switch" --json "bcast_router.p4.json"*** Error setting resource limits. Mininet's performance may be affected.*** Creating network*** Adding hosts:h1 h2 h3 *** Adding switches:s1 *** Adding links:(0ms delay) (0ms delay) (h1, s1) (0ms delay) (0ms delay) (h2, s1) (0ms delay) (0ms delay) (h3, s1) *** Configuring hostsh1 h2 h3 *** Starting controller*** Starting 1 switchess1 Starting P4 switch s1.simple_switch -i 1@s1-eth1 -i 2@s1-eth2 -i 3@s1-eth3 --pcap --thrift-port 9090 --nanolog ipc:///tmp/bm-0-log.ipc --device-id 0 bcast_router.p4.json --log-consoleP4 switch s1 has been started.-----------------------table_add ipv4_lpm broadcast 255.255.255.255/32 =&gt;table_add forward set_dmac 255.255.255.255 =&gt; ff:ff:ff:ff:ff:ffmc_mgrp_create 1mc_node_create 0 1 2 3mc_node_associate 1 0table_add ipv4_lpm broadcast 255.255.255.255/32 =&gt;table_add forward set_dmac 255.255.255.255 =&gt; ff:ff:ff:ff:ff:ffmc_mgrp_create 1mc_node_create 0 1 2 3mc_node_associate 1 0table_set_default send_frame _droptable_set_default forward _droptable_set_default ipv4_lpm _droptable_add send_frame rewrite_mac 2 =&gt; 00:aa:00:01:00:02table_add forward set_dmac 10.0.2.10 =&gt; 00:04:00:00:00:02table_add ipv4_lpm set_nhop 10.0.2.10/32 =&gt; 10.0.2.10 2table_add send_frame rewrite_mac 3 =&gt; 00:aa:00:01:00:03table_add forward set_dmac 10.0.3.10 =&gt; 00:04:00:00:00:03table_add ipv4_lpm set_nhop 10.0.3.10/32 =&gt; 10.0.3.10 3table_add send_frame rewrite_mac 1 =&gt; 00:aa:00:01:00:01table_add forward set_dmac 10.0.1.10 =&gt; 00:04:00:00:00:01table_add ipv4_lpm set_nhop 10.0.1.10/32 =&gt; 10.0.1.10 1Obtaining JSON from switch...DoneControl utility for runtime P4 table manipulationRuntimeCmd: Adding entry to lpm match table ipv4_lpmmatch key: LPM-ff:ff:ff:ff/32action: broadcastruntime data: Entry has been added with handle 0RuntimeCmd: Adding entry to exact match table forwardmatch key: EXACT-ff:ff:ff:ffaction: set_dmacruntime data: ff:ff:ff:ff:ff:ffEntry has been added with handle 0RuntimeCmd: Creating multicast group 1RuntimeCmd: Creating node with rid 0 , port map 1110 and lag map node was created with handle 0RuntimeCmd: Associating node 0 to multicast group 1RuntimeCmd: Adding entry to lpm match table ipv4_lpmmatch key: LPM-ff:ff:ff:ff/32action: broadcastruntime data: Invalid table operation (DUPLICATE_ENTRY)RuntimeCmd: Adding entry to exact match table forwardmatch key: EXACT-ff:ff:ff:ffaction: set_dmacruntime data: ff:ff:ff:ff:ff:ffInvalid table operation (DUPLICATE_ENTRY)RuntimeCmd: Creating multicast group 1RuntimeCmd: Creating node with rid 0 , port map 1110 and lag map node was created with handle 1RuntimeCmd: Associating node 0 to multicast group 1Traceback (most recent call last): File "/usr/local/bin/simple_switch_CLI", line 31, in &lt;module&gt; sswitch_CLI.main() File "/usr/local/lib/python2.7/dist-packages/sswitch_CLI.py", line 93, in main SimpleSwitchAPI(args.pre, standard_client, mc_client, sswitch_client).cmdloop() File "/usr/lib/python2.7/cmd.py", line 142, in cmdloop stop = self.onecmd(line) File "/usr/lib/python2.7/cmd.py", line 221, in onecmd return func(arg) File "/usr/local/lib/python2.7/dist-packages/runtime_CLI.py", line 585, in handle return f(*args, **kwargs) File "/usr/local/lib/python2.7/dist-packages/runtime_CLI.py", line 1543, in do_mc_node_associate self.mc_client.bm_mc_node_associate(0, mgrp, l1_hdl) File "/usr/local/lib/python2.7/dist-packages/bm_runtime/simple_pre_lag/SimplePreLAG.py", line 222, in bm_mc_node_associate self.recv_bm_mc_node_associate() File "/usr/local/lib/python2.7/dist-packages/bm_runtime/simple_pre_lag/SimplePreLAG.py", line 246, in recv_bm_mc_node_associate raise result.ouchbm_runtime.simple_pre_lag.ttypes.InvalidMcOperation: InvalidMcOperation(code=4)**********Network configuration for: h1Default interface: h1-eth0 10.0.0.1 00:04:00:00:00:01********************Network configuration for: h2Default interface: h2-eth0 10.0.0.2 00:04:00:00:00:02********************Network configuration for: h3Default interface: h3-eth0 10.0.0.3 00:04:00:00:00:03**********h1 ./bcast_listen.pyh2 ./bcast_listen.pyh3 ./bcast_send.py(None, '')(None, "received 'hello everyone' from ('10.0.3.10', 60592)\n")(None, "received 'hello everyone' from ('10.0.3.10', 60592)\n")*** Stopping 0 controllers*** Stopping 3 links...*** Stopping 1 switchess1 *** Stopping 3 hostsh1 h2 h3 *** Donesunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples$ sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples$ ls /tmp/p4app_logs/h1.stdout h2.stdout h3.stdout p4s.s1.log s1-eth1.pcap s1-eth2.pcap s1-eth3.pcap sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples$ cat /tmp/p4app_logs/p4s.s1.log Calling target program-options parser[09:22:09.326] [bmv2] [D] [thread 83] Set default entry for table 'ipv4_lpm': NoAction - [09:22:09.326] [bmv2] [D] [thread 83] Set default entry for table 'forward': NoAction - [09:22:09.326] [bmv2] [D] [thread 83] Set default entry for table 'send_frame': NoAction - Adding interface s1-eth1 as port 1[09:22:09.326] [bmv2] [D] [thread 83] Adding interface s1-eth1 as port 1Adding interface s1-eth2 as port 2[09:22:09.355] [bmv2] [D] [thread 83] Adding interface s1-eth2 as port 2Adding interface s1-eth3 as port 3[09:22:09.395] [bmv2] [D] [thread 83] Adding interface s1-eth3 as port 3Thrift server was started[09:22:10.462] [bmv2] [T] [thread 97] bm_get_config[09:22:10.465] [bmv2] [T] [thread 97] bm_table_add_entry[09:22:10.465] [bmv2] [D] [thread 97] Entry 0 added to table 'ipv4_lpm'[09:22:10.465] [bmv2] [D] [thread 97] Dumping entry 0Match key:* ipv4.dstAddr : LPM ffffffff/32Action entry: broadcast - [09:22:10.466] [bmv2] [T] [thread 97] bm_table_add_entry[09:22:10.466] [bmv2] [D] [thread 97] Entry 0 added to table 'forward'[09:22:10.466] [bmv2] [D] [thread 97] Dumping entry 0Match key:* ingress_metadata.nhop_ipv4: EXACT ffffffffAction entry: set_dmac - ffffffffffff,[09:22:10.466] [bmv2] [T] [thread 97] bm_mc_mgrp_create[09:22:10.466] [bmv2] [D] [thread 97] mgrp node created for mgid 1[09:22:10.466] [bmv2] [T] [thread 97] bm_mc_node_create[09:22:10.466] [bmv2] [D] [thread 97] node created for rid 0[09:22:10.466] [bmv2] [T] [thread 97] bm_mc_node_associate[09:22:10.466] [bmv2] [D] [thread 97] node associated with mgid 1[09:22:10.467] [bmv2] [T] [thread 97] bm_table_add_entry[09:22:10.467] [bmv2] [E] [thread 97] Error when trying to add entry to table 'ipv4_lpm'[09:22:10.487] [bmv2] [T] [thread 97] bm_table_add_entry[09:22:10.487] [bmv2] [E] [thread 97] Error when trying to add entry to table 'forward'[09:22:10.488] [bmv2] [T] [thread 97] bm_mc_mgrp_create[09:22:10.488] [bmv2] [D] [thread 97] mgrp node created for mgid 1[09:22:10.488] [bmv2] [T] [thread 97] bm_mc_node_create[09:22:10.488] [bmv2] [D] [thread 97] node created for rid 0[09:22:10.488] [bmv2] [T] [thread 97] bm_mc_node_associate[09:22:10.488] [bmv2] [E] [thread 97] node associate failed, node is already associated[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Processing packet received on port 3[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Parser 'parser': start[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Extracting header 'ethernet'[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Parser state 'start': key is 0800[09:22:10.819] [bmv2] [T] [thread 89] [0.0] [cxt 0] Bytes parsed: 14[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Extracting header 'ipv4'[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Parser state 'parse_ipv4' has no switch, going to default next state[09:22:10.819] [bmv2] [T] [thread 89] [0.0] [cxt 0] Bytes parsed: 34[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Parser 'parser': end[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Pipeline 'ingress': start[09:22:10.819] [bmv2] [T] [thread 89] [0.0] [cxt 0] bcast_router.p4(76) Condition "hdr.ipv4.isValid()" is true[09:22:10.819] [bmv2] [T] [thread 89] [0.0] [cxt 0] Applying table 'ipv4_lpm'[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Looking up key:* ipv4.dstAddr : ffffffff[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Table 'ipv4_lpm': hit with handle 0[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Dumping entry 0Match key:* ipv4.dstAddr : LPM ffffffff/32Action entry: broadcast - [09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Action entry is broadcast - [09:22:10.819] [bmv2] [T] [thread 89] [0.0] [cxt 0] bcast_router.p4(42) Executing action broadcast[09:22:10.819] [bmv2] [T] [thread 89] [0.0] [cxt 0] Applying table 'forward'[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Looking up key:* ingress_metadata.nhop_ipv4: ffffffff[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Table 'forward': hit with handle 0[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Dumping entry 0Match key:* ingress_metadata.nhop_ipv4: EXACT ffffffffAction entry: set_dmac - ffffffffffff,[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Action entry is set_dmac - ffffffffffff,[09:22:10.819] [bmv2] [T] [thread 89] [0.0] [cxt 0] bcast_router.p4(47) Executing action set_dmac[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Pipeline 'ingress': end[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Multicast requested for packet[09:22:10.819] [bmv2] [D] [thread 89] number of packets replicated : 3[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Replicating packet on port 1[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Replicating packet on port 2[09:22:10.819] [bmv2] [D] [thread 89] [0.0] [cxt 0] Replicating packet on port 3[09:22:10.820] [bmv2] [D] [thread 91] [0.1] [cxt 0] Pipeline 'egress': start[09:22:10.820] [bmv2] [T] [thread 91] [0.1] [cxt 0] bcast_router.p4(27) Condition "hdr.ipv4.isValid()" is true[09:22:10.820] [bmv2] [T] [thread 91] [0.1] [cxt 0] Applying table 'send_frame'[09:22:10.820] [bmv2] [D] [thread 91] [0.1] [cxt 0] Looking up key:* standard_metadata.egress_port: 0001[09:22:10.820] [bmv2] [D] [thread 91] [0.1] [cxt 0] Table 'send_frame': miss[09:22:10.820] [bmv2] [D] [thread 91] [0.1] [cxt 0] Action entry is NoAction - [09:22:10.820] [bmv2] [T] [thread 91] [0.1] [cxt 0] /usr/local/share/p4c/p4include/core.p4(55) Executing action NoAction[09:22:10.820] [bmv2] [D] [thread 91] [0.1] [cxt 0] Pipeline 'egress': end[09:22:10.820] [bmv2] [D] [thread 91] [0.1] [cxt 0] Deparser 'deparser': start[09:22:10.820] [bmv2] [D] [thread 91] [0.1] [cxt 0] Updating checksum 'cksum'[09:22:10.820] [bmv2] [D] [thread 91] [0.1] [cxt 0] Deparsing header 'ethernet'[09:22:10.820] [bmv2] [D] [thread 91] [0.1] [cxt 0] Deparsing header 'ipv4'[09:22:10.820] [bmv2] [D] [thread 91] [0.1] [cxt 0] Deparser 'deparser': end[09:22:10.820] [bmv2] [D] [thread 92] [0.2] [cxt 0] Pipeline 'egress': start[09:22:10.820] [bmv2] [T] [thread 92] [0.2] [cxt 0] bcast_router.p4(27) Condition "hdr.ipv4.isValid()" is true[09:22:10.820] [bmv2] [T] [thread 92] [0.2] [cxt 0] Applying table 'send_frame'[09:22:10.820] [bmv2] [D] [thread 92] [0.2] [cxt 0] Looking up key:* standard_metadata.egress_port: 0002[09:22:10.820] [bmv2] [D] [thread 92] [0.2] [cxt 0] Table 'send_frame': miss[09:22:10.820] [bmv2] [D] [thread 92] [0.2] [cxt 0] Action entry is NoAction - [09:22:10.820] [bmv2] [T] [thread 92] [0.2] [cxt 0] /usr/local/share/p4c/p4include/core.p4(55) Executing action NoAction[09:22:10.820] [bmv2] [D] [thread 92] [0.2] [cxt 0] Pipeline 'egress': end[09:22:10.820] [bmv2] [D] [thread 92] [0.2] [cxt 0] Deparser 'deparser': start[09:22:10.820] [bmv2] [D] [thread 92] [0.2] [cxt 0] Updating checksum 'cksum'[09:22:10.820] [bmv2] [D] [thread 92] [0.2] [cxt 0] Deparsing header 'ethernet'[09:22:10.820] [bmv2] [D] [thread 92] [0.2] [cxt 0] Deparsing header 'ipv4'[09:22:10.820] [bmv2] [D] [thread 92] [0.2] [cxt 0] Deparser 'deparser': end[09:22:10.820] [bmv2] [D] [thread 93] [0.3] [cxt 0] Pipeline 'egress': start[09:22:10.820] [bmv2] [T] [thread 93] [0.3] [cxt 0] bcast_router.p4(27) Condition "hdr.ipv4.isValid()" is true[09:22:10.820] [bmv2] [T] [thread 93] [0.3] [cxt 0] Applying table 'send_frame'[09:22:10.820] [bmv2] [D] [thread 93] [0.3] [cxt 0] Looking up key:* standard_metadata.egress_port: 0003[09:22:10.820] [bmv2] [D] [thread 93] [0.3] [cxt 0] Table 'send_frame': miss[09:22:10.820] [bmv2] [D] [thread 93] [0.3] [cxt 0] Action entry is NoAction - [09:22:10.820] [bmv2] [T] [thread 93] [0.3] [cxt 0] /usr/local/share/p4c/p4include/core.p4(55) Executing action NoAction[09:22:10.820] [bmv2] [D] [thread 93] [0.3] [cxt 0] Pipeline 'egress': end[09:22:10.820] [bmv2] [D] [thread 93] [0.3] [cxt 0] Deparser 'deparser': start[09:22:10.820] [bmv2] [D] [thread 93] [0.3] [cxt 0] Updating checksum 'cksum'[09:22:10.820] [bmv2] [D] [thread 93] [0.3] [cxt 0] Deparsing header 'ethernet'[09:22:10.820] [bmv2] [D] [thread 93] [0.3] [cxt 0] Deparsing header 'ipv4'[09:22:10.820] [bmv2] [D] [thread 93] [0.3] [cxt 0] Deparser 'deparser': end[09:22:10.820] [bmv2] [D] [thread 94] [0.1] [cxt 0] Transmitting packet of size 56 out of port 1[09:22:10.820] [bmv2] [D] [thread 94] [0.2] [cxt 0] Transmitting packet of size 56 out of port 2[09:22:10.820] [bmv2] [D] [thread 94] [0.3] [cxt 0] Transmitting packet of size 56 out of port 3sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app/examples$ docker 镜像大小当前版本 docker 镜像只有 908MB，已集成 tshark / scapy 等工具，不算大。 123sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4app$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEp4lang/p4app latest 07024040be0e 6 hours ago 908MB]]></content>
      <categories>
        <category>p4</category>
      </categories>
      <tags>
        <tag>p4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Quagga 入门]]></title>
    <url>%2F201705%2Fnetworks%2Fquagga%2Fquickstart.html</url>
    <content type="text"><![CDATA[telnet 登陆 zebra CLI，其中通过 netstat -tlpun | grep zebra 查看 zebra 开放的 telnet 端口号。 12345678910111213141516171819202122232425262728293031323334353637root@leaf1:/# netstat -tlpun | grep zebratcp 0 0 127.0.0.1:2601 0.0.0.0:* LISTEN 113/zebra root@leaf1:/# telnet localhost 2601Trying 127.0.0.1...Connected to localhost.Escape character is '^]'.Hello, this is Quagga (version 0.99.24.1).Copyright 1996-2005 Kunihiro Ishiguro, et al.User Access VerificationPassword: Router&gt; Router&gt; Router&gt; enPassword: Router# clear Clear stored data configure Configuration from vty interface copy Copy configuration debug Debugging functions (see also 'undebug') disable Turn off privileged mode command echo Echo a message back to the vty end End current mode and change to enable mode. exit Exit current mode and down to previous mode help Description of the interactive help system list Print command list logmsg Send a message to enabled logging destinations no Negate a command or set its defaults quit Exit current mode and down to previous mode show Show running system information terminal Set terminal line parameters who Display who is on vty write Write running configuration to memory, network, or terminalRouter# 默认配置放于 /etc/quagga，例如本文默认密码为 zebra。 12345678root@leaf1:/# cat /etc/quagga/zebra.conf hostname Routerpassword zebraenable password zebra!interface lo!line vty 本文 bgp 配置： 123456789101112131415161718192021root@leaf1:/# cat /etc/quagga/bgpd.conf hostname bgpdpassword zebraenable password zebralog file /var/log/quagga/bgpd.logrouter bgp 64101 bgp router-id 10.0.1.100 network 0.0.0.0/0 network 10.0.1.0/24 network 10.0.2.0/24 network 10.1.11.0/24 network 10.1.12.0/24 neighbor 10.1.11.2 remote-as 64200 neighbor 10.1.11.2 timers 1 3 neighbor 10.1.12.2 remote-as 64200 neighbor 10.1.12.2 timers 1 3 maximum-paths 16access-list all permit anyroot@leaf1:/#]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>quagga</tag>
        <tag>路由协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PPPoE 协议分析]]></title>
    <url>%2F201705%2Fnetworks%2Fpppoe.html</url>
    <content type="text"><![CDATA[【TODO】 应用背景人们想通过相同的接入设备来连接到远程站点上的多个主机，同时接入设备能够提供与拨号上网类似的访问控制和计费功能。在众多的接入技术中，把多个主机连接到接入设备的最经济的方法就是以太网，而PPP协议可以提供良好的访问控制和计费功能，于是产生了在以太网上传输PPP的方法，即PPPoE。PPPoE协议的提出解决了用户上网收费等实际应用问题，得到了宽带接入运营商的认可并广为采用。 目前的网络架构中，通常部署在家用路由器（PPPoE client）与 BRAS（PPPoE Server）。 RFC RFC 1661, The Point-to-Point Protocol RFC 2516, A Method for Transmitting PPP Over Ethernet (PPPoE) PPPoE发现阶段会话阶段终止阶段PPP主要有三个组成部分： A method for encapsulating multi-protocol datagrams. A Link Control Protocol (LCP) for establishing, configuring, and testing the data-link connection. A family of Network Control Protocols (NCPs) for establishing and configuring different network-layer protocols. 参考文献 RFC 1661, The Point-to-Point Protocol RFC 2516, A Method for Transmitting PPP Over Ethernet (PPPoE) H3C PPPoE 技术白皮书 wikipedia Point to Point Protocol PPPoE Interface_Interface)]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>ppp</tag>
        <tag>pppoe networks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SecureCRT 配置使用记录]]></title>
    <url>%2F201705%2Fprogrammer%2Ftools%2Fscrt_config.html</url>
    <content type="text"><![CDATA[默认配置文件Windows 下，SecureCRT 配置文件默认存放于 C:\Users\xxx\AppData\Roaming\VanDyke\Config。可直接备份该目录，复用所有配置。具体详见官方文章Backing Up and Restoring SecureCRT® for Windows® and SecureFX® Settings。 logging 配置The Log File category of the Session Options dialog allows you to customize the logging options for the selected session A session is a set of options that are assigned to a connection to a remote machine. These settings and options are saved under a session name and allow the user to have different preferences for different hosts.. Log file name group This section allows you to specify a default filename for your log file. You can enter a path or filename, or you can use the Browse button to open the Save As dialog and select the path or filename. You can also include any of the variables listed in the Substitution section below. These variables will be expanded when SecureCRT writes to the log file. Options group This section lets you specify log file behaviors. Prompt for filename Check this option to prompt the user for the session log filename when the log is started. Start log upon connect Check this option to start writing to the session log file whenever a connection A data path or circuit between two computers over a phone line, network cable, or other means. is made. By default, this option is not selected. Overwrite file If this option is selected and the session log file already exists, the current log file will be overwritten by the new session log file. Append to file If this option is selected and the session log file already exists, the new session log will be appended to the existing log file. If the log file does not already exist, a new file is created. Raw log Check this option to write every character received by SecureCRT, including terminal A device usually consisting of a keyboard, a display unit such as a cathode ray tube, and a serial port used for entering and sending data to a computer and displaying any data received from the computer. Terminals are usually connected to a computer with a serial line or some other type of connection. There are many terminal types including VT100, VT102, VT220, and others. escape sequences, to the session log file. By default, this option is off. Start new log file at midnight Check this option to have SecureCRT start a new log file each night at midnight. Using this feature can aid in automatic log rotation. Custom log data group This section lets you specify custom messages to be written to the log file. You can include any of the variables listed in the Substitution section below. These variables will be expanded when SecureCRT writes to the log file. Upon connect Entries in this box will be written to the log file when the session connects. Upon disconnect Entries in this box will be written to the log file when the session disconnects. On each line Entries in this box will be written to each line of the log file. Log only custom data If this option is selected, SecureCRT will log only the custom data from the three fields above. All normal log messages will be suppressed. Substitutions group In the dialog, this section lists some of the variables that SecureCRT can expand when writing to the log file. A complete list is shown below. %H - hostname %S - session name %Y - four-digit year %y - two-digit year %M - two-digit month %D - two-digit day of the month %P - port %h - two-digit hour %m - two-digit minute %s - two-digit seconds %t - three-digit milliseconds %% - percent (%) %envvar% - environment variable Note: The environment variable substitution occurs first.]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>SecureCRT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 定时执行备份任务]]></title>
    <url>%2F201704%2Flinux%2Fexecute_scheduled_commands.html</url>
    <content type="text"><![CDATA[本地搭建一个 dokuwiki 服务器，考虑备份需求，每天备份服务器内容到另一台设备。 服务器 IP：172.168.111.192 备份设备 IP：192.168.204.168 通过 cron 命令进行定时任务执行。 前期工作见本博客另一篇文章 如何让 scp / ssh 不需要密码。 实现备份的脚本在服务器 172.168.111.192 上实现备份脚本。 123456789root@ubuntu:~# cat dokuwiki.backup.sh #!/bin/bashbackpath=/var/www/backupdate=`date +%y%m%d`site='dokuwiki'tar zcf $&#123;backpath&#125;$&#123;site&#125;"-"$&#123;date&#125;.tar.gz /var/www/$&#123;site&#125;scp $&#123;backpath&#125;$&#123;site&#125;"-"$&#123;date&#125;.tar.gz sunyongfeng@192.168.204.168:/home/sunyongfeng/backup/$&#123;site&#125;"-"$&#123;date&#125;.tar.gzroot@ubuntu:~# cron 配置在服务器 172.168.111192 上每天 4:30 执行备份脚本。 1234567891011121314151617181920212223242526root@ubuntu:~# export EDITOR=vim root@ubuntu:~# crontab -e no crontab for root - using an empty one# Edit this file to introduce tasks to be run by cron.# # Each task to run has to be defined through a single line# indicating with different fields when the task will be run# and what command to run for the task# # To define the time you can provide concrete values for# minute (m), hour (h), day of month (dom), month (mon),# and day of week (dow) or use '*' in these fields (for 'any').# # Notice that tasks will be started based on the cron's system# daemon's notion of time and timezones.# # Output of the crontab jobs (including errors) is sent through# email to the user the crontab file belongs to (unless redirected).# # For example, you can run a backup of all your user accounts# at 5 a.m every week with:# 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/# # For more information see the manual pages of crontab(5) and cron(8)# # m h dom mon dow command30 04 * * * /root/dokuwiki.backup.sh 首次选择 cron 编辑器不小心选择了 nano，不懂怎么用。通过 export EDITOR=vim 将编辑器切成 vim。 online cron 表达式生成器: https://crontab-generator.org/ 注意，每 30 分钟执行一次的写法： */30 * * * * ls &gt;/dev/null 2&gt;&amp;1 效果备份机器 192.168.204.168 上的效果： 123456789101112131415161718192021222324252627282930313233343536373839404142sunyongfeng@openswitch-OptiPlex-380:~/backup$ ls -altotal 8759824drwxrwxrwx 7 sunyongfeng sunyongfeng 4096 5月 31 04:30 .drwxr-xr-x 44 sunyongfeng sunyongfeng 4096 5月 31 09:24 ..-rw-r--r-- 1 sunyongfeng sunyongfeng 30790523 4月 18 20:26 dokuwiki-170418.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 30829080 4月 25 14:14 dokuwiki-170425.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 30829128 4月 26 04:31 dokuwiki-170426.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 30840695 4月 27 04:31 dokuwiki-170427.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 30878801 4月 28 04:31 dokuwiki-170428.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 30878561 4月 29 04:31 dokuwiki-170429.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 30878561 4月 30 04:31 dokuwiki-170430.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 30878561 5月 1 04:31 dokuwiki-170501.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 30878561 5月 2 04:31 dokuwiki-170502.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 30925192 5月 3 04:31 dokuwiki-170503.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31827534 5月 4 04:31 dokuwiki-170504.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31830576 5月 5 04:31 dokuwiki-170505.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31830576 5月 6 04:31 dokuwiki-170506.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31830576 5月 7 04:32 dokuwiki-170507.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31830576 5月 8 04:31 dokuwiki-170508.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31832468 5月 9 04:31 dokuwiki-170509.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31832468 5月 10 04:31 dokuwiki-170510.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31833486 5月 11 04:31 dokuwiki-170511.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31834472 5月 12 04:31 dokuwiki-170512.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31833802 5月 13 04:31 dokuwiki-170513.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31833802 5月 14 04:31 dokuwiki-170514.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31835188 5月 15 04:31 dokuwiki-170515.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31835398 5月 16 04:30 dokuwiki-170516.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31834919 5月 17 04:30 dokuwiki-170517.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31834919 5月 18 04:30 dokuwiki-170518.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31832950 5月 19 04:30 dokuwiki-170519.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31832950 5月 20 04:30 dokuwiki-170520.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31832950 5月 21 04:30 dokuwiki-170521.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31832950 5月 22 04:30 dokuwiki-170522.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31832950 5月 23 04:30 dokuwiki-170523.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31832950 5月 24 04:30 dokuwiki-170524.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31833337 5月 25 04:30 dokuwiki-170525.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31833232 5月 26 04:30 dokuwiki-170526.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31833446 5月 27 04:30 dokuwiki-170527.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31833446 5月 28 04:30 dokuwiki-170528.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31835384 5月 29 04:30 dokuwiki-170529.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31835403 5月 30 04:30 dokuwiki-170530.tar.gz-rw-r--r-- 1 sunyongfeng sunyongfeng 31835403 5月 31 04:30 dokuwiki-170531.tar.gz misc cron 的默认工作目录，$HOME]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让 scp / ssh 不需要密码]]></title>
    <url>%2F201704%2Flinux%2Fscp_ssh_without_password.html</url>
    <content type="text"><![CDATA[How to use the Linux ‘scp’ command without a password to make remote backupsHow to create a public and private key pair to use ssh and scp without using a password, which lets you automate a remote server backup process. 目标：通过 server 上的脚本，通过 cron 每天备份文件到 client。 h1，sunyongfeng@192.168.204.168，client，用于保存服务器备份文件 h2，root@172.18.111.192，server，需要通过脚本，每天备份文件到 192.168.204.168 步骤： 在 server 端生成 rsa 密钥对，ssh-keygen -t rsa 1234567891011121314151617181920212223242526272829root@ubuntu:~# ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:c7:42:12:d7:40:58:16:0f:2b:29:6c:2b:67:6b:1c:e3 root@ubuntuThe key's randomart image is:+--[ RSA 2048]----+| .+O+ || . .= +. || + + o . || . o + . || . * S o || * + o || E || . || |+-----------------+root@ubuntu:~# root@ubuntu:~# ls .ssh/ -al total 20drwx------ 2 root root 4096 Apr 25 14:05 .drwx------ 7 root root 4096 Apr 25 13:51 ..-rw------- 1 root root 1679 Apr 25 13:54 id_rsa-rw-r--r-- 1 root root 393 Apr 25 13:54 id_rsa.pub-rw-r--r-- 1 root root 444 Apr 6 16:58 known_hosts 拷贝公钥到 client 192.168.204.168，注意此时从 172.18.111.192 scp 拷贝时还需要密码。scp .ssh/id_rsa.pub sunyongfeng@192.168.204.168:/home/sunyongfeng/.ssh/authorized_keys 1234root@ubuntu:~# scp .ssh/id_rsa.pub sunyongfeng@192.168.204.168:/home/sunyongfeng/.ssh/authorized_keyssunyongfeng@192.168.204.168's password: id_rsa.pub 100% 393 0.4KB/s 00:00 root@ubuntu:~# 验证从 server 172.18.111.192 scp 到 192.168.204.168 已不需要密码。下文同时确认 ssh 远程 192.168.204.168 不需要密码。 12345678910111213141516root@ubuntu:~# scp .ssh/id_rsa.pub sunyongfeng@192.168.204.168:/home/sunyongfeng/.ssh/authorized_keysid_rsa.pub 100% 393 0.4KB/s 00:00 root@ubuntu:~# root@ubuntu:~# ssh sunyongfeng@192.168.204.168Welcome to Ubuntu 16.04 LTS (GNU/Linux 3.19.8-031908-generic x86_64) * Documentation: https://help.ubuntu.com/234 packages can be updated.0 updates are security updates.Last login: Tue Apr 25 12:36:14 2017 from 192.168.204.167sunyongfeng@openswitch-OptiPlex-380:~$ exitlogoutConnection to 192.168.204.168 closed.root@ubuntu:~#]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
        <tag>远程登录</tag>
        <tag>scp</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xterm / gnome-terminal 无法 tab 补全]]></title>
    <url>%2F201704%2Flinux%2Fxterm.html</url>
    <content type="text"><![CDATA[问题：gnome-terminal / xterm 的 profile 失效，且无法进行 tab 补全。 从命令行起 gnome-terminal / xterm，带执行参数 bash 即可。 gnome-terminal -x bash xterm -e bash 问题：term 太小，vim 打开看到篇幅很小1stty rows 40 cols 200 stty 的功能很强大，还可以修改串口波特率： 1stty -F /dev/ttyS0 speed 115200]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>xterm</tag>
        <tag>gnome-terminal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[移植 openswitch 到 arm]]></title>
    <url>%2F201704%2Fprogrammer%2Fyocto%2Fporting_openswitch_to_arm.html</url>
    <content type="text"><![CDATA[HP ops 目前已过时，现在主导 openswitch 项目的是 DELL 和 SnapRoute，主推 DELL NAS + SnapRoute Flexswitch （称为 opx）。 本文 openswitch 指 HP ops。记录以前移植 openswtich 到 arm CPU 的过程。 1. BSP 适配1.1. 新增一个新产品在目录 yocto/openswitch/ 下新建 meta-platform-openswitch-[product]，其中 product 对应新增的产品名字，可以从已有的产品目录拷贝。以 xxx 为例子： 使用 cp 命令，拷贝其他产品目录为 meta-platform-openswitch-xxx： 1cp meta-platform-openswitch-as6712 meta-platform-openswitch-xxx –r 删除 recipes-kernel 以外的配方目录（以 recipes-* 开头的） 将目录下所有文件的中 as6712 修改为 xxx，主要有以下几个文件： conf/machine/as6712.conf 重命名为 conf/machine/xxx.conf conf/layer/conf README rules.make recipes-kernel 子目录下的 *.bbappend 中的 PR_append 根据 cpu 架构适配 conf/machine/xxx.conf 文件，xxx 的 cpu 是 arm cortexa9 系列，其中 DEFAULTTUNE 定义表示不支持硬件 FPU。 12345DEFAULTTUNE ?= "core2-64"require conf/machine/include/tune-core2.inc改成：DEFAULTTUNE ?= "cortexa9-neon"require conf/machine/include/tune-cortexa9.inc 根据产品支持的内核版本，修订 PREFERRED_VERSION_linux-ops 参数 暂时屏蔽 MACHINE_FEATURES 和 MACHINE_ESSENTIAL_EXTRA_RDEPENDS，根据需要添加 1.2. 添加一个新内核版本支持 在目录 yocto/openswitch/meta-distro-openswitch/recipes-kernel/linux/ 新增 linux-ops_[version].bb 文件，可以从其他版本复制 修订 *.bb 文件 对应内核版本号，KERNEL_RELEASE = &quot;3.10.18&quot; 对应内核源码下载地址，当前为本地地址 SRC_URI = http://192.168.x.x/linux-3.10.18.tar.gz;name=kernel 对应源码的 md5sum 值（可以使用 linux md5sum 工具计算），SRC_URI[kernel.md5sum] = &quot;e19cbb242d776223c337e10a31ca9865&quot; 对应源码的 sha256sum 值（可以使用 linux sha256sum 工具计算），SRC_URI[kernel.sha256sum] = &quot;a11abd0ac80c6195aaab16c8be3e97c07c705d0ee135f3c5c092a99c4973b1be&quot; 备注：两个 checksum 和下载地址要保证正确，不然编译的时候会出错 由于 openswitch 的 linux-ops 不支持设备树，需要新增文件 linux-dtb.inc，并且修订文件 linux.inc： 123LOCALVERSION ?= ""require linux-dtb.inc #新增#kernel_conf_variable CMDLINE "\"$&#123;CMDLINE&#125; $&#123;CMDLINE_DEBUG&#125;\"" 适配 xxx，新增文件： 12yocto/openswitch/meta-platform-openswitch-xxx/recipes-kernel/dtc/dtc_git.bbappendyocto/openswitch/meta-platform-openswitch-xxx/recipes-kernel/linux/linux-ops_3.10.18.bbappend 在 meta-platform-openswitch-xxx/recipes-kernel/linux/linux-ops/ 增加内核配置文件以及产品需要的 patch文件 1.3. 适配完成之后，使用 make kernel 编译内核模块no log。 1.4. 调试问题汇总 Open-switch 内核默认编译出来的 image 是 zimage，我的设备 uboot 比较老，不支持这种格式；可以通过在 xxx.config 中新增 KERNEL_IMAGETYPE = &quot;uImage&quot; 来指定成 uimage 格式。 在设备树编译的时候，需要指定目录的在内核的绝对地址，不能单单执行个xx.dts: KERNEL_DEVICETREE = &quot;${S}/arch/arm/boot/dts/zzz_yyy.dts&quot; 内核编译出来的 image 如果使用 uImage 或者 zImage 的时候，内核需要打开以下配置，并且 cpu 产品目录需要有这个文件 arch/arm/mach-yyy/include/mach/uncompress.h，否则会出现调整内核之后死机： 1234CONFIG_BLK_DEV_INITRD=yCONFIG_INITRAMFS_SOURCE=""CONFIG_RD_GZIP=yCONFIG_DECOMPRESS_GZIP=y 如果使用的 uImage 或者 zImage 格式加载，内核的入口函数是 arch/arm/boot/bootp/init.S 中，这个文件主要是跳转到 misc.c 自解压内核 image，然后跳转到真正的内核执行。 如果出现自解压完成，调整到真正内核执行的时候无 log 输出，可以将内核的 early debug 打开，具体配置宏如下： 1234567CONFIG_DEBUG_LL=yCONFIG_DEBUG_LL_UART_NONE=y# CONFIG_DEBUG_ICEDCC is not set# CONFIG_DEBUG_SEMIHOSTING is not setCONFIG_DEBUG_LL_INCLUDE="mach/debug-macro.S"CONFIG_UNCOMPRESS_INCLUDE="mach/uncompress.h"CONFIG_EARLY_PRINTK=y 如果出现以下的错误 log，是由于 uboot 未传入正确的设备树或者参数导致： 12345678910-21-09:30:03.036:Uncompressing Linux... done, booting the kernel.10-21-09:30:03.036:10-21-09:30:03.036:Error: unrecognized/unsupported machine ID (r1 = 0x00000bb8).10-21-09:30:03.036:10-21-09:30:03.036:Available machine support:10-21-09:30:03.036:10-21-09:30:03.051:ID (hex) NAME10-21-09:30:03.051:ffffffff XXX YYY ZZZ10-21-09:30:03.051: 使用 bootm 命令可以带两地址，第一个表示 image 的地址，第二个表示设备树地址，bootm 62000000 - 62400000。 1.5. kernel defconfig1.6. 支持 systemd 的 kernel defconfig这里的 defconfig 不全是支持 systemd 所需配置。支持 systemd 所需配置见 systemd README，注意不同的 systemd 版本可能对内核的配置要求不一样。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164diff --git a/yocto/openswitch/meta-platform-openswitch-xxx/recipes-kernel/linux/linux-ops/defconfig b/yocto/openswitch/meta-platform-openswitch-xxx/recipes-kernel/linux/linux-ops/defconfigindex a61c606..06a5f0e 100755--- a/yocto/openswitch/meta-platform-openswitch-xxx/recipes-kernel/linux/linux-ops/defconfig+++ b/yocto/openswitch/meta-platform-openswitch-xxx/recipes-kernel/linux/linux-ops/defconfig@@ -41,7 +41,7 @@ CONFIG_SYSVIPC=y CONFIG_SYSVIPC_SYSCTL=y CONFIG_POSIX_MQUEUE=y CONFIG_POSIX_MQUEUE_SYSCTL=y-# CONFIG_FHANDLE is not set+CONFIG_FHANDLE=y # CONFIG_AUDIT is not set CONFIG_HAVE_GENERIC_HARDIRQS=y @@ -91,7 +91,15 @@ CONFIG_RCU_FANOUT_LEAF=16 CONFIG_IKCONFIG=y CONFIG_IKCONFIG_PROC=y CONFIG_LOG_BUF_SHIFT=21-# CONFIG_CGROUPS is not set+CONFIG_CGROUPS=y+# CONFIG_CGROUP_DEBUG is not set+# CONFIG_CGROUP_FREEZER is not set+# CONFIG_CGROUP_DEVICE is not set+# CONFIG_CPUSETS is not set+# CONFIG_CGROUP_CPUACCT is not set+# CONFIG_RESOURCE_COUNTERS is not set+# CONFIG_CGROUP_SCHED is not set+# CONFIG_BLK_CGROUP is not set # CONFIG_CHECKPOINT_RESTORE is not set # CONFIG_NAMESPACES is not set CONFIG_UIDGID_CONVERTED=y@@ -99,13 +107,7 @@ CONFIG_UIDGID_CONVERTED=y # CONFIG_SCHED_AUTOGROUP is not set # CONFIG_SYSFS_DEPRECATED is not set # CONFIG_RELAY is not set-CONFIG_BLK_DEV_INITRD=y-CONFIG_INITRAMFS_SOURCE=""-CONFIG_RD_GZIP=y-# CONFIG_RD_BZIP2 is not set-# CONFIG_RD_LZMA is not set-# CONFIG_RD_XZ is not set-# CONFIG_RD_LZO is not set+# CONFIG_BLK_DEV_INITRD is not set # CONFIG_CC_OPTIMIZE_FOR_SIZE is not set CONFIG_SYSCTL=y CONFIG_ANON_INODES=y@@ -380,12 +382,14 @@ CONFIG_ARM_AMBA=y CONFIG_PCI=y CONFIG_PCI_DOMAINS=y CONFIG_PCI_SYSCALL=y+# CONFIG_ARCH_SUPPORTS_MSI is not set # CONFIG_PCI_DEBUG is not set # CONFIG_PCI_REALLOC_ENABLE_AUTO is not set # CONFIG_PCI_STUB is not set # CONFIG_PCI_IOV is not set # CONFIG_PCI_PRI is not set # CONFIG_PCI_PASID is not set+# CONFIG_PCIEPORTBUS is not set # CONFIG_PCCARD is not set #@@ -452,10 +456,7 @@ CONFIG_ATAGS=y # CONFIG_DEPRECATED_PARAM_STRUCT is not set CONFIG_ZBOOT_ROM_TEXT=0x0 CONFIG_ZBOOT_ROM_BSS=0x0-CONFIG_ARM_APPENDED_DTB=y-CONFIG_ARM_ATAG_DTB_COMPAT=y-CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_FROM_BOOTLOADER=y-# CONFIG_ARM_ATAG_DTB_COMPAT_CMDLINE_EXTEND is not set+# CONFIG_ARM_APPENDED_DTB is not set CONFIG_CMDLINE="console=ttyS0,115200n8 maxcpus=1 mem=240M" CONFIG_CMDLINE_FROM_BOOTLOADER=y # CONFIG_CMDLINE_EXTEND is not set@@ -463,7 +464,7 @@ CONFIG_CMDLINE_FROM_BOOTLOADER=y # CONFIG_XIP_KERNEL is not set # CONFIG_KEXEC is not set # CONFIG_CRASH_DUMP is not set-CONFIG_AUTO_ZRELADDR=y+# CONFIG_AUTO_ZRELADDR is not set # # CPU Power Management@@ -478,7 +479,7 @@ CONFIG_AUTO_ZRELADDR=y # # At least one emulation must be selected #-# CONFIG_VFP is not set+#CONFIG_VFP=y # # Userspace binary formats@@ -544,6 +545,7 @@ CONFIG_HAVE_NET_DSA=y CONFIG_RPS=y CONFIG_RFS_ACCEL=y CONFIG_XPS=y+# CONFIG_NETPRIO_CGROUP is not set CONFIG_BQL=y # CONFIG_BPF_JIT is not set @@ -571,7 +573,8 @@ CONFIG_HAVE_BPF_JIT=y # Generic Driver Options # CONFIG_UEVENT_HELPER_PATH="/sbin/mdev"-# CONFIG_DEVTMPFS is not set+CONFIG_DEVTMPFS=y+CONFIG_DEVTMPFS_MOUNT=y CONFIG_STANDALONE=y CONFIG_PREVENT_FIRMWARE_BUILD=y CONFIG_FW_LOADER=y@@ -1760,8 +1763,15 @@ CONFIG_ARM_GIC=y # CONFIG_DCACHE_WORD_ACCESS=y # CONFIG_EXT2_FS is not set-# CONFIG_EXT3_FS is not set+CONFIG_EXT3_FS=y+CONFIG_EXT3_DEFAULTS_TO_ORDERED=y+CONFIG_EXT3_FS_XATTR=y+# CONFIG_EXT3_FS_POSIX_ACL is not set+# CONFIG_EXT3_FS_SECURITY is not set # CONFIG_EXT4_FS is not set+CONFIG_JBD=y+# CONFIG_JBD_DEBUG is not set+CONFIG_FS_MBCACHE=y # CONFIG_REISERFS_FS is not set # CONFIG_JFS_FS is not set # CONFIG_XFS_FS is not set@@ -1769,6 +1779,7 @@ CONFIG_DCACHE_WORD_ACCESS=y # CONFIG_BTRFS_FS is not set # CONFIG_NILFS2_FS is not set # CONFIG_FS_POSIX_ACL is not set+CONFIG_EXPORTFS=y CONFIG_FILE_LOCKING=y CONFIG_FSNOTIFY=y CONFIG_DNOTIFY=y@@ -1932,7 +1943,6 @@ CONFIG_HAVE_DEBUG_KMEMLEAK=y # CONFIG_DEBUG_LOCKING_API_SELFTESTS is not set # CONFIG_DEBUG_STACK_USAGE is not set # CONFIG_DEBUG_KOBJECT is not set-# CONFIG_DEBUG_HIGHMEM is not set # CONFIG_DEBUG_BUGVERBOSE is not set # CONFIG_DEBUG_INFO is not set # CONFIG_DEBUG_VM is not set@@ -1983,13 +1993,9 @@ CONFIG_HAVE_ARCH_KGDB=y # CONFIG_STRICT_DEVMEM is not set # CONFIG_ARM_UNWIND is not set CONFIG_DEBUG_USER=y-CONFIG_DEBUG_LL=y-CONFIG_DEBUG_LL_UART_NONE=y-# CONFIG_DEBUG_ICEDCC is not set-# CONFIG_DEBUG_SEMIHOSTING is not set+# CONFIG_DEBUG_LL is not set CONFIG_DEBUG_LL_INCLUDE="mach/debug-macro.S" CONFIG_UNCOMPRESS_INCLUDE="mach/uncompress.h"-CONFIG_EARLY_PRINTK=y # CONFIG_OC_ETM is not set # CONFIG_PID_IN_CONTEXTIDR is not set @@ -2142,7 +2148,6 @@ CONFIG_LZO_COMPRESS=y CONFIG_LZO_DECOMPRESS=y # CONFIG_XZ_DEC is not set # CONFIG_XZ_DEC_BCJ is not set-CONFIG_DECOMPRESS_GZIP=y CONFIG_HAS_IOMEM=y CONFIG_HAS_IOPORT=y CONFIG_HAS_DMA=y 2. gcc tune2.1.rootfs 不可用xxx cpu 为 arm cortex-a9 芯片。DEFAULTTUNE 置为 cortexa9 或 cortexa9-neon 时，编译出来的 rootfs 不可用：启机运行时，会出现 undefined instruction，内核 kill init 退出： 123456789101112131415161718192021222324init (1): undefined instruction: pc=b6ebcbdcCode: e1866315 ee021b90 e2402020 e1866235 (f37204a1)Kernel panic - not syncing: Attempted to kill init! exitcode=0x00000004 CPU1: stoppingCPU: 1 PID: 0 Comm: swapper/1 Tainted: G W 3.10.18 #1Backtrace:[&lt;c00117b8&gt;] (dump_backtrace+0x0/0x10c) from [&lt;c00119cc&gt;] (show_stack+0x18/0x1c)r6:00000000 r5:00000001 r4:c041d9f8 r3:00000000[&lt;c00119b4&gt;] (show_stack+0x0/0x1c) from [&lt;c02e2034&gt;] (dump_stack+0x24/0x28)[&lt;c02e2010&gt;] (dump_stack+0x0/0x28) from [&lt;c0013ca4&gt;] (handle_IPI+0x118/0x134)[&lt;c0013b8c&gt;] (handle_IPI+0x0/0x134) from [&lt;c0008620&gt;] (gic_handle_irq+0x60/0x64)r6:ef06ff68 r5:c04022f4 r4:fee2010c r3:c000f14c[&lt;c00085c0&gt;] (gic_handle_irq+0x0/0x64) from [&lt;c000e0c0&gt;] (__irq_svc+0x40/0x50)Exception stack(0xef06ff68 to 0xef06ffb0)ff60: c18116b0 00000000 00002fdc 00000000 ef06e000 ef06e000ff80: c0401f28 c0401f70 c02e7b2c ef06e000 ef06e000 ef06ffbc ef06ffc0 ef06ffb0ffa0: c000f14c c000f150 60000113 ffffffffr7:ef06ff9c r6:ffffffff r5:60000113 r4:c000f150[&lt;c000f11c&gt;] (arch_cpu_idle+0x0/0x38) from [&lt;c0055c60&gt;] (cpu_startup_entry+0xec/0x13c)[&lt;c0055b74&gt;] (cpu_startup_entry+0x0/0x13c) from [&lt;c02debd8&gt;] (secondary_start_kernel+0x128/0x130)r7:c041da1c[&lt;c02deab0&gt;] (secondary_start_kernel+0x0/0x130) from [&lt;612de104&gt;] (0x612de104)r4:9003c06a r3:c02de0ec 这个问题排查了约两个星期，排查的方向： 内核是否支持 systemd？根据 systemd 官方说明文档配置内核，启机还是挂在同样的地方； rootfs 的格式是不是有问题（ubifs 还是 ext3）？把 rootfs 改为 ubifs，启机还是挂在同样的地方； 反汇编通过 objdump vmlinux 或看system map table，都没有对应 PC 值。这个 undefined instruction 的意思应该就是说明没有这个指令，所以不用看了，找也找不着。 偶然的机会，与同事的讨论中，他曾经在某个产品上使用 debian 8 （默认采用 systemd） 的 rootfs 跑过。因此通过 ops-build 编译的 kernel + debian 8 rootfs （U盘启动）确认内核没有问题。既然内核没有问题，那就得看 debian jessie arm 版本编译的结果与 ops-build 编译结果的差异，通过 readelf -A systemd 查看 systemd 编译结果的架构相关信息，发现了差异： 不可用的 rootfs： 12345678910111213141516171819sunyongfeng@openswitch-OptiPlex-380:~/workshop/rgosm-build/prj_xxx/images/rootfs/lib/systemd$ arm-cortex_a9-linux-gnueabi-readelf -A systemdAttribute Section: aeabiFile Attributes Tag_CPU_name: "7-A" Tag_CPU_arch: v7 Tag_CPU_arch_profile: Application Tag_ARM_ISA_use: Yes Tag_THUMB_ISA_use: Thumb-2 Tag_VFP_arch: VFPv3 Tag_Advanced_SIMD_arch: NEONv1 Tag_ABI_PCS_wchar_t: 4 Tag_ABI_FP_rounding: Needed Tag_ABI_FP_denormal: Needed Tag_ABI_FP_exceptions: Needed Tag_ABI_FP_number_model: IEEE 754 Tag_ABI_align8_needed: Yes Tag_ABI_enum_size: int Tag_ABI_HardFP_use: SP and DP Tag_CPU_unaligned_access: v6 可用的 rootfs： 123456789101112131415sunyongfeng@openswitch-OptiPlex-380:~/workshop/rgosm-build/prj_xxx/images/rootfs$ arm-cortex_a9-linux-gnueabi-readelf -A lib/systemd/systemdAttribute Section: aeabiFile Attributes Tag_CPU_name: "4T" Tag_CPU_arch: v4T Tag_ARM_ISA_use: Yes Tag_THUMB_ISA_use: Thumb-1 Tag_ABI_PCS_wchar_t: 4 Tag_ABI_FP_rounding: Needed Tag_ABI_FP_denormal: Needed Tag_ABI_FP_exceptions: Needed Tag_ABI_FP_number_model: IEEE 754 Tag_ABI_align8_needed: Yes Tag_ABI_align8_preserved: Yes, except leaf SP Tag_ABI_enum_size: int 主要差异在 NEON、VFP 和 HardFP 上。因尝试改 tune-cortexa9.inc 等相关文件调整默认 FPU 等编译选项，但是一直修改失败，因此换了个思路，看 debian porting to arm 用了什么编译选项。详见 debian 移植到 arm 32 的编译选项 ，根据文中的建议 tune gcc。 2.2. tune gcc 配置 yocto/openswitch/meta-platform-openswitch-xxx/conf/machine/xxx.conf，改 DEFAULTTUNE 为 armv4t 12DEFAULTTUNE ?= "armv4t"require conf/machine/include/tune-cortexa9.inc 配置 yocto/poky/meta/conf/machine/include/arm/arch-arm.inc，改 TARGET_FPU 为 soft，添加选项 -mabi=aapcs-linux 配置 yocto/poky/meta/conf/machine/include/arm/feature-arm-neon.inc 和 yocto/poky/meta/conf/machine/include/arm/feature-arm-vfp.inc，把 FPU 相关配置改为 soft。 123456789101112131415161718192021222324252627282930313233343536373839sunyongfeng@openswitch-OptiPlex-380:~/workshop/ops-build.rj$ git diff yocto/poky/meta/conf/machine*diff --git a/yocto/poky/meta/conf/machine/include/arm/arch-arm.inc b/yocto/poky/meta/conf/machine/include/arm/arch-arm.incindex 90b80c4..b1a04b8 100644--- a/yocto/poky/meta/conf/machine/include/arm/arch-arm.inc+++ b/yocto/poky/meta/conf/machine/include/arm/arch-arm.inc@@ -13,5 +13,6 @@ TUNE_PKGARCH = "$&#123;ARMPKGARCH&#125;$&#123;ARMPKGSFX_THUMB&#125;$&#123;ARMPKGSFX_DSP&#125;$&#123;ARMPKGSFX_EABI&#125; ABIEXTENSION = "eabi" -TARGET_FPU = "$&#123;@d.getVar('ARMPKGSFX_FPU', True).strip('-') or 'soft'&#125;"+TARGET_FPU = "soft"+TUNE_CCARGS .= " -mabi=aapcs-linux" diff --git a/yocto/poky/meta/conf/machine/include/arm/feature-arm-neon.inc b/yocto/poky/meta/conf/machine/include/arm/feature-arm-neon.incindex e8b2b85..25d612e 100644--- a/yocto/poky/meta/conf/machine/include/arm/feature-arm-neon.inc+++ b/yocto/poky/meta/conf/machine/include/arm/feature-arm-neon.inc@@ -1,3 +1,3 @@TUNEVALID[neon] = "Enable Neon SIMD accelerator unit."-TUNE_CCARGS .= "$&#123;@bb.utils.contains("TUNE_FEATURES", "neon", bb.utils.contains("TUNE_FEATURES", "vfpv4", " -mfpu=neon-vfpv4", " -mfpu=neon", d), "" , d)&#125;"-ARMPKGSFX_FPU .= "$&#123;@bb.utils.contains("TUNE_FEATURES", "neon", "-neon", "", d)&#125;"+TUNE_CCARGS .= "$&#123;@bb.utils.contains("TUNE_FEATURES", "neon", bb.utils.contains("TUNE_FEATURES", "vfpv4", " -msoft-float", " -msoft-float", d), "" , d)&#125;"+ARMPKGSFX_FPU .= "$&#123;@bb.utils.contains("TUNE_FEATURES", "neon", "", "", d)&#125;"diff --git a/yocto/poky/meta/conf/machine/include/arm/feature-arm-vfp.inc b/yocto/poky/meta/conf/machine/include/arm/feature-arm-vfp.incindex 13927ff..73efcb8 100644--- a/yocto/poky/meta/conf/machine/include/arm/feature-arm-vfp.inc+++ b/yocto/poky/meta/conf/machine/include/arm/feature-arm-vfp.inc@@ -2,8 +2,8 @@ TUNEVALID[vfp] = "Enable Vector Floating Point (vfp) unit."ARMPKGSFX_FPU .= "$&#123;@bb.utils.contains("TUNE_FEATURES", "vfp", "-vfp", "" ,d)&#125;" TUNEVALID[vfpv4] = "Enable Vector Floating Point Version 4 (vfpv4) unit."-ARMPKGSFX_FPU .= "$&#123;@bb.utils.contains("TUNE_FEATURES", "vfpv4", "-vfpv4", "" ,d)&#125;"+ARMPKGSFX_FPU .= "$&#123;@bb.utils.contains("TUNE_FEATURES", "vfpv4", "-vfp", "" ,d)&#125;" TUNEVALID[callconvention-hard] = "Enable EABI hard float call convention, requires VFP."-TUNE_CCARGS .= "$&#123;@bb.utils.contains("TUNE_FEATURES", "vfp", bb.utils.contains("TUNE_FEATURES", "callconvention-hard", " -mfloat-abi=hard", " -mfloat-abi=softfp", d), "" ,d)&#125;"-ARMPKGSFX_EABI .= "$&#123;@bb.utils.contains("TUNE_FEATURES", [ "callconvention-hard", "vfp" ], "hf", "", d)&#125;"+TUNE_CCARGS .= "$&#123;@bb.utils.contains("TUNE_FEATURES", "vfp", bb.utils.contains("TUNE_FEATURES", "callconvention-hard", " -mfloat-abi=soft", " -mfloat-abi=soft", d), "" ,d)&#125;"+ARMPKGSFX_EABI .= "$&#123;@bb.utils.contains("TUNE_FEATURES", [ "callconvention-hard", "vfp" ], "", "", d)&#125;" 2.3. 关于 xxx CPU 是否支持 NEON 和 VFPxxx CPU 的芯片手册上有明确写支持 NEON 和 VFP，但是不清楚如何使能 NEON，是否要在上电和通过特定配置使能？通过 cat /proc/cpuinfo 可以看出芯片不支持 NEON 和 VFP，但是 /proc/cpuinfo 能完全体现 CPU features 吗？PS：内核有明确打开了配置 CONFIG_NEON=y 与 CONFIG_VFP=y。 123456789101112131415161718192021222324root@ops-xxx:~# cat /proc/cpuinfoprocessor : 0model name : ARMv7 Processor rev 0 (v7l)BogoMIPS : 1987.37Features : swp half thumb fastmult edsp tlsCPU implementer : 0x41CPU architecture: 7CPU variant : 0x3CPU part : 0xc09CPU revision : 0 processor : 1model name : ARMv7 Processor rev 0 (v7l)BogoMIPS : 1993.93Features : swp half thumb fastmult edsp tlsCPU implementer : 0x41CPU architecture: 7CPU variant : 0x3CPU part : 0xc09CPU revision : 0 Hardware : yyy CPURevision : 0000Serial : 0000000000000000 通过查阅资料发现 NEON 应该是在系统运行时使能的： 内核在遇到第一个NEON指令时会产生一个Undefined Instruction的异常，这会让内核自动重启NEON协处理器，内核还可以在上下文切换时关闭NEON来省电。BY 《ARM平台NEON指令的编译和优化》 以及： arm 论坛 “How to enable Neon in cortex A8?“Yes you can’t enable it directly from user mode you have to have the privilege though the startup code for the process or an interrupt when such an instruction is first used should do that normally. For the actual instructions needed have you seen: ARM Compiler armcc User Guide : 5.5 Enabling NEON and FPU for bare-metal 直接在 uboot 中修订？http://lists.denx.de/pipermail/u-boot/2015-January/201269.html TODO 后续再做验证。FPU 基本只应用于图像处理、音视频处理，与我们无关，因此可以放心不用。 3. 编译问题及修订记录3.1. python xattr 在 x86 平台上直接使用交叉编译结果问题 log： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849NOTE: Preparing RunQueueNOTE: Checking sstate mirror object availability (for 545 objects)NOTE: Executing SetScene TasksNOTE: Executing RunQueue TasksERROR: Function failed: do_compile (log file is located at /home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/python-xattr/0.8.0-r0/temp/log.do_compile.14582)ERROR: Logfile of failure stored in: /home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/python-xattr/0.8.0-r0/temp/log.do_compile.14582Log data follows:| DEBUG: Executing shell function do_compile| running build| Traceback (most recent call last):| File "setup.py", line 67, in &lt;module&gt;| cmdclass=&#123;'build': cffi_build&#125;,| File "/home/sunyongfeng/workshop/ops-build.rj/build/tmp/sysroots/x86_64-linux/usr/lib/python2.7/distutils/core.py", line 151, in setup| dist.run_commands()| File "/home/sunyongfeng/workshop/ops-build.rj/build/tmp/sysroots/x86_64-linux/usr/lib/python2.7/distutils/dist.py", line 953, in run_commands| self.run_command(cmd)| File "/home/sunyongfeng/workshop/ops-build.rj/build/tmp/sysroots/x86_64-linux/usr/lib/python2.7/distutils/dist.py", line 971, in run_command| cmd_obj.ensure_finalized()| File "/home/sunyongfeng/workshop/ops-build.rj/build/tmp/sysroots/x86_64-linux/usr/lib/python2.7/distutils/cmd.py", line 109, in ensure_finalized| self.finalize_options()| File "setup.py", line 15, in finalize_options| from xattr.lib import ffi| File "/home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/python-xattr/0.8.0-r0/xattr-0.8.0/xattr/__init__.py", line 12, in &lt;module&gt;| from .lib import (XATTR_NOFOLLOW, XATTR_CREATE, XATTR_REPLACE,| File "/home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/python-xattr/0.8.0-r0/xattr-0.8.0/xattr/lib.py", line 596, in &lt;module&gt;| """, ext_package='xattr')| File "/home/sunyongfeng/workshop/ops-build.rj/build/tmp/sysroots/x86_64-linux/usr/lib/python2.7/site-packages/cffi/api.py", line 424, in verify| lib = self.verifier.load_library()| File "/home/sunyongfeng/workshop/ops-build.rj/build/tmp/sysroots/x86_64-linux/usr/lib/python2.7/site-packages/cffi/verifier.py", line 111, in load_library| return self._load_library()| File "/home/sunyongfeng/workshop/ops-build.rj/build/tmp/sysroots/x86_64-linux/usr/lib/python2.7/site-packages/cffi/verifier.py", line 222, in _load_library| return self._vengine.load_library()| File "/home/sunyongfeng/workshop/ops-build.rj/build/tmp/sysroots/x86_64-linux/usr/lib/python2.7/site-packages/cffi/vengine_cpy.py", line 155, in load_library| raise ffiplatform.VerificationError(error)| cffi.ffiplatform.VerificationError: importing '/home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/python-xattr/0.8.0-r0/xattr-0.8.0/xattr/__pycache__/_cffi__xf88a1d89x3f40c4a9.so': /home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/python-xattr/0.8.0-r0/xattr-0.8.0/xattr/__pycache__/_cffi__xf88a1d89x3f40c4a9.so: wrong ELF class: ELFCLASS32| ERROR: python setup.py build execution failed.| WARNING: exit code 1 from a shell command.| ERROR: Function failed: do_compile (log file is located at /home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/python-xattr/0.8.0-r0/temp/log.do_compile.14582)ERROR: Task 3879 (/home/sunyongfeng/workshop/ops-build.rj/yocto/openswitch/meta-foss-openswitch/recipes-devtools/python/python-xattr_0.8.0.bb, do_compile) failed with exit code '1'NOTE: Tasks Summary: Attempted 2351 tasks of which 2295 didn't need to be rerun and 1 failed.Waiting for 0 running tasks to finish:Summary: 1 task failed: /home/sunyongfeng/workshop/ops-build.rj/yocto/openswitch/meta-foss-openswitch/recipes-devtools/python/python-xattr_0.8.0.bb, do_compileSummary: There was 1 WARNING message shown.Summary: There was 1 ERROR message shown, returning a non-zero exit code.tools/Rules.make:216: recipe for target '_fs' failedmake: *** [_fs] Error 1sunyongfeng@openswitch-OptiPlex-380:~/workshop/ops-build.rj$ 原因：见 github issue I don’t think it’s a cffi issue. I tried to cross compile for a 32 bit system from a 64 bit system. cffi module cffi_backend.so compiled OK for the target (that is 32 bit). The problem is that when cryptography tries to pre-cross compile (for 32 bit) cffi modules (_Cryptography_cffi*.so), it uses (host) 64 bit compiler flags and tries to load the 32 bit cross compiled _cffi_backend.so. This is why you get “wrong ELF class: ELFCLASS32”. There needs to be some way to configure the C compiler flags from within the cryptography package while cross compiling the cffi modules. You can see how cffi module itself is allowing that in its setup.py file. Another python package I was able to configure the target c flags is python readline. I got around this problem (dirty hack) by skipping the cffi modules pre-cross compilation process (Cryptography_cffi*.so) and copying (during the build time) those modules I compiled on the target system. 这种交叉编译时在 build 系统上直接使用编译给 host 的结果，很是蛋疼。 解决： Well I could get it working myself by following midicase comment on vincentbernat/snimpy. build and install host cffi build and install target packages that depend in cffi build and install target cffiI’ve created a detailed install instructions https://github.com/AndreMiras/km/wiki/CFFI-Cross-Compile. 依葫芦画瓢，也衔把 cffi 编译成 build 主机的结果，后续 ARM 设备上要用的话，再编译一个 ARM 架构的 .so。优雅的做法是打 patch 改 xattr 编译 cffi 的配置文件，先编译成 build 机可用、再编译成 host 机可用的结果。 123sunyongfeng@openswitch-OptiPlex-380:~/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/python-xattr/0.8.0-r0/xattr-0.8.0/xattr/__pycache__$ gcc -o _cffi__xf88a1d89x3f40c4a9.so _cffi__xf88a1d89x3f40c4a9.c -shared -I/usr/include/python2.7/ -fPICsunyongfeng@openswitch-OptiPlex-380:~/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/python-xattr/0.8.0-r0/xattr-0.8.0/xattr/__pycache__$ ls_cffi__x7c9e2f59xb862c7dd.c _cffi__xf88a1d89x3f40c4a9.c _cffi__xf88a1d89x3f40c4a9.so _cffi__xf88a1d89x3f40c4a9.so.arm xattr 3.2. go 编译失败go 编译不过，go 的依赖方是 ops-webui，应该是 web 操作界面相关的东西，目前还用不上直接删了。 1234567| WARNING: exit code 2 from a shell command.| ERROR: Function failed: do_compile (log file is located at /home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/x86_64-openswitch-linux-gnueabi/go-cross/1.6.3-r0/temp/log.do_compile.31635)ERROR: Task 3543 (/home/sunyongfeng/workshop/ops-build.rj/yocto/openswitch/meta-foss-openswitch/recipes-devtools/go/go-cross_1.6.3.bb, do_compile) failed with exit code '1'NOTE: Tasks Summary: Attempted 3606 tasks of which 3599 didn't need to be rerun and 1 failed.Waiting for 0 running tasks to finish: Summary: 1 task failed: 删除 ops-webui.bb 删除 recipes-go 删除 recipes-nodejs 12345deleted: yocto/openswitch/meta-distro-openswitch/recipes-ops/mgmt/ops-webui.bbdeleted: yocto/openswitch/meta-foss-openswitch/recipes-go/prometheus/prometheus-promu_git.bbdeleted: yocto/openswitch/meta-foss-openswitch/recipes-nodejs/nodejs/nodejs.incdeleted: yocto/openswitch/meta-foss-openswitch/recipes-nodejs/nodejs/nodejs4.incdeleted: yocto/openswitch/meta-foss-openswitch/recipes-nodejs/nodejs/nodejs_4.1.2.bb 3.3. ops-* 多地方出现 VLOG format 和指针强转 Warning 导致编译失败这纯粹是 ops 代码的问题，估计没有 porting 到 32 位机上。出现 warning 的位置实在太多，暂不考虑直接改 .c/.h 源代码。考虑从编译选项入手。 由于带 -Werror，所以 Warning 会被当成 Error 处理。在 local.conf 中配置 -Wno-error 可体现在编译选项中，但是这个编译选项在 -Werror 之前，经确认，要放在之后才能生效。因此需要考虑打 patch 删除源码配置文件中编译选项带的 -Werror。 ops-* 组件使用两种编译工具，CMake 与 autoconf。这里为快速适配，还没有使用打 patch 的方法打补丁。 3.3.1. CMake 类处理查找所有 CMakeLists.txt 文件，删除文件中的所有 -Werror。1find . -name "CMakeLists.txt" | xargs sed -i "s/ -Werror//g" 3.3.2. autoconf 类处理只有 ops-lldpd 组件用的 autoconf 且出现 warning。 删除 build/tmp/stamps 目录内 ops-lldpd.do_configure.xxx，这样做才能重新 configure； 修改 build/tmp/work/armv4-openswitch-linux-gnueabi/ops-lldpd/gitAUTOINC+fd74e10ef2-r0/git/ 源码configure.ac文件，将其中的-Werror` 选项删除。 123456789101112131415161718192021diff --git a/configure.ac b/configure.acindex c476286..ea5d5fb 100644--- a/configure.ac+++ b/configure.ac@@ -29,7 +29,7 @@ AC_CONFIG_MACRO_DIR([m4]) AC_SUBST([CONFIGURE_ARGS], [$ac_configure_args]) # Configure automake-AM_INIT_AUTOMAKE([foreign -Wall -Werror])+AM_INIT_AUTOMAKE([foreign -Wall]) AM_MAINTAINER_MODE m4_ifdef([AM_SILENT_RULES], [AM_SILENT_RULES(yes)]) @@ -70,7 +70,6 @@ AX_CFLAGS_GCC_OPTION([-fdiagnostics-show-option]) AX_CFLAGS_GCC_OPTION([-fdiagnostics-color=auto]) AX_CFLAGS_GCC_OPTION([-pipe]) AX_CFLAGS_GCC_OPTION([-Wall])-AX_CFLAGS_GCC_OPTION([-Werror]) AX_CFLAGS_GCC_OPTION([-W]) AX_CFLAGS_GCC_OPTION([-Wextra]) AX_CFLAGS_GCC_OPTION([-Wformat]) 这个定义没有的使用地方没有写好，导致好多 ops-lldpd 强转的地方编译不过： 12345678910111213141516171819202122232425262728293031323334353637383940104 /* 105 * For the initial release, this will just refer to the 106 * relevant UCD header files. 107 * In due course, the types and structures relevant to the 108 * Net-SNMP API will be identified, and defined here directly. 109 * 110 * But for the time being, this header file is primarily a placeholder, 111 * to allow application writers to adopt the new header file names. 112 */ 113 114 typedef union &#123; 115 long *integer; 116 u_char *string; 117 oid *objid; 118 u_char *bitstring; 119 struct counter64 *counter64; 120 #ifdef NETSNMP_WITH_OPAQUE_SPECIAL_TYPES 121 float *floatVal; 122 double *doubleVal; 123 /* 124 * t_union *unionVal; 125 */ 126 #endif /* NETSNMP_WITH_OPAQUE_SPECIAL_TYPES */ 127 &#125; netsnmp_vardata; 128 129 130 #define MAX_OID_LEN 128 /* max subid's in an oid */ 131 132 /** @typedef struct variable_list netsnmp_variable_list 133 * Typedefs the variable_list struct into netsnmp_variable_list */ 134 /** @struct variable_list 135 * The netsnmp variable list binding structure, it's typedef'd to 136 * netsnmp_variable_list. 137 */ 138 typedef struct variable_list &#123; 139 /** NULL for last variable */ 140 struct variable_list *next_variable; 141 /** Object identifier of variable */ 142 oid *name; ⮀ NORMAL ⮀ net-snmp/types.h log： 123456789101112/home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/ops-lldpd/gitAUTOINC+fd74e10ef2-r0/git/src/snmp/lldpPortConfigTable_interface.c: In function '_lldpPortConfigTable_get_column':/home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/ops-lldpd/gitAUTOINC+fd74e10ef2-r0/git/src/snmp/lldpPortConfigTable_interface.c:323:56: warning: cast increases required alignment of target type [-Wcast-align] rc = lldpPortConfigAdminStatus_get(rowreq_ctx, (long *)var-&gt;val.string); ^/home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/ops-lldpd/gitAUTOINC+fd74e10ef2-r0/git/src/snmp/lldpPortConfigTable_interface.c:329:51: warning: cast increases required alignment of target type [-Wcast-align] (long *)var-&gt;val.string); ^/home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/ops-lldpd/gitAUTOINC+fd74e10ef2-r0/git/src/snmp/lldpPortConfigTable_interface.c:336:45: warning: cast increases required alignment of target type [-Wcast-align] (u_long *)var-&gt;val.string); ^/home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/cortexa9-vfp-neon-openswitch-linux-gnueabi/ops-lldpd/gitAUTOINC+fd74e10ef2-r0/git/src/snmp/lldpPortConfigTable_interface.c:340:19: warning: cast increases required alignment of target type [-Wcast-align] if (*((u_long *)var-&gt;val.string) &amp; mask) 3.4. openswitch-disk-image.bb task do_rootfs 失败原因：usermod 命令找不到 group ovsdb-client 等 group。log：1234567891011121314151617181920| NOTE: Performing usermod with [-R /home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/xxx-openswitch-linux-gnueabi/openswitch-disk-image/1.0-r0/rootfs -g ovsdb-client opsd] and 1 times of retry| usermod: group 'ovsdb-client' does not exist| Server refused shutdown. Remaining client fds: 2| Client pids: 2799 8830| Server will shut down after all clients exit.| WARNING: usermod command did not succeed. Retrying...| ERROR: Tried running usermod command 1 times without success, giving up| WARNING: exit code 1 from a shell command.| DEBUG: Python function do_rootfs finished| ERROR: Function failed: set_user_group (log file is located at /home/sunyongfeng/workshop/ops-build.rj/build/tmp/work/xxx-openswitch-linux-gnueabi/openswitch-disk-image/1.0-r0/temp/log.do_rootfs.2799)ERROR: Task 7 (/home/sunyongfeng/workshop/ops-build.rj/yocto/openswitch/meta-distro-openswitch/recipes-core/images/openswitch-disk-image.bb, do_rootfs) failed with exit code '1'NOTE: Tasks Summary: Attempted 4408 tasks of which 4407 didn't need to be rerun and 1 failed.No currently running tasks (4405 of 4411)Summary: 1 task failed: /home/sunyongfeng/workshop/ops-build.rj/yocto/openswitch/meta-distro-openswitch/recipes-core/images/openswitch-disk-image.bb, do_rootfsSummary: There was 1 WARNING message shown.Summary: There was 1 ERROR message shown, returning a non-zero exit code.tools/Rules.make:216: recipe for target '_fs' failedmake: *** [_fs] Error 1 看 rootfs 里面，没有看到 group 没有 ops_admin、ovsdb-client 等。而 yocto/openswitch/meta-distro-openswitch/classes/openswitch-image.bbclass 中的 EXTRA_USER_PARAMS 有添加用户到这几个 group 中。 12345678910111213141516171819202122inherit core-image extrausers EXTRA_USERS_PARAMS = "\ useradd -N -M -r opsd; \ usermod -s /bin/false opsd;\ useradd -N -P netop netop; \ useradd -N -P admin admin; \ useradd -N -P remote_user remote_user; \ usermod -g ops_admin admin;\ usermod -g ops_netop netop;\ usermod -g ops_netop remote_user;\ usermod -g ovsdb-client opsd;\ usermod -G ovsdb-client netop;\ usermod -G ovsdb-client remote_user;\ usermod -s /bin/bash admin;\ usermod -s /usr/bin/vtysh netop;\ usermod -s /usr/bin/vtysh remote_user;\ " IMAGE_FEATURES += "ssh-server-openssh" IMAGE_FEATURES += "package-management"IMAGE_GEN_DEBUGFS = "1" IMAGE_FSTYPES += "dbg.tar" 而 yocto/openswitch/meta-distro-openswitch/recipes-ops/openvswitch/ops-openvswitch.bb 中有配置添加 group： 1GROUPADD_PARAM_$&#123;PN&#125; ="-g 1020 ovsdb-client;ops_netop;ops_admin" 这个配置没在 rootsf 中生效： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950sunyongfeng@openswitch-OptiPlex-380:~/workshop/ops-build.rj/build/tmp/work/xxx-openswitch-linux-gnueabi/openswitch-disk-image/1.0-r0/rootfs$ cat etc/group root:x:0:daemon:x:1:bin:x:2:sys:x:3:adm:x:4:tty:x:5:disk:x:6:lp:x:7:mail:x:8:news:x:9:uucp:x:10:man:x:12:proxy:x:13:kmem:x:15:input:x:19:dialout:x:20:fax:x:21:voice:x:22:cdrom:x:24:floppy:x:25:tape:x:26:sudo:x:27:audio:x:29:dip:x:30:www-data:x:33:backup:x:34:operator:x:37:list:x:38:irc:x:39:src:x:40:gnats:x:41:shadow:x:42:utmp:x:43:video:x:44:sasl:x:45:plugdev:x:46:staff:x:50:games:x:60:shutdown:x:70:users:x:100:nogroup:x:65534:rpc:x:999:netdev:x:998:messagebus:x:997:sshd:x:996:lock:x:995:systemd-journal:x:994:systemd-journal-gateway:x:993:systemd-timesync:x:992: 因此，在usermod 使用不存在的 group 前，先执行 groupadd。 1234567891011121314diff --git a/yocto/openswitch/meta-distro-openswitch/classes/openswitch-image.bbclass b/yocto/openswitch/meta-distro-openswitch/classes/openswitch-image.bbclassindex 996503c..5e1e9e8 100644--- a/yocto/openswitch/meta-distro-openswitch/classes/openswitch-image.bbclass+++ b/yocto/openswitch/meta-distro-openswitch/classes/openswitch-image.bbclass@@ -2,6 +2,9 @@ inherit core-image extrausers EXTRA_USERS_PARAMS = "\ useradd -N -M -r opsd; \ usermod -s /bin/false opsd;\+ groupadd -g 1020 ovsdb-client; \+ groupadd ops_netop; \+ groupadd ops_admin; \ usermod -g ovsdb-client opsd;\ useradd -N -P netop netop; \ useradd -N -P admin admin; \ 4. 编译太慢？4.1. 下载源码慢的问题编译的时候，会实时下载要编译的源代码包，由于 GFW 的缘故，代码下载得很慢，导致整个工程编译时间超长。因此可一次下载，多次使用，改 DL_DIR。 原始位置，tools/config/local.conf.in 和 tools/config/site.conf.in 在 make configure xxx 之后，亦可直接修订 build/conf/local.conf 4.2. 如果使用已编译的结果利用 yocto sstate 特性。配置 SSTATE_DIR 4.1. 和 4.2. 的配置修订如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849diff --git a/tools/config/local.conf.in b/tools/config/local.conf.inindex 80eefbe..eaeb301 100644--- a/tools/config/local.conf.in+++ b/tools/config/local.conf.in@@ -39,7 +39,7 @@ MACHINE = "##PLATFORM##" # # The default is a downloads directory under TOPDIR which is the build directory. #-#DL_DIR ?= "$&#123;TOPDIR&#125;/downloads"+DL_DIR ?= "/home/sunyongfeng/backup/downloads" # # Where to place shared-state files@@ -55,7 +55,7 @@ MACHINE = "##PLATFORM##" # # The default is a sstate-cache directory under TOPDIR. #-#SSTATE_DIR ?= "$&#123;TOPDIR&#125;/sstate-cache"+SSTATE_DIR ?= "/home/sunyongfeng/backup/sstate-cache" # # Where to place the build output@@ -197,10 +197,14 @@ BB_DISKMON_DIRS = "\ # NOTE: if the mirror uses the same structure as SSTATE_DIR, you need to add PATH # at the end as shown in the examples below. This will be substituted with the # correct path within the directory structure.+#SSTATE_MIRRORS ?= "\+#file://.* http://##DISTRO_SSTATE_ADDRESS##/PATH \+#" SSTATE_MIRRORS ?= "\-file://.* http://##DISTRO_SSTATE_ADDRESS##/PATH"+file:///home/sunyongfeng/backup/sstate-cache http://##DISTRO_SSTATE_ADDRESS##/PATH" -SOURCE_MIRROR_URL ?= "http://##DISTRO_ARCHIVE_ADDRESS##/"+#SOURCE_MIRROR_URL ?= "http://##DISTRO_ARCHIVE_ADDRESS##/"+SOURCE_MIRROR_URL ?= "file:///home/sunyongfeng/backup/downloads/" INHERIT += "own-mirrors" BB_GENERATE_MIRROR_TARBALLS = "1"diff --git a/tools/config/site.conf.in b/tools/config/site.conf.inindex 9fa46c5..4aa4206 100644--- a/tools/config/site.conf.in+++ b/tools/config/site.conf.in@@ -21,5 +21,5 @@ SCONF_VERSION = "1" ##ALL_PROXY## # Uncomment this to use a shared download directory-#DL_DIR = "/some/shared/download/directory/"+DL_DIR = "/home/sunyongfeng/backup/downloads/" 4.3. parse recipe 实在太慢改 ops-* 的源码路径为 github。但是 ops-tunnel github 上面还没有，需要自己改 DL_DIR 中的 ops-tunnel 包名。 1234DL_DIR 请改成你自己的 DL_DIRmv DL_DIR/git2/git.openswitch.net.openswitch.ops-tunnel.done DL_DIR/git2/github.com.open-switch.ops-tunnel.donemv DL_DIR/git2/git.openswitch.net.openswitch.ops-tunnel DL_DIR/git2/github.com.open-switch.ops-tunnel patch： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283diff --git a/yocto/openswitch/meta-distro-openswitch/conf/distro/openswitch.conf b/yocto/openswitch/meta-distro-openswitch/conf/distro/openswitch.confindex dd776f0..b6c18b3 100644--- a/yocto/openswitch/meta-distro-openswitch/conf/distro/openswitch.conf+++ b/yocto/openswitch/meta-distro-openswitch/conf/distro/openswitch.conf@@ -6,8 +6,11 @@ DISTRO_CODENAME = "epazote" SDK_VENDOR = "-openswitchsdk" SDK_VERSION := "$&#123;@'$&#123;DISTRO_VERSION&#125;'.replace('snapshot-$&#123;DATE&#125;','snapshot')&#125;" -OPS_REPO_HOSTNAME ?= "git.openswitch.net"-OPS_REPO_PATH ?= "openswitch"+#OPS_REPO_HOSTNAME ?= "git.openswitch.net"+#OPS_REPO_PATH ?= "openswitch"+#OPS_REPO_BASE_URL ?= "git://$&#123;OPS_REPO_HOSTNAME&#125;/$&#123;OPS_REPO_PATH&#125;"+OPS_REPO_HOSTNAME ?= "github.com"+OPS_REPO_PATH ?= "open-switch" OPS_REPO_BASE_URL ?= "git://$&#123;OPS_REPO_HOSTNAME&#125;/$&#123;OPS_REPO_PATH&#125;" OPS_REPO_PROTOCOL ?= "https" OPS_REPO_BRANCH ?= "master"diff --git a/yocto/openswitch/meta-distro-openswitch/recipes-ops/infra/ops-website.bb b/yocto/openswitch/meta-distro-openswitch/recipes-ops/infra/ops-website.bbindex 79c50f6..caa166d 100644--- a/yocto/openswitch/meta-distro-openswitch/recipes-ops/infra/ops-website.bb+++ b/yocto/openswitch/meta-distro-openswitch/recipes-ops/infra/ops-website.bb@@ -4,7 +4,7 @@ LIC_FILES_CHKSUM = "file://$&#123;COMMON_LICENSE_DIR&#125;/Apache-2.0;md5=89aea4e17d99a7ca BRANCH ?= "$&#123;OPS_REPO_BRANCH&#125;" -SRC_URI = "git://$&#123;OPS_REPO_HOSTNAME&#125;/infra/website;protocol=$&#123;OPS_REPO_PROTOCOL&#125;;branch=$&#123;BRANCH&#125; \+SRC_URI = "git://$&#123;OPS_REPO_HOSTNAME&#125;/open-switch/infra_website;protocol=$&#123;OPS_REPO_PROTOCOL&#125;;branch=$&#123;BRANCH&#125; \ " SRCREV="$&#123;AUTOREV&#125;"diff --git a/yocto/openswitch/meta-distro-openswitch/recipes-ops/switchd/ops-switchd.bb b/yocto/openswitch/meta-distro-openswitch/recipes-ops/switchd/ops-switchd.bbindex 8d622bd..d74cd9e 100644--- a/yocto/openswitch/meta-distro-openswitch/recipes-ops/switchd/ops-switchd.bb+++ b/yocto/openswitch/meta-distro-openswitch/recipes-ops/switchd/ops-switchd.bb@@ -6,7 +6,7 @@ DEPENDS = "ops ops-openvswitch ops-ovsdb ops-utils libyaml jemalloc ops-cli" BRANCH ?= "$&#123;OPS_REPO_BRANCH&#125;" -SRC_URI = "$&#123;OPS_REPO_BASE_URL&#125;/ops-switchd;protocol=$&#123;OPS_REPO_PROTOCOL&#125;;branch=$&#123;BRANCH&#125; \+SRC_URI = "$&#123;OPS_REPO_BASE_URL&#125;/ops-switchd.git;protocol=$&#123;OPS_REPO_PROTOCOL&#125;;branch=$&#123;BRANCH&#125; \ file://switchd_nnn.service \ file://switchd_sim.service \ file://switchd_p4sim.service \@@ -14,7 +14,7 @@ SRC_URI = "$&#123;OPS_REPO_BASE_URL&#125;/ops-switchd;protocol=$&#123;OPS_REPO_PROTOCOL&#125;;branch file://switchd_sai.service \ " -SRCREV = "f17ef096d728b79c77a24cd908fdbcf9b18bcd6c"+SRCREV = "d345f87cd17ced3b97a73ace23c387de5db62842" # When using AUTOREV, we need to force the package version to the revision of git # in order to avoid stale shared states.@@ -33,18 +33,18 @@ FILES_$&#123;PN&#125; = "$&#123;sbindir&#125;/ops-switchd $&#123;libdir&#125;/libswitchd_plugins.so.1* $&#123;libdi FILES_$&#123;PN&#125; += "/usr/lib/cli/plugins/" do_install_append() &#123;- install -d $&#123;D&#125;$&#123;systemd_unitdir&#125;/system- if $&#123;@bb.utils.contains('MACHINE_FEATURES','nnnmmm','true','false',d)&#125;; then- install -m 0644 $&#123;WORKDIR&#125;/switchd_nnn.service $&#123;D&#125;$&#123;systemd_unitdir&#125;/system/switchd.service- elif $&#123;@bb.utils.contains('MACHINE_FEATURES','xpliant','true','false',d)&#125;; then- install -m 0644 $&#123;WORKDIR&#125;/switchd_xpliant.service $&#123;D&#125;$&#123;systemd_unitdir&#125;/system/switchd.service- elif $&#123;@bb.utils.contains('IMAGE_FEATURES','ops-p4','true','false',d)&#125;; then+ install -d $&#123;D&#125;$&#123;systemd_unitdir&#125;/system+#if $&#123;@bb.utils.contains('MACHINE_FEATURES','nnnmmm','true','false',d)&#125;; then+# install -m 0644 $&#123;WORKDIR&#125;/switchd_nnn.service $&#123;D&#125;$&#123;systemd_unitdir&#125;/system/switchd.service+# elif $&#123;@bb.utils.contains('MACHINE_FEATURES','xpliant','true','false',d)&#125;; then+# install -m 0644 $&#123;WORKDIR&#125;/switchd_xpliant.service $&#123;D&#125;$&#123;systemd_unitdir&#125;/system/switchd.service+# elif $&#123;@bb.utils.contains('IMAGE_FEATURES','ops-p4','true','false',d)&#125;; then install -m 0644 $&#123;WORKDIR&#125;/switchd_p4sim.service $&#123;D&#125;$&#123;systemd_unitdir&#125;/system/switchd.service- elif $&#123;@bb.utils.contains('MACHINE_FEATURES','ops-container','true','false',d)&#125;; then- install -m 0644 $&#123;WORKDIR&#125;/switchd_sim.service $&#123;D&#125;$&#123;systemd_unitdir&#125;/system/switchd.service- elif $&#123;@bb.utils.contains('MACHINE_FEATURES','ops-sai','true','false',d)&#125;; then- install -m 0644 $&#123;WORKDIR&#125;/switchd_sai.service $&#123;D&#125;$&#123;systemd_unitdir&#125;/system/switchd.service- fi+# elif $&#123;@bb.utils.contains('MACHINE_FEATURES','ops-container','true','false',d)&#125;; then+# install -m 0644 $&#123;WORKDIR&#125;/switchd_sim.service $&#123;D&#125;$&#123;systemd_unitdir&#125;/system/switchd.service+# elif $&#123;@bb.utils.contains('MACHINE_FEATURES','ops-sai','true','false',d)&#125;; then+# install -m 0644 $&#123;WORKDIR&#125;/switchd_sai.service $&#123;D&#125;$&#123;systemd_unitdir&#125;/system/switchd.service+# fi install -d $&#123;D&#125;/usr/share/opsplugins for plugin in $(find $&#123;S&#125;/opsplugins -name "*.py"); do \ 5. 其他配置5.1. 如何新增 CFLAG、LDFLAG 选项？在 local.conf 中添加对应 FLAG，以 -Wno-error 为例。 123456BUILD_CFLAGS += " -Wno-error "BUILD_CPPFLAGS += " -Wno-error "BUILD_CXXFLAGS += " -Wno-error "TARGET_CFLAGS += " -Wno-error "TARGET_CPPFLAGS += " -Wno-error "TARGET_CXXFLAGS += " -Wno-error " 5.2. 使用 pre-built 交叉编译工具链（linaro）FAIL。 可研究 SDK，将交叉编译链一次编出，后续无需再编译。 5.3. 配置 ops-switchd-p4switch-plugin修改 machine 的 conf，yocto/openswitch/meta-platform-openswitch-xxx/conf/machine/xxx.conf： 1PREFERRED_PROVIDER_virtual/ops-switchd-switch-api-plugin ?= "ops-switchd-p4switch-plugin" 官方 README 的说明应已过时： The P4 plugin is activated adding the following line in /build/conf/local.conf EXTRA_IMAGE_FEATURES = “ops-p4” (use += if other image features are defined)https://github.com/open-switch/ops-switchd-p4switch-plugin 6. 运行问题记录与解决6.1. ops-switchd-p4switch-plugin 没有打包到 rootfs6.2. 运行时出现 rsyslog、ops-init.servic 等业务起不来log 如下： 123456789101112131415161718192021222324252627282930313233343536373839404142[20161110:184441.388][FAILED] Failed to start openswitch first boot process.[20161110:184441.388]See "systemctl status ops-first-boot.service" for details.[20161110:184445.440][FAILED] Failed to start OpenSwitch system initialization script.[20161110:184445.440]See "systemctl status ops-init.service" for details.[20161110:184447.615]systemd[1]: Unit ops-powerd.service entered failed state.[20161110:184447.615]systemd[1]: ops-powerd.service failed.[20161110:184447.646]systemd[1]: Unit ops-lacpd.service entered failed state.[20161110:184447.646]systemd[1]: ops-lacpd.service failed.[20161110:184447.677]systemd[1]: Unit ops-portd.service entered failed state.[20161110:184447.677]systemd[1]: ops-portd.service failed.[20161110:184447.708]systemd[1]: Unit ops-tempd.service entered failed state.[20161110:184447.708]systemd[1]: ops-tempd.service failed.[20161110:184447.740]systemd[1]: Unit ops-zebra.service entered failed state.[20161110:184447.740]systemd[1]: ops-zebra.service failed.[20161110:184447.771]systemd[1]: Unit ops-ledd.service entered failed state.[20161110:184447.771]systemd[1]: ops-ledd.service failed.[20161110:184447.802]systemd[1]: Unit aaautils.service entered failed state.[20161110:184447.802]systemd[1]: aaautils.service failed.[20161110:184447.833]systemd[1]: Unit ops-stpd.service entered failed state.[20161110:184447.833]systemd[1]: ops-stpd.service failed.[20161110:184447.865]systemd[1]: Unit ops-bgpd.service entered failed state.[20161110:184447.865]systemd[1]: ops-bgpd.service failed.[20161110:184447.865]systemd[1]: Unit ops-classifierd.service entered failed state.[20161110:184447.865]systemd[1]: ops-classifierd.service failed.[20161110:184447.927]systemd[1]: Unit ops-relay.service entered failed state.[20161110:184447.927]systemd[1]: ops-relay.service failed.[20161110:184447.958]systemd[1]: Unit ops-intfd.service entered failed state.[20161110:184447.958]systemd[1]: ops-intfd.service failed.[20161110:184447.990]systemd[1]: Unit ops-ospfd.service entered failed state.[20161110:184447.990]systemd[1]: ops-ospfd.service failed.[20161110:184448.021]systemd[1]: Unit ops-arpmgrd.service entered failed state.[20161110:184448.021]systemd[1]: ops-arpmgrd.service failed.[20161110:184448.052]systemd[1]: Unit dhcp_tftp.service entered failed state.[20161110:184448.052]systemd[1]: dhcp_tftp.service failed.[20161110:184448.083]systemd[1]: Unit ops-fand.service entered failed state.[20161110:184448.083]systemd[1]: ops-fand.service failed.[20161110:184448.115]systemd[1]: Unit ops-sysd.service entered failed state.[20161110:184448.115]systemd[1]: ops-sysd.service failed.[20161110:184448.146]systemd[1]: Unit ops-lldpd.service entered failed state.[20161110:184448.146]systemd[1]: ops-lldpd.service failed.[20161110:184448.146]systemd[1]: Unit ops-vland.service entered failed state.[20161110:184448.146]systemd[1]: ops-vland.service failed. 进一步看 log：所有问题都是 open(&quot;/proc/self/ns/net&quot;): No such file or directory，原因是内核配置 namespace 没有开启。 12345678910111213141516171819202122[20161110:184548.411]ops-xxx:~$ systemctl status ops-first-boot.service[20161110:184548.536]● ops-first-boot.service - openswitch first boot process[20161110:184548.536] Loaded: loaded (/lib/systemd/system/ops-first-boot.service; enabled; vendor preset: enabled)[20161110:184548.536] Active: failed (Result: exit-code) since Thu 1970-01-01 00:00:08 UTC; 1min 7s ago[20161110:184548.536] Process: 100 ExecStart=/usr/sbin/setcap cap_audit_write+eip /usr/bin/vtysh (code=exited, status=1/FAILURE)[20161110:184548.551] Main PID: 100 (code=exited, status=1/FAILURE)[20161110:184549.505]ops-xxx:~$ [20161110:184613.881]ops-xxx:~$ systemd[1]: Unit rsyslog.service entered failed state.[20161110:184622.878]systemd[1]: Unit rsyslog.service entered failed state.[20161110:184622.878]systemd[1]: rsyslog.service failed.[20161110:184624.488]systemctl status rsyslog.service[20161110:184624.534]● rsyslog.service - System Logging Service[20161110:184624.534] Loaded: loaded (/lib/systemd/system/rsyslog.service; enabled; vendor preset: enabled)[20161110:184624.534] Active: failed (Result: exit-code) since Thu 1970-01-01 00:01:51 UTC; 41ms ago[20161110:184624.534] Process: 3112 ExecStart=/sbin/ip netns exec swns /usr/sbin/rsyslogd -n (code=exited, status=1/FAILURE)[20161110:184624.550] Main PID: 3112 (code=exited, status=1/FAILURE)[20161110:184830.707]ops-xxx:~$ systemctl status ops-init.service[20161110:184830.770]● ops-init.service - OpenSwitch system initialization script[20161110:184830.770] Loaded: loaded (/lib/systemd/system/ops-init.service; enabled; vendor preset: enabled)[20161110:184830.770] Active: failed (Result: exit-code) since Thu 1970-01-01 00:00:11 UTC; 3min 46s ago[20161110:184830.770] Process: 161 ExecStart=/usr/sbin/ops-init (code=exited, status=1/FAILURE)[20161110:184830.770] Main PID: 161 (code=exited, status=1/FAILURE) 对应的 namespace 内核配置： 1234567CONFIG_NAMESPACES=yCONFIG_UTS_NS=yCONFIG_IPC_NS=y# CONFIG_USER_NS is not setCONFIG_PID_NS=yCONFIG_NET_NS=yCONFIG_UIDGID_CONVERTED=y 6.3. P4 交换机模拟器启动失败log： 12[FAILED] Failed to start P4 Switch simulation Daemon.See "systemctl status simple_switch.service" for details. 原因：内核配置没有开启支持 VNET 12345678910ops-xxx:~$ systemctl status simple_switch.service● simple_switch.service - P4 Switch simulation Daemon Loaded: loaded (/lib/systemd/system/simple_switch.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since Thu 1970-01-01 00:00:13 UTC; 1min 26s ago Process: 222 ExecStartPre=/sbin/ip netns exec emulns ip link add veth250 type veth peer name veth251 (code=exited, status=2) Process: 214 ExecStartPre=/sbin/ip netns add emulns (code=exited, status=0/SUCCESS) Process: 210 ExecStartPre=/sbin/ip netns del emulns (code=exited, status=1/FAILURE) Process: 206 ExecStartPre=/bin/rm -f /var/run/simple_switch.pid (code=exited, status=0/SUCCESS)ops-xxx:~$ sudo/sbin/ip netns exec emulns ip link add veth250 type veth peer nameRTNETLINK answers: Operation not supported 6.4. CLI 不可用log： 123root@ops-xxx:~# vtysh ops-xxx# show interface System is not ready. Please retry after few seconds.. ip netns exec emulns ip tuntap add mode tap eth0ip netns exec emulns ifconfig eth0 up 查看 bmv2 runtime command line 命令：https://github.com/p4lang/behavioral-model/blob/master/tools/runtime_CLI.pyruntime cli：ip netns exec emulns /usr/sbin/simple_switch -i 64@veth250 –thrift-port 10001 –nanolog ipc:///tmp/bm-log.ipc /usr/share/ovs_p4_plugin/switch_bmv2.json 12345678#!/bin/bashset -x for iface in `seq 1 7` ; do /sbin/ip netns exec emulns ip tuntap add mode tap eth$iface /sbin/ip netns exec emulns /sbin/ip ifconfig eth$iface up echo port_add eth$iface `expr $iface - 1` | /sbin/ip netns exec emulns /usr/bin/bm_tools/runtime_CLI.py --json /usr/share/ovs_p4_plugin/switch_bmv2.json --thrift-port 10001done 可能需要配置的地方： https://github.com/open-switch/ops-build/blob/55c9f56fd3fc7a87cd5c7273374b910998630203/yocto/openswitch/meta-platform-openswitch-genericx86-64/recipes-ops/platform/ops-hw-config.bbappend https://github.com/open-switch/ops-hw-config/tree/master/Generic-x86/X86-64/P4 https://github.com/open-switch/ops-build/blob/55c9f56fd3fc7a87cd5c7273374b910998630203/yocto/openswitch/meta-distro-openswitch/recipes-ops/openvswitch/ops-openvswitch.bb IMAGE_FEATURES[validitems] += “ops-p4” 7. 其他问题x86_64 上的一个 QA 问题编译时提示： 1WARNING: QA Issue: ops-cli rdepends on libcap, but it isn't a build dependency? [build-deps] 这个问题可能导致编译 ops-cli 时，configure 不过。]]></content>
      <categories>
        <category>yocto</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>openswitch</tag>
        <tag>yocto</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xmind 转换成 excel]]></title>
    <url>%2F201704%2Fprogrammer%2Fpython%2Fxmind2excel.html</url>
    <content type="text"><![CDATA[思路思路直接使用 百码山庄 的文章 【原创】XMind免费到Excel的全过程。该文使用 nodejs / php 实现本功能，本文使用 python 实现。 转换 xmind 文件为 freemind .mm 后缀文件。 freemind 文件实为 xml 格式，通过解析 xml 文件，按格式导出为 excel。 freemind 格式分析freemind 文件格式分析，xml 源码及 xmind mindmap 如下所示。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;map version="0.8.1"&gt; &lt;node TEXT="项目计划" MODIFIED="1492867311576" ID="0hai9mmspjp2s786pcir50olb1" CREATED="1492867311576"&gt; &lt;node TEXT="相关信息" MODIFIED="1492867311576" ID="3a979etehnf0scej54cpf5ha4j" CREATED="1492867311576" POSITION="right"&gt; &lt;icon BUILTIN="bookmark"/&gt; &lt;node TEXT="项目经理" MODIFIED="1492867311576" ID="734nep595s7klig55tfn46h3tr" CREATED="1492867311576"&gt; &lt;hook NAME="accessories/plugins/NodeNote.properties"&gt; &lt;text&gt;乔老爷子&lt;/text&gt; &lt;/hook&gt; &lt;/node&gt; &lt;node TEXT="团队成员" MODIFIED="1492867311576" ID="1omqdu3bt7s4he6ckksd7e3isl" CREATED="1492867311576"/&gt; &lt;node TEXT="项目介绍" MODIFIED="1492867311576" ID="7ftss79m00ap1okqk0eb0r49el" CREATED="1492867311576"/&gt; &lt;node TEXT="关键利益者" MODIFIED="1492867311576" ID="0p7adcg16k0gescfg56c6hpijo" CREATED="1492867311576"/&gt; &lt;node TEXT="背景介绍" MODIFIED="1492867311577" ID="4jjtr2fckvmmbb4hv05oe87b0u" CREATED="1492867311577"&gt; &lt;node TEXT="example.xls" MODIFIED="1492867311579" ID="3b36u0f56pme6e577sbu69q04j" CREATED="1492867311577" LINK="images/3rjca88od8011qer034ihv0oan.xls"/&gt; &lt;/node&gt; &lt;/node&gt; &lt;node TEXT="目标" MODIFIED="1492867311579" ID="2qouef1qf60nlp0gu85hvtpnle" CREATED="1492867311579" POSITION="right"&gt; &lt;icon BUILTIN="bookmark"/&gt; &lt;/node&gt; &lt;node TEXT="必要条件" MODIFIED="1492867311579" ID="3o4g7q484m4dn2prpn0t63fb9o" CREATED="1492867311579" POSITION="right"&gt; &lt;icon BUILTIN="bookmark"/&gt; &lt;node TEXT="预算" MODIFIED="1492867311579" ID="1n8to0eqqbl7qpenj65m6rd5jq" CREATED="1492867311579"/&gt; &lt;node TEXT="人员" MODIFIED="1492867311579" ID="4886f7qdnnur0h33l4bjeuqjvr" CREATED="1492867311579"/&gt; &lt;node TEXT="资产" MODIFIED="1492867311579" ID="3hqhdaf3v3gr2bh7ttkq89ue06" CREATED="1492867311579"/&gt; &lt;node TEXT="2017.04.22 确认" MODIFIED="1492867311580" ID="3i0vobk9ovfplks8s78drjktki" CREATED="1492867311580"/&gt; &lt;/node&gt; &lt;node TEXT="&lt;html&gt;&lt;img src="images/57hi95enuhcl1c15525mg15r1o.png"&gt;" MODIFIED="1492867311580" ID="0ed31t5hvpa6hfevf213pollgh" CREATED="1492867311580" POSITION="right"&gt; &lt;arrowlink ID="401c8v21ebt0buq4evf77ct7o0" STARTARROW="None" ENDARROW="Default" DESTINATION="6b0sc8ub8t8ji82o37j15j7pnt"/&gt; &lt;node TEXT="第一阶段" MODIFIED="1492867311582" ID="2uhjdmrfb533f2n1d8cd9rt1r2" CREATED="1492867311582"&gt; &lt;node TEXT="高优先级" MODIFIED="1492867311582" ID="68on3d5udtcv2gb00qsl6drm5c" CREATED="1492867311582"/&gt; &lt;node TEXT="中等优先级" MODIFIED="1492867311582" ID="48ls3s61qj2vdstu7jsc51etb3" CREATED="1492867311582"/&gt; &lt;node TEXT="较低优先级" MODIFIED="1492867311582" ID="5c4rujcj281sorpd6l5fv6e712" CREATED="1492867311582"/&gt; &lt;/node&gt; &lt;node TEXT="标志" MODIFIED="1492867311582" ID="2mnset6sop3p30ahgpgu0rasvp" CREATED="1492867311582"/&gt; &lt;node TEXT="第二阶段" MODIFIED="1492867311582" ID="4vvd2ij06hopllstsafc42qg7m" CREATED="1492867311582"&gt; &lt;node TEXT="高优先级" MODIFIED="1492867311582" ID="5nhhs8090vqf9bsqqdf2be575d" CREATED="1492867311582"/&gt; &lt;node TEXT="中等优先级" MODIFIED="1492867311582" ID="2g0bvlskuq04gmetl0r5om4hsq" CREATED="1492867311582"/&gt; &lt;node TEXT="较低优先级" MODIFIED="1492867311582" ID="1shjdng4ufjvj2drsk2gc2ldrf" CREATED="1492867311582"/&gt; &lt;/node&gt; &lt;node TEXT="标志" MODIFIED="1492867311582" ID="2km9h415v1c64th1ma9hpjovsa" CREATED="1492867311582"/&gt; &lt;node TEXT="第三阶段" MODIFIED="1492867311582" ID="4s4rf2536vmh7j1o7clh64be21" CREATED="1492867311582"&gt; &lt;node TEXT="高优先级" MODIFIED="1492867311582" ID="542m4dbcci533bgs3b83vfu95m" CREATED="1492867311582"/&gt; &lt;node TEXT="中等优先级" MODIFIED="1492867311582" ID="1gj5005bf8s0q1brmv5lltbab8" CREATED="1492867311582"/&gt; &lt;node TEXT="较低优先级" MODIFIED="1492867311582" ID="0r65aga724a778tionvopubipd" CREATED="1492867311582"/&gt; &lt;/node&gt; &lt;node TEXT="标志" MODIFIED="1492867311582" ID="3ncr651qia6e4cv2vposgusuhu" CREATED="1492867311582"/&gt; &lt;/node&gt; &lt;node TEXT="&lt;html&gt;&lt;img src="images/701at6fa712kqn6r5nb6ri83ud.png"&gt;" MODIFIED="1492867311582" ID="6b0sc8ub8t8ji82o37j15j7pnt" CREATED="1492867311582" POSITION="left"&gt; &lt;node TEXT="已完成的任务" MODIFIED="1492867311611" ID="071u3nqfdiic6sau5f7fdg3ctr" CREATED="1492867311611"/&gt; &lt;node TEXT="取消的任务" MODIFIED="1492867311611" ID="6tj8kg88oumtel0ki8lu0jjncp" CREATED="1492867311611"/&gt; &lt;node TEXT="被延迟的任务" MODIFIED="1492867311611" ID="2nl2npf0774uu7374uhsv640ad" CREATED="1492867311611"/&gt; &lt;node TEXT="暂停的任务" MODIFIED="1492867311611" ID="1ab39j3upshgvgsja654na18lr" CREATED="1492867311611"/&gt; &lt;node TEXT="进行中的任务" MODIFIED="1492867311611" ID="3duu8bv3jol9htep4brrhj27tp" CREATED="1492867311611"/&gt; &lt;/node&gt; &lt;node TEXT="风险" MODIFIED="1492867311611" ID="3r7div183nssfcspufbed5gsut" CREATED="1492867311611" POSITION="left"&gt; &lt;node TEXT="风险1" MODIFIED="1492867311611" ID="79qem186f8retr8h2m6p94fh9s" CREATED="1492867311611"&gt; &lt;node TEXT="描述" MODIFIED="1492867311611" ID="747p6vp33fp925p1rsc5tpdvhh" CREATED="1492867311611"/&gt; &lt;node TEXT="可能的影响" MODIFIED="1492867311611" ID="3e5tj66vk777rmmuck8sd9hf4s" CREATED="1492867311611"/&gt; &lt;node TEXT="严重程度" MODIFIED="1492867311611" ID="2v578nqjtjmc0us7qpiq9mfg67" CREATED="1492867311611"/&gt; &lt;node TEXT="可能性" MODIFIED="1492867311611" ID="3caf7q4vrsjbh9tutrslkv1ceg" CREATED="1492867311611"/&gt; &lt;node TEXT="事前检测出来的可能性" MODIFIED="1492867311611" ID="6f3rjgd0pbahphscurp4s0b6b6" CREATED="1492867311611"/&gt; &lt;node TEXT="相应的缓解方法" MODIFIED="1492867311611" ID="178k163mtpbfn817dp7nk72n5t" CREATED="1492867311611"/&gt; &lt;node TEXT="推荐的解决方案" MODIFIED="1492867311611" ID="4s839q2p2hikk0qs8e60fnropd" CREATED="1492867311611"/&gt; &lt;/node&gt; &lt;node TEXT="风险2" MODIFIED="1492867311611" ID="26k9binqncjakkb6kq2jrooibj" CREATED="1492867311611"&gt; &lt;node TEXT="描述" MODIFIED="1492867311611" ID="6ftav360fer4ei9vud0rou4mn0" CREATED="1492867311611"/&gt; &lt;node TEXT="可能的影响" MODIFIED="1492867311611" ID="2mp59ni55sicoqccj7ioka737g" CREATED="1492867311611"/&gt; &lt;node TEXT="严重程度" MODIFIED="1492867311611" ID="4mshvotfm0c3t8qn2sr34pk4as" CREATED="1492867311611"/&gt; &lt;node TEXT="可能性" MODIFIED="1492867311611" ID="27ibg9mm2lurv62m84sr17jk1a" CREATED="1492867311611"/&gt; &lt;node TEXT="事前检测出来的可能性" MODIFIED="1492867311611" ID="6443iv9kjlsn7rglj3tqsn65vd" CREATED="1492867311611"/&gt; &lt;node TEXT="相应的缓解方法" MODIFIED="1492867311611" ID="7dirapfhic24srerve84vnod1u" CREATED="1492867311611"/&gt; &lt;node TEXT="推荐的解决方案" MODIFIED="1492867311611" ID="2e1qlidincv7jtg3aeuh2p5m3j" CREATED="1492867311611"/&gt; &lt;/node&gt; &lt;/node&gt; &lt;/node&gt;&lt;/map&gt; 根节点 1&lt;map version="0.8.1"&gt;` mindmap 节点 1&lt;node TEXT="项目计划" MODIFIED="1492867311576" ID="0hai9mmspjp2s786pcir50olb1" CREATED="1492867311576"&gt; 联系节点，即 xmind 中的箭头，ctrl + l 1&lt;arrowlink ID="221s6rn1ft46fc6207057chd1k" STARTINCLINATION="43;180" STARTARROW="None" ENDARROW="Default" DESTINATION="61q31b1bilu0mpim374q7hn048"/&gt; 备注节点，node 节点的子节点。 12345&lt;node TEXT="项目经理" MODIFIED="1492867311576" ID="734nep595s7klig55tfn46h3tr" CREATED="1492867311576"&gt; &lt;hook NAME="accessories/plugins/NodeNote.properties"&gt; &lt;text&gt;乔老爷子&lt;/text&gt; &lt;/hook&gt;&lt;/node&gt; 概要节点，同 mindmap 节点 1&lt;node TEXT="2017.04.22 确认" MODIFIED="1492867311580" ID="3i0vobk9ovfplks8s78drjktki" CREATED="1492867311580"/&gt; 特殊标签 —— 图标 1&lt;icon BUILTIN="bookmark"/&gt; 问题：xmind bug，图片所在节点的文字不会导出到 freemind 中。 1&lt;node TEXT="&lt;html&gt;&lt;img src="images/57hi95enuhcl1c15525mg15r1o.png"&gt;" MODIFIED="1492867311580" ID="0ed31t5hvpa6hfevf213pollgh" CREATED="1492867311580" POSITION="right"&gt; 综上，需归递解析出 freemind 的每个 node 标签，并分析是否为叶子节点，根据是否叶子节点判断excel row 是否加一，将 node 标签的 TEXT 属性值写入 excel 第 row 行，第 level 列。 第一版 —— xml 递归解析参考代码参考代码，Python - How to determine hierarchy level of parsed XML elements? 中 pradyunsg 的回答，通过递归的获取子节点的形式达到获取 xml 等级的目的。 原代码： 123456789101112import xml.etree.ElementTree as ETdef perf_func(elem, func, level=0): func(elem,level) for child in elem.getchildren(): perf_func(child, func, level+1)def print_level(elem,level): print '-'*level+elem.tagroot = ET.parse('XML_file.xml')perf_func(root.getroot(), print_level) 适配到 freemind 的解析实现获取属性 ‘TEXT’，参考 xml.etree.ElementTree — The ElementTree XML API。 12345678910111213141516#!/usr/bin/pythonimport xml.etree.ElementTree as ETdef perf_func(elem, func, level=0): func(elem,level) for child in elem.getchildren(): perf_func(child, func, level+1)def print_level(elem,level): name = elem.get('TEXT') if name is not None: print '-'*level + nameroot = ET.parse('test.xml')perf_func(root.getroot(), print_level) 使用到的 python 语法： if 语句，通过 is not None 判断非空。 第二版 —— 导出为 excel缺点：使用全局变量 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/usr/bin/pythonimport xml.etree.ElementTree as ETimport xlwtg_row = 0def do_write_excel(text, row, col): print text + " row %d + col %d"%(row, col) ws.write(row, col, text) def perf_func(elem, func, level = 0): global g_row func(elem, g_row, level) # elem maybe not a node tag # if elem.tag is 'node': for child in list(elem): name = child.get('TEXT') perf_func(child, func, level + 1) if child.find('node') is None and name is not None: g_row = g_row + 1def write_excel(elem, row, level): name = elem.get('TEXT') if name is not None: do_write_excel(name, row, level) ''' if elem.find('node') is None and name is not None: print "leaf" + '-' * level + name elif name is not None: print '-' * level + name '''root = ET.parse('sde.xml')map_version = root.getroot()first_node = map_version.find('node')wb = xlwt.Workbook()ws = wb.add_sheet('freemind2excel')perf_func(first_node, write_excel)wb.save('freemind2excel.xls') 使用到的 Python 语法： 字符串判空，if a == b，注意 is 是用于判断是否同一个对象。 list 判空，if not a。 全局变量，在函数前定义，在函数内要定义为 global etree.ElementTree 获取 elementTree 树对象，parse(source) 获取 element 对象，getroot 获取 tag 的值，elem.tag 获取首个标签为 node 的 element，elem.find(‘node’) 获取属性 TEXT 的值，elem.get(‘TEXT’) xlwt 实例化，xlwt.workbook() 添加 sheet，add_sheet 保存 xls 文件，save 写数据，write 第三版 —— 带参数解析 python 参数解析内嵌库 argparse python 参数解析方法汇总，Python中的命令行解析工具介绍 python argparse 使用详解，argparse - 命令行选项与参数解析（译） 本文只需要带个参数，一是输入文件，二是输出文件，其中输入文件为必选选项，输出文件为可选，输出文件默认为 freemind2excel.xls。 源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/usr/bin/pythonimport xml.etree.ElementTree as ETimport xlwtimport argparseg_row = 0def do_write_excel(text, row, col): #print text + " row %d + col %d"%(row, col) ws.write(row, col, text) def perf_func(elem, func, level = 0): global g_row func(elem, g_row, level) for child in list(elem): name = child.get('TEXT') perf_func(child, func, level + 1) if child.find('node') is None and name is not None: g_row = g_row + 1def write_excel(elem, row, level): name = elem.get('TEXT') if name is not None: do_write_excel(name, row, level)parser = argparse.ArgumentParser()parser.add_argument('-i', '--input-file', type=str, dest='inputfile', required=True)parser.add_argument('-o', '--output-file', type=str, dest='outputfile', default='freemind2excel.xls', help='Default outputfile is freemind2excel.xls')args = parser.parse_args()if args.inputfile is None: parser.print_help() exit()root = ET.parse(args.inputfile)map_version = root.getroot()first_node = map_version.find('node')wb = xlwt.Workbook()ws = wb.add_sheet('freemind2excel')perf_func(first_node, write_excel)wb.save(args.outputfile) 运行结果： 123456789sunnogo@DESKTOP-VM2TU8I:~/workshop/xmind2excel$ ./xmind2excel.pyusage: xmind2excel.py [-h] -i INPUTFILE [-o OUTPUTFILE]xmind2excel.py: error: argument -i/--input-file is requiredsunnogo@DESKTOP-VM2TU8I:~/workshop/xmind2excel$ ./xmind2excel.py -i project_plan.mmsunnogo@DESKTOP-VM2TU8I:~/workshop/xmind2excel$ ls *.xlsfreemind2excel.xlssunnogo@DESKTOP-VM2TU8I:~/workshop/xmind2excel$ ./xmind2excel.py -i project_plan.mm -o test.xlssunnogo@DESKTOP-VM2TU8I:~/workshop/xmind2excel$ ls *.xlsfreemind2excel.xls test.xls]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows 通过 vnc4server 远程 ubuntu]]></title>
    <url>%2F201704%2Flinux%2Fvnc4server.html</url>
    <content type="text"><![CDATA[程序安装与配置运行linode 有一篇详尽的文章：Install VNC on Ubuntu 16.04。 ubuntu 安装 vnc4server，sudo apt-get install vnc4server 运行 vncpasswd，配置密码，密码至少6个字符，至多8个字符 运行 vnc4server :1，启动 vnc server。可通过 vnc4server -kill :1 关闭 vnc server。 windows chrome 安装 vnc viewer 插件 通过 ip:5901 远程登陆，默认使用 x-terminal-emulator &amp; x-window-manager 界面。 配置使用 gnome 界面，参考链接 安装包，sudo apt-get install gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal 修改配置文件 ~/.vnc/xstartup logvnc4server 配置与运行1234567891011121314sunyongfeng@openswitch-OptiPlex-380:~$ vncpasswd Password:Verify:sunyongfeng@openswitch-OptiPlex-380:~$ sunyongfeng@openswitch-OptiPlex-380:~$ vncserver :1New 'openswitch-OptiPlex-380:1 (sunyongfeng)' desktop is openswitch-OptiPlex-380:1Starting applications specified in /home/sunyongfeng/.vnc/xstartupLog file is /home/sunyongfeng/.vnc/openswitch-OptiPlex-380:1.logsunyongfeng@openswitch-OptiPlex-380:~$ sunyongfeng@openswitch-OptiPlex-380:~$ vncserver -kill :1Killing Xvnc4 process ID 2788 配置支持 gnome 界面1234567891011121314151617181920sunyongfeng@openswitch-OptiPlex-380:~$ cat .vnc/xstartup #!/bin/sh# Uncomment the following two lines for normal desktop:# unset SESSION_MANAGER# exec /etc/X11/xinit/xinitrc[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresourcesxsetroot -solid greyvncconfig -iconic &amp;#x-terminal-emulator -geometry 80x24+10+10 -ls -title "$VNCDESKTOP Desktop" &amp;#x-window-manager &amp;gnome-panel &amp;gnome-settings-daemon &amp;metacity &amp;nautilus &amp;gnome-terminal &amp;sunyongfeng@openswitch-OptiPlex-380:~$ Screenshotchrome 插件 插件 输入 IP &amp; 端口号 输入密码 xwindow 界面 gnome 界面]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>远程登录</tag>
        <tag>vnc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 快速入门]]></title>
    <url>%2F201704%2Fprogrammer%2Fdocker%2Fquickstart.html</url>
    <content type="text"><![CDATA[安装 docker一键安装 docker：wget -qO- https://get.docker.com/ | sh。 基本操作 运行容器，docker run 有多种选项。docker run -d --net=host --privileged -t -v workshop:/workshop --name jerome debian:jessie bash -v 选项，将 host 目录挂载到 docker 容器系统中 --name your_name，为运行的容器命名，相信直接操作名字总比操作一串数字方便、可用 查看运行中的容器，docker ps 容器退出后，还会缓存在系统中， 查看缓存，docker ps -a 运行缓存，docker start jerome， 删除缓存，docker rm jerome 进入容器 shell 命令行，docker exec -it jerome bash，不会像 docker attach 进去退出后，直接将在跑的 docker 实例退出来。 怕误操作导致缓存丢失？那就提交一下，docker commit jerome debian:jessie_jerome 查看本地镜像，docker images 重命名镜像，docker tag image-id REPOSITORY[:TAG] 复制文件到容器中，docker cp abc jerome:/ or docker cp jerome:/abc host_dir/abc 清除 images, docker rmi， -f 强制清除，如果碰到这种 log，Error response from daemon: conflict: unable to delete b3370fb9c34a (must be forced) - image is being used by stopped container a1e524588570，带 -f 选项清除 docker rmi -f $(docker images -f &quot;dangling=true&quot; -q)，删除 :，没有 tag 的 image docker rmi -f $(docker images &quot;your_image_name*&quot; -q)，删除以 “your_image_name” 开头的所有 image 进入正在运行的容器命令行样例： 123456789sunyongfeng@openswitch-OptiPlex-380:~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESdab2267a06dd p4dockerswitch_bmv2 "/bin/bash" About a minute ago Up About a minute elastic_morsesunyongfeng@openswitch-OptiPlex-380:~$ docker exec -i -t dab2267a06dd /bin/bashroot@dab2267a06dd:/# root@dab2267a06dd:/# lsbin dev home lib64 mnt nanomsg-1.0.0.tar.gz opt proc run srv third-party thrift-0.9.2.tar.gz usrboot etc lib media nanomsg-1.0.0 nnpy p4factory root sbin sys thrift-0.9.2 tmp varroot@dab2267a06dd:/# docker 使用中国源见 https://www.docker-cn.com/registry-mirror 方法1： 1$ docker pull registry.docker-cn.com/library/ubuntu:16.04 方法2：拉取的时候加参数 --registry-mirror=https://registry.docker-cn.com 方法3：默认配置，需要重启 docker 服务才能生效 为了永久性保留更改，您可以修改 /etc/docker/daemon.json 文件并添加上 registry-mirrors 键值。 123&#123; "registry-mirrors": ["https://registry.docker-cn.com"]&#125; 修改保存后重启 Docker 以使配置生效。 本地 repo详见 https://docs.docker.com/registry/，参考 https://www.jianshu.com/p/fc544e27b507。 docker 命令没有权限必须 sudo docker xxx？ 见 使用docker第一步: 本指南假设你已经完成了Docker的安装工作。检查你安装的Docker,运行以下命令： 12# Check that you have a working install$ docker info 如果你得到 docker: command not found，你可能没有完整的安装上Docker。如果你得到 /var/lib/docker/repositories: permission denied，那你可能没有权限访问你主机上的Docker。 为获得访问Docker权限可以直接在命令前加sudo，或者采取以下步骤授予权限：： 123456# 如果还没有docker group就添加一个：$ sudo groupadd docker# 将用户加入该group内。然后退出并重新登录即可生效。$ sudo gpasswd -a $&#123;USER&#125; docker# 重启docker$ sudo service docker restart docker 空间不足配置 docker 的 basesize。 1234567sudo systemctl stop docker/etc/docker/daemon.json&#123; "storage-driver": "devicemapper"&#125;sudo dockerd --storage-opt dm.basesize=50Gsudo systemctl start docker 修改 docker storage driver 为 aufsubuntu 16.04 默认为 overlay2，但是目前在用的 sonic 不支持，因此只能回退为 aufs。可通过 docker info 命令查看，其中有一句为： 1Storage Driver: overlay2 ubuntu 16.04 如何支持 aufs？详见 Use the AUFS storage driver。 查看本机 docker storage driver 是否为 aufs，docker info， 备份 docker 数据，sudo cp /var/lib/docker /var/lib/docker.bak 停止 docker 服务，sudo service docker stop 确认系统是否支持 aufs，grep aufs /proc/filesystem 如果系统不支持 aufs，安装依赖包，sudo apt-get install linux-image-extra-$(uname -r) linux-image-extra-virtual 加载 aufs 内核模块，sudo modprobe aufs 配置 docker 启动参数，依赖 /etc/docker/daemon.json 为以下内容。 启动 docker 服务，sudo service docker start 确认 docker storage driver 已改为 aufs，docker info /etc/docker/daemon.json 内容： 123&#123; "storage-driver": "aufs" &#125; docker 提示 daemon 未运行提示如下： 12$ docker psCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? 找 docker log 看原因，原因为 /etc/docker/daemon.json 的配置文件有问题 123$ vi /var/log/docker.logunable to configure the Docker daemon with file /etc/docker/daemon.json: invalid character 'r' looking for beginning of object key string 查看配置文件： 12$ cat /etc/docker/daemon.json &#123;registry-mirrors: [https://registry.docker-cn.com]&#125; 正确的配置文件对比发现，配置的 field 和 value 都要有双引号 12345&#123; "storage-driver": "aufs", "experimental": true, "registry-mirrors": ["https://registry.docker-cn.com"]&#125; 为什么我的配置文件没有双引号？查看 Dockerfile: 12RUN echo "DOCKER_OPTS=\"--experimental\"" &gt;&gt; /etc/default/dockerRUN mkdir /etc/docker &amp;&amp; echo "&#123;"registry-mirrors": ["https://registry.docker-cn.com"]&#125;" &gt;&gt; /etc/docker/daemon.json 正确的写法如下，echo 的用法整错了。 12RUN echo "DOCKER_OPTS=\"--experimental\"" &gt;&gt; /etc/default/dockerRUN mkdir /etc/docker &amp;&amp; echo "&#123;\"registry-mirrors\": [\"https://registry.docker-cn.com\"]&#125;" &gt;&gt; /etc/docker/daemon.json echo 样例： 1234~$ echo "&#123;"registry-mirrors": ["https://registry.docker-cn.com"]&#125;" &#123;registry-mirrors: [https://registry.docker-cn.com]&#125;~$ echo "&#123;\"registry-mirrors\": [\"https://registry.docker-cn.com\"]&#125;"&#123;"registry-mirrors": ["https://registry.docker-cn.com"]&#125; Dockerfile 中找不到对应路径的文件见 https://stackoverflow.com/questions/48126926/unable-to-locate-file-in-docker-container: 先通过 COPY 把文件拷贝到 docker 容器中的路径 使用时使用 docker 容器中的路径 即 docker build 时，RUN 时使用的路径，是 docker 容器中的路径。 持续集成编译时出现 ‘the input device is not a TTY’原因: 持续集成环境没有以 tty 形式进行编译，需要把 docker run 的 -t 选项删除。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux升级内核后 docker 不可用]]></title>
    <url>%2F201704%2Flinux%2Fdocker_failed_after_update_kernel.html</url>
    <content type="text"><![CDATA[问题描述因开发需求，降级 ubuntu 16.04 内核版本 4.4.0 为 3.19，之后 docker 启机失败。 问题 log通过 sudo systemctl status docker.service 查看 docker 启动信息发现，docker 因 aufs 驱动问题无法正常启动。 log: 123456789101112131415161718192021222324sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ sudo service docker startJob for docker.service failed because the control process exited with error code. See "systemctl status docker.service" and "journalctl -xe" for details.sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ sudo systemctl status docker.service● docker.service - Docker Application Container Engine Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since 二 2017-04-18 16:38:26 CST; 9s ago Docs: https://docs.docker.com Process: 3058 ExecStart=/usr/bin/dockerd -H fd:// (code=exited, status=1/FAILURE) Main PID: 3058 (code=exited, status=1/FAILURE)4月 18 16:38:25 openswitch-OptiPlex-380 systemd[1]: Starting Docker Application Container Engine...4月 18 16:38:25 openswitch-OptiPlex-380 dockerd[3058]: time="2017-04-18T16:38:25.914144290+08:00" level=info msg="libcontainerd: new containerd process, pid: 3064"4月 18 16:38:26 openswitch-OptiPlex-380 dockerd[3058]: time="2017-04-18T16:38:26.962727971+08:00" level=error msg="[graphdriver] prior storage driver \"aufs\" failed:4月 18 16:38:26 openswitch-OptiPlex-380 dockerd[3058]: time="2017-04-18T16:38:26.962806596+08:00" level=fatal msg="Error starting daemon: error initializing graphdriv4月 18 16:38:26 openswitch-OptiPlex-380 systemd[1]: docker.service: Main process exited, code=exited, status=1/FAILURE4月 18 16:38:26 openswitch-OptiPlex-380 systemd[1]: Failed to start Docker Application Container Engine.4月 18 16:38:26 openswitch-OptiPlex-380 systemd[1]: docker.service: Unit entered failed state.4月 18 16:38:26 openswitch-OptiPlex-380 systemd[1]: docker.service: Failed with result 'exit-code'.sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ sudo systemctl start dockerJob for docker.service failed because the control process exited with error code. See "systemctl status docker.service" and "journalctl -xe" for details.sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ docker --versionDocker version 1.12.3, build 6b644ec 问题解决见 prior storage driver “aufs” failed: driver not supported Error starting daemon: error initializing graphdriver: driver not supported 中 Sergey Podobry 的答复： Try removing all downloaded images sudo rm -rf /var/lib/docker/aufs That helped me to recover docker after a kernel update. Related issues on the github: https://github.com/docker/docker/issues/14026 https://github.com/docker/docker/issues/15651 本文通过备份的形式，重启 PC 后，docker 可正常运行。 123456789sunyongfeng@openswitch-OptiPlex-380:/var/lib$ sudo mv /var/lib/docker /var/lib/docker.old [sudo] password for sunyongfeng: sunyongfeng@openswitch-OptiPlex-380:/var/lib$ sudo shutdown -r 0...sunyongfeng@openswitch-OptiPlex-380:~$ ps -e | grep docker 717 ? 00:00:00 dockerd 796 ? 00:00:00 docker-containesunyongfeng@openswitch-OptiPlex-380:~$]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跑通 p4factory app int]]></title>
    <url>%2F201704%2Fnetworks%2Fp4%2Fdemo_int.html</url>
    <content type="text"><![CDATA[运行环境ubuntu 16.04 + linux kernel 3.19 步骤详见： app/int/readme p4factory readme switch readme 问题 fix 见下文。 运行成功图示 执行 int_ref_topology.py iperf 打流 webui - 拓扑 webui - flows webui - 时延 webui - notification 问题解决记录内核版本切换为 3.19目前 vxlan-gpe 的内核模块基于内核 3.19，而目前常用 Linux 发行版的内核版本都在 4.2 以上，不切换则编译不过。更好的办法是，直接使用内核版本为 3.19 的 Linux 发行版。 详见 p4factory issue 136用于支持内核版本 3.19。详见另一篇文章 ubuntu 用回旧版内核 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/apps/int/vxlan-gpe$ makemake -C /lib/modules/4.4.0-72-generic/build M=/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe modulesmake[1]: Entering directory '/usr/src/linux-headers-4.4.0-72-generic' CC [M] /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.o/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:94:7: error: redefinition of ‘union vxlan_addr’ union vxlan_addr &#123; ^In file included from /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:44:0:include/net/vxlan.h:119:7: note: originally defined here union vxlan_addr &#123; ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:100:8: error: redefinition of ‘struct vxlan_rdst’ struct vxlan_rdst &#123; ^In file included from /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:44:0:include/net/vxlan.h:125:8: note: originally defined here struct vxlan_rdst &#123; ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:122:8: error: redefinition of ‘struct vxlan_dev’ struct vxlan_dev &#123; ^In file included from /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:44:0:include/net/vxlan.h:152:8: note: originally defined here struct vxlan_dev &#123; ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c: In function ‘vxlan_fdb_info’:/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:423:9: error: void value not ignored as it ought to be return nlmsg_end(skb, nlh); ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c: In function ‘vxlan_udp_encap_recv’:/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1255:4: error: ‘struct vxlan_sock’ has no member named ‘rcv’ vs-&gt;rcv(vs, skb, vxh-&gt;vx_vni); ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c: In function ‘vxlan6_xmit_skb’:/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1681:7: error: implicit declaration of function ‘vlan_tx_tag_present’ [-Werror=implicit-function-declaration] + (vlan_tx_tag_present(skb) ? VLAN_HLEN : 0); ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1708:23: warning:passing argument 1 of ‘udp_tunnel6_xmit_skb’ from incompatible pointer type [-Wincompatible-pointer-types] udp_tunnel6_xmit_skb(vs-&gt;sock, dst, skb, dev, saddr, daddr, prio, ^In file included from /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:37:0:include/net/udp_tunnel.h:87:5: note: expected ‘struct dst_entry *’ but argument is of type ‘struct socket *’ int udp_tunnel6_xmit_skb(struct dst_entry *dst, struct sock *sk, ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1708:33: warning:passing argument 2 of ‘udp_tunnel6_xmit_skb’ from incompatible pointer type [-Wincompatible-pointer-types] udp_tunnel6_xmit_skb(vs-&gt;sock, dst, skb, dev, saddr, daddr, prio, ^In file included from /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:37:0:include/net/udp_tunnel.h:87:5: note: expected ‘struct sock *’ but argument is of type ‘struct dst_entry *’ int udp_tunnel6_xmit_skb(struct dst_entry *dst, struct sock *sk, ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1708:2: error: too few arguments to function ‘udp_tunnel6_xmit_skb’ udp_tunnel6_xmit_skb(vs-&gt;sock, dst, skb, dev, saddr, daddr, prio, ^In file included from /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:37:0:include/net/udp_tunnel.h:87:5: note: declared here int udp_tunnel6_xmit_skb(struct dst_entry *dst, struct sock *sk, ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c: In function ‘vxlan_xmit_skb’:/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1787:29: warning:passing argument 1 of ‘udp_tunnel_xmit_skb’ from incompatible pointer type [-Wincompatible-pointer-types] return udp_tunnel_xmit_skb(vs-&gt;sock, rt, skb, src, dst, tos, ^In file included from /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:37:0:include/net/udp_tunnel.h:81:5: note: expected ‘struct rtable *’ but argument is of type ‘struct socket *’ int udp_tunnel_xmit_skb(struct rtable *rt, struct sock *sk, struct sk_buff *skb, ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1787:39: warning:passing argument 2 of ‘udp_tunnel_xmit_skb’ from incompatible pointer type [-Wincompatible-pointer-types] return udp_tunnel_xmit_skb(vs-&gt;sock, rt, skb, src, dst, tos, ^In file included from /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:37:0:include/net/udp_tunnel.h:81:5: note: expected ‘struct sock *’ but argument is of type ‘struct rtable *’ int udp_tunnel_xmit_skb(struct rtable *rt, struct sock *sk, struct sk_buff *skb, ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1787:9: error: too few arguments to function ‘udp_tunnel_xmit_skb’ return udp_tunnel_xmit_skb(vs-&gt;sock, rt, skb, src, dst, tos, ^In file included from /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:37:0:include/net/udp_tunnel.h:81:5: note: declared here int udp_tunnel_xmit_skb(struct rtable *rt, struct sock *sk, struct sk_buff *skb, ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c: In function ‘vxlan_xmit_one’:/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1941:34: warning:passing argument 1 of ‘ipv6_stub-&gt;ipv6_dst_lookup’ from incompatible pointer type [-Wincompatible-pointer-types] if (ipv6_stub-&gt;ipv6_dst_lookup(sk, &amp;ndst, &amp;fl6)) &#123; ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1941:34: note: expected ‘struct net *’ but argument is of type ‘struct sock *’/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1941:38: warning:passing argument 2 of ‘ipv6_stub-&gt;ipv6_dst_lookup’ from incompatible pointer type [-Wincompatible-pointer-types] if (ipv6_stub-&gt;ipv6_dst_lookup(sk, &amp;ndst, &amp;fl6)) &#123; ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1941:38: note: expected ‘struct sock *’ but argument is of type ‘struct dst_entry **’/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1941:45: warning:passing argument 3 of ‘ipv6_stub-&gt;ipv6_dst_lookup’ from incompatible pointer type [-Wincompatible-pointer-types] if (ipv6_stub-&gt;ipv6_dst_lookup(sk, &amp;ndst, &amp;fl6)) &#123; ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1941:45: note: expected ‘struct dst_entry **’ but argument is of type ‘struct flowi6 *’/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1941:7: error: too few arguments to function ‘ipv6_stub-&gt;ipv6_dst_lookup’ if (ipv6_stub-&gt;ipv6_dst_lookup(sk, &amp;ndst, &amp;fl6)) &#123; ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c: At top level:/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:2468:12: error: unknown type name ‘vxlan_rcv_t’ vxlan_rcv_t *rcv, void *data, ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:2520:7: error: unknown type name ‘vxlan_rcv_t’ vxlan_rcv_t *rcv, void *data, ^In file included from include/linux/linkage.h:6:0, from include/linux/kernel.h:6, from /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:14:/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:2546:19: error: ‘vxlan_sock_add’ undeclared here (not in a function) EXPORT_SYMBOL_GPL(vxlan_sock_add); ^include/linux/export.h:57:16: note: in definition of macro ‘__EXPORT_SYMBOL’ extern typeof(sym) sym; \ ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:2546:1: note: in expansion of macro ‘EXPORT_SYMBOL_GPL’ EXPORT_SYMBOL_GPL(vxlan_sock_add); ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c: In function ‘vxlan_sock_work’:/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:2557:8: error: called object ‘vxlan_sock_add’ is not a function or function pointer nvs = vxlan_sock_add(net, port, vxlan_rcv, NULL, false, vxlan-&gt;flags); ^In file included from include/linux/linkage.h:6:0, from include/linux/kernel.h:6, from /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:14:/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:2546:19: note: declared here EXPORT_SYMBOL_GPL(vxlan_sock_add); ^include/linux/export.h:57:21: note: in definition of macro ‘__EXPORT_SYMBOL’ extern typeof(sym) sym; \ ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:2546:1: note: in expansion of macro ‘EXPORT_SYMBOL_GPL’ EXPORT_SYMBOL_GPL(vxlan_sock_add); ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c: At top level:/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:604:25: warning: vxlan_gro_receive’ defined but not used [-Wunused-function] static struct sk_buff **vxlan_gro_receive(struct sk_buff **head, struct sk_buff * ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:669:12: warning: vxlan_gro_complete’ defined but not used [-Wunused-function] static int vxlan_gro_complete(struct sk_buff *skb, int nhoff) ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:692:13: warning: vxlan_notify_add_rx_port’ defined but not used [-Wunused-function] static void vxlan_notify_add_rx_port(struct vxlan_sock *vs) ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1219:12: warning:‘vxlan_udp_encap_recv’ defined but not used [-Wunused-function] static int vxlan_udp_encap_recv(struct sock *sk, struct sk_buff *skb) ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:2427:13: warning:‘vxlan_del_work’ defined but not used [-Wunused-function] static void vxlan_del_work(struct work_struct *work) ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:2434:23: warning:‘vxlan_create_sock’ defined but not used [-Wunused-function] static struct socket *vxlan_create_sock(struct net *net, bool ipv6, ^/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c: In function ‘vxlan_xmit_skb’:/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.c:1789:1: warning: control reaches end of non-void function [-Wreturn-type] &#125; ^cc1: some warnings being treated as errorsscripts/Makefile.build:264: recipe for target '/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.o' failedmake[2]: *** [/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/vxlan.o] Error 1Makefile:1420: recipe for target '_module_/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe' failedmake[1]: *** [_module_/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe] Error 2make[1]: Leaving directory '/usr/src/linux-headers-4.4.0-72-generic'Makefile:4: recipe for target 'all' failedmake: *** [all] Error 2sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/apps/int/vxlan-gpe$ make cleanmake -C /lib/modules/4.4.0-72-generic/build M=/home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe cleanmake[1]: Entering directory '/usr/src/linux-headers-4.4.0-72-generic' CLEAN /home/sunyongfeng/workshop/p4factory/apps/int/vxlan-gpe/.tmp_versionsmake[1]: Leaving directory '/usr/src/linux-headers-4.4.0-72-generic'sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/apps/int/vxlan-gpe$ 解决 Linux 内核到 3.19 后，docker 无法运行详见另一篇文章 Linux升级内核后 docker 不可用 123456789101112131415161718192021222324sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ sudo service docker startJob for docker.service failed because the control process exited with error code. See "systemctl status docker.service" and "journalctl -xe" for details.sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ sudo systemctl status docker.service● docker.service - Docker Application Container Engine Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) Active: failed (Result: exit-code) since 二 2017-04-18 16:38:26 CST; 9s ago Docs: https://docs.docker.com Process: 3058 ExecStart=/usr/bin/dockerd -H fd:// (code=exited, status=1/FAILURE) Main PID: 3058 (code=exited, status=1/FAILURE)4月 18 16:38:25 openswitch-OptiPlex-380 systemd[1]: Starting Docker Application Container Engine...4月 18 16:38:25 openswitch-OptiPlex-380 dockerd[3058]: time="2017-04-18T16:38:25.914144290+08:00" level=info msg="libcontainerd: new containerd process, pid: 3064"4月 18 16:38:26 openswitch-OptiPlex-380 dockerd[3058]: time="2017-04-18T16:38:26.962727971+08:00" level=error msg="[graphdriver] prior storage driver \"aufs\" failed:4月 18 16:38:26 openswitch-OptiPlex-380 dockerd[3058]: time="2017-04-18T16:38:26.962806596+08:00" level=fatal msg="Error starting daemon: error initializing graphdriv4月 18 16:38:26 openswitch-OptiPlex-380 systemd[1]: docker.service: Main process exited, code=exited, status=1/FAILURE4月 18 16:38:26 openswitch-OptiPlex-380 systemd[1]: Failed to start Docker Application Container Engine.4月 18 16:38:26 openswitch-OptiPlex-380 systemd[1]: docker.service: Unit entered failed state.4月 18 16:38:26 openswitch-OptiPlex-380 systemd[1]: docker.service: Failed with result 'exit-code'.sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ sudo systemctl start dockerJob for docker.service failed because the control process exited with error code. See "systemctl status docker.service" and "journalctl -xe" for details.sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/makefiles$ docker --versionDocker version 1.12.3, build 6b644ec 解决 int_ref_topology.py 失败问题docker_node.py 运行失败详见 p4factory issue 193 执行 mininet 起 docker 起不来。解决: replace : start = int(line) to start = int(line.strip()) # strip will chop the &#39;\n&#39; 1234567891011121314151617181920212223sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/mininet$ sudo ./int_ref_topology.py --model-dir=$P4HOME/install Adding switch spine1Traceback (most recent call last): File "./int_ref_topology.py", line 131, in &lt;module&gt; run_cfg(model_dir) File "./int_ref_topology.py", line 91, in run_cfg net = mgr.setupAndStartNetwork() File "/home/sunyongfeng/workshop/p4factory/mininet/int_cfg.py", line 140, in setupAndStartNetwork self.addSwitches() File "/home/sunyongfeng/workshop/p4factory/mininet/int_cfg.py", line 177, in addSwitches pps = s.pps, qdepth = s.qdepth ) File "/usr/lib/python2.7/dist-packages/mininet/net.py", line 240, in addSwitch sw = cls( name, **defaults ) File "/home/sunyongfeng/workshop/p4factory/mininet/docker/p4model.py", line 55, in __init__ DockerSwitch.__init__( self, name, **kwargs ) File "/home/sunyongfeng/workshop/p4factory/mininet/docker/docker_node.py", line 30, in __init__ Node.__init__( self, name, **kwargs ) File "/usr/lib/python2.7/dist-packages/mininet/node.py", line 106, in __init__ self.startShell() File "/home/sunyongfeng/workshop/p4factory/mininet/docker/docker_node.py", line 119, in startShell self.pid = int(ps_out[0])ValueError: invalid literal for int() with base 10: "'21431'\n"sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/mininet$ ps_out 的结果 [&quot;&#39;22326&#39;\n&quot;]，因此 L119 应改为： 1self.pid = int((ps_out[0].strip()).strip('\'')) 链接：Python strip() 方法用于移除字符串头尾指定的字符（默认为空格）。 解决 docker 内 bmv2 无法运行的问题非必需。 原因：ubuntu 16.04 默认 gcc 版为 5.4.0，而 bmv2 docker ubuntu 版本为 14.04，其默认 gcc 为 4.8。因此升级 docker 中的 ubuntu 版本为 16.04 1234567891011121314151617181920212223242526272829303132333435sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/mininet$ sudo ./int_ref_topology.py --model-dir=$P4HOME/install Adding switch spine1Adding switch spine2Adding switch leaf1Adding switch leaf2Waiting 10 seconds for switches to intialize...INT Config spine1Traceback (most recent call last): File "./int_ref_topology.py", line 131, in &lt;module&gt; run_cfg(model_dir) File "./int_ref_topology.py", line 91, in run_cfg net = mgr.setupAndStartNetwork() File "/home/sunyongfeng/workshop/p4factory/mininet/int_cfg.py", line 147, in setupAndStartNetwork self.configSwitches() File "/home/sunyongfeng/workshop/p4factory/mininet/int_cfg.py", line 237, in configSwitches self.configSwitch(s) File "/home/sunyongfeng/workshop/p4factory/mininet/int_cfg.py", line 251, in configSwitch client.switcht_api_init( device ) File "/home/sunyongfeng/workshop/p4factory/submodules/switch/switchapi/switch_api_thrift/switch_api_rpc.py", line 1565, in switcht_api_init return self.recv_switcht_api_init() File "/home/sunyongfeng/workshop/p4factory/submodules/switch/switchapi/switch_api_thrift/switch_api_rpc.py", line 1577, in recv_switcht_api_init (fname, mtype, rseqid) = iprot.readMessageBegin() File "/usr/local/lib/python2.7/dist-packages/thrift/protocol/TBinaryProtocol.py", line 134, in readMessageBegin sz = self.readI32() File "/usr/local/lib/python2.7/dist-packages/thrift/protocol/TBinaryProtocol.py", line 217, in readI32 buff = self.trans.readAll(4) File "/usr/local/lib/python2.7/dist-packages/thrift/transport/TTransport.py", line 60, in readAll chunk = self.read(sz - have) File "/usr/local/lib/python2.7/dist-packages/thrift/transport/TTransport.py", line 161, in read self.__rbuf = BufferIO(self.__trans.read(max(sz, self.__rbuf_size))) File "/usr/local/lib/python2.7/dist-packages/thrift/transport/TSocket.py", line 117, in read buff = self.handle.recv(sz)socket.error: [Errno 104] Connection reset by peersunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/mininet$ 根本原因为工具链问题，gcc 版本不一致。 12345678910111213141516171819202122232425sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/mininet$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES50b20ec98aac p4dockerswitch_bmv2 "/bin/sh -c /bin/bash" 47 seconds ago Up 45 seconds 0.0.0.0:26001-&gt;9091/tcp, 0.0.0.0:27001-&gt;10001/tcp leaf2d04a024c559e p4dockerswitch_bmv2 "/bin/sh -c /bin/bash" 48 seconds ago Up 46 seconds 0.0.0.0:26000-&gt;9091/tcp, 0.0.0.0:27000-&gt;10001/tcp leaf14678cbfe6b2b p4dockerswitch_bmv2 "/bin/sh -c /bin/bash" 49 seconds ago Up 47 seconds 0.0.0.0:26003-&gt;9091/tcp, 0.0.0.0:27003-&gt;10001/tcp spine2701da5748dc9 p4dockerswitch_bmv2 "/bin/sh -c /bin/bash" 50 seconds ago Up 48 seconds 0.0.0.0:26002-&gt;9091/tcp, 0.0.0.0:27002-&gt;10001/tcp spine1sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory/mininet$ docker attach 701da5748dc9bin dev lib mnt nnpy proc sbin third-party tmpboot etc lib64 nanomsg-1.0.0 opt root srv thrift-0.9.2 usrconfigs home media nanomsg-1.0.0.tar.gz p4factory run sys thrift-0.9.2.tar.gz varbmv2_driver.log bmv2_model.log start.shcat: /tmp/dmvdr: No such file or directorybin dev lib mnt nnpy proc sbin third-party tmpboot etc lib64 nanomsg-1.0.0 opt root srv thrift-0.9.2 usrconfigs home media nanomsg-1.0.0.tar.gz p4factory run sys thrift-0.9.2.tar.gz varbmv2_driver.log bmv2_model.log start.sh/home/sunyongfeng/workshop/p4/install/bin/bmswitchp4_drivers: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /home/sunyongfeng/workshop/p4/install/lib/bmpd/switch/libpd.so.0)/home/sunyongfeng/workshop/p4/install/bin/bmswitchp4_drivers: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/sunyongfeng/workshop/p4/install/lib/bmpd/switch/libpd.so.0)/home/sunyongfeng/workshop/p4/install/bin/bmswitchp4_drivers: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /home/sunyongfeng/workshop/p4/install/lib/bmpd/switch/libpd.so.0)/home/sunyongfeng/workshop/p4/install/bin/bmswitchp4_drivers: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /home/sunyongfeng/workshop/p4/install/lib/bmpd/switch/libpdthrift.so.0)/home/sunyongfeng/workshop/p4/install/bin/bmswitchp4_drivers: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /home/sunyongfeng/workshop/p4/install/lib/libbmpdfixed.so.0)/home/sunyongfeng/workshop/p4/install/bin/bmswitchp4_drivers: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /home/sunyongfeng/workshop/p4/install/lib/libbmpdfixedthrift.so.0)/home/sunyongfeng/workshop/p4/install/bin/bmswitchp4_drivers: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /home/sunyongfeng/workshop/p4/install/lib/libruntimestubs.so.0)/home/sunyongfeng/workshop/p4/install/bin/bmswitchp4_drivers: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /home/sunyongfeng/workshop/p4/install/lib/libsimpleswitch_thrift.so.0)/home/sunyongfeng/workshop/p4/install/bin/simple_switch: error while loading shared libraries: libboost_system.so.1.58.0: cannot open shared object file: No such file or directory 更新后的 Dockerfile patch: 1234567891011121314151617181920212223242526272829diff --git a/docker/Dockerfile b/docker/Dockerfileold mode 100644new mode 100755index 42c87af..e9003fc--- a/docker/Dockerfile+++ b/docker/Dockerfile@@ -1,4 +1,4 @@-FROM ubuntu:14.04+FROM ubuntu:16.04 MAINTAINER Antonin Bas &lt;antonin@barefootnetworks.com&gt; RUN apt-get update@@ -41,7 +41,6 @@ RUN apt-get install -y \ redis-server \ redis-tools \ subversion \- tshark \ xterm RUN pip install tenjin@@ -84,7 +83,7 @@ RUN mkdir -p /tmp/install_tmp ; \ wget -c http://archive.apache.org/dist/thrift/0.9.2/thrift-0.9.2.tar.gz ; \ tar zxvf thrift-0.9.2.tar.gz ; \ cd thrift-0.9.2 ; \- ./configure --with-cpp=yes --with-c_glib=no --with-java=no --with-ruby=no --with-erlang=no --with-go=no --with-nodejs=no ; \+ ./configure ; \ make -j4 ; \ make install ; \ ldconfig ; \ DockerFile 解决 tshark 卡在 yes/noDockerFile 的改造，tshark 无法直接配置通过，卡在 yes/no。详见上一小节 Dockerfile，先不安装 tshark，等 bmv2 docker image 打好后，再进去安装、重新 commit docker image。 在 docker 内使用 simple_switch_CLI非必需，仅用于确认表项是否正常下发。 leaf/spine docker 内无法使用 simple_switch_CLI： 改 Dockerfile 的 thrift 配置为默认配置，不简化 docker 内的 thrift 在 docker 内通过 pip 安装 thrift，pip install --upgrade thrift 通过命令访问 simple_switch_CLI，/home/sunyongfeng/workshop/p4/install/bin/simple_switch_CLI --json /home/sunyongfeng/workshop/p4/install/share/bmpd/switch/switch.json --thrift-port 10001 没有安装好 thrift 的问题： 1234567891011root@leaf1:/home/sunyongfeng# /home/sunyongfeng/workshop/p4/install/bin/simple_switch_CLITraceback (most recent call last): File "/home/sunyongfeng/workshop/p4/install/bin/simple_switch_CLI", line 30, in &lt;module&gt; import sswitch_CLI File "/home/sunyongfeng/workshop/p4/install/lib/python2.7/site-packages/sswitch_CLI.py", line 23, in &lt;module&gt; import runtime_CLI File "/home/sunyongfeng/workshop/p4/install/lib/python2.7/site-packages/runtime_CLI.py", line 30, in &lt;module&gt; import bmpy_utils as utils File "/home/sunyongfeng/workshop/p4/install/lib/python2.7/site-packages/bmpy_utils.py", line 30, in &lt;module&gt; from thrift.protocol import TMultiplexedProtocolImportError: cannot import name TMultiplexedProtocol 一开始不知道 simple_switch thrift 开放的端口是多少，通过 netstat -anp 确认为 10001。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849root@leaf1:/# /home/sunyongfeng/workshop/p4/install/bin/simple_switch_CLI --json /home/sunyongfeng/workshop/p4/install/share/bmpd/switch/switch.json Error when requesting config md5 sum from switchroot@leaf1:/# netstat -anp Active Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:9090 0.0.0.0:* LISTEN 81/bmswitchp4_drivetcp 0 0 0.0.0.0:9091 0.0.0.0:* LISTEN 81/bmswitchp4_drivetcp 0 0 0.0.0.0:9092 0.0.0.0:* LISTEN 81/bmswitchp4_drivetcp 0 0 127.0.0.1:2601 0.0.0.0:* LISTEN 114/zebra tcp 0 0 127.0.0.1:2605 0.0.0.0:* LISTEN 118/bgpd tcp 0 0 0.0.0.0:10001 0.0.0.0:* LISTEN 67/simple_switchtcp 0 0 0.0.0.0:179 0.0.0.0:* LISTEN 118/bgpd tcp 0 0 127.0.0.1:10001 127.0.0.1:40983 ESTABLISHED 67/simple_switchtcp 0 0 127.0.0.1:40984 127.0.0.1:10001 ESTABLISHED 81/bmswitchp4_drivetcp 0 0 127.0.0.1:10001 127.0.0.1:40985 ESTABLISHED 67/simple_switchtcp 0 0 127.0.0.1:10001 127.0.0.1:40984 ESTABLISHED 67/simple_switchtcp 0 0 127.0.0.1:40983 127.0.0.1:10001 ESTABLISHED 81/bmswitchp4_drivetcp 0 0 127.0.0.1:9090 127.0.0.1:46833 TIME_WAIT - tcp 0 0 127.0.0.1:40985 127.0.0.1:10001 ESTABLISHED 81/bmswitchp4_drivetcp 0 0 127.0.0.1:9090 127.0.0.1:46829 TIME_WAIT - tcp6 0 0 :::179 :::* LISTEN 118/bgpd raw6 0 0 :::58 :::* 7 114/zebra Active UNIX domain sockets (servers and established)Proto RefCnt Flags Type State I-Node PID/Program name Pathunix 2 [ ACC ] STREAM LISTENING 576586 118/bgpd /var/run/quagga/bgpd.vtyunix 2 [ ACC ] STREAM LISTENING 575606 114/zebra /var/run/quagga/zserv.apiunix 2 [ ACC ] STREAM LISTENING 575609 114/zebra /var/run/quagga/zebra.vtyunix 2 [ ACC ] STREAM LISTENING 574079 67/simple_switch /tmp/bmv2-0-notifications.ipcunix 3 [ ] STREAM CONNECTED 574211 81/bmswitchp4_drive unix 3 [ ] STREAM CONNECTED 575248 67/simple_switch unix 3 [ ] STREAM CONNECTED 576590 118/bgpd unix 3 [ ] STREAM CONNECTED 574212 81/bmswitchp4_drive unix 3 [ ] STREAM CONNECTED 574218 67/simple_switch /tmp/bmv2-0-notifications.ipcunix 3 [ ] STREAM CONNECTED 575295 81/bmswitchp4_drive unix 3 [ ] STREAM CONNECTED 575841 123/watchquagga unix 3 [ ] STREAM CONNECTED 575271 81/bmswitchp4_drive unix 3 [ ] STREAM CONNECTED 576591 114/zebra /var/run/quagga/zserv.apiunix 3 [ ] STREAM CONNECTED 576807 118/bgpd /var/run/quagga/bgpd.vtyunix 3 [ ] STREAM CONNECTED 578621 114/zebra /var/run/quagga/zebra.vtyunix 3 [ ] STREAM CONNECTED 575296 81/bmswitchp4_drive unix 3 [ ] STREAM CONNECTED 576589 114/zebra /var/run/quagga/zserv.apiunix 3 [ ] STREAM CONNECTED 576588 118/bgpd unix 3 [ ] STREAM CONNECTED 575247 67/simple_switch unix 3 [ ] STREAM CONNECTED 574344 81/bmswitchp4_drive unix 3 [ ] STREAM CONNECTED 574345 81/bmswitchp4_drive unix 3 [ ] STREAM CONNECTED 578620 123/watchquagga root@leaf1:/# /home/sunyongfeng/workshop/p4/install/bin/simple_switch_CLI --json /home/sunyongfeng/workshop/p4/install/share/bmpd/switch/switch.json --thrift-port 10001Control utility for runtime P4 table manipulationRuntimeCmd: 查看 ipv4_fib 和 ipv4_fib_lpm 表，确认表项安装 OK。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230RuntimeCmd: show_tablesacl_stats [implementation=None, mk=]adjust_lkp_fields [implementation=None, mk=ipv4_valid(valid, 1), ipv6_valid(valid, 1)]bd_flood [implementation=None, mk=ingress_metadata.bd(exact, 16), l2_metadata.lkp_pkt_type(exact, 3)]compute_ipv4_hashes [implementation=None, mk=ingress_metadata.drop_flag(exact, 1)]compute_ipv6_hashes [implementation=None, mk=ingress_metadata.drop_flag(exact, 1)]compute_non_ip_hashes [implementation=None, mk=ingress_metadata.drop_flag(exact, 1)]compute_other_hashes [implementation=None, mk=hash_metadata.hash1(exact, 16)]dmac [implementation=None, mk=ingress_metadata.bd(exact, 16), l2_metadata.lkp_mac_da(exact, 48)]drop_stats [implementation=None, mk=]ecmp_group [implementation=ecmp_action_profile, mk=l3_metadata.nexthop_index(exact, 16)]egress_bd_map [implementation=None, mk=egress_metadata.bd(exact, 16)]egress_bd_stats [implementation=None, mk=egress_metadata.bd(exact, 16), l2_metadata.lkp_pkt_type(exact, 3)]egress_filter [implementation=None, mk=]egress_filter_drop [implementation=None, mk=]egress_ip_acl [implementation=None, mk=acl_metadata.egress_if_label(ternary, 16), acl_metadata.egress_bd_label(ternary, 16), ipv4.srcAddr(ternary, 32), ipv4.dstAddr(ternary, 32), ipv4.protocol(ternary, 8), acl_metadata.egress_src_port_range_id(exact, 8), acl_metadata.egress_dst_port_range_id(exact, 8)]egress_ipv6_acl [implementation=None, mk=acl_metadata.egress_if_label(ternary, 16), acl_metadata.egress_bd_label(ternary, 16), ipv6.srcAddr(ternary, 128), ipv6.dstAddr(ternary, 128), ipv6.nextHdr(ternary, 8), acl_metadata.egress_src_port_range_id(exact, 8), acl_metadata.egress_dst_port_range_id(exact, 8)]egress_l4_dst_port [implementation=None, mk=l3_metadata.egress_l4_dport(range, 16)]egress_l4_src_port [implementation=None, mk=l3_metadata.egress_l4_sport(range, 16)]egress_l4port_fields [implementation=None, mk=tcp_valid(valid, 1), udp_valid(valid, 1), icmp_valid(valid, 1)]egress_mac_acl [implementation=None, mk=acl_metadata.egress_if_label(ternary, 16), acl_metadata.egress_bd_label(ternary, 16), ethernet.srcAddr(ternary, 48), ethernet.dstAddr(ternary, 48), ethernet.etherType(ternary, 16)]egress_nat [implementation=None, mk=nat_metadata.nat_rewrite_index(exact, 14)]egress_port_mapping [implementation=None, mk=standard_metadata.egress_port(exact, 9)]egress_qos_map [implementation=None, mk=qos_metadata.egress_qos_group(ternary, 5), qos_metadata.lkp_tc(ternary, 8)]egress_system_acl [implementation=None, mk=fabric_metadata.reason_code(ternary, 16), standard_metadata.egress_port(ternary, 9), intrinsic_metadata.deflection_flag(ternary, 1), l3_metadata.l3_mtu_check(ternary, 16), acl_metadata.acl_deny(ternary, 1)]egress_vlan_xlate [implementation=None, mk=egress_metadata.ifindex(exact, 16), egress_metadata.bd(exact, 16)]egress_vni [implementation=None, mk=egress_metadata.bd(exact, 16), tunnel_metadata.egress_tunnel_type(exact, 5)]fabric_ingress_dst_lkp [implementation=None, mk=fabric_header.dstDevice(exact, 8)]fabric_ingress_src_lkp [implementation=None, mk=fabric_header_multicast.ingressIfindex(exact, 16)]fabric_lag [implementation=fabric_lag_action_profile, mk=fabric_metadata.dst_device(exact, 8)]fwd_result [implementation=None, mk=l2_metadata.l2_redirect(ternary, 1), acl_metadata.acl_redirect(ternary, 1), acl_metadata.racl_redirect(ternary, 1), l3_metadata.rmac_hit(ternary, 1), l3_metadata.fib_hit(ternary, 1), nat_metadata.nat_hit(ternary, 1), l2_metadata.lkp_pkt_type(ternary, 3), l3_metadata.lkp_ip_type(ternary, 2), multicast_metadata.igmp_snooping_enabled(ternary, 1), multicast_metadata.mld_snooping_enabled(ternary, 1),multicast_metadata.mcast_route_hit(ternary, 1), multicast_metadata.mcast_bridge_hit(ternary, 1), multicast_metadata.mcast_rpf_group(ternary, 16), multicast_metadata.mcast_mode(ternary, 2)]ingress_bd_stats [implementation=None, mk=]ingress_l4_dst_port [implementation=None, mk=l3_metadata.lkp_l4_dport(range, 16)]ingress_l4_src_port [implementation=None, mk=l3_metadata.lkp_l4_sport(range, 16)]ingress_port_mapping [implementation=None, mk=standard_metadata.ingress_port(exact, 9)]ingress_port_properties [implementation=None, mk=standard_metadata.ingress_port(exact, 9)]ingress_qos_map_dscp [implementation=None, mk=qos_metadata.ingress_qos_group(ternary, 5), l3_metadata.lkp_dscp(ternary, 8)]ingress_qos_map_pcp [implementation=None, mk=qos_metadata.ingress_qos_group(ternary, 5), l2_metadata.lkp_pcp(ternary, 3)]int_bos [implementation=None, mk=int_header.total_hop_cnt(ternary, 8), int_header.instruction_mask_0003(ternary, 4), int_header.instruction_mask_0407(ternary, 4), int_header.instruction_mask_0811(ternary, 4), int_header.instruction_mask_1215(ternary, 4)]int_insert [implementation=None, mk=int_metadata_i2e.source(ternary, 1), int_metadata_i2e.sink(ternary, 1), int_header_valid(valid, 1)]int_inst_0003 [implementation=None, mk=int_header.instruction_mask_0003(exact, 4)]int_inst_0407 [implementation=None, mk=int_header.instruction_mask_0407(exact, 4)]int_inst_0811 [implementation=None, mk=int_header.instruction_mask_0811(exact, 4)]int_inst_1215 [implementation=None, mk=int_header.instruction_mask_1215(exact, 4)]int_meta_header_update [implementation=None, mk=int_metadata.insert_cnt(ternary, 8)]int_outer_encap [implementation=None, mk=ipv4_valid(valid, 1), vxlan_gpe_valid(valid, 1), int_metadata_i2e.source(exact, 1), tunnel_metadata.egress_tunnel_type(ternary, 5)]int_sink_update_outer [implementation=None, mk=vxlan_gpe_int_header_valid(valid, 1), ipv4_valid(valid, 1), int_metadata_i2e.sink(exact, 1)]int_source [implementation=None, mk=int_header_valid(valid, 1), ipv4_valid(valid, 1), ipv4_metadata.lkp_ipv4_da(ternary, 32), ipv4_metadata.lkp_ipv4_sa(ternary, 32), inner_ipv4_valid(valid, 1), inner_ipv4.dstAddr(ternary, 32), inner_ipv4.srcAddr(ternary, 32)]int_terminate [implementation=None, mk=int_header_valid(valid, 1), vxlan_gpe_int_header_valid(valid, 1), ipv4_valid(valid, 1), ipv4_metadata.lkp_ipv4_da(ternary, 32), inner_ipv4_valid(valid, 1), inner_ipv4.dstAddr(ternary, 32)]ip_acl [implementation=None, mk=acl_metadata.if_label(ternary, 16), acl_metadata.bd_label(ternary, 16), ipv4_metadata.lkp_ipv4_sa(ternary, 32), ipv4_metadata.lkp_ipv4_da(ternary, 32), l3_metadata.lkp_ip_proto(ternary, 8), acl_metadata.ingress_src_port_range_id(exact, 8), acl_metadata.ingress_dst_port_range_id(exact, 8), tcp.flags(ternary, 8), l3_metadata.lkp_ip_ttl(ternary, 8)]ipsg [implementation=None, mk=ingress_metadata.ifindex(exact, 16), ingress_metadata.bd(exact, 16), l2_metadata.lkp_mac_sa(exact, 48), ipv4_metadata.lkp_ipv4_sa(exact, 32)]ipsg_permit_special [implementation=None, mk=l3_metadata.lkp_ip_proto(ternary, 8), l3_metadata.lkp_l4_dport(ternary, 16), ipv4_metadata.lkp_ipv4_da(ternary, 32)]ipv4_dest_vtep [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv4.dstAddr(exact, 32), tunnel_metadata.ingress_tunnel_type(exact, 5)]ipv4_fib [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv4_metadata.lkp_ipv4_da(exact, 32)]ipv4_fib_lpm [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv4_metadata.lkp_ipv4_da(lpm, 32)]ipv4_multicast_bridge [implementation=None, mk=ingress_metadata.bd(exact, 16), ipv4_metadata.lkp_ipv4_sa(exact, 32), ipv4_metadata.lkp_ipv4_da(exact, 32)]ipv4_multicast_bridge_star_g [implementation=None, mk=ingress_metadata.bd(exact, 16), ipv4_metadata.lkp_ipv4_da(exact, 32)]ipv4_multicast_route [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv4_metadata.lkp_ipv4_sa(exact, 32), ipv4_metadata.lkp_ipv4_da(exact, 32)]ipv4_multicast_route_star_g [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv4_metadata.lkp_ipv4_da(exact, 32)]ipv4_racl [implementation=None, mk=acl_metadata.bd_label(ternary, 16), ipv4_metadata.lkp_ipv4_sa(ternary, 32), ipv4_metadata.lkp_ipv4_da(ternary, 32), l3_metadata.lkp_ip_proto(ternary, 8), acl_metadata.ingress_src_port_range_id(exact, 8), acl_metadata.ingress_dst_port_range_id(exact, 8)]ipv4_src_vtep [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv4.srcAddr(exact, 32), tunnel_metadata.ingress_tunnel_type(exact, 5)]ipv4_urpf [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv4_metadata.lkp_ipv4_sa(exact, 32)]ipv4_urpf_lpm [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv4_metadata.lkp_ipv4_sa(lpm, 32)]ipv6_acl [implementation=None, mk=acl_metadata.if_label(ternary, 16), acl_metadata.bd_label(ternary, 16), ipv6_metadata.lkp_ipv6_sa(ternary, 128), ipv6_metadata.lkp_ipv6_da(ternary, 128), l3_metadata.lkp_ip_proto(ternary, 8), acl_metadata.ingress_src_port_range_id(exact, 8), acl_metadata.ingress_dst_port_range_id(exact, 8), tcp.flags(ternary, 8), l3_metadata.lkp_ip_ttl(ternary, 8)]ipv6_dest_vtep [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv6.dstAddr(exact, 128), tunnel_metadata.ingress_tunnel_type(exact, 5)]ipv6_fib [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv6_metadata.lkp_ipv6_da(exact, 128)]ipv6_fib_lpm [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv6_metadata.lkp_ipv6_da(lpm, 128)]ipv6_multicast_bridge [implementation=None, mk=ingress_metadata.bd(exact, 16), ipv6_metadata.lkp_ipv6_sa(exact, 128), ipv6_metadata.lkp_ipv6_da(exact, 128)]ipv6_multicast_bridge_star_g [implementation=None, mk=ingress_metadata.bd(exact, 16), ipv6_metadata.lkp_ipv6_da(exact, 128)]ipv6_multicast_route [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv6_metadata.lkp_ipv6_sa(exact, 128), ipv6_metadata.lkp_ipv6_da(exact, 128)]ipv6_multicast_route_star_g [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv6_metadata.lkp_ipv6_da(exact, 128)]ipv6_racl [implementation=None, mk=acl_metadata.bd_label(ternary, 16), ipv6_metadata.lkp_ipv6_sa(ternary, 128), ipv6_metadata.lkp_ipv6_da(ternary, 128), l3_metadata.lkp_ip_proto(ternary, 8), acl_metadata.ingress_src_port_range_id(exact, 8), acl_metadata.ingress_dst_port_range_id(exact, 8)]ipv6_src_vtep [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv6.srcAddr(exact, 128), tunnel_metadata.ingress_tunnel_type(exact, 5)]ipv6_urpf [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv6_metadata.lkp_ipv6_sa(exact, 128)]ipv6_urpf_lpm [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv6_metadata.lkp_ipv6_sa(lpm, 128)]l3_rewrite [implementation=None, mk=ipv4_valid(valid, 1), ipv6_valid(valid, 1), mpls[0]_valid(valid, 1), ipv4.dstAddr(ternary, 32), ipv6.dstAddr(ternary, 128)]lag_group [implementation=lag_action_profile, mk=ingress_metadata.egress_ifindex(exact, 16)]learn_notify [implementation=None, mk=l2_metadata.l2_src_miss(ternary, 1), l2_metadata.l2_src_move(ternary, 16), l2_metadata.stp_state(ternary, 3)]mac_acl [implementation=None, mk=acl_metadata.if_label(ternary, 16), acl_metadata.bd_label(ternary, 16), l2_metadata.lkp_mac_sa(ternary, 48), l2_metadata.lkp_mac_da(ternary, 48), l2_metadata.lkp_mac_type(ternary, 16)]meter_action [implementation=None, mk=meter_metadata.packet_color(exact, 2), meter_metadata.meter_index(exact, 16)]meter_index [implementation=None, mk=meter_metadata.meter_index(exact, 16)]mirror [implementation=None, mk=i2e_metadata.mirror_session_id(exact, 16)]mpls [implementation=None, mk=tunnel_metadata.mpls_label(exact, 20), inner_ipv4_valid(valid, 1), inner_ipv6_valid(valid, 1)]mtu [implementation=None, mk=l3_metadata.mtu_index(exact, 8), ipv4_valid(valid, 1), ipv6_valid(valid, 1)]nat_dst [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv4_metadata.lkp_ipv4_da(exact, 32), l3_metadata.lkp_ip_proto(exact, 8), l3_metadata.lkp_l4_dport(exact, 16)]nat_flow [implementation=None, mk=l3_metadata.vrf(ternary, 16), ipv4_metadata.lkp_ipv4_sa(ternary, 32), ipv4_metadata.lkp_ipv4_da(ternary, 32), l3_metadata.lkp_ip_proto(ternary, 8), l3_metadata.lkp_l4_sport(ternary, 16), l3_metadata.lkp_l4_dport(ternary, 16)]nat_src [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv4_metadata.lkp_ipv4_sa(exact, 32), l3_metadata.lkp_ip_proto(exact, 8), l3_metadata.lkp_l4_sport(exact, 16)]nat_twice [implementation=None, mk=l3_metadata.vrf(exact, 16), ipv4_metadata.lkp_ipv4_sa(exact, 32), ipv4_metadata.lkp_ipv4_da(exact, 32)l3_metadata.lkp_ip_proto(exact, 8), l3_metadata.lkp_l4_sport(exact, 16), l3_metadata.lkp_l4_dport(exact, 16)]native_packet_over_fabric [implementation=None, mk=ipv4_valid(valid, 1), ipv6_valid(valid, 1)]nexthop [implementation=None, mk=l3_metadata.nexthop_index(exact, 16)]outer_ipv4_multicast [implementation=None, mk=multicast_metadata.ipv4_mcast_key_type(exact, 1), multicast_metadata.ipv4_mcast_key(exact, 16), ipv4.srcAddr(exact, 32), ipv4.dstAddr(exact, 32)]outer_ipv4_multicast_star_g [implementation=None, mk=multicast_metadata.ipv4_mcast_key_type(exact, 1), multicast_metadata.ipv4_mcast_key(exact, 16), ipv4.dstAddr(ternary, 32)]outer_ipv6_multicast [implementation=None, mk=multicast_metadata.ipv6_mcast_key_type(exact, 1), multicast_metadata.ipv6_mcast_key(exact, 16), ipv6.srcAddr(exact, 128), ipv6.dstAddr(exact, 128)]outer_ipv6_multicast_star_g [implementation=None, mk=multicast_metadata.ipv6_mcast_key_type(exact, 1), multicast_metadata.ipv6_mcast_key(exact, 16), ipv6.dstAddr(ternary, 128)]outer_rmac [implementation=None, mk=l3_metadata.rmac_group(exact, 10), ethernet.dstAddr(exact, 48)]port_vlan_mapping [implementation=bd_action_profile, mk=ingress_metadata.ifindex(exact, 16), vlan_tag_[0]_valid(valid, 1), vlan_tag_[0].vid(exact, 12), vlan_tag_[1]_valid(valid, 1), vlan_tag_[1].vid(exact, 12)]replica_type [implementation=None, mk=multicast_metadata.replica(exact, 1), egress_metadata.same_bd_check(ternary, 16)]rewrite [implementation=None, mk=l3_metadata.nexthop_index(exact, 16)]rewrite_multicast [implementation=None, mk=ipv4_valid(valid, 1), ipv6_valid(valid, 1), ipv4.dstAddr(ternary, 32), ipv6.dstAddr(ternary, 128)]rid [implementation=None, mk=intrinsic_metadata.egress_rid(exact, 16)]rmac [implementation=None, mk=l3_metadata.rmac_group(exact, 10), l2_metadata.lkp_mac_da(exact, 48)]sflow_ing_take_sample [implementation=None, mk=ingress_metadata.sflow_take_sample(ternary, 32), sflow_metadata.sflow_session_id(exact, 16)]sflow_ingress [implementation=None, mk=ingress_metadata.ifindex(ternary, 16), ipv4_metadata.lkp_ipv4_sa(ternary, 32), ipv4_metadata.lkp_ipv4_da(ternary, 32), sflow_valid(valid, 1)]smac [implementation=None, mk=ingress_metadata.bd(exact, 16), l2_metadata.lkp_mac_sa(exact, 48)]smac_rewrite [implementation=None, mk=egress_metadata.smac_idx(exact, 9)]spanning_tree [implementation=None, mk=ingress_metadata.ifindex(exact, 16), l2_metadata.stp_group(exact, 10)]storm_control [implementation=None, mk=standard_metadata.ingress_port(exact, 9), l2_metadata.lkp_pkt_type(ternary, 3)]storm_control_stats [implementation=None, mk=meter_metadata.packet_color(exact, 2), standard_metadata.ingress_port(exact, 9)]switch_config_params [implementation=None, mk=]system_acl [implementation=None, mk=acl_metadata.if_label(ternary, 16), acl_metadata.bd_label(ternary, 16), ingress_metadata.ifindex(ternary, 16), l2_metadata.lkp_mac_type(ternary, 16), l2_metadata.port_vlan_mapping_miss(ternary, 1), security_metadata.ipsg_check_fail(ternary, 1), acl_metadata.acl_deny(ternary, 1), acl_metadata.racl_deny(ternary, 1), l3_metadata.urpf_check_fail(ternary, 1), ingress_metadata.drop_flag(ternary, 1), l3_metadata.l3_copy(ternary, 1), l3_metadata.rmac_hit(ternary, 1), l3_metadata.routed(ternary, 1), ipv6_metadata.ipv6_src_is_link_local(ternary, 1), l2_metadata.same_if_check(ternary, 16), tunnel_metadata.tunnel_if_check(ternary, 1), l3_metadata.same_bd_check(ternary, 16), l3_metadata.lkp_ip_ttl(ternary, 8), l2_metadata.stp_state(ternary, 3), ingress_metadata.control_frame(ternary, 1), ipv4_metadata.ipv4_unicast_enabled(ternary, 1), ipv6_metadata.ipv6_unicast_enabled(ternary, 1), ingress_metadata.egress_ifindex(ternary, 16), fabric_metadata.reason_code(ternary, 16)]traffic_class [implementation=None, mk=qos_metadata.tc_qos_group(ternary, 5), qos_metadata.lkp_tc(ternary, 8)]tunnel [implementation=None, mk=tunnel_metadata.tunnel_vni(exact, 24), tunnel_metadata.ingress_tunnel_type(exact, 5), inner_ipv4_valid(valid, 1), inner_ipv6_valid(valid, 1)]tunnel_decap_process_inner [implementation=None, mk=inner_tcp_valid(valid, 1), inner_udp_valid(valid, 1), inner_icmp_valid(valid, 1)]tunnel_decap_process_outer [implementation=None, mk=tunnel_metadata.ingress_tunnel_type(exact, 5), inner_ipv4_valid(valid, 1), inner_ipv6_valid(valid, 1)]tunnel_dmac_rewrite [implementation=None, mk=tunnel_metadata.tunnel_dmac_index(exact, 14)]tunnel_dst_rewrite [implementation=None, mk=tunnel_metadata.tunnel_dst_index(exact, 14)]tunnel_encap_process_inner [implementation=None, mk=ipv4_valid(valid, 1), ipv6_valid(valid, 1), tcp_valid(valid, 1), udp_valid(valid, 1), icmp_valid(valid, 1)]tunnel_encap_process_outer [implementation=None, mk=tunnel_metadata.egress_tunnel_type(exact, 5), tunnel_metadata.egress_header_count(exact, 4), multicast_metadata.replica(exact, 1)]tunnel_lookup_miss [implementation=None, mk=ipv4_valid(valid, 1), ipv6_valid(valid, 1)]tunnel_mtu [implementation=None, mk=tunnel_metadata.tunnel_index(exact, 14)]tunnel_rewrite [implementation=None, mk=tunnel_metadata.tunnel_index(exact, 14)]tunnel_smac_rewrite [implementation=None, mk=tunnel_metadata.tunnel_smac_index(exact, 9)]tunnel_src_rewrite [implementation=None, mk=tunnel_metadata.tunnel_src_index(exact, 9)]urpf_bd [implementation=None, mk=l3_metadata.urpf_bd_group(exact, 16), ingress_metadata.bd(exact, 16)]validate_mpls_packet [implementation=None, mk=mpls[0].label(ternary, 20), mpls[0].bos(ternary, 1), mpls[0]_valid(valid, 1), mpls[1].label(ternary, 20), mpls[1].bos(ternary, 1), mpls[1]_valid(valid, 1), mpls[2].label(ternary, 20), mpls[2].bos(ternary, 1), mpls[2]_valid(valid, 1)]validate_outer_ethernet [implementation=None, mk=ethernet.srcAddr(ternary, 48), ethernet.dstAddr(ternary, 48), vlan_tag_[0]_valid(valid, 1), vlan_tag_[1]_valid(valid, 1)]validate_outer_ipv4_packet [implementation=None, mk=ipv4.version(ternary, 4), ipv4.ttl(ternary, 8), ipv4.srcAddr(ternary, 32)]validate_outer_ipv6_packet [implementation=None, mk=ipv6.version(ternary, 4), ipv6.hopLimit(ternary, 8), ipv6.srcAddr(ternary, 128)]validate_packet [implementation=None, mk=l2_metadata.lkp_mac_sa(ternary, 48), l2_metadata.lkp_mac_da(ternary, 48), l3_metadata.lkp_ip_type(ternary, 2), l3_metadata.lkp_ip_ttl(ternary, 8), l3_metadata.lkp_ip_version(ternary, 4), ipv4_metadata.lkp_ipv4_sa(ternary, 32), ipv6_metadata.lkp_ipv6_sa(ternary, 128)]vlan_decap [implementation=None, mk=vlan_tag_[0]_valid(valid, 1), vlan_tag_[1]_valid(valid, 1)]RuntimeCmd: table_dump ipv4_fib==========TABLE ENTRIES**********Dumping entry 0x0Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: EXACT 00000000Action entry: fib_hit_nexthop - 06**********Dumping entry 0x1Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: EXACT 0a000164Action entry: fib_hit_nexthop - 03**********Dumping entry 0x2Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: EXACT 0a000264Action entry: fib_hit_nexthop - 03**********Dumping entry 0x3Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: EXACT 0a010b01Action entry: fib_hit_nexthop - 03**********Dumping entry 0x4Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: EXACT 0a010c01Action entry: fib_hit_nexthop - 03**********Dumping entry 0x1000005Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: EXACT 0a000202Action entry: fib_hit_nexthop - 07**********Dumping entry 0x3000006Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: EXACT 0a010c02Action entry: fib_hit_nexthop - 08**********Dumping entry 0x7Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: EXACT 0a000101Action entry: fib_hit_nexthop - 09==========Dumping default entryAction entry: on_miss - ==========RuntimeCmd: table_dump ipv4_fib_lpm==========TABLE ENTRIES**********Dumping entry 0x0Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: LPM 7f000000/8Action entry: fib_hit_nexthop - 05**********Dumping entry 0x1Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: LPM 00000000/0Action entry: fib_hit_nexthop - 06**********Dumping entry 0x2Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: LPM 0a000164/24Action entry: fib_hit_nexthop - 03**********Dumping entry 0x3Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: LPM 0a000264/24Action entry: fib_hit_nexthop - 03**********Dumping entry 0x4Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: LPM 0a010b01/24Action entry: fib_hit_nexthop - 03**********Dumping entry 0x5Match key:* l3_metadata.vrf : EXACT 0001* ipv4_metadata.lkp_ipv4_da: LPM 0a010c01/24Action entry: fib_hit_nexthop - 03==========Dumping default entryAction entry: on_miss - ==========RuntimeCmd: root@leaf1:/# 解决 mininet 起来后 host 间无法互 Ping原因：docker 的物理端口配置问题，实际拓扑使用 leaf1-eth1，但是配置却配到 swp1。 详见 p4factory issue 194 patch 如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596diff --git a/mininet/configs/leaf1/l3_int_ref_topo/startup_config.sh b/mininet/configs/leaf1/l3_int_ref_topo/startup_config.shindex 6432a4c..5d34e05 100755--- a/mininet/configs/leaf1/l3_int_ref_topo/startup_config.sh+++ b/mininet/configs/leaf1/l3_int_ref_topo/startup_config.sh@@ -2,15 +2,15 @@ stty -echo; set +m -ip link set dev swp1 address 00:01:00:00:00:01-ip link set dev swp2 address 00:01:00:00:00:02-ip link set dev swp3 address 00:01:00:00:00:03-ip link set dev swp4 address 00:01:00:00:00:04+ip link set dev leaf1-eth1 address 00:01:00:00:00:01+ip link set dev leaf1-eth2 address 00:01:00:00:00:02+ip link set dev leaf1-eth3 address 00:01:00:00:00:03+ip link set dev leaf1-eth4 address 00:01:00:00:00:04 -ip address add 10.0.1.100/24 broadcast + dev swp1-ip address add 10.0.2.100/24 broadcast + dev swp2-ip address add 10.1.11.1/24 broadcast + dev swp3-ip address add 10.1.12.1/24 broadcast + dev swp4+ip address add 10.0.1.100/24 broadcast + dev leaf1-eth1+ip address add 10.0.2.100/24 broadcast + dev leaf1-eth2+ip address add 10.1.11.1/24 broadcast + dev leaf1-eth3+ip address add 10.1.12.1/24 broadcast + dev leaf1-eth4 cp /configs/quagga/* /etc/quagga/ chown quagga.quagga /etc/quagga/*diff --git a/mininet/configs/leaf2/l3_int_ref_topo/startup_config.sh b/mininet/configs/leaf2/l3_int_ref_topo/startup_config.shindex 0a5637f..7562c72 100755--- a/mininet/configs/leaf2/l3_int_ref_topo/startup_config.sh+++ b/mininet/configs/leaf2/l3_int_ref_topo/startup_config.sh@@ -2,15 +2,15 @@ stty -echo; set +m -ip link set dev swp1 address 00:02:00:00:00:01-ip link set dev swp2 address 00:02:00:00:00:02-ip link set dev swp3 address 00:02:00:00:00:03-ip link set dev swp4 address 00:02:00:00:00:04+ip link set dev leaf2-eth1 address 00:02:00:00:00:01+ip link set dev leaf2-eth2 address 00:02:00:00:00:02+ip link set dev leaf2-eth3 address 00:02:00:00:00:03+ip link set dev leaf2-eth4 address 00:02:00:00:00:04 -ip address add 10.0.3.100/24 broadcast + dev swp1-ip address add 10.0.4.100/24 broadcast + dev swp2-ip address add 10.1.21.1/24 broadcast + dev swp3-ip address add 10.1.22.1/24 broadcast + dev swp4+ip address add 10.0.3.100/24 broadcast + dev leaf2-eth1+ip address add 10.0.4.100/24 broadcast + dev leaf2-eth2+ip address add 10.1.21.1/24 broadcast + dev leaf2-eth3+ip address add 10.1.22.1/24 broadcast + dev leaf2-eth4 cp /configs/quagga/* /etc/quagga/ chown quagga.quagga /etc/quagga/*diff --git a/mininet/configs/spine1/l3_int_ref_topo/startup_config.sh b/mininet/configs/spine1/l3_int_ref_topo/startup_config.shindex f2ecfc0..33f4878 100755--- a/mininet/configs/spine1/l3_int_ref_topo/startup_config.sh+++ b/mininet/configs/spine1/l3_int_ref_topo/startup_config.sh@@ -2,11 +2,11 @@ stty -echo; set +m -ip link set dev swp1 address 00:03:00:00:00:01-ip link set dev swp2 address 00:03:00:00:00:02+ip link set dev spine1-eth1 address 00:03:00:00:00:01+ip link set dev spine1-eth2 address 00:03:00:00:00:02 -ip address add 10.1.11.2/24 broadcast + dev swp1-ip address add 10.1.21.2/24 broadcast + dev swp2+ip address add 10.1.11.2/24 broadcast + dev spine1-eth1+ip address add 10.1.21.2/24 broadcast + dev spine2-eth2 cp /configs/quagga/* /etc/quagga/ chown quagga.quagga /etc/quagga/*diff --git a/mininet/configs/spine2/l3_int_ref_topo/startup_config.sh b/mininet/configs/spine2/l3_int_ref_topo/startup_config.shindex 7a28663..be95656 100755--- a/mininet/configs/spine2/l3_int_ref_topo/startup_config.sh+++ b/mininet/configs/spine2/l3_int_ref_topo/startup_config.sh@@ -2,11 +2,11 @@ stty -echo; set +m -ip link set dev swp1 address 00:04:00:00:00:01-ip link set dev swp2 address 00:04:00:00:00:02+ip link set dev spine2-eth1 address 00:04:00:00:00:01+ip link set dev spine2-eth2 address 00:04:00:00:00:02 -ip address add 10.1.12.2/24 broadcast + dev swp1-ip address add 10.1.22.2/24 broadcast + dev swp2+ip address add 10.1.12.2/24 broadcast + dev spine2-eth1+ip address add 10.1.22.2/24 broadcast + dev spine2-eth2 cp /configs/quagga/* /etc/quagga/ chown quagga.quagga /etc/quagga/* iperf 提示拒绝连接非必需，仅出现过一次，默认每个 host 的 iperf server 都会启动。h3 iperf 似乎默认没有启动。 12 root  ~  workshop  p4factory  mininet  iperf -c 10.2.1.3 -t 60connect failed: Connection refused 在 h3 中启动： 123456 root  ~  workshop  p4factory  mininet  iperf -s------------------------------------------------------------Server listening on TCP port 5001TCP window size: 85.3 KByte (default)------------------------------------------------------------[ 18] local 10.2.1.3 port 5001 connected with 10.2.1.1 port 45594 在 h1 中 运行 iperf 客户端： 12345678 root  ~  workshop  p4factory  mininet  iperf -c 10.2.1.3 -t 6000000------------------------------------------------------------Client connecting to 10.2.1.3, TCP port 5001TCP window size: 85.3 KByte (default)------------------------------------------------------------[ 17] local 10.2.1.1 port 45594 connected with 10.2.1.3 port 5001^C[ ID] Interval Transfer Bandwidth[ 17] 0.0-639.1 sec 341 MBytes 4.47 Mbits/sec monitor 网页无法显示正在运行的流目前在 h1 iperf h3 的时候，可以通过在 leaf1 中 tshark -i leaf1-eth1 确认输入报文，tshark -i leaf1-eth4 确认输出报文。可看到报文是 vxlan-gpe 封装（UDP port 4790），但是目前 monitor client 网页上还无法看到 INT 汇总会的图表以及正在运行的流。 问题原因：bridge 过滤掉 UDP 报文，具体为哪条过滤表项目前还未细究。 Okay. The solution to this lies in the quirks of how linux bridges get filtered. Essentially, you need to go in disable all the filters so that the UDP packets can get through. Details here: https://wiki.linuxfoundation.org/networking/bridge 解决方法： 12# cd /proc/sys/net/bridge# for f in bridge-nf-*; do echo 0 &gt; $f; done 详见 p4-dev 邮件列表，INT demo issue - Bad UDP checksum for packets headed to monitor。]]></content>
      <categories>
        <category>p4</category>
      </categories>
      <tags>
        <tag>p4</tag>
        <tag>int</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu 用回旧版内核]]></title>
    <url>%2F201704%2Flinux%2Fstartup_with_old_kernel.html</url>
    <content type="text"><![CDATA[尝试跑 p4factory app int，其 vxlan 内核模块目前只支持内核版本 3.19，而当前 ubuntu 16.04 默认内核版本都为 16.04，内核模块编译不过，因此需要安装旧版内核并默认启动旧版内核。 完整流程下载旧 Linux 内核版本见 askubuntu David Foerster 的答复。从 Kernel/MainlineBuilds 下载旧版内核 deb，链接，这里以 3.19.8-vivid 为例。 headers, 32-bit, 64-bit images, 32-bit, 64-bit 安装旧 Linux 内核版本 安装依赖sudo apt-get install module-init-tools 修改 /usr/src/linux-headers-3.19.8-031908-generic/include/generated/utsrelease.h 宏 #define UTS_UBUNTU_RELEASE_ABI 031908 为 #define UTS_UBUNTU_RELEASE_ABI 31908。 使用 sudo dpkg -i xxx.deb，将 xxx 替换为你下载的 headers 和 images。 失败log - 未安装 module-init-tools12345678910111213141516171819202122sunyongfeng@openswitch-OptiPlex-380:~/Downloads$ sudo dpkg -i linux-headers-3.19.8-031908_3.19.8-031908.201505110938_all.deb Selecting previously unselected package linux-headers-3.19.8-031908.(Reading database ... 366654 files and directories currently installed.)Preparing to unpack linux-headers-3.19.8-031908_3.19.8-031908.201505110938_all.deb ...Unpacking linux-headers-3.19.8-031908 (3.19.8-031908.201505110938) ...Setting up linux-headers-3.19.8-031908 (3.19.8-031908.201505110938) ...sunyongfeng@openswitch-OptiPlex-380:~/Downloads$ sudo dpkg -i linux-headers-3.19.8-031908linux-headers-3.19.8-031908_3.19.8-031908.201505110938_all.deb linux-headers-3.19.8-031908-generic_3.19.8-031908.201505110938_amd64.debsunyongfeng@openswitch-OptiPlex-380:~/Downloads$ sudo dpkg -i linux-image-3.19.8-031908-generic_3.19.8-031908.201505110938_amd64.deb Selecting previously unselected package linux-image-3.19.8-031908-generic.(Reading database ... 382437 files and directories currently installed.)Preparing to unpack linux-image-3.19.8-031908-generic_3.19.8-031908.201505110938_amd64.deb ...Done.Unpacking linux-image-3.19.8-031908-generic (3.19.8-031908.201505110938) ...dpkg: dependency problems prevent configuration of linux-image-3.19.8-031908-generic: linux-image-3.19.8-031908-generic depends on module-init-tools (&gt;= 3.3-pre11-4ubuntu3); however: Package module-init-tools is not installed.dpkg: error processing package linux-image-3.19.8-031908-generic (--install): dependency problems - leaving unconfiguredErrors were encountered while processing: linux-image-3.19.8-031908-generic 失败 log - 未修改 utsrelease.h1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162sunyongfeng@openswitch-OptiPlex-380:~/Downloads$ sudo apt-get install module-init-tools Reading package lists... DoneBuilding dependency tree Reading state information... DoneThe following packages were automatically installed and are no longer required: linux-headers-4.4.0-66 linux-headers-4.4.0-66-generic linux-headers-4.4.0-70 linux-headers-4.4.0-70-generic linux-image-4.4.0-66-generic linux-image-4.4.0-70-generic linux-image-extra-4.4.0-66-generic linux-image-extra-4.4.0-70-generic linux-tools-4.4.0-66 linux-tools-4.4.0-66-generic linux-tools-4.4.0-70 linux-tools-4.4.0-70-genericUse 'sudo apt autoremove' to remove them.The following NEW packages will be installed: module-init-tools0 upgraded, 1 newly installed, 0 to remove and 261 not upgraded.2 not fully installed or removed.Need to get 2,320 B of archives.After this operation, 18.4 kB of additional disk space will be used.Get:1 http://mirrors.aliyun.com/ubuntu xenial/universe amd64 module-init-tools all 22-1ubuntu4 [2,320 B]Fetched 2,320 B in 5s (449 B/s) Selecting previously unselected package module-init-tools.(Reading database ... 387755 files and directories currently installed.)Preparing to unpack .../module-init-tools_22-1ubuntu4_all.deb ...Unpacking module-init-tools (22-1ubuntu4) ...Setting up module-init-tools (22-1ubuntu4) ...Setting up linux-image-3.19.8-031908-generic (3.19.8-031908.201505110938) ...Running depmod.update-initramfs: deferring update (hook will be called later)Examining /etc/kernel/postinst.d.run-parts: executing /etc/kernel/postinst.d/apt-auto-removal 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericrun-parts: executing /etc/kernel/postinst.d/dkms 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericERROR (dkms apport): kernel package linux-headers-3.19.8-031908-generic is not supportedError! Bad return status for module build on kernel: 3.19.8-031908-generic (x86_64)Consult /var/lib/dkms/lttng-modules/2.8.0/build/make.log for more information.run-parts: executing /etc/kernel/postinst.d/initramfs-tools 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericupdate-initramfs: Generating /boot/initrd.img-3.19.8-031908-genericrun-parts: executing /etc/kernel/postinst.d/pm-utils 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericrun-parts: executing /etc/kernel/postinst.d/unattended-upgrades 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericrun-parts: executing /etc/kernel/postinst.d/update-notifier 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericrun-parts: executing /etc/kernel/postinst.d/zz-update-grub 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericGenerating grub configuration file ...Warning: Setting GRUB_TIMEOUT to a non-zero value when GRUB_HIDDEN_TIMEOUT is set is no longer supported.Found linux image: /boot/vmlinuz-4.4.0-72-genericFound initrd image: /boot/initrd.img-4.4.0-72-genericFound linux image: /boot/vmlinuz-4.4.0-71-genericFound initrd image: /boot/initrd.img-4.4.0-71-genericFound linux image: /boot/vmlinuz-4.4.0-70-genericFound initrd image: /boot/initrd.img-4.4.0-70-genericFound linux image: /boot/vmlinuz-4.4.0-66-genericFound initrd image: /boot/initrd.img-4.4.0-66-genericFound linux image: /boot/vmlinuz-4.4.0-64-genericFound initrd image: /boot/initrd.img-4.4.0-64-genericFound linux image: /boot/vmlinuz-4.4.0-45-genericFound initrd image: /boot/initrd.img-4.4.0-45-genericFound linux image: /boot/vmlinuz-3.19.8-031908-genericFound initrd image: /boot/initrd.img-3.19.8-031908-genericFound memtest86+ image: /boot/memtest86+.elfFound memtest86+ image: /boot/memtest86+.bindoneSetting up linux-headers-3.19.8-031908-generic (3.19.8-031908.201505110938) ...Examining /etc/kernel/header_postinst.d.run-parts: executing /etc/kernel/header_postinst.d/dkms 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericERROR (dkms apport): kernel package linux-headers-3.19.8-031908-generic is not supportedError! Bad return status for module build on kernel: 3.19.8-031908-generic (x86_64)Consult /var/lib/dkms/lttng-modules/2.8.0/build/make.log for more information. 查看 make.log 发现，dkms 将 /usr/src/linux-headers-3.19.8-031908-generic/include/generated/utsrelease.h 的十进制数宏 #define UTS_UBUNTU_RELEASE_ABI 031908 用成八进制数（估计是不兼容旧版本导致，不过 utsrelease.h 的这种写法也很别扭，因为默认使用 0 做为前导码标识八进制数）。将该宏改为 #define UTS_UBUNTU_RELEASE_ABI 31908 即可。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788sunyongfeng@openswitch-OptiPlex-380:~/Downloads$ vi /var/lib/dkms/lttng-modules/2.8.0/build/make.log 1 DKMS make.log for lttng-modules-2.8.0 for kernel 3.19.8-031908-generic (x86_64) 2 2017年 04月 18日 星期二 14:50:53 CST 3 make: Entering directory '/usr/src/linux-headers-3.19.8-031908-generic' 4 CC [M] /var/lib/dkms/lttng-modules/2.8.0/build/lttng-ring-buffer-client-discard.o 5 CC [M] /var/lib/dkms/lttng-modules/2.8.0/build/lttng-ring-buffer-client-overwrite.o 6 CC [M] /var/lib/dkms/lttng-modules/2.8.0/build/lttng-ring-buffer-metadata-client.o 7 CC [M] /var/lib/dkms/lttng-modules/2.8.0/build/lttng-ring-buffer-client-mmap-discard.o 8 CC [M] /var/lib/dkms/lttng-modules/2.8.0/build/lttng-ring-buffer-client-mmap-overwrite.o 9 CC [M] /var/lib/dkms/lttng-modules/2.8.0/build/lttng-ring-buffer-metadata-mmap-client.o 10 CC [M] /var/lib/dkms/lttng-modules/2.8.0/build/lttng-clock.o 11 CC [M] /var/lib/dkms/lttng-modules/2.8.0/build/lttng-events.o 12 In file included from /var/lib/dkms/lttng-modules/2.8.0/build/lttng-kernel-version.h:29:0, 13 from /var/lib/dkms/lttng-modules/2.8.0/build/wrapper/page_alloc.h:28, 14 from /var/lib/dkms/lttng-modules/2.8.0/build/lttng-events.c:27: 15 include/generated/utsrelease.h:2:32: error: invalid digit "9" in octal constant 16 #define UTS_UBUNTU_RELEASE_ABI 031908 17 ^ 18 /var/lib/dkms/lttng-modules/2.8.0/build/lttng-kernel-version.h:49:31: note: in expansion of macro ‘UTS_UBUNTU_RELEASE_ABI’ 19 ((LINUX_VERSION_CODE &lt;&lt; 8) + UTS_UBUNTU_RELEASE_ABI) 20 ^ 21 /var/lib/dkms/lttng-modules/2.8.0/build/lttng-kernel-version.h:56:3: note: in expansion of macro ‘LTTNG_UBUNTU_VERSION_CODE’ 22 (LTTNG_UBUNTU_VERSION_CODE &gt;= \ 23 ^ 24 /var/lib/dkms/lttng-modules/2.8.0/build/wrapper/page_alloc.h:39:6: note: in expansion of macro ‘LTTNG_UBUNTU_KERNEL_RANGE’ 25 || LTTNG_UBUNTU_KERNEL_RANGE(3,16,7,34, 3,17,0,0))) 26 ^ 27 include/generated/utsrelease.h:2:32: error: invalid digit "9" in octal constant 28 #define UTS_UBUNTU_RELEASE_ABI 031908 29 ^ 30 /var/lib/dkms/lttng-modules/2.8.0/build/lttng-kernel-version.h:49:31: note: in expansion of macro ‘UTS_UBUNTU_RELEASE_ABI’ 31 ((LINUX_VERSION_CODE &lt;&lt; 8) + UTS_UBUNTU_RELEASE_ABI) 32 ^ 33 /var/lib/dkms/lttng-modules/2.8.0/build/lttng-kernel-version.h:58:3: note: in expansion of macro ‘LTTNG_UBUNTU_VERSION_CODE’ 34 LTTNG_UBUNTU_VERSION_CODE &lt; \ 35 ^ 36 /var/lib/dkms/lttng-modules/2.8.0/build/wrapper/page_alloc.h:39:6: note: in expansion of macro ‘LTTNG_UBUNTU_KERNEL_RANGE’ 37 || LTTNG_UBUNTU_KERNEL_RANGE(3,16,7,34, 3,17,0,0))) 38 ^ 39 include/generated/utsrelease.h:2:32: error: invalid digit "9" in octal constant 40 #define UTS_UBUNTU_RELEASE_ABI 031908 41 ^ 42 /var/lib/dkms/lttng-modules/2.8.0/build/lttng-kernel-version.h:49:31: note: in expansion of macro ‘UTS_UBUNTU_RELEASE_ABI’ 43 ((LINUX_VERSION_CODE &lt;&lt; 8) + UTS_UBUNTU_RELEASE_ABI) 44 ^ 45 /var/lib/dkms/lttng-modules/2.8.0/build/lttng-kernel-version.h:56:3: note: in expansion of macro ‘LTTNG_UBUNTU_VERSION_CODE’ 46 (LTTNG_UBUNTU_VERSION_CODE &gt;= \ 47 ^ 48 /var/lib/dkms/lttng-modules/2.8.0/build/wrapper/page_alloc.h:71:5: note: in expansion of macro ‘LTTNG_UBUNTU_KERNEL_RANGE’ 49 &amp;&amp; LTTNG_UBUNTU_KERNEL_RANGE(3,13,11,50, 3,14,0,0)) 50 ^ 51 include/generated/utsrelease.h:2:32: error: invalid digit "9" in octal constant 52 #define UTS_UBUNTU_RELEASE_ABI 031908 53 ^ 54 /var/lib/dkms/lttng-modules/2.8.0/build/lttng-kernel-version.h:49:31: note: in expansion of macro ‘UTS_UBUNTU_RELEASE_ABI’ 55 ((LINUX_VERSION_CODE &lt;&lt; 8) + UTS_UBUNTU_RELEASE_ABI) 56 ^ 57 /var/lib/dkms/lttng-modules/2.8.0/build/lttng-kernel-version.h:58:3: note: in expansion of macro ‘LTTNG_UBUNTU_VERSION_CODE’ 58 LTTNG_UBUNTU_VERSION_CODE &lt; \ 59 ^ 60 /var/lib/dkms/lttng-modules/2.8.0/build/wrapper/page_alloc.h:71:5: note: in expansion of macro ‘LTTNG_UBUNTU_KERNEL_RANGE’ 61 &amp;&amp; LTTNG_UBUNTU_KERNEL_RANGE(3,13,11,50, 3,14,0,0)) 62 ^ 63 scripts/Makefile.build:257: recipe for target '/var/lib/dkms/lttng-modules/2.8.0/build/lttng-events.o' failed 64 make[1]: *** [/var/lib/dkms/lttng-modules/2.8.0/build/lttng-events.o] Error 1 65 Makefile:1382: recipe for target '_module_/var/lib/dkms/lttng-modules/2.8.0/build' failed 66 make: *** [_module_/var/lib/dkms/lttng-modules/2.8.0/build] Error 2 57 /var/lib/dkms/lttng-modules/2.8.0/build/lttng-kernel-version.h:58:3: note: in expansion of macro ‘LTTNG_UBUNTU_VERSION_CODE’ 58 LTTNG_UBUNTU_VERSION_CODE &lt; \ 59 ^ 60 /var/lib/dkms/lttng-modules/2.8.0/build/wrapper/page_alloc.h:71:5: note: in expansion of macro ‘LTTNG_UBUNTU_KERNEL_RANGE’ 61 &amp;&amp; LTTNG_UBUNTU_KERNEL_RANGE(3,13,11,50, 3,14,0,0)) 62 ^ 63 scripts/Makefile.build:257: recipe for target '/var/lib/dkms/lttng-modules/2.8.0/build/lttng-events.o' failed 64 make[1]: *** [/var/lib/dkms/lttng-modules/2.8.0/build/lttng-events.o] Error 1 65 Makefile:1382: recipe for target '_module_/var/lib/dkms/lttng-modules/2.8.0/build' failed 66 make: *** [_module_/var/lib/dkms/lttng-modules/2.8.0/build] Error 2 58 LTTNG_UBUNTU_VERSION_CODE &lt; \ 59 ^ 60 /var/lib/dkms/lttng-modules/2.8.0/build/wrapper/page_alloc.h:71:5: note: in expansion of macro ‘LTTNG_UBUNTU_KERNEL_RANGE’ 61 &amp;&amp; LTTNG_UBUNTU_KERNEL_RANGE(3,13,11,50, 3,14,0,0)) 62 ^ 63 scripts/Makefile.build:257: recipe for target '/var/lib/dkms/lttng-modules/2.8.0/build/lttng-events.o' failed 64 make[1]: *** [/var/lib/dkms/lttng-modules/2.8.0/build/lttng-events.o] Error 1 65 Makefile:1382: recipe for target '_module_/var/lib/dkms/lttng-modules/2.8.0/build' failed 66 make: *** [_module_/var/lib/dkms/lttng-modules/2.8.0/build] Error 2 67 make: Leaving directory '/usr/src/linux-headers-3.19.8-031908-generic' ⮀ NORMAL ⮀ ⭤ /var/lib/dkms/lttng-modules/2.8.0/build/make.log ⮀ ⮂ unix ⮃ utf-8 ⮃ no ft ⮂ 100% ⮂ ⭡ 67:27 修改后 log： 1234567891011121314151617181920212223242526272829303132333435363738394041424344sunyongfeng@openswitch-OptiPlex-380:~/Downloads$ sudo dpkg -i linux-image-3.19.8-031908-generic_3.19.8-031908.201505110938_amd64.deb (Reading database ... 387757 files and directories currently installed.)Preparing to unpack linux-image-3.19.8-031908-generic_3.19.8-031908.201505110938_amd64.deb ...Done.Unpacking linux-image-3.19.8-031908-generic (3.19.8-031908.201505110938) over (3.19.8-031908.201505110938) ...Examining /etc/kernel/postrm.d .run-parts: executing /etc/kernel/postrm.d/initramfs-tools 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericrun-parts: executing /etc/kernel/postrm.d/zz-update-grub 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericSetting up linux-image-3.19.8-031908-generic (3.19.8-031908.201505110938) ...Running depmod.update-initramfs: deferring update (hook will be called later)Not updating initrd symbolic links since we are being updated/reinstalled (3.19.8-031908.201505110938 was configured last, according to dpkg)Not updating image symbolic links since we are being updated/reinstalled (3.19.8-031908.201505110938 was configured last, according to dpkg)Examining /etc/kernel/postinst.d.run-parts: executing /etc/kernel/postinst.d/apt-auto-removal 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericrun-parts: executing /etc/kernel/postinst.d/dkms 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericrun-parts: executing /etc/kernel/postinst.d/initramfs-tools 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericupdate-initramfs: Generating /boot/initrd.img-3.19.8-031908-genericrun-parts: executing /etc/kernel/postinst.d/pm-utils 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericrun-parts: executing /etc/kernel/postinst.d/unattended-upgrades 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericrun-parts: executing /etc/kernel/postinst.d/update-notifier 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericrun-parts: executing /etc/kernel/postinst.d/zz-update-grub 3.19.8-031908-generic /boot/vmlinuz-3.19.8-031908-genericGenerating grub configuration file ...Warning: Setting GRUB_TIMEOUT to a non-zero value when GRUB_HIDDEN_TIMEOUT is set is no longer supported.Found linux image: /boot/vmlinuz-4.4.0-72-genericFound initrd image: /boot/initrd.img-4.4.0-72-genericFound linux image: /boot/vmlinuz-4.4.0-71-genericFound initrd image: /boot/initrd.img-4.4.0-71-genericFound linux image: /boot/vmlinuz-4.4.0-70-genericFound initrd image: /boot/initrd.img-4.4.0-70-genericFound linux image: /boot/vmlinuz-4.4.0-66-genericFound initrd image: /boot/initrd.img-4.4.0-66-genericFound linux image: /boot/vmlinuz-4.4.0-64-genericFound initrd image: /boot/initrd.img-4.4.0-64-genericFound linux image: /boot/vmlinuz-4.4.0-45-genericFound initrd image: /boot/initrd.img-4.4.0-45-genericFound linux image: /boot/vmlinuz-3.19.8-031908-genericFound initrd image: /boot/initrd.img-3.19.8-031908-genericFound memtest86+ image: /boot/memtest86+.elfFound memtest86+ image: /boot/memtest86+.bindonesunyongfeng@openswitch-OptiPlex-380:~/Downloads$ 修改 grub详见 Set “older” kernel as default grub entry 中 DaimyoKirby 的回答。 备份 grub 配置，sudo cp /etc/default/grub /etc/default/grub.bak 修改 grub 配置，sudo vi /etc/default/grub，将 GRUB_DEFAULT=0 改为 GRUB_DEFAULT=&quot;Advanced options for Ubuntu&gt;Ubuntu, with Linux 3.19.8-031908-generic&quot;。 Advanced options for Ubuntu 表示 grub 的第一级菜单 &gt; 表示接下一级菜单 Ubuntu, with Linux 3.19.8-031908-generic 表示第二级菜单 以上菜单都可在 /boot/grub/grub.cfg 中指到原始字符 更新 grub，sudo update-grub 确认修订成功更新 grub 后，sudo shutdown -r 0 重启设备，重新登陆设备，通过 uname -a 确认内核已更新为旧版内核。 12sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory$ uname -aLinux openswitch-OptiPlex-380 3.19.8-031908-generic #201505110938 SMP Mon May 11 13:39:59 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
        <tag>grub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[p4factory使用记录]]></title>
    <url>%2F201704%2Fnetworks%2Fp4%2Fp4factory.html</url>
    <content type="text"><![CDATA[问题记录1234567891011sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory$ git submodule update --init --recursiveCloning into 'submodules/infra'...Permission denied (publickey).fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists.fatal: clone of 'git@github.com:floodlight/infra' into submodule path 'submodules/infra' failedFailed to recurse into submodule path 'submodules/p4ofagent/submodules/indigo/submodules/bigcode'Failed to recurse into submodule path 'submodules/p4ofagent/submodules/indigo'Failed to recurse into submodule path 'submodules/p4ofagent' 安装 ptfpython setup --install --prefix=$P4HOME/install 1234567891011121314151617181920212223242526You are attempting to install a package to a directory that is noton PYTHONPATH and which Python does not read ".pth" files from. Theinstallation directory you specified (via --install-dir, --prefix, orthe distutils default setting) was: /usr/local/lib/python2.7/site-packages/and your PYTHONPATH environment variable currently contains: ''Here are some of your options for correcting the problem:* You can choose a different installation directory, i.e., one that is on PYTHONPATH or supports .pth files* You can add the installation directory to the PYTHONPATH environment variable. (It must then also be on PYTHONPATH whenever you run Python and want to use the package(s) you are installing.)* You can set up the installation directory to support ".pth" files by using one of the approaches described here: http://packages.python.org/distribute/easy_install.html#custom-installation-locationsPlease make the appropriate changes for your system and try again. 解决：export switch configure 失败pdfixed 头文件找不到 bmv2 configure 时要加上 pdfixed]]></content>
      <categories>
        <category>p4</category>
      </categories>
      <tags>
        <tag>p4</tag>
        <tag>int</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux虚拟网络设备 TUN/TAP 与 VETH pair 的差异]]></title>
    <url>%2F201704%2Fnetworks%2Ftuntap_veth.html</url>
    <content type="text"><![CDATA[近来随着 P4 的发展，软件交换机在 ovs 之后又热了起来。软件交换机，顾名思义纯软件实现交换功能，相对于传统交换机的物理端口，软件交换机的端口一般采用虚拟端口的形式。本文探索常用的虚拟网络设备 tuntap 与 veth。 TUN/TAP基本概念 A gateway to userspace. TUN 和 TAP 设备是 Linux 内核虚拟网络设备，纯软件实现。TUN（TUNnel）设备模拟网络层设备，处理三层报文如 IP 报文。TAP 设备模拟链路层设备，处理二层报文，比如以太网帧。TUN 用于路由，而 TAP 用于创建网桥。OS 向连接到 TUN/TAP 设备的用户空间程序发送报文；用户空间程序可像往物理口发送报文那样向 TUN/TAP 口发送报文，在这种情况下，TUN/TAP 设备发送（或注入）报文到 OS 协议栈，就像报文是从物理口收到一样。 链接:TUN/TAP: The user-space application/VM can read or write an ethernet frame to the tap interface and it would reach the host kernel, where it would be handled like any other ethernet frame that reached the kernel via physical (e.g. eth0) ports. You can potentially add it to a software-bridge (e.g. linux-bridge) 如何工作TUN/TAP 为简单的点对点或以太网设备，不是从物理介质接收数据包，而是从用户空间程序接收；不是通过物理介质发送数据包，而将它们发送到用户空间程序。假设您在 tap0 上配置 IPX，那么每当内核向 tap0 发送一个 IPX 数据包时，它将传递给应用程序（例如 VTun）。应用程序加密、压缩数据包，并通过 TCP/UDP 发送到对端。对端的应用程序解压缩、解密接收的数据包，并将数据包写入 TAP 设备，然后内核处理数据包，就像该数据包来自真实的物理设备。 用途用于加密、VPN、隧道、虚拟机等等（encryption, VPN, tunneling,virtual machines）。 参考资料 kernel doc tuntap virtual networking devices in linux Linux Networking Explained [wikipedia tuntap] veth pair基本概念 Virtual Ethernet CableBidirectional FIFOOften used to cross namespaces 虚拟以太网电缆，注意，Cable，不是 vNIC。使用双向有名管道实现。常用于不同 namespace 之间的通信，即 namespace 数据穿越或容器数据穿越。 由于是 Cable，所以必须以对的形式出现。一个配置样例，链接 链接:VETH: Typically used when you are trying to connect two entities which would want to “get hold of” (for lack of better phrase) an interface to forward/receive frames. These entities could be containers/bridges/ovs-switch etc. Say you want to connect a docker/lxc container to OVS. You can create a veth pair and push the first interface to the docker/lxc (say, as a phys interface) and push the other interface to OVS. You cannot do this with TAP. 如何工作向 veth pair 的一端输入数据，veth pair 转换请求发送报文为需要接收处理的报文，将其注入内核协议栈，在另一端能读到此数据。 用途如上所述，常用于不同命名空间之间进行数据穿越。 参考资料 Linux 上的基础网络设备详解 Linux Networking Explained]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>networks</tag>
        <tag>tuntap</tag>
        <tag>veth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行压缩 & 解压缩 - tar]]></title>
    <url>%2F201704%2Fshell%2Ftar.html</url>
    <content type="text"><![CDATA[tar 为 GNU 打包工具，目前在标准 Linux 发行版上已经整合进压缩/解压缩工具 gzip、bzip2 和 xz。 打包，后缀为 .tar，称为 tarfile 打包 + 压缩，后缀为 .tar.gz、.tar.bz2、.tar.xz，称为 tarball。此为 linux 最常用的压缩、解压缩方式。 windows 中常见的压缩包有 .zip 和 .rar，可通过 unzip 和 unrar 两个工具进行解压。通过 apt-get install 安装即可。 压缩 gzip，tar -zcvf xxx.tar.gz ./* bzip2，tar -jcvf xxx.tar.bz2 ./* xz，tar -Jcvf xxx.tar.xz ./* 压缩时，排除某个目录、某个后续或某个文件，--exclude dir --exclude *.jpg --exclude a_dir/sb.bin 压缩时，压缩的源目录和压缩包同一个目录的情况下，通过 --warning=no-file-changed 去除告警。 解压缩，tar -xvf xxx.tar.gz 查看压缩包内容，tar -tf xxx.tar.gz 解压到特定目录，tar -xvf xxx.tar.gz -C /your/dir/ 以 p4factory 为例，log 如下。 压缩前大小： 12sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory$ du -hd 07.0M . 压缩： 12345678910111213141516sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory$ sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory$ tar -zcvf p4factory.tar.gz ./*./apps/./apps/int/./apps/int/monitor/./apps/int/monitor/preprocessor.py./apps/int/monitor/monitor.py./apps/int/monitor/client_msg_handler.py./apps/int/monitor/topology.json./apps/int/monitor/client/./apps/int/monitor/client/index.html./apps/int/monitor/client/styles/./apps/int/monitor/client/styles/main.css./apps/int/monitor/client/lib/./apps/int/monitor/client/lib/cola.v1.min.js... 压缩后大小： 12sunyongfeng@openswitch-OptiPlex-380:~/workshop/p4factory$ ls -alh p4factory.tar.gz -rw-rw-r-- 1 sunyongfeng sunyongfeng 771K 4月 17 14:26 p4factory.tar.gz 解压过程： 123456789101112131415sunyongfeng@openswitch-OptiPlex-380:~/workshop/test-tar$ tar xvf ../p4factory/p4factory.tar.gz ./apps/./apps/int/./apps/int/monitor/./apps/int/monitor/preprocessor.py./apps/int/monitor/monitor.py./apps/int/monitor/client_msg_handler.py./apps/int/monitor/topology.json./apps/int/monitor/client/./apps/int/monitor/client/index.html./apps/int/monitor/client/styles/./apps/int/monitor/client/styles/main.css./apps/int/monitor/client/lib/./apps/int/monitor/client/lib/cola.v1.min.js...]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[P4资料集]]></title>
    <url>%2F201704%2Fnetworks%2Fp4%2Fcollection.html</url>
    <content type="text"><![CDATA[Meetings workshop 1，2015.6.4 workshop 2，2015.11.18 workshop 2016，2016.5.24 GNTC 2016 P4 workshop, 2016.12.8 Papers P4: Programming Protocol-Independent Packet ProcessorsPat Bosshart, Dan Daly, Glen Gibb, Martin Izzard, Nick McKeown, Jennifer Rexford, Cole Schlesinger, Dan Talayco, Amin Vahdat, George Varghese, David WalkerACM Sigcomm Computer Communications Review (CCR). Volume 44, Issue #3 (July 2014)8 pages pdf , Chinese Edition pdf Millions of Little Minions: Using Packets for Low Latency Network Programming and VisibilityVimalkumar Jeyakumar, Mohammad Alizadeh, Yilong Geng, Changhoon Kim, David Mazières, Stanford University, Cisco Systems, Barefoot NetworksSigcomm 201412 pages pdf , slides , website Tiny Packet Programmssame as Tiny Packet Programs for low-latency network control and monitoring, HotNets 2013 Towards Programmable Packet SchedulingAnirudh Sivamaran, Suvinay Subramanian, Anurag Agrawal, Sharad Chole, Shang-Tse Chuang, Tom Edsall, Mohammad Alizadeh, Sachin Katti, Nick McKeown, Hari BalakrishnanHotNets’ 15, Philadelphia, PA7 pages pdf Same as: Programmable Packet Scheduling at Line Rate at SIGCOMM 2016，14 pages， pdf , slide Forwarding metamorphosis: fast programmable match-action processing in hardware for SDNPat Bosshart, Glen Gibb, Hun-Seok Kim, George Varghese, Nick McKeown, Martin Izzard, Fernando Mujica, Mark HorowitzACM SIGCOMM 201312 pages pdf ClickNP Highly Flexible and High Performance Network Processing with Reconfigurable HardwareBojie Li (USTC / Microsoft Research), Kun Tan (Microsoft Research), Layong (Larry) Luo (Microsoft), Yanqing Peng (SJTU / Microsoft Research), Renqian Luo (USTC / Microsoft Research), Ningyi Xu (Microsoft Research), Yongqiang Xiong (Microsoft Research), Peng Cheng (Microsoft Research), Enhong Chen (USTC)ACM SIGCOMM 201614 pages pdf , slide A Cloud-Scale Acceleration ArchitectureAdrian M. Caulfield (Microsoft), Eric S. Chung (Microsoft), Andrew Putnam (Microsoft), Hari Angepat (Microsoft), Jeremy Fowers (Microsoft), Michael Haselman (Microsoft), Stephen Heil (Microsoft), Matt Humphrey (Microsoft), Puneet Kaur (Microsoft), Joo-Young Kim (Microsoft), Daniel Lo (Microsoft), Todd Massengill (Microsoft), Kalin Ovtcharov (Microsoft), Michael Papamichael (Microsoft), Lisa Woods (Microsoft), Sitaram Lanka (Microsoft), Derek Chiou (Microsoft), Doug Burger (Microsoft)The 49th Annual IEEE/ACM International Symposium on Microarchitecture, 2016MICRO-49, October 15-19, 2016, Taipei, Taiwan13 pages pdf , News Universal Packet SchedulingRadhika Mittal, Rachit Agarwal, and Sylvia Ratnasamy, University of California, Berkeley; Scott Shenker, University of California, Berkeley, and International Computer Science InstituteNSDI 201622 pages pdf , slide Compiling Packet Programs to Reconfigurable SwitchesLavanya Jose, Lisa Yan, George Varghese, Nick McKeownNSDI ‘15, Oakland, CA13 pages pdf Packet Transactions: High-Level Programming for Line-Rate SwitchesAnirudh Sivaraman (MIT CSAIL), Alvin Cheung (University of Washington, Seattle), Mihai Budiu (VMWare Research), Changhoon Kim (Barefoot Networks), Mohammad Alizadeh (MIT CSAIL), Hari Balakrishnan (MIT CSAIL), George Varghese (Microsoft Research), Nick McKeown (Stanford University), Steve Licking (Barefoot Networks)IN ACM SIGCOMM 201614 pages pdf , slide HULA: Scalable load balancing using programmable data-planeNaga Katta, Mukesh Hira, Changhoon Kim, Anirudh Sivaraman, and Jennifer Rexfordin Symposium on SDN Research, March 2016.12 pages pdf , slide PISCES: A programmable, protocol-independent software switchMuhammad Shahbaz, Sean Choi, Ben Pfaff, Changhoon Kim, Nick Feamster, Nick McKeown, Jennifer RexfordACM SIGCOMM, August 201614 pages pdf , slide DC.p4-Programming the Forwarding Plane of a Data Center SwitchAnirudh Sivaraman(MIT), Changhoon Kim(Barefoot Networks), Ramkumar Krishnamoorthy(Barefoot Networks), Advait Dixit(Barefoot Networks), Mihai Budiu(Barefoot Networks)SOSR ‘15 Proceedings of the 1st ACM SIGCOMM Symposium on Software Defined Networking Research8 pages pdf FlowRadar: A Better NetFlow for Data CentersYuliang Li and Rui Miao, University of Southern California; Changhoon Kim, Barefoot Networks; Minlan Yu, University of Southern CaliforniaNSDI 201615 pages pdf , slide Automatically verifying reachability and well-formedness in P4 NetworksNuno P. Lopes, Nikolaj Bjørner, George Varghese, Andrey Rybalchenko, Microsoft Research; Nick McKeown, Stanford University; Dan Talayco, Ketos Inc.13 pages pdf Policy Routing using Process-Level IdentiﬁersOliver Michel, Eric Keller, University of Colorado Boulder2016 IEEE International Conference on Cloud Engineering Workshop (IC2EW)6 pages pdf Paxos Made Switch-yHuynh Tu Dang, Marco Canini, Fernando Pedone, Robert Soule, Universita della Svizzera italiana, Universite catholique de LouvainACM SIGCOMM Computer Communication Review, Volume 46, Number 2, April 20166 pages pdf ,website NetPaxos OpenState: Programming Platform-independent Stateful OpenFlow Applications Inside the SwitchG. Bianchi, M. Bonola, A. Capone, C. Cascone, Univ. Roma Tor Vergata, Politecnico di MilanoACM SIGCOMM Computer Communication Review, vol. 44, no. 2, pp. 44–51, 20147 pages pdf website OpenState SDN project projects Early DDoS Detection P4FPGA Project]]></content>
      <categories>
        <category>p4</category>
      </categories>
      <tags>
        <tag>p4</tag>
        <tag>dataplane</tag>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dokuwiki 支持百度统计]]></title>
    <url>%2F201704%2Fadministrator%2Fdokuwiki%2Fsuppport_baidu_tongji.html</url>
    <content type="text"><![CDATA[dokuwiki 支持 plugin:googleanalytics，template bootstrap3 模板 也支持 google analytics。不过众所周知的原因，天朝内无法使用 google 的服务，因此考虑如何支持百度统计。 百度统计添加新网站后，得到统计代码： 123456789&lt;script&gt;var _hmt = _hmt || [];(function() &#123; var hm = document.createElement("script"); hm.src = "https://hm.baidu.com/hm.js?xxxxxxxxxxxxxxxxxxxxxxxxxx"; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);&#125;)();&lt;/script&gt; 百度官方建议的代码安装步骤： 12341. 请将代码添加到网站全部页面的&lt;/head&gt;标签前。2. 建议在header.htm类似的页头模板页面中安装，以达到一处安装，全站皆有的效果。3. 如需在JS文件中调用统计分析代码，请直接去掉以下代码首尾的，&lt;script type="text/javascript"&gt;与&lt;/script&gt;后，放入JS文件中即可。如果代码安装正确，一般20分钟后，可以查看网站分析数据。 因此本文主要考虑如何将百度统计代码插入到 &lt;head&gt; 标签中。 本文使用 template:bootstrap3 ，该模板的 HTML Hooks 一节提示可通过 meta.html 添加内容到 &lt;head&gt; 内部。 Inside the HTML &lt;head&gt;, use this to add additional styles or metaheaders 不过经过尝试在 /var/www/dokuwiki/lib/tpl/bootstrap3/extra/hooks/meta.html 加入统计代码，点开网页看源码，并未查看到统计代码。考虑到该模板支持 google analytics，因此直接以 &lt;head&gt; 为关键字搜索： 1234sunyongfeng@ubuntu:/var/www/dokuwiki/lib/tpl/bootstrap3$ grep -r "&lt;head&gt;" mediamanager.php:&lt;head&gt;main.php:&lt;head&gt;detail.php:&lt;head&gt; 从文件名可直接排队 mediamanager.php，查看 main.php 和 detail.php 及 dokuwiki 某个页面的源码，发现 main.php 为想要的目标文件。 main.php 部分内容： 123456789101112131415161718192021222324252627282930/** * DokuWiki Bootstrap3 Template * * @link http://dokuwiki.org/template:bootstrap3 * @author Giuseppe Di Terlizzi &lt;giuseppe.diterlizzi@gmail.com&gt; * @license GPL 2 (http://www.gnu.org/licenses/gpl.html) */if (!defined('DOKU_INC')) die(); // must be run from within DokuWiki@require_once(dirname(__FILE__).'/tpl_functions.php'); // include hook for template functionsinclude_once(dirname(__FILE__).'/tpl_global.php'); // Include template global variablesheader('X-UA-Compatible: IE=edge,chrome=1');?&gt;&lt;!DOCTYPE html&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="&lt;?php echo $conf['lang'] ?&gt;" lang="&lt;?php echo $conf['lang'] ?&gt;" dir="&lt;?php echo $lang['direction'] ?&gt;" class="no-js"&gt;&lt;head&gt; &lt;meta charset="UTF-8" /&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge" /&gt; &lt;title&gt;&lt;?php echo bootstrap3_page_browser_title() ?&gt;&lt;/title&gt; &lt;script&gt;(function(H)&#123;H.className=H.className.replace(/\bno-js\b/,'js')&#125;)(document.documentElement)&lt;/script&gt; &lt;meta name="viewport" content="width=device-width,initial-scale=1" /&gt; &lt;?php echo tpl_favicon(array('favicon', 'mobile')) ?&gt; &lt;?php tpl_includeFile('meta.html') ?&gt; &lt;?php tpl_metaheaders() ?&gt; &lt;?php bootstrap3_google_analytics() ?&gt; &lt;!--[if lt IE 9]&gt; &lt;script type="text/javascript" src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt;&lt;/head&gt; 某个 wiki 页面的源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh" lang="zh" dir="ltr" class="no-js"&gt;&lt;head&gt; &lt;meta charset="UTF-8" /&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge" /&gt; &lt;title&gt;wiki:markdown语法 [交换机技术平台部 wiki]&lt;/title&gt; &lt;script&gt;(function(H)&#123;H.className=H.className.replace(/\bno-js\b/,'js')&#125;)(document.documentElement)&lt;/script&gt; &lt;meta name="viewport" content="width=device-width,initial-scale=1" /&gt; &lt;link rel="shortcut icon" href="/dokuwiki/lib/tpl/bootstrap3/images/favicon.ico" /&gt;&lt;link rel="apple-touch-icon" href="/dokuwiki/lib/tpl/bootstrap3/images/apple-touch-icon.png" /&gt; &lt;meta name="generator" content="DokuWiki"/&gt;&lt;meta name="robots" content="index,follow"/&gt;&lt;meta name="keywords" content="wiki,markdown语法"/&gt;&lt;link type="text/css" rel="stylesheet" href="/dokuwiki/lib/tpl/bootstrap3/assets/bootstrap/united/bootstrap.min.css"/&gt;&lt;link type="text/css" rel="stylesheet" href="/dokuwiki/lib/tpl/bootstrap3/assets/fonts/united.fonts.css"/&gt;&lt;link rel="search" type="application/opensearchdescription+xml" href="/dokuwiki/lib/exe/opensearch.php" title="交换机技术平台部 wiki"/&gt;&lt;link rel="start" href="/dokuwiki/"/&gt;&lt;link rel="contents" href="/dokuwiki/doku.php/wiki:markdown语法?do=index" title="网站地图"/&gt;&lt;link rel="alternate" type="application/rss+xml" title="最近更改" href="/dokuwiki/feed.php"/&gt;&lt;link rel="alternate" type="application/rss+xml" title="当前命名空间" href="/dokuwiki/feed.php?mode=list&amp;amp;ns=wiki"/&gt;&lt;link rel="edit" title="编辑本页" href="/dokuwiki/doku.php/wiki:markdown语法?do=edit"/&gt;&lt;link rel="alternate" type="text/html" title="纯HTML" href="/dokuwiki/doku.php/wiki:markdown%E8%AF%AD%E6%B3%95?do=export_xhtml"/&gt;&lt;link rel="alternate" type="text/plain" title="Wiki Markup 语言" href="/dokuwiki/doku.php/wiki:markdown%E8%AF%AD%E6%B3%95?do=export_raw"/&gt;&lt;link rel="canonical" href="http://172.18.111.192:10090/dokuwiki/doku.php/wiki:markdown语法"/&gt;&lt;link rel="stylesheet" type="text/css" href="/dokuwiki/lib/exe/css.php?t=bootstrap3&amp;amp;tseed=397ac3e12611e6079f8bfb104ef97c20"/&gt;&lt;link type="text/css" rel="stylesheet" href="/dokuwiki/lib/tpl/bootstrap3/assets/font-awesome/css/font-awesome.min.css"/&gt;&lt;!--[if gte IE 9]&gt;&lt;!--&gt;&lt;script type="text/javascript"&gt;/*&lt;![CDATA[*/var NS='wiki';var SIG=' --- //[[sunyongfeng@ruijie.com.cn|孙勇峰]] 2017/04/14 22:20//';var JSINFO = &#123;"id":"wiki:markdown\u8bed\u6cd5","namespace":"wiki","isadmin":1,"isauth":1,"bootstrap3":&#123;"mode":"show","config":&#123;"collapsibleSections":0,"sidebarOnNavbar":1,"tagsOnTop":1,"tocAffix":1,"tocCollapseOnScroll":1,"tocCollapsed":0,"showSemanticPopup":0&#125;&#125;&#125;;/*!]]&gt;*/&lt;/script&gt;&lt;script type="text/javascript" charset="utf-8" src="/dokuwiki/lib/exe/jquery.php?tseed=23f888679b4f1dc26eef34902aca964f"&gt;&lt;/script&gt;&lt;script type="text/javascript" charset="utf-8" src="/dokuwiki/lib/exe/js.php?t=bootstrap3&amp;amp;tseed=397ac3e12611e6079f8bfb104ef97c20"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="/dokuwiki/lib/tpl/bootstrap3/assets/bootstrap/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="/dokuwiki/lib/tpl/bootstrap3/assets/anchorjs/anchor.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="/dokuwiki/lib/tpl/bootstrap3/assets/bootstrap/js/bootstrap-hover-dropdown.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript"&gt;/*&lt;![CDATA[*/jQuery(document).ready(function() &#123; jQuery('body').scrollspy(&#123; target: '#dw__toc', offset: 30 &#125;);jQuery("#dw__toc").affix(&#123; offset: &#123; top: (jQuery("main").position().top), bottom: (jQuery(document).height() - jQuery("main").height()) &#125; &#125;);jQuery(document).trigger('bootstrap3:anchorjs'); &#125;);/*!]]&gt;*/&lt;/script&gt;&lt;!--&lt;![endif]--&gt;&lt;style type="text/css"&gt;@media screen &#123; body &#123; padding-top: 20px; &#125; #dw__toc.affix &#123; top: 10px; position: fixed !important; &#125; #dw__toc .nav .nav .nav &#123; display: none; &#125;&#125;&lt;/style&gt; &lt;!--[if lt IE 9]&gt; &lt;script type="text/javascript" src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt;&lt;/head&gt; 故在 main.php 的 &lt;/head&gt; 前添加百度代码。重新加载 wiki 页面，发现百度统计代码已添加。过几分钟后，在百度统计网页上，可以看到统计信息。 修改后的 main.php： 123456789101112131415161718192021222324252627282930313233343536373839/** * DokuWiki Bootstrap3 Template * * @link http://dokuwiki.org/template:bootstrap3 * @author Giuseppe Di Terlizzi &lt;giuseppe.diterlizzi@gmail.com&gt; * @license GPL 2 (http://www.gnu.org/licenses/gpl.html) */if (!defined('DOKU_INC')) die(); // must be run from within DokuWiki@require_once(dirname(__FILE__).'/tpl_functions.php'); // include hook for template functionsinclude_once(dirname(__FILE__).'/tpl_global.php'); // Include template global variablesheader('X-UA-Compatible: IE=edge,chrome=1');?&gt;&lt;!DOCTYPE html&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="&lt;?php echo $conf['lang'] ?&gt;" lang="&lt;?php echo $conf['lang'] ?&gt;" dir="&lt;?php echo $lang['direction'] ?&gt;" class="no-js"&gt;&lt;head&gt; &lt;meta charset="UTF-8" /&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge" /&gt; &lt;title&gt;&lt;?php echo bootstrap3_page_browser_title() ?&gt;&lt;/title&gt; &lt;script&gt;(function(H)&#123;H.className=H.className.replace(/\bno-js\b/,'js')&#125;)(document.documentElement)&lt;/script&gt; &lt;meta name="viewport" content="width=device-width,initial-scale=1" /&gt; &lt;?php echo tpl_favicon(array('favicon', 'mobile')) ?&gt; &lt;?php tpl_includeFile('meta.html') ?&gt; &lt;?php tpl_metaheaders() ?&gt; &lt;?php bootstrap3_google_analytics() ?&gt; &lt;!--[if lt IE 9]&gt; &lt;script type="text/javascript" src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;script&gt; var _hmt = _hmt || []; (function() &#123; var hm = document.createElement("script"); hm.src = "https://hm.baidu.com/hm.js?b3ec3db35b5308953eb2e2d1ba02d3c0"; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s); &#125;)(); &lt;/script&gt;&lt;/head&gt; 修改后的 wiki 页面源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;!DOCTYPE html&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh" lang="zh" dir="ltr" class="no-js"&gt;&lt;head&gt; &lt;meta charset="UTF-8" /&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge" /&gt; &lt;title&gt;wiki:markdown语法 [交换机技术平台部 wiki]&lt;/title&gt; &lt;script&gt;(function(H)&#123;H.className=H.className.replace(/\bno-js\b/,'js')&#125;)(document.documentElement)&lt;/script&gt; &lt;meta name="viewport" content="width=device-width,initial-scale=1" /&gt; &lt;link rel="shortcut icon" href="/dokuwiki/lib/tpl/bootstrap3/images/favicon.ico" /&gt;&lt;link rel="apple-touch-icon" href="/dokuwiki/lib/tpl/bootstrap3/images/apple-touch-icon.png" /&gt; &lt;meta name="generator" content="DokuWiki"/&gt;&lt;meta name="robots" content="index,follow"/&gt;&lt;meta name="keywords" content="wiki,markdown语法"/&gt;&lt;link type="text/css" rel="stylesheet" href="/dokuwiki/lib/tpl/bootstrap3/assets/bootstrap/united/bootstrap.min.css"/&gt;&lt;link type="text/css" rel="stylesheet" href="/dokuwiki/lib/tpl/bootstrap3/assets/fonts/united.fonts.css"/&gt;&lt;link rel="search" type="application/opensearchdescription+xml" href="/dokuwiki/lib/exe/opensearch.php" title="交换机技术平台部 wiki"/&gt;&lt;link rel="start" href="/dokuwiki/"/&gt;&lt;link rel="contents" href="/dokuwiki/doku.php/wiki:markdown语法?do=index" title="网站地图"/&gt;&lt;link rel="alternate" type="application/rss+xml" title="最近更改" href="/dokuwiki/feed.php"/&gt;&lt;link rel="alternate" type="application/rss+xml" title="当前命名空间" href="/dokuwiki/feed.php?mode=list&amp;amp;ns=wiki"/&gt;&lt;link rel="edit" title="编辑本页" href="/dokuwiki/doku.php/wiki:markdown语法?do=edit"/&gt;&lt;link rel="alternate" type="text/html" title="纯HTML" href="/dokuwiki/doku.php/wiki:markdown%E8%AF%AD%E6%B3%95?do=export_xhtml"/&gt;&lt;link rel="alternate" type="text/plain" title="Wiki Markup 语言" href="/dokuwiki/doku.php/wiki:markdown%E8%AF%AD%E6%B3%95?do=export_raw"/&gt;&lt;link rel="canonical" href="http://172.18.111.192:10090/dokuwiki/doku.php/wiki:markdown语法"/&gt;&lt;link rel="stylesheet" type="text/css" href="/dokuwiki/lib/exe/css.php?t=bootstrap3&amp;amp;tseed=397ac3e12611e6079f8bfb104ef97c20"/&gt;&lt;link type="text/css" rel="stylesheet" href="/dokuwiki/lib/tpl/bootstrap3/assets/font-awesome/css/font-awesome.min.css"/&gt;&lt;!--[if gte IE 9]&gt;&lt;!--&gt;&lt;script type="text/javascript"&gt;/*&lt;![CDATA[*/var NS='wiki';var SIG=' --- //[[sunyongfeng@ruijie.com.cn|孙勇峰]] 2017/04/14 22:20//';var JSINFO = &#123;"id":"wiki:markdown\u8bed\u6cd5","namespace":"wiki","isadmin":1,"isauth":1,"bootstrap3":&#123;"mode":"show","config":&#123;"collapsibleSections":0,"sidebarOnNavbar":1,"tagsOnTop":1,"tocAffix":1,"tocCollapseOnScroll":1,"tocCollapsed":0,"showSemanticPopup":0&#125;&#125;&#125;;/*!]]&gt;*/&lt;/script&gt;&lt;script type="text/javascript" charset="utf-8" src="/dokuwiki/lib/exe/jquery.php?tseed=23f888679b4f1dc26eef34902aca964f"&gt;&lt;/script&gt;&lt;script type="text/javascript" charset="utf-8" src="/dokuwiki/lib/exe/js.php?t=bootstrap3&amp;amp;tseed=397ac3e12611e6079f8bfb104ef97c20"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="/dokuwiki/lib/tpl/bootstrap3/assets/bootstrap/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="/dokuwiki/lib/tpl/bootstrap3/assets/anchorjs/anchor.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" src="/dokuwiki/lib/tpl/bootstrap3/assets/bootstrap/js/bootstrap-hover-dropdown.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript"&gt;/*&lt;![CDATA[*/jQuery(document).ready(function() &#123; jQuery('body').scrollspy(&#123; target: '#dw__toc', offset: 30 &#125;);jQuery("#dw__toc").affix(&#123; offset: &#123; top: (jQuery("main").position().top), bottom: (jQuery(document).height() - jQuery("main").height()) &#125; &#125;);jQuery(document).trigger('bootstrap3:anchorjs'); &#125;);/*!]]&gt;*/&lt;/script&gt;&lt;!--&lt;![endif]--&gt;&lt;style type="text/css"&gt;@media screen &#123; body &#123; padding-top: 20px; &#125; #dw__toc.affix &#123; top: 10px; position: fixed !important; &#125; #dw__toc .nav .nav .nav &#123; display: none; &#125;&#125;&lt;/style&gt; &lt;!--[if lt IE 9]&gt; &lt;script type="text/javascript" src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;script&gt; var _hmt = _hmt || []; (function() &#123; var hm = document.createElement("script"); hm.src = "https://hm.baidu.com/hm.js?b3ec3db35b5308953eb2e2d1ba02d3c0"; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s); &#125;)(); &lt;/script&gt;&lt;/head&gt;]]></content>
      <categories>
        <category>administrator</category>
      </categories>
      <tags>
        <tag>administrator</tag>
        <tag>dokuwiki</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个灰常灰常简单的 HTTP server]]></title>
    <url>%2F201704%2Fadministrator%2Fpython_SimpleHTTPServer.html</url>
    <content type="text"><![CDATA[目标 release 一个版本，该版本含一个 800MB 左右的 vagrant box。思前想后都觉得不方便，因此想搭个 http server，仅供公司内部使用，类似 hfs。然后在这里看到了最佳解决方案 Python SimpleHTTPServer。 使用方式： 选择一个目录做为根目录，在该目录下执行 python -m SimpleHTTPServer [端口号]，端口号默认为 8000。 在浏览器上输入 http://192.168.204.167:8000（将 8000 替换为所使用的端口号），就可以在网页上进行操作了。 引自 coolshell 非常简单的PYTHON HTTP服务 如果你的目录下有一个叫 index.html 的文件名的文件，那么这个文件就会成为一个默认页，如果没有这个文件，那么，目录列表就会显示出来。 这里以目录列表为例： 123456789sunyongfeng@ubuntu:~/pyhttpfs$ tree.└── box └── 0.9.0 └── origin32.box2 directories, 1 filessunyongfeng@ubuntu:~/pyhttpfs$ python -m SimpleHTTPServer 20090Serving HTTP on 0.0.0.0 port 20090 ... 在浏览器上：]]></content>
      <categories>
        <category>administrator</category>
      </categories>
      <tags>
        <tag>administrator</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用的 dokuwiki plugin]]></title>
    <url>%2F201704%2Fadministrator%2Fdokuwiki%2Fplugin.html</url>
    <content type="text"><![CDATA[Markdown 语法支持 插件，plugin:Markdowku，该插件可直接在 wiki 页上写 markdown 语法文本，不需要特殊处理。 用法，对比 plugin:markdownextra 需要额外配置 Front Matter, Markdowku 可直接在 wiki 编辑页面使用 markdown 语法，不需要特殊的命名或语法块。 评论区 插件，plugin:discussion 用法，~~DISCUSSION~~ ，插入该语句到 wiki 中，即可在 wiki 内容后添加评论区。 配置，管理-&gt;配置管理-&gt;Discussion，比较有用的配置： 订阅评论区 通知版主有新评论 允许未注册用户评论 可通过 wiki 语法评论 导航indexmenu默认在侧表栏显示2级目录，其他层级点击显示。 在 sidebar 页面输入： 1&#123;&#123;indexmenu&gt;..#2|navbar nocookie&#125;&#125; simplenavi目录树好看，不过响应很慢。 pdf 阅读器 插件，plugin:pdfjs 用法： 1&#123;&#123;pdfjs&gt;:ns:document.pdf&#125;&#125; 亦有 google docs 插件gview，不过用的 google docs 服务，天朝目前应该用不了。 显示最新修订 插件，plugin:changes 显示最近修订。 This plugin allows you to embed a list of recent changes as a simple list into any page. 贡献统计 插件，plugin:authorstats 支持发出邮件 插件，plugin:smtp]]></content>
      <categories>
        <category>dokuwiki</category>
      </categories>
      <tags>
        <tag>administrator</tag>
        <tag>dokuwiki</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dokuwiki 邮件发送]]></title>
    <url>%2F201704%2Fadministrator%2Fdokuwiki%2Fsendmail.html</url>
    <content type="text"><![CDATA[不使用外部邮箱可直接发邮件sendmail 安装 sendmail，apt-get install sendmail，安装时间有点长，约 7 分钟。 配置 hosts，详见 Sendmail very slow - /etc/hosts configuration。 hostname，获取本机 hostname，本样例值为 ubuntu vi /etc/hosts，修改 127.0.0.1 localhost 一行为 127.0.0.1 ubuntu.localdomain ubuntu localhost。注意，ubuntu.localdomain 为必须值，而且不可另起一行。 mail 发送失败问题排查注册用户后，邮件发送失败提示 regmailfail “发送密码邮件时产生错误。请联系管理员！”，如果语言为英文的话，log 为“Looks like there was an error on sending the password mail. Please contact the admin!”。 查看发送失败的原因查看 /var/log/lighttpd/error.log，确认原因为服务器没有安装 sendmail。 12017-09-29 11:13:55: (mod_fastcgi.c.2673) FastCGI-stderr: PHP Question2Answer email send error: Could not instantiate mail function. apt-get install sendmail，安装时间有点长，约 7 分钟。 注册后，在注册页面卡很久查看 /var/log/mail.log，确认发一封邮件约需要 20 分钟。原因为解析不到 hostname，sleep 一段时间后 retry。 12345678910111213141516Sep 29 16:40:27 ubuntu sm-msp-queue[21553]: My unqualified host name (ubuntu) unknown; sleeping for retrySep 29 16:42:27 ubuntu sm-msp-queue[21553]: unable to qualify my own domain name (ubuntu) -- using short nameSep 29 16:57:19 ubuntu sendmail[21561]: My unqualified host name (ubuntu) unknown; sleeping for retrySep 29 16:59:19 ubuntu sendmail[21561]: unable to qualify my own domain name (ubuntu) -- using short nameSep 29 16:59:19 ubuntu sendmail[21561]: v8T8xJkc021561: from=www-data, size=2020, class=0, nrcpts=1, msgid=&lt;201709290859.v8T8xJkc021561@ubuntu&gt;, relay=www-data@localhostSep 29 17:00:19 ubuntu sm-mta[21562]: v8T8xJvo021562: from=&lt;www-data@ubuntu&gt;, size=2191, class=0, nrcpts=1, msgid=&lt;201709290859.v8T8xJkc021561@ubuntu&gt;, proto=ESMTP, daemon=MTA-v4, relay=localhost [127.0.0.1]Sep 29 17:00:19 ubuntu sendmail[21561]: v8T8xJkc021561: to=sunnogo1 &lt;sun@xxx.com.cn&gt;, ctladdr=www-data (33/33), delay=00:01:00, xdelay=00:01:00, mailer=relay, pri=32020, relay=[127.0.0.1] [127.0.0.1], dsn=2.0.0, stat=Sent (v8T8xJvo021562 Message accepted for delivery)Sep 29 17:00:40 ubuntu sm-mta[21582]: STARTTLS=client, relay=mx.xxx.com.cn., version=TLSv1/SSLv3, verify=FAIL, cipher=ECDHE-RSA-AES256-SHA, bits=256/256Sep 29 17:00:41 ubuntu sm-mta[21582]: v8T8xJvo021562: to=&lt;sun@xxx.com.cn&gt;, ctladdr=&lt;www-data@ubuntu&gt; (33/33), delay=00:00:22, xdelay=00:00:22, mailer=esmtp, pri=122191, relay=mx.xxx.com.cn. [172.16.2.173],dsn=2.0.0, stat=Sent (&lt;201709290859.v8T8xJkc021561@ubuntu&gt; [InternalId=1588969] Queued mail for delivery) 配置好 hosts 之后，注册还需要等 20 多秒安装后，发送一封邮件约 20s。从 log 上看，是公司邮件服务器响应太慢。dokuwiki 的邮件发送是同步发送。 123456789Sep 29 17:38:12 ubuntu sendmail[1864]: v8T9cCZX001864: to=sunnogo2 &lt;sun@xxx.com.cn&gt;, ctladdr=www-data (33/33), delay=00:00:00, xdelay=00:00:00, mailer=relay, pri=32020, relay=[127.0.0.1] [127.0.0.1], dsn=2.0.0,stat=Sent (v8T9cCSA001865 Message accepted for delivery)Sep 29 17:38:33 ubuntu sm-mta[1867]: STARTTLS=client, relay=mx.xxx.com.cn., version=TLSv1/SSLv3, verify=FAIL, cipher=ECDHE-RSA-AES256-SHA, bits=256/256Sep 29 17:38:34 ubuntu sm-mta[1867]: v8T9cCSA001865: to=&lt;sun@xxx.com.cn&gt;, ctladdr=&lt;www-data@ubuntu.localdomain&gt; (33/33), delay=00:00:22, xdelay=00:00:22, mailer=esmtp, pri=122215, relay=mx.xxx.com.cn. [172.16.2.173], dsn=2.0.0, stat=Sent (&lt;201709290938.v8T9cCZX001864@ubuntu.localdomain&gt; [InternalId=1590347] Queued mail for delivery) 附：SMTP发包方式详见 dokuwiki 邮件发送 附：sendmail 安装 log123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149root@ubuntu:/var/www/dokuwiki# apt-get install sendmailReading package lists... DoneBuilding dependency tree Reading state information... DoneThe following extra packages will be installed: m4 procmail sendmail-base sendmail-bin sendmail-cf sensible-mdaSuggested packages: sendmail-doc rmail logcheck sasl2-binRecommended packages: default-mta mail-transport-agent fetchmailThe following NEW packages will be installed: m4 procmail sendmail sendmail-base sendmail-bin sendmail-cf sensible-mda0 upgraded, 7 newly installed, 0 to remove and 169 not upgraded.Need to get 1,038 kB of archives.After this operation, 4,707 kB of additional disk space will be used.Do you want to continue? [Y/n] yGet:1 http://cn.archive.ubuntu.com/ubuntu/ trusty/main m4 amd64 1.4.17-2ubuntu1 [195 kB]Get:2 http://cn.archive.ubuntu.com/ubuntu/ trusty/universe sendmail-base all 8.14.4-4.1ubuntu1 [139 kB]Get:3 http://cn.archive.ubuntu.com/ubuntu/ trusty/universe sendmail-cf all 8.14.4-4.1ubuntu1 [86.1 kB]Get:4 http://cn.archive.ubuntu.com/ubuntu/ trusty/universe sendmail-bin amd64 8.14.4-4.1ubuntu1 [469 kB]Get:5 http://cn.archive.ubuntu.com/ubuntu/ trusty-updates/main procmail amd64 3.22-21ubuntu0.1 [135 kB]Get:6 http://cn.archive.ubuntu.com/ubuntu/ trusty/universe sensible-mda amd64 8.14.4-4.1ubuntu1 [8,246 B]Get:7 http://cn.archive.ubuntu.com/ubuntu/ trusty/universe sendmail all 8.14.4-4.1ubuntu1 [6,248 B]Fetched 1,038 kB in 0s (1,375 kB/s) Selecting previously unselected package m4.(Reading database ... 64411 files and directories currently installed.)Preparing to unpack .../m4_1.4.17-2ubuntu1_amd64.deb ...Unpacking m4 (1.4.17-2ubuntu1) ...Selecting previously unselected package sendmail-base.Preparing to unpack .../sendmail-base_8.14.4-4.1ubuntu1_all.deb ...Unpacking sendmail-base (8.14.4-4.1ubuntu1) ...Selecting previously unselected package sendmail-cf.Preparing to unpack .../sendmail-cf_8.14.4-4.1ubuntu1_all.deb ...Unpacking sendmail-cf (8.14.4-4.1ubuntu1) ...Selecting previously unselected package sendmail-bin.Preparing to unpack .../sendmail-bin_8.14.4-4.1ubuntu1_amd64.deb ...Unpacking sendmail-bin (8.14.4-4.1ubuntu1) ...Selecting previously unselected package procmail.Preparing to unpack .../procmail_3.22-21ubuntu0.1_amd64.deb ...Unpacking procmail (3.22-21ubuntu0.1) ...Selecting previously unselected package sensible-mda.Preparing to unpack .../sensible-mda_8.14.4-4.1ubuntu1_amd64.deb ...Unpacking sensible-mda (8.14.4-4.1ubuntu1) ...Selecting previously unselected package sendmail.Preparing to unpack .../sendmail_8.14.4-4.1ubuntu1_all.deb ...Unpacking sendmail (8.14.4-4.1ubuntu1) ...Processing triggers for man-db (2.6.7.1-1ubuntu1) ...Processing triggers for install-info (5.2.0.dfsg.1-2) ...Processing triggers for ureadahead (0.100.0-16) ...Setting up m4 (1.4.17-2ubuntu1) ...Setting up sendmail-base (8.14.4-4.1ubuntu1) ...Saving current /etc/mail/sendmail.mc,cf to /var/backupsSetting up sendmail-cf (8.14.4-4.1ubuntu1) ...Setting up sendmail-bin (8.14.4-4.1ubuntu1) ...update-rc.d: warning: default stop runlevel arguments (0 1 6) do not match sendmail Default-Stop values (1)update-alternatives: using /usr/lib/sm.bin/sendmail to provide /usr/sbin/sendmail-mta (sendmail-mta) in auto modeupdate-alternatives: using /usr/lib/sm.bin/sendmail to provide /usr/sbin/sendmail-msp (sendmail-msp) in auto mode * Stopping Mail Transport Agent (MTA) sendmail [ OK ] Updating sendmail environment ...Reading configuration from /etc/mail/sendmail.conf.Validating configuration.Writing configuration to /etc/mail/sendmail.conf.Writing /etc/cron.d/sendmail.Could not open /etc/mail/databases(No such file or directory), creating it.Reading configuration from /etc/mail/sendmail.conf.Validating configuration.Writing configuration to /etc/mail/sendmail.conf.Writing /etc/cron.d/sendmail.Could not open /etc/mail/databases(No such file or directory), creating it.Reading configuration from /etc/mail/sendmail.conf.Validating configuration.Creating /etc/mail/databases...Checking filesystem, this may take some time - it will not hang! ... Done. Checking for installed MDAs...Adding link for newly extant program (mail.local)Adding link for newly extant program (procmail)sasl2-bin not installed, not configuring sendmail support.To enable sendmail SASL2 support at a later date, invoke "/usr/share/sendmail/update_auth" Creating/Updating SSL(for TLS) informationCreating /etc/mail/tls/starttls.m4...Creating SSL certificates for sendmail.Generating DSA parameters, 2048 bit long primeThis could take some time........+.+.........+.....................+.+.......+...............+.............+............+++++++++++++++++++++++++++++++++++++++++++++++++++*.+.................+.......+..............+.+..............................+....+...............+.+..+...+......+.......+..+....................+...................+................+.+..........+....+.+.....+..+..+.................+.............+....+....+.......+.................................+..............+....+..+.+......................+.......+.....+.............+.....+.........+............+......+....................+....+....+..+................................+.......+........+.+...+................+....................+++++++++++++++++++++++++++++++++++++++++++++++++++*Generating RSA private key, 2048 bit long modulus...........................................................................+++..............+++e is 65537 (0x10001)*** *** *** WARNING *** WARNING *** WARNING *** WARNING *** *** ***Everything you need to support STARTTLS (encrypted mail transmissionand user authentication via certificates) is installed and configuredbut is *NOT* being used.To enable sendmail to use STARTTLS, you need to:1) Add this line to /etc/mail/sendmail.mc and optionally to /etc/mail/submit.mc: include(`/etc/mail/tls/starttls.m4')dnl2) Run sendmailconfig3) Restart sendmailChecking &#123;sendmail,submit&#125;.mc and related databases...Reading configuration from /etc/mail/sendmail.conf.Validating configuration.Creating /etc/mail/databases...Reading configuration from /etc/mail/sendmail.conf.Validating configuration.Creating /etc/mail/databases...Reading configuration from /etc/mail/sendmail.conf.Validating configuration.Creating /etc/mail/Makefile...Reading configuration from /etc/mail/sendmail.conf.Validating configuration.Writing configuration to /etc/mail/sendmail.conf.Writing /etc/cron.d/sendmail.Disabling HOST statistics file(/var/lib/sendmail/host_status).Creating /etc/mail/sendmail.cf...Creating /etc/mail/submit.cf...Informational: confCR_FILE file empty: /etc/mail/relay-domainsWarning: confCT_FILE source file not found: /etc/mail/trusted-users it was createdInformational: confCT_FILE file empty: /etc/mail/trusted-usersUpdating /etc/mail/access...Linking /etc/aliases to /etc/mail/aliasesInformational: ALIAS_FILE file empty: /etc/mail/aliasesUpdating /etc/mail/aliases...WARNING: local host name (ubuntu) is not qualified; see cf/README: WHO AM I?/etc/mail/aliases: 0 aliases, longest 0 bytes, 0 bytes total Warning: 1 database(s) sources were not found, (but were created)▽ please investigate. * Starting Mail Transport Agent (MTA) sendmail [ OK ]Setting up procmail (3.22-21ubuntu0.1) ...Setting up sensible-mda (8.14.4-4.1ubuntu1) ...Setting up sendmail (8.14.4-4.1ubuntu1) ... CAUTION！若开户 163 邮箱的“授权码”功能，本文无效。 问题概述 插件 smtp 问题：配置 163 邮箱后，无法发出邮件 原因：发送邮件的 sender 邮箱与配置授权的 163 邮箱不一致 解决：配置设置-&gt;通知设置，mailfrom 自动发送邮件时使用的邮件地址 填成与授权的 163 邮箱保持一致。 smtp 插件配置配置：管理-&gt;配置设置，点击目录，选择 smtp。 配置项： plugin»smtp»smtp_host，您的 SMTP 发送服务器。比如 smtp.163.com。 plugin»smtp»smtp_port，您的 SMTP 服务器监听端口。通常是 25，对于 SSL常是 465。比如，25 plugin»smtp»smtp_ssl，您的 SMTP 服务器所用的加密类型？有 ssl/tls/无，比如 无 plugin»smtp»auth_user，如果需要认证，在这里输入您的用户名。比如 `xxx@163.com` plugin»smtp»auth_pass，对应 auth_user 用户名的密码。注意，每次进行 配置设置，都要重新输入密码。 plugin»smtp»debug，在发送失败时显示完整的错误信息？在一切正常时请关闭！调试时勾选。 smtp 调试与553问题解决使用 plugin:smtp 自带的测试工具，在 管理 -&gt; 附加插件，点击 @检查 SMTP 配置，进入 SMTP 测试界面。写目标邮箱地址到 to 框中，点 sendmail 按钮。 出现错误 Log： 12345678910111213141516171819202122232425 There was an unexpected problem communicating with SMTP: Unexpected return code - Expected: 250, Got: 553 | 553 Mail from must equal authorized user SMTP log:Set: the serverSet: the authSet: a message will be sentConnecting to smtp.163.com at 25Got: 220 163.com Anti-spam GT for Coremail System (163com[20141201])Sent: EHLO [172.18.111.192]Got: 250-mailGot: 250-PIPELININGGot: 250-AUTH LOGIN PLAINGot: 250-AUTH=LOGIN PLAINGot: 250-coremail 1Uxr2xKj7kG0xkI17xGrU7I0s8sdfsf808Cz28x1UUUUU7Ic2I0Y2UFdFM3xUCa0xDrUUUUjGot: 250-STARTTLSGot: 250 8BITMIMESent: AUTH LOGINGot: 334 dXdsDFD806Sent: c3Vu80FSKerjMuY29tGot: 334 UGFz32380cmQ6Sent: QVJzYW5iSDF8989bDYwNTk1Got: 235 Authentication successfulSent: MAIL FROM:&lt;noreply@163.com&gt;Got: 553 Mail from must equal authorized userAbove may contain passwords - do not post online! Message wasn't sent. SMTP seems not to work properly. 提醒 553 错误，发送者的邮箱地址必须是登陆的邮箱地址。 客户端错误代码, smtp sever reply:553 mail from must equal authorized user 形成原因, 网易服务器smtp机器要求身份验证帐号和发信帐号必须一致，如果用户在发送邮件时，身份验证帐号和发件人帐号是不同的，因此拒绝发送。 解决办法/流程, 退信表明发信服务器要求身份验证. 建议： 确认一定要勾选“我的服务器要求身份验证” 请核实客户端中设置的电子邮箱地址是否填写正确，确认是输入完整的正确的邮箱地址。 设置的回复地址是否和邮箱地址是一致的，并且是完整的邮箱地址。 回到 管理 -&gt; 配置管理界面，发现 通知设置 中的 mailfrom 自动发送邮件时使用的邮件地址，填为 `noreply@163.com`，与授权的邮箱不一致。将此配置改为授权的 xxx@163.com 即可。修改后，重新测试，可正常发送邮件。 log: 1Message was sent. SMTP seems to work. 发送的邮件： 1234567891011发件人: xxx@163.com [mailto:xxx@163.com] 发送时间: 2017年4月6日 14:08收件人: 孙勇峰 &lt;sunyongfeng@xxx.com&gt;主题: [Administrator] DokuWiki says helloHi sunyongfengThis is a test from http://xxx.com/dokuwiki/ ________________________________________本邮件由 DokuWiki 自动创建http://xxx.com/dokuwiki/]]></content>
      <categories>
        <category>dokuwiki</category>
      </categories>
      <tags>
        <tag>administrator</tag>
        <tag>dokuwiki</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件归档管理经验]]></title>
    <url>%2F201704%2Fmisc%2Ffile_management.html</url>
    <content type="text"><![CDATA[归档的文件命名经验组内学习 SIGCOMM / NSDI 论文，对 SIGCOMM / NSDI 论文进行归档。 小组 A 负责 SIGCOMM 论文，下载文章，并按文章名重命名文件、归档。例如，Dealine-Aware Datacenter TCP，默认下载后的文件名为 p115.pdf 小组 B 负责 NSDI 论文，下载文章，不进行重命名，但是通过 excel 表格建立下载链接索引。例如，OSA: An Optical Switching Architecture for Data Center Networks with Unprecedented Flexibility，默认下载后文件名为 nsdi12-final88.pdf，建立的索引路径为http://svn.xxx.net/svndoc/d11/2015/一部/技术研究/论文学习/NSDI/2012/Data Center Networking/nsdi12-final88.pdf 一年后… 部门组织架构调整，原存放论文学习的 URL 为 http://svn.xxx.net/svndoc/d11/2015/n部/技术研究/论文学习/NSDI/2012/Data Center Networking/nsdi12-final88.pdf。如果此时想查阅 OSA: An Optical Switching Architecture for Data Center Networks with Unprecedented Flexibility，则只能先查找其索引路径，看存储的文件名是什么，然后才能找得到文件。而如果像小组 A 的存档方法，通过 everything 或 listary 等工具，直接输入文件名就可以快速找到文件了。]]></content>
      <categories>
        <category>misc</category>
      </categories>
      <tags>
        <tag>misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件版本号]]></title>
    <url>%2F201704%2Fprogrammer%2Fversion_number.html</url>
    <content type="text"><![CDATA[版本号规则[major].[minor].[revision] major，主版本号，软体有重大更新的时候递增，重大更新通常是指功能与介面都有大幅度变动的时候。不向下兼容。 minor，次版本号，软体发布新功能，但是并不会大幅影响到整个软体的时候递增。可向下兼容。 revision，修订版本号（打补丁），通常是在修订软件 bug 后，发布 bug 的修订版时递增。 有些版本编号除了上述三者之外，还会有「build」。也就是只要每次 build 一次软件就会递增一次，有时候甚至会使用 build 的日期或时间。 软件版本周期软件版本周期是指电脑软件的发展及发行过程，如下图，从Pre-alpha（准预览版本）发展到Alpha（预览版本）、Beta（测试版本）、Released candidate （最终测试版本）至最后的Gold（完成版）。 pre-alpha（准预览版本）有时候软件会在Alpha或Beta版本前先发布Pre-alpha版本。一般而言相对于Alpha或Beta版本，Pre-alpha版本是一个功能不完整的版本。 alpha（预览版本）Alpha版本仍然需要测试，其功能亦未完善，因为它是整个软件发布周期中的第一个阶段，所以它的名称是“Alpha”，希腊字母中的第一个字母“α”。Alpha版本通常会送到开发软件的组织或某群体中的软件测试者作内部测试。在市场上，越来越多公司会邀请外部客户或合作伙伴参与其测试。这令软件在此阶段有更大的可用性测试。在测试的第一个阶段中，开发者通常会进行白盒测试。其他测试会在稍后时间由其他测试团体以黑盒或灰盒技术进行，不过有时会同时进行。 beta（测试版本）Beta版本是软件最早对外公开的软件版本，由公众参与测试。一般来说，Beta包含所有功能，但可能有一些已知问题和较轻微的程序错误（BUG）。Beta版本的测试者通常是开发软件的组织的客户，他们会以免费或优惠价钱得到软件。Beta版本亦作为测试产品的支持和市场反应等。其他情况，例如微软曾以Community Technology Preview（简称CTP，中文称为“社区技术预览”）为发布软件的测试版本之一，微软将这个阶段的软件散布给有需要先行试用的用户或厂商，并收集这些人的使用经验，以便作为进一步修正软件的参考。 rc（最终测试版本）Release Candidate（简称RC）指可能成为最终产品的候选版本，如果未出现问题则可发布成为正式版本。在此阶段的产品通常包含所有功能、或接近完整，亦不会出现严重问题。多数开源软件会推出两个RC版本，最后的RC2则成为正式版本。闭源软件较少公开使用，微软公司在Windows 7上应用此名称。苹果公司把在这阶段的产品称为“Golden Master”（简称GM），而最后的GM即成为正式版本。 RTMRTM（Release To Manufacturing）之简称，意思是：发放给生产商。某些计算机程序以“RTM”作为软件版本代号，例如微软Windows 7发行零售版前的RTM版本主要是发放给组装机生产商用，使制造商能够提早进行集成工作或解决软件与硬件设备可能遇到的错误。RTM版本并不一定意味着创作者解决了软件所有问题；仍有可能向公众发布前更新版本。以Windows 7为例：RTM版与零售版的版本号是一样的。另外一种RTM的称呼是RTW（Release To Web），表示正式版本的软件发布到Web网站上供客户免费下载，这个名词在ASP.NET组件以及Silverlight的发布上很常见。 Stable稳定版本来自预览版本释出使用与改善而修正完成。为目前所使用的软件在匹配需求规格的硬件与操作系统中运行不会造成严重的不兼容或是硬件冲突，其已受过某定量的测试无误后所释出者。 windows 版本MSDNMSDN（Microsoft Developer Network）软件是微软公司面向软件开发者的一种版本。MSDN 涵盖了所有可以被开发扩充的平台和应用程序，如微软公司的百科全书 Encarta，或者是各种游戏，是不包括在 MSDN 之内的，因为这些产品直接面向最终用户，没有进行程序开发的必要。 MSDN 在 Operating System 以上的等级都有附微软的软件授权，根据 MSDN 的使用者授权合约(EULA)，软件只授权给使用 MSDN 的那一位开发人员，专供开发与测试之用，其他人不可使用 MSDN 所附软件。包含企业不能用 MSDN附的 SQL Server Enterprise Edition 做为生产环境中的数据库服务器；秘书不能使用 MSDN 所附的 Office2007 等等。 OEMOEM（Original Equipment Manufacturer）软件只能随机器出货，不能零售，所以也叫做随机版。OEM软件只能全新安装，不能从旧有作系统升级。 如果买笔记型计算机或品牌计算机就会有随机版软件。包装不像零售版精美，通常只有一片cd和说明书(授权书)。这种系统通常会少一些驱动，而且目前的OEM软件很少放在光盘里能给你安装，要么就是恢复盘，要么就是硬盘镜像。 RTLRTL版 Retail 正式零售版，供市面上架零售。 VOLVolume OR Volume Licensing for Organizations，即团体批量许可证，根据这个许可，当企业或者政府需要大量购买一软件时可以获得优惠。这种产品的光盘的卷标都带有”VOL”字样，就取”Volume”前3个字母，以表明是批量。这种版本根据购买数量等又细分为“开放式许可证”(Open License)、“选择式许可证(Select License)”、“企业协议(Enterprise Agreement)”、“学术教育许可证(Academic Volume Licensing)”等5种版本，上海政府 VOL版XP就是这种批量购买的版本。根据 VOL 计划规定， VOL 产品是不需要激活的(无论升级到SP1还是SP2)。 EVAL评估版 CTPCommunity Test Preview FPPFPP就是零售版（盒装软件），这种产品的光盘的卷标都带有”FPP”字样，比如英文WXPPro的FPP版本的光盘卷标就是WXPFPP_EN，其中WX表示是Windows XP，P是Professional（H是Home），FPP表明是零售版本，EN是表明是英语。获得途径除了在商店购买之外，（H是Home），FPP表明是零售版本，EN是表明是英语。获得途径除了在商店购买之外，某些MSDN用户也可以得到。 参考文献 SLMT’s Blog, 版本編號的命名規則 zh.wikipedia, 软件版本号 en.wikipedia, software versioning zh.wikipedia，软件版本周期 gdaily，查看你的完整 Windows 版本 Retail、VOL、OEM、RTM web duper，Windows MSDN、OEM、RTM、VOL等各版本的区别]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dokuwiki 中文支持]]></title>
    <url>%2F201704%2Fadministrator%2Fdokuwiki%2Fdokuwiki_chinese.html</url>
    <content type="text"><![CDATA[中文名 page 被转为 url 保存到磁盘注意： 每次升級 dokuwiki 都必须做“问题解决”一节中第2步操作。 元凶：URL rewrite。 bug 现象页面 public:linux工具箱 在磁盘中被保存为： 1dokuwiki/data/pages/public/linux%E5%B7%A5%E5%85%B7%E7%AE%B1/ 处理后： 1dokuwiki/data/pages/public/linux工具箱/ 问题解决参考文献： 勿慢牛 blog 页面名和命名空间 修订记录： 1.修改文件 dokuwiki/conf/local.php，在末尾增加 1$conf['fnencode'] = 'gbk'; 2.修改文件 dokuwiki/inc/pageutils.php，删除掉文件名转 url 的操作。 处理完这一步，可验证一下。添加个中文 page，到 data 目录查看是否保存为中文名。 1234567891011121314151617181920212223242526272829303132333435363738394041function utf8_encodeFN($file,$safe=true)&#123; global $conf; if($conf['fnencode'] == 'utf-8') return $file; if($safe &amp;&amp; preg_match('#^[a-zA-Z0-9/_\-\.%]+$#',$file))&#123; return $file; &#125; if($conf['fnencode'] == 'safe')&#123; return SafeFN::encode($file); &#125; // 注释这里 //$file = urlencode($file); //$file = str_replace('%2F','/',$file); return $file;&#125;/** * Decode a filename back to UTF-8 * * Uses the 'fnencode' option to determine encoding * * @author Andreas Gohr &lt;andi@splitbrain.org&gt; * @see urldecode * * @param string $file file name * @return string */function utf8_decodeFN($file)&#123; global $conf; if($conf['fnencode'] == 'utf-8') return $file; if($conf['fnencode'] == 'safe')&#123; return SafeFN::decode($file); &#125; // 注释这里 // return urldecode($file); return $file;&#125; 3.恢复原先以 url 格式保存的文件名为中文名以 python3 运行如下脚本，注意修改 wikipath 为 dokuwiki 路径。实测在 linux 下可用。 1234567891011121314151617181920212223242526272829"""dokuwiki转码程序。（请将本程序保存为utf8文本）作用：将dokuwiki默认的编码方式编码生成的目录名、文件名，统一转换为可识别的中文。要求python版本大于等于3.4""" from pathlib import Pathfrom urllib.parse import unquote wikipath = 'd:/lzweb/wiki' # 请在这里设置好dokuwiki的安装目录 rootpath = Path(wikipath)rootpath = rootpath / 'data' def pathRename(path): # 对path进行转码 newname = path.parent / unquote(path.name) path.rename(newname) def dealpath(path): # 对path下的全部文件和目录进行递归编码转换 allpath = path.glob('*') # 遍历path下的第一层目录 for p in allpath: if p.is_file(): pathRename(p) elif p.is_dir(): # 如果是目录 dealpath(p) # 先对目录下的所有内容改名 pathRename(p) # 再对该目录改名 print('转码开始，请耐心等候...')dealpath(rootpath)print('完成全部转换。') 4.解决 sitemap 乱码问题，修改 dokuwiki/inc/common.php 123456789101112131415161718192021222324252627282930313233343536function wl($id = '', $urlParameters = '', $absolute = false, $separator = '&amp;amp;') &#123; global $conf; if(is_array($urlParameters)) &#123; if(isset($urlParameters['rev']) &amp;&amp; !$urlParameters['rev']) unset($urlParameters['rev']); if(isset($urlParameters['at']) &amp;&amp; $conf['date_at_format']) $urlParameters['at'] = date($conf['date_at_format'],$urlParameters['at']); $urlParameters = buildURLparams($urlParameters, $separator); &#125; else &#123; $urlParameters = str_replace(',', $separator, $urlParameters); &#125; if($id === '') &#123; $id = $conf['start']; &#125; //注释这里 //$id = idfilter($id); if($absolute) &#123; $xlink = DOKU_URL; &#125; else &#123; $xlink = DOKU_BASE; &#125; if($conf['userewrite'] == 2) &#123; $xlink .= DOKU_SCRIPT.'/'.$id; if($urlParameters) $xlink .= '?'.$urlParameters; &#125; elseif($conf['userewrite']) &#123; $xlink .= $id; if($urlParameters) $xlink .= '?'.$urlParameters; &#125; elseif($id) &#123; $xlink .= DOKU_SCRIPT.'?id='.$id; if($urlParameters) $xlink .= $separator.$urlParameters; &#125; else &#123; $xlink .= DOKU_SCRIPT; if($urlParameters) $xlink .= '?'.$urlParameters; &#125; return $xlink;&#125;]]></content>
      <categories>
        <category>dokuwiki</category>
      </categories>
      <tags>
        <tag>administrator</tag>
        <tag>dokuwiki</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[版本控制的思考]]></title>
    <url>%2F201704%2Ftools%2Fthink_on_version_control.html</url>
    <content type="text"><![CDATA[GIT 分支模型本文分支模型来自《一个成功的 Git 分支模型》。 文中采用 git 进行分支管理，亦可同时适用于 svn。 基础概念 master: 主分支，主要用来版本发布。 develop：日常开发分支，该分支正常保存了开发的最新代码。 feature：具体的功能开发分支，只与 develop 分支交互。 release：release 分支可以认为是 master 分支的未测试版。比如说某一期的功能全部开发完成，那么就将 develop 分支合并到 release 分支，测试没有问题并且到了发布日期就合并到 master 分支，进行发布。 hotfix：线上 bug 修复分支。 核心问题 项目太多，分支如何管理？ 产品组 解决方案组 项目太赶，统一的分支应如何保证代码修订不会影响非本项目产品？ 听说另一个事业部的同学，改 3 行代码改出多个 bug。 现实是，即使有统一的分支，为时效性，项目组只会测试本项目所涉及的产品，不会投入测试该统一分支的所有产品。 思考的一个分支管理模型 新项目分支； 基于 develop 分支开 feature 分支，进行功能开发； 功能开发结束后，如果功能没有被废弃，则将 feature 分支的修订同步回 develop 分支； 从 develop 分支开出 release 分支，进行测试； 如果测试没有问题，则合并到 master 分支，进行发布。 如果项目发布前，发现 bug，则基于 master 分支起 hot-fix 分支，hot-fix 分支解决完 bug 后，需要同步到 master 同时同步回 develop。 bug 定位由产品组/解决方案组定位； bug 解决由软件组解决； bug 同步由软件组同步。 hot-fix 分支有期限，最多只维护半年。 如果是产品组/解决方案组的特殊功能需求，代码由产品组/解决方案组自行维护。 主分支 master 分支 develop 分支 约束： origin/master 这个分支上 HEAD 引用所指向的代码都是可发布的。 origin/develop这个分支上HEAD引用所指向的代码总是反应了下一个版本所要交付特性的最新的代码变更。一些人管它叫“整合分支”。它也是自动构建系统执行构建命令的分支。 当 develop 分支上的代码达到一个稳定状态，并准备发布时，所有代码变更都应合并到 master 分支，并打上去发布版本号的 tag。 每次代码合并到master分支时，它就是一个人为定义的新的发布产品。理论上而言，在这我们应该非常严格，当master分支有新的提交时，我们应该使用Git的钩子脚本执行自动构建命令，然后将软件推送到生产环境的服务器中进行发布。 辅助性分支紧邻 master 和 develop 分支，我们的开发模型采用了另外一种辅助性的分支，以帮助团队成员间的并行开发，特性的简单跟踪，产品的发布准备事宜，以及快速的解决线上问题。不同于主分支，这些辅助性分支往往只要有限的生命周期，因为他们最终会被删除。不同类型的分支包括： 特性分支，feature branches Release 分支 Hotfix 分支 特性分支 特性分支基于 develop 分支创建，最终合并入 develop 分支。 约束： 特性分支的命名，除了 master、develop、release- 或 hotfix- 以后，可以随便起名。 特性分支只存在开发者本地版本库，不在远程版本库。 特性分支(有时候也成主题分支)用于开发未来某个版本新的特性。当开始一个新特性的开发时，这个特性未来将发布于哪个目标版本，此刻我们是不得而知的。特性分支的本质特征就是只要特性还在开发，他就应该存在，但最终这些特性分支会被合并到develop分支(目的是在新版本中添加新的功能)或者被丢弃(它只是一个令人失望的试验) 发布分支发布分支基于 develop 分支创建，必须合并到 develop 分支和 master 分支。 约束： 命名为 release-* Release分支用于支持一个新版本的发布。他们允许在最后时刻进行一些小修小改。甚至允许进行一些小bug的修改，为新版本的发布准要一些元数据(版本号，构建时间等)。通过在release分支完成这些工作，develop分支将会合并这些特性以备下一个大版本的发布。 从develop分支拉取新的release分支的时间点是当开发工作已经达到了新版本的期望值。至少在这个时间点，下一版本准备发布的所有目标特性必须已经合并到了develop分支。更远版本的目标特性不必合并会develop分支。这些特性必须等到个性分支创建后，才能合并回develop分支 在release分支创建好后，就会获取到一个分配好即将发布的版本号，不能更早，就在这个时间点。在此之前，develop分支代码反应出了下一版本的代码变更，但是到底下一版本是 0.3 还是 1.0，不是很明确，直到release分支被建立后一切都确定了。这些决定在release分支开始建立，项目版本号等项目规则出来后就会做出。 新的分支会存在一段时间，直到新版本最终发布。在这段时间里，bug的解决可以在这个分支进行(不要在develop分支进行)。此时是严禁添加新的大特性。这些修改必须合并回develop分支，之后就等待新版本的发布。 hotfix 分支 Hotfix 分支基于 master 分支创建，必须合并回 develop 分支和 master 分支。 约束： 命名为 hotfix-* Hotfix分支在某种程度上非常像release分支，他们都意味着为某个新版本发布做准备，并且都是预先不可知的。Hotfix分支是基于当前生产环境的产品的一个bug急需解决而必须创建的。当某个版本的产品有一个严重bug需要立即解决，Hotfix分支需要从master分支上该版本对应的tag上进行建立，因为这个tag标记了产品版本。 完成工作后，解决掉的bug代码需要合并回master分支，但同时也需要合并到develop分支，目的是保证在下一版中该bug已经被解决。这多么像release分支啊。 这里可能会有一些异常情况，当一个release分支存在时，hotfix 分支需要合并到release 分支，而不是develop分支。当release分支的使命完成后，合并回release分支的bugfix代码最终也会被合并到develop分支。(当develop分支急需解决这些bug，而等不到release分支的结束，你可以安全的将这些bugfix代码合并到develop分支，这样做也是可以的)。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>版本控制</tag>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决 Can't load IA 32-bit .dll on a AMD 64-bit platform]]></title>
    <url>%2F201704%2Fprogrammer%2Fjava%2F32bit_in_64bit_system.html</url>
    <content type="text"><![CDATA[问题log： 12C:\Users\R0\Downloads\win32&gt;java -Xmx1024m -jar xxx.jarjava.lang.UnsatisfiedLinkError: C:\Users\R0\Downloads\win32\jxxx.dll: Can't load IA 32-bit .dll on a AMD 64-bit platform 通过 -d32 选项指定使用 32 位 JVM，同样出错： 123C:\Users\R0\Downloads\win32&gt;java -d32 -Xmx1024m -jar xxx.jarError: This Java instance does not support a 32-bit JVM.Please install the desired version. 解决，下载 32 位 JRE，并使用 32 位 java.exe 的绝对路径调用 java。 例如： 1C:\Users\R0\Downloads\win32&gt;"C:\Program Files (x86)\Java\jre1.8.0_121\bin\java.exe" -Xmx1024m -jar xxx.jar]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vagrant 使用记录]]></title>
    <url>%2F201703%2Fprogrammer%2Ftools%2Fvagrant.html</url>
    <content type="text"><![CDATA[vagrant 如何 ping 通虚拟机vagrant 默认网络通信机制vagrant 默认使用 NAT 端口映射，可以通过端口映射访问虚机内部端口号。但是默认情况下，vagrant 可以访问外网，但是外部世界访问不了 vagrant （类似以前在学校，学校内可以访问外网，但是外网访问不了教育网）。如果你想在外部访问 vagrant 虚机提供的服务，需要配置端口映射，比如将虚机的端口 80 映射成 host 机的端口 8080，详见 vagrant networking basic usage： 1config.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8080 默认情况下，vagrant 虚机中有一张网卡，默认IP 10.0.2.15。虚机可上外网，host 无法 ping 通虚机。 vagrant 其他通信机制private network详见vagrant networking private_network。 通常利用 provider 创建的虚拟网卡，例如 virtualBox 的 Host-Only Network。 1234567以太网适配器 VirtualBox Host-Only Network: 连接特定的 DNS 后缀 . . . . . . . : 本地链接 IPv6 地址. . . . . . . . : fe80::a801:a2e7:cbd9:7126%3 IPv4 地址 . . . . . . . . . . . . : 192.168.56.1 子网掩码 . . . . . . . . . . . . : 255.255.255.0 默认网关. . . . . . . . . . . . . : vagrant 的配置： 静态IP： 1config.vm.network "private_network", ip: "192.168.56.10" 动态IP： 1config.vm.network "private_network", type: "dhcp" 配置后虚机中新增一张网卡，如下的 enp0s8。 123456789101112131415161718192021222324252627vagrant@ubuntu-xenial:~$ sudo ifconfig -aenp0s3 Link encap:Ethernet HWaddr 02:6a:71:da:1d:13 inet addr:10.0.2.15 Bcast:10.0.2.255 Mask:255.255.255.0 inet6 addr: fe80::6a:71ff:feda:1d13/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:45731 errors:0 dropped:0 overruns:0 frame:0 TX packets:20045 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:37231206 (37.2 MB) TX bytes:1387674 (1.3 MB)enp0s8 Link encap:Ethernet HWaddr 08:00:27:c4:aa:2c inet addr:192.168.56.10 Bcast:192.168.56.255 Mask:255.255.255.0 inet6 addr: fe80::a00:27ff:fec4:aa2c/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:818 errors:0 dropped:0 overruns:0 frame:0 TX packets:575 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:96862 (96.8 KB) TX bytes:100624 (100.6 KB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:8 errors:0 dropped:0 overruns:0 frame:0 TX packets:8 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:480 (480.0 B) TX bytes:480 (480.0 B) 此是 host 可以 ping 通虚机。 1234567891011121314C:\Users\R0&gt;ping 192.168.56.10正在 Ping 192.168.56.10 具有 32 字节的数据:来自 192.168.56.10 的回复: 字节=32 时间&lt;1ms TTL=64来自 192.168.56.10 的回复: 字节=32 时间&lt;1ms TTL=64来自 192.168.56.10 的回复: 字节=32 时间&lt;1ms TTL=64来自 192.168.56.10 的回复: 字节=32 时间&lt;1ms TTL=64192.168.56.10 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，往返行程的估计时间(以毫秒为单位): 最短 = 0ms，最长 = 0ms，平均 = 0msC:\Users\R0&gt; public network利用 provider 提供的 bridge （桥接功能）。 vagrant halt 无法关机失败 log： 123456789101112131415E:\vagrant&gt;Vagrant halt==&gt; default: Attempting graceful shutdown of VM...The following SSH command responded with a non-zero exit status.Vagrant assumes that this means the command failed!shutdown -h nowStdout from the command:Stderr from the command:E:\vagrant&gt; 解决方法，见 issue 1659 @rfay 的回答。即将默认用户配置为 sudoers 后，还要在 /etc/sudoers 中添加 vagrant ALL=(ALL) NOPASSWD:ALL。 1234567@dengzhp I've done this to myself any number of times by messing up the /etc/sudoers or /etc/sudoers.d. I did it today, which is why I landed here. Somewhere in /etc/sudoers (or /etc/sudoers.d if it's included) you have to havevagrant ALL=(ALL) NOPASSWD:ALLDefaults:vagrant !requirettywithout that, the vagrant ssh (without tty) fails mysteriously. I once again had built a machine without my puppet vagrant module, which adds this in.@mitchellh if there's not already an FAQ on this, it's a good topic for one. I seem to do it over and over again :-) 不过我的环境中，/etc/sudoers 默认权限为只读，因此，直接将 vagrant ALL=(ALL) NOPASSWD:ALL 添加在 /etc/sudoers.d/username 中。 12345vagrant@ubuntu-xenial:~$ ls -al /etc/sudoers-r--r----- 1 root root 755 Jan 20 16:01 /etc/sudoersvagrant@ubuntu-xenial:~$ sudo cat /etc/sudoers.d/vagrantvagrant ALL=(ALL) NOPASSWD:ALLvagrant@ubuntu-xenial:~$ vagrantfile 添加端口映射后 vagrant up 失败添加一个新的端口映射到 Vagrantfile，config.vm.network &quot;forwarded_port&quot;, guest: 16385, host: 26385。之后执行 vagrant up 失败，log： 1234E:\vagrant&gt;Vagrant reload==&gt; default: Attempting graceful shutdown of VM...==&gt; default: Clearing any previously set forwarded ports...C:/HashiCorp/Vagrant/embedded/gems/gems/vagrant-1.9.3/lib/vagrant/util/is_port_open.rb:21:in `initialize': The requested address is not valid in its context. - connect(2) for "0.0.0.0" port 16385 (Errno::EADDRNOTAVAIL) 解决方法详见 issue 8395，配置中加上 host_id，最终端口映射的配置为 config.vm.network &quot;forwarded_port&quot;, guest: 16385, host: 26385, host_ip: &quot;127.0.0.1&quot;123456Had the same problem on Windows 7.This problem seems to be caused by the new host_ip parameter for the port forwarding feature.I suggest that for compatibility reason, the default host_ip parameter should be set to 127.0.0.1 instead of 0.0.0.0I managed to make the 1.9.3 version working by rewritten all my Vagrantfile(s) and adding the host_id: "127.0.0.1" parameter for each of the "forwarded_port" network configuration.E.g.:config.vm.network "forwarded_port", guest: 22, host: 1022, host_ip: "127.0.0.1", id: 'ssh' ubuntu 16.04 32-bit box 用户名密码反人类一般情况下，vagrant box 用户名密码都为 vagrant，但是使用的第一个 box 却违反这个规则。xenial32 的默认用户名为 ubuntu，密码为7ea1ebda4a3d566ade4dd808。 具体的 Box 内部 Vagrantfile 内容为： 1234567891011121314# Front load the includesinclude_vagrantfile = File.expand_path("../include/_Vagrantfile", __FILE__)load include_vagrantfile if File.exist?(include_vagrantfile)Vagrant.configure("2") do |config| config.vm.base_mac = "026A71DA1D13" config.ssh.username = "ubuntu" config.ssh.password = "7ea1ebda4a3d566ade4dd808" config.vm.provider "virtualbox" do |vb| vb.customize [ "modifyvm", :id, "--uart1", "0x3F8", "4" ] vb.customize [ "modifyvm", :id, "--uartmode1", "file", File.join(Dir.pwd, "ubuntu-xenial-16.04-cloudimg-console.log") ] endend vagrant box add base ubuntu/xenial32 具体的下载位置windows 下具体下载位置为 C:\Users\yourName\.vagrant.d\boxes\base\。 vagrant 如何打包？vagrant 打包事实上使用 tar + gzip 进行打包，后缀命名为 .box。vagrant package 命令的打包结果据说不好使，没有实测。 外网如何使用 vagrant 服务端口映射时，ip 填 host IP，而不是 127.0.0.1 本地地址。 如下配置，实测可在 172.x.x.x 网段 ssh 远程登陆虚机。 12config.vm.network "forwarded_port", guest: 16385, host: 26385, host_ip: "192.168.1.2"config.vm.network "forwarded_port", guest: 22, host: 2222, host_ip: "192.168.1.2" ssh 远程登陆 log： 12345678910111213141516171819202122232425root@ubuntu:~# ssh vagrant@192.168.1.2 -p 2222vagrant@192.168.1.2's password: Welcome to Ubuntu 14.04.5 LTS (GNU/Linux 3.13.0-115-generic i686) * Documentation: https://help.ubuntu.com/ System information as of Thu Apr 6 09:03:15 UTC 2017 System load: 0.26 Processes: 78 Usage of /: 4.2% of 39.34GB Users logged in: 0 Memory usage: 16% IP address for eth0: 10.0.2.15 Swap usage: 0% IP address for eth1: 192.168.56.10 Graph this data and manage this system at: https://landscape.canonical.com/ Get cloud support with Ubuntu Advantage Cloud Guest: http://www.ubuntu.com/business/services/cloudNew release '16.04.2 LTS' available.Run 'do-release-upgrade' to upgrade to it.Last login: Thu Apr 6 09:03:16 2017 from 10.0.2.2vagrant@vagrant-ubuntu-trusty-32:~$ 未决问题：bridge 模式下，跨网段 ping，内网可以 ping 通外网，外网 ping 不通内网。 三机集群配置支持变量，以程序的方式做配置。 1234567891011121314151617181920212223242526272829303132333435363738# -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.configure("2") do |config| (1..3).each do |i| config.vm.define "node#&#123;i&#125;" do |node| # 设置虚拟机的Box node.vm.box = "ubuntu/trusty32" # 设置虚拟机的主机名 node.vm.hostname="node#&#123;i&#125;" # 设置虚拟机的IP node.vm.network "private_network", ip: "192.168.56.1#&#123;i&#125;" # 设置端口映射 node.vm.network "forwarded_port", guest: 16385, host: "#&#123;i&#125;6385", host_ip: "127.0.0.1" node.vm.network "forwarded_port", guest: 22, host: "#&#123;i&#125;0022", host_ip: "127.0.0.1" node.vm.box_check_update = false # 设置主机与虚拟机的共享目录 # node.vm.synced_folder "~/Desktop/share", "/home/vagrant/share" # VirtaulBox相关配置 node.vm.provider "virtualbox" do |v| # 设置虚拟机的名称 v.name = "node#&#123;i&#125;" # 设置虚拟机的内存大小 v.memory = 512 # 设置虚拟机的CPU个数 v.cpus = 1 end # 使用shell脚本进行软件安装和配置 # node.vm.provision "shell", inline: &lt;&lt;-SHELL # # SHELL # end end endend]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>vagrant</tag>
        <tag>virtualBox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Huge page 概述]]></title>
    <url>%2F201703%2Fprogrammer%2Flinux%2Fhugetlbpage.html</url>
    <content type="text"><![CDATA[参考： https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt https://wiki.debian.org/Hugepages When a process uses some memory, the CPU is marking the RAM as used by that process. For efficiency, the CPU allocate RAM by chunks of 4K bytes (it’s the default value on many platforms). Those chunks are named pages. Those pages can be swapped to disk, etc. Since the process address space are virtual, the CPU and the operating system have to remember which page belong to which process, and where it is stored. Obviously, the more pages you have, the more time it takes to find where the memory is mapped. When a process uses 1GB of memory, that’s 262144 entries to look up (1GB / 4K). If one Page Table Entry consume 8bytes, that’s 2MB (262144 * 8) to look-up. Most current CPU architectures support bigger pages (so the CPU/OS have less entries to look-up), those are named Huge pages (on Linux), Super Pages (on BSD) or Large Pages (on Windows), but it all the same thing.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim 插件记录]]></title>
    <url>%2F201702%2Fprogrammer%2Ftools%2Fvim_plugin.html</url>
    <content type="text"><![CDATA[powerlinePowerline 是 vim 的状态行插件，让你的状态行更加酷炫，装 13 利器。 有图有真相： 全局示意图：来自CENALULU’S TECH BLOG。 Powerline is a statusline plugin for vim, and provides statuslines and prompts for several other applications, including zsh, bash, tmux, IPython, Awesome, i3 and Qtile. windows 下的字体可直接在 github 上搜，个人比较喜欢 consolas 字体。 下载字体 双击字体，点击安装 在 console 上（比如 SecureCRT 或 putty）选择字体为 Consolas for Powerline。 winmanager有个 bug，使用 wm 启用 winmanager 的时候会出现一个空的窗口。详见 将Vim改造为强大的IDE—Vim集成Ctags/Taglist/Cscope/Winmanager/NERDTree/OmniCppComplete（有图有真相） 。 找到.vim 中 的winmanager.vim 添加如下的 exe &#39;q&#39; 12345678function! &lt;SID&gt;ToggleWindowsManager() if IsWinManagerVisible() call s:CloseWindowsManager() else call s:StartWindowsManager() exe 'q' end endfunction vundle git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundle .vimrc 配置好要安装的插件，可参考我的配置文件 用 vim 随便打开一个文件，:BundleInstall 安装配置好的插件 cscope for c like language例如配置 P4 lang: mkdir ~/.vim/plugin cd ~/.vim/plugin wget http://cscope.sourceforge.net/cscope_maps.vim cd your_p4_src cscope -R *.p4 vim xxx.p4, 尽情享用 tag 跳转等功能。]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dos命令使用记录]]></title>
    <url>%2F201702%2Fwindows%2Fcmd.html</url>
    <content type="text"><![CDATA[网卡设置netsh 命令 12netsh interface ip set address "本地连接" static your_ip your_ipmask gateway metricnetsh interface ip set dns "本地连接" static DNS_ADDRESS primary 输出目录树（tree）命令：tree /f &gt; dir_pic_tree.txt，输出的结果在 cmd 的当前目录下，如果不带 &gt; dir_pic_tree.txt，则直接打印到 cmd 界面。 例如输出 Pictures 目录的目录树： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263C:\Users\R04220\Pictures&gt;tree /f文件夹 PATH 列表卷序列号为 0000009A B477:AC59C:.│ dir_pic_tree.txt│ paper.小组完成情况.png│ paper.延期数据.png│ paper.总数据.png│ paper.总数据2.png│ save-spotlight.ps1│ ├─Camera Roll├─Saved Pictures└─Spotlight ├─CopyAssets ├─Horizontal │ 07d13665d2a42b6a9b1308d76ea9d43ede14964ac843f5c646e11d8537323c75.jpg │ 2eabdd4e869a9ba575a2c7ab85026357cfc21f27aba7e5aefb06ef0611a66a8c.jpg │ 3260bc4d05d2d4b9426e114713aece847a7807b26fe85ead14ccf1d4b5653f5f.jpg │ 389abcdbb34cd0352e7e9c216859a1373a9a0beeb245b6f866c4459604e5fc83.jpg │ 4422e3ac278425ebdf387990995c10159dd787dfc3914bca5062208b6cd4af8b.jpg │ 4699a04f5e6c7ecf0c86891a1bb98933dac79228b21633d8a34f153e3c1d3180.jpg │ 498f917a9bbc3ce7bf061ef6bb2f832aaa37fc813e40c94d4f5f9f23c3567a5b.jpg │ 51ed125c041ab491a2494aad469656480d30e2e07c019634329de28613b68aac.jpg │ 52e51ea8bfb1886d16a84c83f2bee187b0b129cd3260339cf54f596882fabedc.jpg │ 56127afeae00317c8ee4efebbed57156e9ec6c0a2be7c6f5e164428a37805abf.jpg │ 611ae451bfcb5a31fed1deb8766815bd8b522e67f737ce4ee38f40d51d1a659d.jpg │ 7586db4f8911367a593e56e98f92fccd1d78bd34c8b30052b71b94a859eac1c0.jpg │ 8659dbdf640884f349f2a010048ed000ccc600c90897427f3e6d27972e15bfda.jpg │ 888733fb259bbdc503f23baf71603d81d01b068dca3f8e5c62248eee1092c17e.jpg │ 8e0c39f07085cd7862d7472c12204e8ecaa82d62e580c68664faec960babcddd.jpg │ 90bfcc1d948170fd252992ceaf68c59596b86ef26cf4d448f9e8000348a152ae.jpg │ b2c87ee5f28245a081a6d6181a31840a84cc6c983d2c4f1d524ab5e879e41edd.jpg │ cacc63578dda6099e9d6465b8247f118e60de9eb4aa81d2cecd5107628028a0e.jpg │ d6f886a44d933673742740f2df0fd045a75d2457b80ce52deac53d6d50da0ae2.jpg │ daab366938f9d2fc1f6783121248a75089dec6bf5adfbb6d8447710793efd5a6.jpg │ db6c55aaea5ca497ad8fed0219e9742551594d612f46a291daf351bc106ef759.jpg │ f6eb0171205b66d1f01c947af1144093544c7eab4716c59f1bf872703af26409.jpg │ └─Vertical 0a965b06725e3eb45058e1e1c699d529f026aa170fa43696659801d56807ee8c.jpg 149be707844d99bf1d13b6f6ee0071952861e6ec9d475e5d588139f6477e7b3e.jpg 1fbbd6779aa1407e13c2837941b61650f06f35a282b29f478d07f4bd77ca926e.jpg 212909107619586a7a3b6abe628a9ef9a1bead207b3d0b88f6ac6b6ffcb2070f.jpg 25befdccd1b9f6b7ed91bcbfca73656998f6e563fea160dca01be9cc1a4cd747.jpg 30a0cdf04b7d029e34f5f75ac25493c66ceac9734c2d6accf9008638a5475953.jpg 3a93ca26063b7552eaff43c70a142aaabd53e99940fa0a25a248bdfa9d96796f.jpg 44fe2b0dca73fadd35d818cb83356e1431f3b0f9729ee9742f5f227e0948de72.jpg 4c6d76fbf970c420376041ec4ad5a97601add0d56838859acaec60bae3227fc1.jpg 4e8ea94abf449377fcc3e45c4033e4e2ef0f91a43c66873d03e351cb640f0264.jpg 5b8006c1069151d12ae83c175af746b84aa11ae46e4834c2f0535b4dc2aa55c5.jpg 60ecfce0af8371c7f3fe030f3c1d040605aaa18e2b44de65c7e09c82aee765d3.jpg 68cbd1d229910ccd15329f9989c13a09fcf869fd09b86d5195bb1cd398b7f80c.jpg 69ed52e624a7bf2e2b95b91339982186d3cd8b85b8a4308b0004c95286cb98d6.jpg 70a0927503e8adc8841749d379177c4f30a03477c305b4f0e595015e308cde0b.jpg 774f1a1a02fd2a4c6612b8f4b4654613a6bbeca5f4bfc2bbf438a0b822321754.jpg 79ae9d23c38685fac276058333d066a728d75a9bc7324e66d395707fa4913140.jpg 815e87ed8cd0d24bdf30132500a23a80f936f808ff5b653807f8de8d7df05a74.jpg 89d40db523257c5397d54e6719d2ac201e3f13b060aecce38663d42ccaba3996.jpg 938eae85fb0af3deda7bd9386c7f0e28d87b64f87736c47f9ddde52306de15e1.jpg a931c3312424a1d9878db81e041f1a6d5704e990d7dd34386ca18e6dc107015e.jpg d4335387d80d96e64933e71a284d0ea466b2e4a95afe1e54a9244efd20caff8e.jpg e37f97eb49a3459589815c0543648a737904e4d91397da43c3618bcaa1a4f75a.jpg]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>dos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么 wireshark 可以抓到小于 64 字节的报文？]]></title>
    <url>%2F201702%2Fnetworks%2Fwireshark_capture_less_64B.html</url>
    <content type="text"><![CDATA[底层不提供显示 FCS以太网报文大小： Preamble, 8B Destination MAC address, 6B Source MAC address, 6B Type/Length, 2B User Data, 46 - 1500B Frame Check Sequence (FCS), 4B 前导码一般被物理层处理掉，且底层一般在驱动层剥除 FCS，因此一般情况下，Wireshark 抓到的最小包为 6B + 6B + 2B + 46B = 60B。 链接： As the Ethernet hardware filters the preamble, it is not given to Wireshark or any other application. Most Ethernet interfaces also either don’t supply the FCS to Wireshark or other applications, or aren’t configured by their driver to do so; therefore, Wireshark will typically only be given the green fields, although on some platforms, with some interfaces, the FCS will be supplied on incoming packets. Ethernet packets with less than the minimum 64 bytes for an Ethernet packet (header + user data + FCS) are padded to 64 bytes, which means that if there’s less than 64-(14+4) = 46 bytes of user data, extra padding data is added to the packet. Beware: the minimum Ethernet packet size is commonly mentioned at 64 bytes, which is including the FCS. This can be confusing as the FCS is often not shown by Wireshark, simply because the underlying mechanisms simply don’t supply it. wireshark 抓到小于 60 字节的报文？ 首先 wireshark 抓到小于 60 字节报文都是本机发出的。 其次 wireshark 能抓到本机小于 60 字节报文的原因：填充报文到 60 字节的行为在 wireshark 抓包后。 链接，What you see is 14 bytes ethernet header, 20 bytes IP header, 8 bytes ICMP header, 1 byte payload, equals 43. The NIC will later add padding bytes to get it up to 60 bytes and adds the FCS. Voila, 64 bytes - but Wireshark grabs the packet too early as Jaap already explained, so you see 43 bytes on the sender side.]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>网络测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 查看 CPU 信息]]></title>
    <url>%2F201702%2Fshell%2Fcpuinfo.html</url>
    <content type="text"><![CDATA[本文记录 Linux 操作系统中查看 CPU 信息的方法。查看的内容包含但不局限于： CPU 型号 CPU 核数 CPU 主频 Cache 容量 CPU 指令集 CPU 特性 cat /proc/cpuinfo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354sunyongfeng@openswitch-OptiPlex-380:~$ cat /proc/cpuinfo processor : 0vendor_id : GenuineIntelcpu family : 6model : 23model name : Intel(R) Core(TM)2 Duo CPU E7500 @ 2.93GHzstepping : 10microcode : 0xa07cpu MHz : 1600.000cache size : 3072 KBphysical id : 0siblings : 2core id : 0cpu cores : 2apicid : 0initial apicid : 0fpu : yesfpu_exception : yescpuid level : 13wp : yesflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx lm constant_tsc arch_perfmon pebs bts rep_good nopl aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm sse4_1 xsave lahf_lm tpr_shadow vnmi flexpriority dthermbugs :bogomips : 5851.77clflush size : 64cache_alignment : 64address sizes : 36 bits physical, 48 bits virtualpower management:processor : 1vendor_id : GenuineIntelcpu family : 6model : 23model name : Intel(R) Core(TM)2 Duo CPU E7500 @ 2.93GHzstepping : 10microcode : 0xa07cpu MHz : 1600.000cache size : 3072 KBphysical id : 0siblings : 2core id : 1cpu cores : 2apicid : 1initial apicid : 1fpu : yesfpu_exception : yescpuid level : 13wp : yesflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx lm constant_tsc arch_perfmon pebs bts rep_good nopl aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm sse4_1 xsave lahf_lm tpr_shadow vnmi flexpriority dthermbugs :bogomips : 5851.77clflush size : 64cache_alignment : 64address sizes : 36 bits physical, 48 bits virtualpower management: dmesg | grep Hz12345sunyongfeng@openswitch-OptiPlex-380:~$ dmesg | grep Hz[ 0.000000] tsc: Detected 2925.887 MHz processor[ 0.104000] smpboot: CPU0: Intel(R) Core(TM)2 Duo CPU E7500 @ 2.93GHz (family: 0x6, model: 0x17, stepping: 0xa)[ 0.280044] hpet0: 3 comparators, 64-bit 14.318180 MHz counter[ 1.840016] tsc: Refined TSC clocksource calibration: 2925.999 MHz lscpu1234567891011121314151617181920212223242526sunyongfeng@openswitch-OptiPlex-380:~$ lscpuArchitecture: x86_64CPU op-mode(s): 32-bit, 64-bitByte Order: Little EndianCPU(s): 2On-line CPU(s) list: 0,1Thread(s) per core: 1Core(s) per socket: 2Socket(s): 1NUMA node(s): 1Vendor ID: GenuineIntelCPU family: 6Model: 23Model name: Intel(R) Core(TM)2 Duo CPU E7500 @ 2.93GHzStepping: 10CPU MHz: 1600.000CPU max MHz: 2933.0000CPU min MHz: 1600.0000BogoMIPS: 5851.77Virtualization: VT-xL1d cache: 32KL1i cache: 32KL2 cache: 3072KNUMA node0 CPU(s): 0,1Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx lm constant_tsc arch_perfmon pebs bts rep_good nopl aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm sse4_1 xsave lahf_lm tpr_shadow vnmi flexpriority dthermsunyongfeng@openswitch-OptiPlex-380:~$ lshw -c cpu1234567891011sunyongfeng@openswitch-OptiPlex-380:~$ sudo lshw -c cpu[sudo] password for sunyongfeng: *-cpu product: Intel(R) Core(TM)2 Duo CPU E7500 @ 2.93GHz vendor: Intel Corp. physical id: 1 bus info: cpu@0 size: 1600MHz capacity: 2933MHz width: 64 bits capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx x86-64 constant_tsc arch_perfmon pebs bts rep_good nopl aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm sse4_1 xsave lahf_lm tpr_shadow vnmi flexpriority dtherm cpufreq sudo dmidecode -t processor123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960sunyongfeng@openswitch-OptiPlex-380:~$ sudo dmidecode -t processor# dmidecode 3.0Getting SMBIOS data from sysfs.SMBIOS 2.5 present.Handle 0x0400, DMI type 4, 40 bytesProcessor Information Socket Designation: CPU Type: Central Processor Family: Core 2 Duo Manufacturer: Intel ID: 7A 06 01 00 FF FB EB BF Signature: Type 0, Family 6, Model 23, Stepping 10 Flags: FPU (Floating-point unit on-chip) VME (Virtual mode extension) DE (Debugging extension) PSE (Page size extension) TSC (Time stamp counter) MSR (Model specific registers) PAE (Physical address extension) MCE (Machine check exception) CX8 (CMPXCHG8 instruction supported) APIC (On-chip APIC hardware supported) SEP (Fast system call) MTRR (Memory type range registers) PGE (Page global enable) MCA (Machine check architecture) CMOV (Conditional move instruction supported) PAT (Page attribute table) PSE-36 (36-bit page size extension) CLFSH (CLFLUSH instruction supported) DS (Debug store) ACPI (ACPI supported) MMX (MMX technology supported) FXSR (FXSAVE and FXSTOR instructions supported) SSE (Streaming SIMD extensions) SSE2 (Streaming SIMD extensions 2) SS (Self-snoop) HTT (Multi-threading) TM (Thermal monitor supported) PBE (Pending break enabled) Version: Not Specified Voltage: 1.2 V External Clock: 1066 MHz Max Speed: 5200 MHz Current Speed: 2933 MHz Status: Populated, Enabled Upgrade: Socket LGA775 L1 Cache Handle: 0x0700 L2 Cache Handle: 0x0701 L3 Cache Handle: Not Provided Serial Number: Not Specified Asset Tag: Not Specified Part Number: Not Specified Core Count: 2 Core Enabled: 2 Thread Count: 2 Characteristics: 64-bit capable sudo watch -n 1 cat /sys/devices/system/cpu/cpu*/cpufreq/cpuinfo_cur_freq监控 CPU 频率变化。 12345sunyongfeng@openswitch-OptiPlex-380:~$ sudo watch -n 1 cat /sys/devices/system/cpu/cpu*/cpufreq/cpuinfo_cur_freqEvery 1.0s: cat /sys/devices/system/cpu/cpu0/cpufreq/cpuinfo_cu... Thu Feb 9 12:50:54 201716000001600000]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CPU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git中文编码问题]]></title>
    <url>%2F201701%2Ftools%2Fgit_encode.html</url>
    <content type="text"><![CDATA[来自 解决git在Windows下的乱码问题。 解决前： 1234567891011121314151617sunyongfeng@openswitch-OptiPlex-380:~/workshop/xx/xx-doc$ git statusOn branch masterInitial commitUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) "\344\270\264\346\227\266\346\226\207\346\241\243/" "\345\217\202\350\200\203\350\265\204\346\226\231/" "\346\213\223\345\261\225\345\237\271\350\256\255/" "\347\253\236\344\272\211\345\210\206\346\236\220/" "\350\247\243\345\206\263\346\226\271\346\241\210/" "\350\256\276\350\256\241\346\226\207\346\241\243/" "\351\241\271\347\233\256\347\256\241\347\220\206/"nothing added to commit but untracked files present (use "git add" to track) 解决： 12345sunyongfeng@openswitch-OptiPlex-380:~/workshop/xx/xx-doc$ git config --global core.quotepath falsesunyongfeng@openswitch-OptiPlex-380:~/workshop/xx/xx-doc$ git config --global gui.encoding utf-8sunyongfeng@openswitch-OptiPlex-380:~/workshop/xx/xx-doc$ git config --global i18n.commit.encoding utf-8sunyongfeng@openswitch-OptiPlex-380:~/workshop/xx/xx-doc$ git config --global i18n.logoutputencoding utf-8sunyongfeng@openswitch-OptiPlex-380:~/workshop/xx/xx-doc$ export LESSCHARSET=utf-8 解决后：12345678910111213141516171819sunyongfeng@openswitch-OptiPlex-380:~/workshop/xx/xx-doc$ git statusOn branch masterInitial commitUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) 临时文档/ 参考资料/ 拓展培训/ 竞争分析/ 解决方案/ 设计文档/ 项目管理/nothing added to commit but untracked files present (use "git add" to track)sunyongfeng@openswitch-OptiPlex-380:~/workshop/xx/xx-doc$ sunyongfeng@openswitch-OptiPlex-380:~/workshop/xx/xx-doc$]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux kernel 编译问题记录]]></title>
    <url>%2F201701%2Fprogrammer%2Flinux%2Fkernel_compile_fail.html</url>
    <content type="text"><![CDATA[Can’t use ‘defined(@array)’Linux kernel 无法编译通过，报了如下错误： 1Can't use 'defined(@array)' (Maybe you should just omit the defined()?) at kernel/timeconst.pl line 373. kernel/timeconst.pl 中的代码： 12345372 @val = @&#123;$canned_values&#123;$hz&#125;&#125;; 373 if (!defined(@val)) &#123; 374 @val = compute_values($hz); 375 &#125; 376 output($hz, @val); 将if (!defined(@val))改为if (!@val)，再次编译就 OK。 原因：perl版本升级到 v5.22.1，发现官网因为一个bug，将defined(@array)去掉了。可以直接使用数组判断非空。 来自：http://blog.5ibc.net/p/48570.html error: implicit declaration of functio ‘ioread8’MIPS 架构没有问题的内核模块代码，切到 x86-64，编译时提示如下错误。通过到 linux 源代码 中搜索对应函数，发现函数位于 include/asm/io.h。由于涉及的文件比较多，直接通过 sed 对所有的 .c 文件添加该头文件引用，find . -name &quot;*.c&quot; -exec sed -i &#39;1 i#include &lt;asm/io.h&gt;&#39; &quot;{}&quot; \; 12345678error: implicit declaration of function 'ioread8' error: implicit declaration of function 'ioread16be' error: implicit declaration of function 'ioread32be' error: implicit declaration of function 'iowrite8' error: implicit declaration of function 'iowrite16be' error: implicit declaration of function 'iowrite32be' error: implicit declaration of function 'ioremap' error: implicit declaration of function 'iounmap']]></content>
      <categories>
        <category>kernel</category>
      </categories>
      <tags>
        <tag>kernel</tag>
        <tag>compile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux c printf 相关记录]]></title>
    <url>%2F201612%2Fprogrammer%2Fc%2Fcontainer_of.html</url>
    <content type="text"><![CDATA[结构体成员取结构体头指针 list_entry-&gt;container_of-&gt;offsetof 344 /*345 list_entry - get the struct for this entry346 @ptr: the &amp;struct list_head pointer.347 @type: the type of the struct this is embedded in.348 @member: the name of the list_struct within the struct.349 /350 #define list_entry(ptr, type, member) \351 container_of(ptr, type, member) 684 /*685 container_of - cast a member of a structure out to the containing structure686 @ptr: the pointer to the member.687 @type: the type of the container struct this is embedded in.688 @member: the name of the member within the struct.689 690 /691 #define container_of(ptr, type, member) ({ \692 const typeof( ((type )0)-&gt;member ) __mptr = (ptr); \693 (type )( (char *)__mptr - offsetof(type,member) );}) Linux/include/linux/stddef.h 1 #ifndef _LINUX_STDDEF_H 2 #define _LINUX_STDDEF_H 3 4 #include &lt;linux/compiler.h&gt; 5 6 #ifdef KERNEL 7 8 #undef NULL 9 #define NULL ((void )0) 10 11 enum { 12 false = 0, 13 true = 1 14 }; 15 16 #undef offsetof 17 #ifdef compiler_offsetof 18 #define offsetof(TYPE,MEMBER) compiler_offsetof(TYPE,MEMBER) 19 #else 20 #define offsetof(TYPE, MEMBER) ((size_t) &amp;((TYPE )0)-&gt;MEMBER) 21 #endif 22 #endif / KERNEL / 23 24 #endif 25 __compiler_offsetof(TYPE,MEMBER)就和gcc的原子操作实现一样，也是编译器built-in]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux c 预处理使用记录]]></title>
    <url>%2F201612%2Fprogrammer%2Fc%2Fpreprocess.html</url>
    <content type="text"><![CDATA[字符串化操作，Stringfication符号 #，对它所引用的宏变量，通过替换后，在其左右各加上一个双引号。 1#define WARN_IF(EXP) do&#123; if (EXP) fprintf(stderr, "Warning: " #EXP "/n"); &#125; while(0) 实际使用中会出现下面所示的替换过程：1WARN_IF (divider == 0); 被替换为：1234do &#123;if (divider == 0)fprintf(stderr, "Warning" "divider == 0" "/n");&#125; while(0); 连接符，Concatenator##，用来将两个token连接成一个Token，连接的Tocken不一定是宏变量。]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux c atomic]]></title>
    <url>%2F201612%2Fprogrammer%2Fc%2Fatomic.html</url>
    <content type="text"><![CDATA[原子操作也是同步的一种，信号量就是一个atomic_t。kernel中，见asm-generic/atomic.h或asm-generic/bitops/atomic.h，据称不要user space中gcc从4.1.1开始支持built-in atomic，但是有架构要求，详见gcc wiki，http://gcc.gnu.org/wiki/Atomic。glibc atomic 下面这个atomic.h是从 http://golubenco.org/2007/06/14/atomic-operations/ down下来的，作者的愿意是替代kernel原有的atomic 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123/** * Atomic type. */typedef struct &#123; volatile int counter;&#125; atomic_t;#define ATOMIC_INIT(i) &#123;(i)&#125;/** * Read atomic variable * @param v pointer of type atomic_t * * Atomically reads the value of @v. */#define atomic_read(v) ((v)-&gt;counter)/** * Set atomic variable * @param v pointer of type atomic_t * @param i required value */#define atomic_set(v,i) (((v)-&gt;counter) = (i))/** * Add to the atomic variable * @param i integer value to add * @param v pointer of type atomic_t */static inline void atomic_add( int i, atomic_t *v )&#123; (void)__sync_add_and_fetch(&amp;v-&gt;counter, i);&#125;/** * Subtract the atomic variable * @param i integer value to subtract * @param v pointer of type atomic_t * * Atomically subtracts @i from @v. */static inline void atomic_sub( int i, atomic_t *v )&#123; (void)__sync_sub_and_fetch(&amp;v-&gt;counter, i);&#125;/** * Subtract value from variable and test result * @param i integer value to subtract * @param v pointer of type atomic_t * * Atomically subtracts @i from @v and returns * true if the result is zero, or false for all * other cases. */static inline int atomic_sub_and_test( int i, atomic_t *v )&#123; return !(__sync_sub_and_fetch(&amp;v-&gt;counter, i));&#125;/** * Increment atomic variable * @param v pointer of type atomic_t * * Atomically increments @v by 1. */static inline void atomic_inc( atomic_t *v )&#123; (void)__sync_fetch_and_add(&amp;v-&gt;counter, 1);&#125;/** * @brief decrement atomic variable * @param v: pointer of type atomic_t * * Atomically decrements @v by 1. Note that the guaranteed * useful range of an atomic_t is only 24 bits. */static inline void atomic_dec( atomic_t *v )&#123; (void)__sync_fetch_and_sub(&amp;v-&gt;counter, 1);&#125;/** * @brief Decrement and test * @param v pointer of type atomic_t * * Atomically decrements @v by 1 and * returns true if the result is 0, or false for all other * cases. */static inline int atomic_dec_and_test( atomic_t *v )&#123; return !(__sync_sub_and_fetch(&amp;v-&gt;counter, 1));&#125;/** * @brief Increment and test * @param v pointer of type atomic_t * * Atomically increments @v by 1 * and returns true if the result is zero, or false for all * other cases. */static inline int atomic_inc_and_test( atomic_t *v )&#123; return !(__sync_add_and_fetch(&amp;v-&gt;counter, 1));&#125;/** * @brief add and test if negative * @param v pointer of type atomic_t * @param i integer value to add * * Atomically adds @i to @v and returns true * if the result is negative, or false when * result is greater than or equal to zero. */static inline int atomic_add_negative( int i, atomic_t *v )&#123; return (__sync_add_and_fetch(&amp;v-&gt;counter, i) &lt; 0);&#125;]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 内核数据结构分析]]></title>
    <url>%2F201612%2Fprogrammer%2Flinux%2Fkernel_data_structure.html</url>
    <content type="text"><![CDATA[【TBD】 链表 队列 映射 红黑树 散列表 位图]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[moinmoin 配置过程记录]]></title>
    <url>%2F201611%2Fadministrator%2Fmoinmoin_setup.html</url>
    <content type="text"><![CDATA[主题配置配置成 bootstrap 主题。 详见 memodump 安装过程。screenshot： markdown 语法支持 安装使用 python markdown 命令：pip install markdown。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051root@ubuntu:~# pip install markdownDownloading/unpacking markdown Downloading Markdown-2.6.7.zip (413kB): 413kB downloaded Running setup.py (path:/tmp/pip_build_root/markdown/setup.py) egg_info for package markdown Installing collected packages: markdown Running setup.py install for markdown changing mode of build/scripts-2.7/markdown_py from 644 to 755 Converting docs/siteindex.txt -&gt; build/docs/siteindex.html Converting docs/release-2.0.1.txt -&gt; build/docs/release-2.0.1.html Converting docs/release-2.0.2.txt -&gt; build/docs/release-2.0.2.html Converting docs/install.txt -&gt; build/docs/install.html Converting docs/index.txt -&gt; build/docs/index.html Converting docs/release-2.4.txt -&gt; build/docs/release-2.4.html Converting docs/release-2.2.1.txt -&gt; build/docs/release-2.2.1.html Converting docs/authors.txt -&gt; build/docs/authors.html Converting docs/release-2.1.0.txt -&gt; build/docs/release-2.1.0.html Converting docs/change_log.txt -&gt; build/docs/change_log.html Converting docs/release-2.3.txt -&gt; build/docs/release-2.3.html Converting docs/cli.txt -&gt; build/docs/cli.html Converting docs/release-2.6.txt -&gt; build/docs/release-2.6.html Converting docs/release-2.2.0.txt -&gt; build/docs/release-2.2.0.html Converting docs/release-2.0.txt -&gt; build/docs/release-2.0.html Converting docs/release-2.5.txt -&gt; build/docs/release-2.5.html Converting docs/release-2.1.1.txt -&gt; build/docs/release-2.1.1.html Converting docs/reference.txt -&gt; build/docs/reference.html Converting docs/test_suite.txt -&gt; build/docs/test_suite.html Converting docs/extensions/definition_lists.txt -&gt; build/docs/extensions/definition_lists.html Converting docs/extensions/footnotes.txt -&gt; build/docs/extensions/footnotes.html Converting docs/extensions/admonition.txt -&gt; build/docs/extensions/admonition.html Converting docs/extensions/abbreviations.txt -&gt; build/docs/extensions/abbreviations.html Converting docs/extensions/index.txt -&gt; build/docs/extensions/index.html Converting docs/extensions/fenced_code_blocks.txt -&gt; build/docs/extensions/fenced_code_blocks.html Converting docs/extensions/sane_lists.txt -&gt; build/docs/extensions/sane_lists.html Converting docs/extensions/tables.txt -&gt; build/docs/extensions/tables.html Converting docs/extensions/api.txt -&gt; build/docs/extensions/api.html Converting docs/extensions/meta_data.txt -&gt; build/docs/extensions/meta_data.html Converting docs/extensions/code_hilite.txt -&gt; build/docs/extensions/code_hilite.html Converting docs/extensions/smarty.txt -&gt; build/docs/extensions/smarty.html Converting docs/extensions/wikilinks.txt -&gt; build/docs/extensions/wikilinks.html Converting docs/extensions/header_id.txt -&gt; build/docs/extensions/header_id.html Converting docs/extensions/extra.txt -&gt; build/docs/extensions/extra.html Converting docs/extensions/nl2br.txt -&gt; build/docs/extensions/nl2br.html Converting docs/extensions/toc.txt -&gt; build/docs/extensions/toc.html Converting docs/extensions/smart_strong.txt -&gt; build/docs/extensions/smart_strong.html Converting docs/extensions/attr_list.txt -&gt; build/docs/extensions/attr_list.html changing mode of /usr/local/bin/markdown_py to 755Successfully installed markdownCleaning up...root@ubuntu:~# moinmoin markdown 插件 详见 ParserMarket/Markdown。下载 text_markdown.py 到 data/plugin/parser。修改 text_markdown.py，把 output_html = markdown(self.raw) 改为 markdown(self.raw, extensions=[&#39;extra&#39;, &#39;abbr&#39;, &#39;attr_list&#39;, &#39;def_list&#39;, &#39;fenced_code&#39;, &#39;footnotes&#39;, &#39;tables&#39;, &#39;smart_strong&#39;, &#39;admonition&#39;, &#39;codehilite&#39;, &#39;headerid&#39;, &#39;meta&#39;, &#39;nl2br&#39;, &#39;sane_lists&#39;, &#39;smarty&#39;, &#39;toc&#39;, &#39;wikilinks&#39;, &#39;del_ins&#39;])，把你需要的 extra 往里加。 这里的 del_ins 是通过 pip install git+git://github.com/aleray/mdx_del_ins.git 安装支持的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344""" MoinMoin - Parser for Markdown Syntax: To use in a code block: &#123;&#123;&#123;&#123;#!text_markdown &lt;add markdown text here&gt; &#125;&#125;&#125;&#125; To use for an entire page: #format text_markdown &lt;add markdown text here&gt; @copyright: 2009 by Jason Fruit (JasonFruit at g mail dot com) @license: GNU GPL, see http://www.gnu.org/licenses/gpl for details"""from markdown import markdownfrom markdown.extensions import ExtensionDependencies = ['user']class Parser: """ A thin wrapper around a Python implementation (http://www.freewisdom.org/projects/python-markdown/) of John Gruber's Markdown (http://daringfireball.net/projects/markdown/) to make it suitable for use with MoinMoin. """ def __init__(self, raw, request, **kw): self.raw = raw self.request = request def format(self, formatter): # output_html = markdown(self.raw) output_html = markdown(self.raw, extensions=['extra', 'abbr', 'attr_list', 'def_list', 'fenced_code', 'footnotes', 'tables', 'smart_strong', 'admonition', 'codehilite', 'headerid', 'meta', 'nl2br', 'sane_lists', 'smarty', 'toc', 'wikilinks', 'del_ins']) try: self.request.write(formatter.rawHTML(output_html)) except: self.request.write(formatter.escapedText(output_html)) 中文语言支持配置安装语言包，使用你配置的超级用户如 WikiAdmin 登陆。访问wiki语言设置页面，根据自己的域名而修改，http://localhost/LanguageSetup?action=language_setup。选择安装简体中文语言包，会看到提示：附件&#39;Simplified_Chinese--all_pages.zip&#39;已安装。 修改默认语言为中文12345[root@syswiki moin]# vim /opt/syswiki/share/moin/wikiconfig.py …………略………… # The main wiki language, set the direction of the wiki pages language_default = 'zh'…………略………… 重启 moinmoin 就可以看到页面换成中文。]]></content>
      <categories>
        <category>administrator</category>
      </categories>
      <tags>
        <tag>administrator</tag>
        <tag>moinmoin</tag>
        <tag>wiki</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装 discourse]]></title>
    <url>%2F201611%2Fadministrator%2Fdiscourse_install.html</url>
    <content type="text"><![CDATA[安装 discourse 到 ubuntu 14.04。详见 Set up Discourse in the cloud in under 30 minutes。 安装 docker命令：wget -qO- https://get.docker.com/ | sh 安装 discourse1234sudo -smkdir /var/discoursegit clone https://github.com/discourse/discourse_docker.git /var/discoursecd /var/discourse 配置 app.xmlapp 的名称自取，此处直接命名为 app。 拷贝默认配置文件 1cp samples/standalone.yml containers/app.yml 配置 ruby 国内源 在 app.yml 添加一行 templates/web.china.template.yml。 123456templates: - "templates/postgres.template.yml" - "templates/redis.template.yml" - "templates/web.template.yml" - "templates/web.ratelimited.template.yml" - "templates/web.china.template.yml" 配置默认端口 这里改默认端口为 10080。123expose: - "10080:80" # http - "10443:443" # https 配置邮箱 用于 administrator 的激活邮件。至关重要！此处用的 163 邮箱。 1234567891011121314151617181920212223242526272829env: LANG: en_US.UTF-8 # DISCOURSE_DEFAULT_LOCALE: en ## How many concurrent web requests are supported? Depends on memory and CPU cores. ## will be set automatically by bootstrap based on detected CPUs, or you can override #UNICORN_WORKERS: 3 ## TODO: The domain name this Discourse instance will respond to ## 此处我个人直接配置 IP DISCOURSE_HOSTNAME: '172.18.xxx.xxx' ## Uncomment if you want the container to be started with the same ## hostname (-h option) as specified above (default "$hostname-$config") #DOCKER_USE_HOSTNAME: true ## TODO: List of comma delimited emails that will be made admin and developer ## on initial signup example 'user1@example.com,user2@example.com' ## 管理员邮箱列表，多个以逗号隔开 DISCOURSE_DEVELOPER_EMAILS: 'your@163.com' ## TODO: The SMTP mail server used to validate new accounts and send notifications DISCOURSE_SMTP_ADDRESS: 'smtp.163.com' # required DISCOURSE_SMTP_PORT: 25 # (optional, default 587) DISCOURSE_SMTP_USER_NAME: 'your@163.com' # required DISCOURSE_SMTP_PASSWORD: 'password' # required, WARNING the char '#' in pw can cause problems! DISCOURSE_SMTP_ENABLE_START_TLS: true # (optional, default true) DISCOURSE_SMTP_AUTHENTICATION: login DISCOURSE_SMTP_OPENSSL_VERIFY_MODE: none 配置邮件的默认发送者： 将 ##- exec: rails r &quot;SiteSetting.notification_email... 的 # 号去掉，并把邮箱设置为你自己的邮箱。 1234567## Any custom commands to run after buildingrun: - exec: echo "Beginning of custom commands" ## If you want to set the 'From' email address for your first registration, uncomment and change: ## After getting the first signup email, re-comment the line. It only needs to run once. - exec: rails r "SiteSetting.notification_email='your@163.com'" - exec: echo "End of custom commands" 调试邮件发送情况，查看 Log 文件 shared/standalone/log/rails/production.log。一个样例：123456Sent mail to sunnogo@163.com (20111.6ms)Job exception: end of file reachedSent mail to sunnogo@163.com (20241.3ms)Job exception: end of file reached 编译、启动 appbootstrap 或 rebuild 的时间很长，特别是第一次运行时，要下载多个组件。 12sudo ./launcher bootstrap appsudo ./launcher start app 即可登陆你的 discourse 论坛开始配置了。]]></content>
      <categories>
        <category>administrator</category>
      </categories>
      <tags>
        <tag>discourse</tag>
        <tag>administrator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 编译时 configure 问题记录]]></title>
    <url>%2F201611%2Fprogrammer%2Ftools%2Fconfigure.html</url>
    <content type="text"><![CDATA[–host, –target and –build 选项这部分内容译自：Configure with –host, –target and –build options。 在交叉编译时，很可能涉及到这三个容易混淆的选项： --build，程序在哪个系统上编译； --host，编译生成的程序在哪个系统上运行； --target，只在交叉编译工具链上使用；交叉编译工具链编译的程序在哪个目标系统上运行。 以 tslib （一个鼠标驱动库）为例：这个动态库在 x86 linux PC 上编译、构建，生成的结果在 arm linux 系统上运行。1./configure --host=arm-linux --build=i686-pc-linux-gnu 以 gcc 为例：（例子有点绕，但是很到位） --build，在 x86 linux PC 上编译 gcc； --host，编译生成的 gcc 可在嵌入式 arm linux 系统上运行； --target，在 arm linux 上 运行 gcc，可编译、构建生成二进制可执行文件，这些可执行文件最终将运行在 x86 linux 系统上。 1./configure --target=i686-pc-linux-gnu --host=arm-linux --build=i686-pc-linux-gnu]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>compile</tag>
        <tag>configure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux c printf 相关记录]]></title>
    <url>%2F201611%2Fprogrammer%2Fc%2Fprintf.html</url>
    <content type="text"><![CDATA[打印 64 位 inthttp://stackoverflow.com/questions/9225567/how-to-print-a-int64-t-type-in-c With C99 the %j length modifier can also be used with the printf family of functions to print values of type int64_t and uint64_t:12345678910111213#include &lt;stdio.h&gt;#include &lt;stdint.h&gt;int main(int argc, char *argv[])&#123; int64_t a = 1LL &lt;&lt; 63; uint64_t b = 1ULL &lt;&lt; 63; printf("a=%jd (0x%jx)\n", a, a); printf("b=%ju (0x%jx)\n", b, b); return 0;&#125;]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BitBake 实用指南]]></title>
    <url>%2F201610%2Fprogrammer%2Fyocto%2FBitbake_practical_guide.html</url>
    <content type="text"><![CDATA[[TOC] 译者序 本文译自 A practical guide to BitBake。 如果你发现 bug、不清楚的章节、打印错误或其他建议，请邮件告知我，我的邮箱是 `sunnogo@gmail.com`。 注意：由于 task 和 recipe 是 BitBake 的基础概念。个人觉得翻译成任务和配方不免有误解之处，因此文中基本不对这两个词做翻译。类似的还有 configure。 序言 1.1 关于本教程如果你阅读本教程，说明你已经知道 BitBake 是一种类似 make 的构建工具，主要用于 OpenEmbedded 和 Yocto 工程构建 Linux 发行版本。你可能也已经意识到 BitBake 的学习曲线有点陡，本文可让这个曲线变平缓一些。 本文不会告诉你 BitBake 的一切，但是会尝试解释使用 BitBake 时用到的一些基本功能。理解这些基础可帮助你开始写自己的 BitBake recipe。 1.2 本教程的目标本教程展示如何创建一个最小工程，并一步步扩展，说明 BitBake 如何运作。 1.3 致谢感谢 Tritech 给我时间准备本文档。同时感谢大家在问题跟踪站点报告的问题与打印错误。 1.4 反馈如果你发现 bug、不清楚的章节、打印错误或其他建议， 请使用 issue tracker https://bitbucket.org/a4z/bitbakeguide/issues，不需要注册。同时也可以使用本文底部的 Disqus 评论功能。 BitBake 2.1 什么是 BitBake以下内容有助于理解 BitBake： 基本上，BitBake是一个Python程序，它由用户创建的配置驱动，可以为用户指定的目标执行用户创建的任务，即所谓的配方（recipes）。 2.1.1 Config、tasks 与 recipes通过一种 BitBake 领域特定语言写 Config、tasks 与 recipes，这种语言包含变量与可执行的 shell、python 代码。所以理论上，BitBake 可以执行代码，你也可以用 BitBake 做除构建软件之外的事情，但是并不推荐这么做。 BitBake 是一种构建软件的工具，因此有一些特殊的功能，比如可以定义依赖关系。BitBake 可以解决依赖关系，并将其任务以正确顺序运行。此外，构建软件包通常包含相同或相似的任务。比如常见的任务：下载源代码包，解压源代码，跑 configure，跑 make，或简单的输出 log。Bitbake 提供一种机制，可通过一种可配置的方式，抽象、封装和重用这个功能。 配置 BitBake BitBake 可以从这里下载：https://github.com/openembedded/bitbake。选择一个版本的分支，并下载 zip。解压 zip 包，可找到一个 bitbake-$version 目录。 注意：本文使用的 Bitbake 版本是 bitbake-1.22，因此适合本教程的 bitbake 版本应该大于或等于1.22。注意：译者使用 bitbake-1.27.0，因此文中样例为 1.27.0 版本 bitbake 样例。提示：如果使用 Yocto，则不需要安装 BitBake，Yocto 源代码本身捆绑了 BitBake。Yocto 要求你 source 一个脚本，这个脚本和我们这里做的一样，安装 BitBake 到我们的环境中。 3.1 安装 BitBake安装过程很简单： 添加 bitbake-$version/bin 目录到 PATH 添加 bitbake-$version/lib 目录到 PYTHONPATH 即执行：12export PATH=/path/to/bbtutor/bitbake/bin:$PATHexport PYTHONPATH=/path/to/bbtutor/bitbake/lib:$PYTHONPATH 这基本和 yocto init 脚本一致。yocto init 脚本同时也创建 build 目录，我们将在一会儿创建。 首先检测是不是一切正常、bitbake 是否安装成功。通过执行以下 bitbake 命令：1bitbake --version 运行结果应该类似：1BitBake Build Tool Core version 1.27.0 3.2 BitBake 文档最实际的版本带有源代码。 在终端中，cd 到 bitbake-$version/doc 目录并执行以下命令，生成 doc/bitbake-user-manual/bitbake-user-manual.html。1make html DOC=bitbake-user-manual 这个文档可与本教程并行阅读，在读完本教程后也需要阅读该文档。 yocto 工程文档 也有一个 bitbake 章节。 创建工程 4.1 Bitbake 工程布局通过 BitBake 工程通过 layers 目录与一个 build 目录组织，layer 目录包含配置文件和 meta data。 4.1.1 Layer 目录Layer 目录包含配置、任务和目标描述。常用 meta-‘something’ 命名 Layer 目录。 4.1.2 Build 目录Build 目录是 bitbake 命令被执行的地方。在这里，BitBake 期望能找到其初始配置文件，并将其生成的所有文件放在这个目录。 为了让 BitBake 运行时出现有任何错误，我们需要创建一个 build 目录和一个 layer 目录，并在此存放一些需要的配置文件。 4.2 最小工程最小的配置看起来像这样：1234567891011bbTutorial/├── build│ ├── bitbake.lock│ └── conf│ └── bblayers.conf└── meta-tutorial ├── classes │ └── base.bbclass └── conf ├── bitbake.conf └── layer.conf 需要创建这 4 个文件： bblayers.conf base.bbclass bitbake.conf layer.conf 4.2.1 需要的配置文件首先描述需要的文件，然后简要说明其内容。 build/conf/bblayers.conf，BitBake 在其工作目录（即 build 目录）期望找到的第一个文件。现在我们以以下内容创建一个 bblayers.conf：123BBPATH := "$&#123;TOPDIR&#125;"BBFILES ?= ""BBLAYERS = "/path/to/meta-tutorial" meta-tutorial/conf/layer.conf，每个 layer 需要一个 conf/layer.conf 文件。现在我们以以下内容创建它：12BBPATH .= ":$&#123;LAYERDIR&#125;"BBFILES += "" meta-tutorial/classes/base.bbclassmeta-tutorial/conf/bitbake.conf现在，这些文件可以从 BitBake 安装目录中获取。这些文件位于文件夹 bitbake-$version/conf 和 bitbake-$version/classes中。只需将它们复制到 tutorial 项目中。 4.2.2 创建文件的一些注意事项build/conf/bblayers.conf 添加当前目录到 BBPATH，TOPDIR 被 BitBake 设置为当前工作目录。 初始设置 BBFILES 变量为空，Recipes 在后面会添加。 添加我们 meta-tutorial 的路径到 BBLAYERS 变量。当 BitBake 开始执行时，它会搜索所有给定的 layer 目录，以便获得其他配置。 meta-tutorial/conf/layer.conf LAYERDIR 是 BitBake 传给其所加载 Layer 的变量。我们添加该路径到 BBPATH 变量。 BBFILES 告诉 BitBake recipes 在哪，现在我们没有添加任何东西，但是一会儿我们会改变它。 注意事项。“.=” 和“+=” 以不添加空格、添加空格的方式，将追加值附给一个变量。 conf/bitbake.confconf/bibake.conf 包含 一系列我们讨论的变量。 classes/base.bbclass一个 *.bbclass 文件包含共享功能。我们的 base.bbclass 包含一些我们一会儿使用的 log 函数，以及一个 buld 任务。并不是很有用，但是 BitBake 有需求，因为如果没有任何具体业务时，BitBake 默认需求的。我们随后将改变此功能。 4.2.3 BitBake 搜索路径对于 BitBake 来讲，有许多 BBPATH 非法和文件路径。这说明如果我们告诉 BitBake 探索一些路径时，它会搜索 BBPATH。我们添加 TOPDIR 和 LAYERDIR 到 BBPATH，放在 classes/base.bbclass 或 conf/bitbake.conf 中的任意一个。当然，我们会添加 meta-tutorial 目录。编译目录不应含有通用文件。只有像 local.conf 对实际编译是有效的，后面我们会用到 local.conf。 第一次运行创建上述四个配置文件后，在终端 cd 到 build 目录，这是我们的工作目录。我们一直在 build 目录运行 bitbake 命令，以便 bitbake 可以找到相应的 conf/bblayers.conf 文件。 现在，在 build 目录，不带任何参数运行 bitbake 命令：1bitbake 如果先前的步骤正确，则控制台会输出：1Nothing to do. Use 'bitbake world' to build everything, or run 'bitbake --help' for usage information. 这没什么用，但是一个好的开始。 这里介绍一个很有用的命令标志：输出一些 debug 信息。执行 bitbake -vDD，然后查看其输出，它告诉我们大量关于 BitBake 如何动作的信息。 1234567891011DEBUG: Found bblayers.conf (~/bbTutorial/build/conf/bblayers.conf)DEBUG: LOAD ~/bbTutorial/build/conf/bblayers.confDEBUG: Adding layer ~/bbTutorial/meta-tutorialDEBUG: LOAD ~/bbTutorial/meta-tutorial/conf/layer.confDEBUG: LOAD ~/bbTutorial/meta-tutorial/conf/bitbake.confDEBUG: BB configuration INHERITs:0: inheriting ~/bbTutorial/meta-tutorial/classes/base.bbclassDEBUG: BB ~/bbTutorial/meta-tutorial/classes/base.bbclass: handle(data, include)DEBUG: LOAD ~/bbTutorial/meta-tutorial/classes/base.bbclassDEBUG: Clearing SRCREV cache due to cache policy of: clearDEBUG: Using cache in '~/bbTutorial/build/tmp/cache/local_file_checksum_cache.dat'DEBUG: Using cache in '~/bbTutorial/build/tmp/cache/bb_codeparser.dat' 你在注意到 BitBake 创建了一个 bitbake.log 文件和一个 tmp 目录？12sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ lsbitbake.lock conf tmp 提示，所有的样例代码都可从 https://bitbucket.org/a4z/bitbakeguide 获取。本样例在 ch04。 第一个 recipe BitBake 需要 recipes 定义要做些什么，现在这里什么都没有。我们可以通过 bitbake -s 确认运行时什么也没做：123456789sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake -sERROR: no recipe files to build, check your BBPATH and BBFILES?Summary: There was 1 ERROR message shown, returning a non-zero exit code.NOTE: Not using a cache. Set CACHE = &lt;directory&gt; to enable.Recipe Name Latest Version Preferred Version=========== ============== =================sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ 这告诉我们两个信息： 没有定义任何 cache； BitBake 真的没事可做，只显示了一个空的 recipe 列表 5.1 cache 位置BitBake 缓存 meta data 在一个目录，即 cache 目录。这会帮助加速后面执行的命令。 我们可通过简单添加一个变量到 bitbake.conf 文件，解决 cache 找不到的问题。因此，我们编辑 meta-tutorial/conf/bitbake.conf 文件，并在底部添加： 1CACHE = "$&#123;TMPDIR&#125;/cache/default" 添加后运行 bitbake -s 的结果：1234sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake -sERROR: no recipe files to build, check your BBPATH and BBFILES?Summary: There was 1 ERROR message shown, returning a non-zero exit code. 注意：在实现项目中，比如 Yocto，这些变量已经设置好，我们不用关心。通常 cache 路径由不同的变量组成，在名称中包含实际的构建配置，如 debug 或 release。 下一步是添加一个 recipe，需要两个步骤： 使 bitbake 可以找到 recipes 写第一个 recipe 5.2 添加一个 recipe 到 tutorial layerBitBake 需要知道一个 layer 提供哪些 recipes，可通过编辑 meta-tutorial/conf/layer.conf 文件，使用通配符告诉 BitBake 加载所有的 recipe：12BBPATH .= ":$&#123;LAYERDIR&#125;"BBFILES += "$&#123;LAYERDIR&#125;/recipes-*/*/*.bb" 现在可以使用先前在 build/conf/bblayers.conf 定义的变量。recipe 文件的扩展名是 .bb，如果我们通过通配符的方式，只用一行就可以告诉 BitBake 加载所有 recipes。 通常 recipes 有自己的目录，并以 groups 的形式收集在一起，也就是说把有关联的 recipes 放在同一个目录。 注意：通常使用 recipes-‘group’ 命令这些目录，这里 group 名表示一个 category 或一些程序。 现在 BitBake 已经知道从哪找 recipe，我们可以开始添加第一个 recipe 了。 按通常的做法，我们创建目录 meta-tutorial/recipes-tutorial/first，并在此创建第一个 recipe。 Recipe 文件也有通用的命名方法：{recipe}_{version}.bb 5.3 创建第一个 recipe 和 task我们的第一个 recipe 只打印一些 log 信息。将它放在 tutorial group，版本为 0.1。所以我们的第一个 recipe 是：meta-tutorial/recipes-tutorial/first/first_0.1.bb12345DESCRIPTION = "I am the first recipe"PR = "r1"do_build () &#123; echo "first: some shell script running as build"&#125; task do_build 覆盖 base.bbclass 中的全局 build task。 PR 是内部修订数据，在每次修订后应被更新。 设置 description 可解释该 recipe 的用途。 如果上面都做对了，可以通过 bitbake -s 列出可用的 recipes。 1234567sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake -sParsing recipes: 100% |################################################################################| Time: 00:00:00Parsing of 1 .bb files complete (0 cached, 1 parsed). 1 targets, 0 skipped, 0 masked, 0 errors.Recipe Name Latest Version Preferred Version=========== ============== =================first :0.1-r1 然后就可以执行 bitbake first 编译 first 组件。1234567sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake firstParsing recipes: 100% |################################################################################| Time: 00:00:00Parsing of 1 .bb files complete (0 cached, 1 parsed). 1 targets, 0 skipped, 0 masked, 0 errors.NOTE: Resolving any missing task queue dependenciesNOTE: Preparing RunQueueNOTE: Executing RunQueue TasksNOTE: Tasks Summary: Attempted 1 tasks of which 0 didn't need to be rerun and all succeeded. 现在检查 tmp/work/first-0.1-r1/temp 目录，里面有一些有趣的文件：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ ls -al tmp/work/first-0.1-r1/temp/total 20drwxrwxr-x 2 sunyongfeng sunyongfeng 4096 10月 20 11:19 .drwxrwxr-x 3 sunyongfeng sunyongfeng 4096 10月 20 11:19 ..lrwxrwxrwx 1 sunyongfeng sunyongfeng 18 10月 20 11:19 log.do_build -&gt; log.do_build.17314-rw-rw-r-- 1 sunyongfeng sunyongfeng 123 10月 20 11:19 log.do_build.17314-rw-rw-r-- 1 sunyongfeng sunyongfeng 37 10月 20 11:19 log.task_orderlrwxrwxrwx 1 sunyongfeng sunyongfeng 18 10月 20 11:19 run.do_build -&gt; run.do_build.17314-rwxrwxr-x 1 sunyongfeng sunyongfeng 909 10月 20 11:19 run.do_build.17314sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/first-0.1-r1/temp/log.do_build.17314 DEBUG: Executing shell function do_buildfirst: some shell script running as buildDEBUG: Shell function do_build finishedsunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/first-0.1-r1/temp/log.task_order do_build (17314): log.do_build.17314sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/first-0.1-r1/temp/run.do_build#!/bin/sh# Emit a useful diagnostic if something fails:bb_exit_handler() &#123; ret=$? case $ret in 0) ;; *) case $BASH_VERSION in "") echo "WARNING: exit code $ret from a shell command.";; *) echo "WARNING: $&#123;BASH_SOURCE[0]&#125;:$&#123;BASH_LINENO[0]&#125; exit $ret from "$BASH_COMMAND"";; esac exit $ret esac&#125;trap 'bb_exit_handler' 0set -eexport HOME="/home/sunyongfeng"export SHELL="/bin/bash"export LOGNAME="sunyongfeng"export USER="sunyongfeng"export PATH="/home/sunyongfeng/ops-build.test/yocto/poky/scripts:/home/sunyongfeng/ops-build.test/yocto/poky/bitbake/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin"export TERM="linux"do_build() &#123; echo "first: some shell script running as build"&#125;cd '/home/sunyongfeng/workshop/test/tutorial/build'do_build# cleanupret=$?trap '' 0exit $? Classes 和 functions 下一步将： 添加一个 class 添加一个使用 class 的 recipe 探索 functions 6.1 创建 mybuild class创建一个不同的 build 函数，并共享。先在 tutorial layer 创建 class，如 meta-tutorial/classes/mybuild.bbclass：12345678addtask buildmybuild_do_build () &#123; echo "running mybuild_do_build." &#125; EXPORT_FUNCTIONS do_build 在 base.class 中，我们添加了一个 build task，它也是一个简单的 shell 函数。mybuild_do 前缀的依据是 class 中 task 定义的规范 classname_do_functionname。 EXPORT_FUNCTIONS 使该 build 函数可被这个 class 的使用者使用，如果不添加这行，则它不会覆盖 base class 中的 build 函数。 现在，已可在第二个 recipe 中使用这个 class。 6.2 在第二个 recipe 中使用 myclass这里添加一个小目标，在 build 任务前先运行一个 patch 函数，这里需要一些 python 的用法。 依据 bitbake 的命名规范，我们添加一个新的 recipe 目录，并在该目录内添加一个 recipe 文件 meta-tutorial/recipes-tutorial/second/second_1.0.bb： 12345678910111213DESCRIPTION = "I am he second recipe"PR = "r1" (1)inherit mybuild (2) def pyfunc(o): (3) print dir (o) python do_mypatch () &#123; (4) bb.note ("runnin mypatch") pyfunc(d) (5)&#125; addtask mypatch before do_build (6) 像 first recipe 那样定义 DESCRIPTION 和 PR； 继承 mybuild class，让 myclass_do_build 成为默认 build task； 纯 python 函数 pyfunc 获取一些参数，并根据该入参运行 python dir 函数； bitbake python 函数 my_patch 添加并注册成一个 task，该 task 要在 build 函数前执行。 mypatch 函数调用 pyfunc 函数，并传入全局 bitbake 变量 d。d (datastore) 由 bitbake 定义，并一直可用。 mypatch 函数被注册成一个 task，并要求在 build 函数前执行。 这就是一个使用 python 函数的样例。 注意：函数部分的内容在 bitbake 手册 3.4 节。 6.3 探索 recipes 和 tasks现在我们有两个 recipes 可用，可探索一些新的 bitbake 命令选项。我们可以获取BitBake 运行时 recipes 及其 tasks、控制过程的信息。 6.3.1 显示 recipes 和 tasks 列表12345678sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake -sParsing recipes: 100% |################################################################################| Time: 00:00:00Parsing of 2 .bb files complete (0 cached, 2 parsed). 2 targets, 0 skipped, 0 masked, 0 errors.Recipe Name Latest Version Preferred Version=========== ============== =================first :0.1-r1 second :1.0-r1 如果想看某个 recipe 提供哪些 tasks，可以通过 bitbake -c listtasks recipe_name 查看：1234567891011sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake -c listtasks secondParsing recipes: 100% |################################################################################| Time: 00:00:00Parsing of 2 .bb files complete (0 cached, 2 parsed). 2 targets, 0 skipped, 0 masked, 0 errors.NOTE: Resolving any missing task queue dependenciesNOTE: Preparing RunQueueNOTE: Executing RunQueue Tasksdo_showdatado_builddo_mypatchdo_listtasksNOTE: Tasks Summary: Attempted 1 tasks of which 0 didn't need to be rerun and all succeeded. 6.4 执行 tasks 或完整构建有些选项可在 recipes 执行 builds 或特定任务时使用。 构建一个 recipe。使用 bitbade recipe-name 执行该 recipe 的所有 tasks。 执行一个 task。使用 bitbake -c your-task recipe-name 只运行 recipe 中的某个 task。 构建所有 recipe。使用 bitbake world 运行所有 recipes 的所有 tasks。 可以玩玩这些命令，看会出现什么。 6.4.1 确认构建过程中的 logBitbake 创建一个 tmp/work 目录存放所有的 log 文件。这些 log 文件包含一些有趣的信息，值得一学。第一次执行完 bitbake world ，其输出为：12345678910111213141516171819202122232425262728sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake worldParsing recipes: 100% |################################################################################| Time: 00:00:00Parsing of 2 .bb files complete (0 cached, 2 parsed). 2 targets, 0 skipped, 0 masked, 0 errors.NOTE: Resolving any missing task queue dependenciesNOTE: Preparing RunQueueNOTE: Executing RunQueue TasksNOTE: Tasks Summary: Attempted 3 tasks of which 0 didn't need to be rerun and all succeeded.sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ tree tmp/work/ tmp/work/├── first-0.1-r1│ └── temp│ ├── log.do_build -&gt; log.do_build.17657│ ├── log.do_build.17657│ ├── log.task_order│ ├── run.do_build -&gt; run.do_build.17657│ └── run.do_build.17657└── second-1.0-r1 ├── second-1.0 └── temp ├── log.do_build -&gt; log.do_build.17659 ├── log.do_build.17659 ├── log.do_mypatch -&gt; log.do_mypatch.17656 ├── log.do_mypatch.17656 ├── log.task_order ├── run.do_build -&gt; run.do_build.17659 ├── run.do_build.17659 ├── run.do_mypatch -&gt; run.do_mypatch.17656 └── run.do_mypatch.17656 这些 log 文件包含很多有用的信息，比如 BitBake 如何运行，执行 tasks 输出了什么。 BitBake layers 典型 BitBake 工程包含多个 layer。通常 layer 包含一个特定主题，比如基础系统、图像系统等。一些工程可以包括不止一个构建目标，每个目标由不同的 layers 组成。例如，构建一个带 GUI 组件或不带 GUI 组件的 Linux 发行版本。 Layers 可以被使用、扩展、配置，也可能部分覆盖已有的 layers。这很重要，因为它允许根据实际要求重用或自定义。 多个 layers 共同动作是通用的例子，因此我们会添加一个额外的层次到工程。 7.1 添加一个 layer通过以下步骤添加一个新的 layer： 创建一个新的 layer 目录 创建 layer 配置 告诉 BitBake 有新的 layer 添加 recipes 到 layer 7.1.1 添加新的 layer 目录创建一个新的目录叫 meta-two：12sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial$ lsbuild meta-tutorial meta-two 7.1.2 配置新 layer添加 meta-two/conf/layer.conf 文件，该文件和 tutorial layer 的一样：12BBPATH .= ":$&#123;LAYERDIR&#125;"BBFILES += "$&#123;LAYERDIR&#125;/recipes-*/*/*.bb" 7.1.3 告诉 BitBake 有新的 layer编辑 build/conf/bblayers.conf，扩展 BBLAYERS 变量：1234BBLAYERS = " \ $&#123;TOPDIR&#125;/../meta-tutorial \ $&#123;TOPDIR&#125;/../meta-two \" bitbake-layer 命令通过 bitbake-layer 命令检查新 layer 配置。首先使用 show-layers 选项，显示该工程的 layers、layers 路径和优先级。这里优先级都是 0，后面会尝试改一下。12345sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake-layers show-layerslayer path priority==========================================================================meta-tutorial /home/sunyongfeng/workshop/test/tutorial/build/../meta-tutorial 0meta-two /home/sunyongfeng/workshop/test/tutorial/build/../meta-two 0 bitbake-layers 命令还有其他有用的选项，可通过 -h 选项显示。123456789101112131415161718192021222324252627282930sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake-layers -husage: bitbake-layers [-h] [-d] [-q] &lt;subcommand&gt; ...BitBake layers utilityoptional arguments: -h, --help show this help message and exit -d, --debug Enable debug output -q, --quiet Print only errorssubcommands: &lt;subcommand&gt; show-layers show current configured layers add-layer Add a layer to bblayers.conf remove-layer Remove a layer from bblayers.conf show-overlayed list overlayed recipes (where the same recipe exists in another layer) show-recipes list available recipes, showing the layer they are provided by show-appends list bbappend files and recipe files they apply to flatten flatten layer configuration into a separate output directory. show-cross-depends Show dependencies between recipes that cross layer boundaries. layerindex-fetch Fetches a layer from a layer index along with its dependent layers, and adds them to conf/bblayers.conf. layerindex-show-depends Find layer dependencies from layer index.Use bitbake-layers &lt;subcommand&gt; --help to get help on a specific command 7.3 扩展 layer 配置在 layer 的 layer.conf 文件中，定义优化级和其他配置值。为配置 layer 的优先级，需要添加新的定义到已有的 layer.conf。以 meta-tutorial/conf/layer.conf 开始，添加：12345# append layer name to list of configured layers BBFILE_COLLECTIONS += "tutorial" # and use name as suffix for other properties BBFILE_PATTERN_tutorial = "^$&#123;LAYERDIR&#125;/" BBFILE_PRIORITY_tutorial = "5" 使用的变量在 BitBake 使用手册有很好的说明，这里不重复。 模式应是清楚的，这里定义 layer 名，并使用这个名字做为其他变量的后缀。这种在 BitBake 变量名中使用用户定义的域后缀机制，在 BitBake 的很多地方可以看到。 同样的，修改 meta-two/conf/layer.conf：12345# append layer name to list of configured layers BBFILE_COLLECTIONS += "tutorial" # and use name as suffix for other properties BBFILE_PATTERN_tutorial = "^$&#123;LAYERDIR&#125;/" BBFILE_PRIORITY_tutorial = "5" 如果此时运行 bitbake-layers show-layers，结果是：12345sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake-layers show-layers layer path priority==========================================================================meta-tutorial /home/sunyongfeng/workshop/test/tutorial/build/../meta-tutorial 5meta-two /home/sunyongfeng/workshop/test/tutorial/build/../meta-two 5 共享和重用配置 截止目前，我们使用 classes 和 config 文件封装配置和 tasks。但是还有更多的方法重用和扩展 tasks 和配置： class 继承 bbappend 文件 include 文件 为说明如何使用这些方法，我们将添加 class 到 layer-two，新的 class 将介绍一个 configure-build 链并使用 class 继承重用现存的 mybuild class。然后在新的 recipe 中使用这个新 class，最后通过 append 方法扩展现有的 recipe。 8.1 class 继承为实现 configure-build 链，这里创建一个 class，该 class 继承 mybuild，并简单添加一个 configure task，让 build task 依赖 configure task。 meta-two/classes/confbuild.bbclass：1234567891011inherit mybuild (1) confbuild_do_configure () &#123; (2) echo "running configbuild_do_configure." &#125; addtask do_configure before do_build (3) EXPORT_FUNCTIONS do_configure (4) 以 mybuild class 为基础； 创建新的函数； 定义函数的顺序，configre 在 build 之前； export 刚创建的函数使之可用。 然后创建 third recipe 使用 confbuild class。meta-two/recipes-base/third_01.bb：123DESCRIPTION = "I am the third recipe"PR = "r1"inherit confbuild 这时运行 bitabke third 会执行 configure 和 build task。123456789101112131415161718192021sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake thirdParsing recipes: 100% |######################################################################################################################################| Time: 00:00:00Parsing of 3 .bb files complete (0 cached, 3 parsed). 3 targets, 0 skipped, 0 masked, 0 errors.NOTE: Resolving any missing task queue dependenciesNOTE: Preparing RunQueueNOTE: Executing RunQueue TasksNOTE: Tasks Summary: Attempted 2 tasks of which 0 didn't need to be rerun and all succeeded.sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/third-01-r1/temp/log.do_build log.do_configure log.task_order run.do_build.19728 run.do_configure.19726 log.do_build.19728 log.do_configure.19726 run.do_build run.do_configure sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/third-01-r1/temp/log.task_order do_configure (19726): log.do_configure.19726do_build (19728): log.do_build.19728sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/third-01-r1/temp/log.do_configureDEBUG: Executing shell function do_configurerunning configbuild_do_configure.DEBUG: Shell function do_configure finishedsunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/third-01-r1/temp/log.do_buildDEBUG: Executing shell function do_buildrunning mybuild_do_build.DEBUG: Shell function do_build finished 8.2 bbappend 文件append 文件可以添加函数到已有 class 中，而不需要创建一个新 class。它向同名 class 添加 append 文件的文本。需要设置 layer 配置，才能加载到对应的 append 文件。因此需要改变 layer 的配置，添加加载 *.bbappend 文件的配置到 BBFILES 变量。例如：meta-two/conf/layer.conf：12BBFILES += "$&#123;LAYERDIR&#125;/recipes-*/*/*.bb \$&#123;LAYERDIR&#125;/recipes-*/*/*.bbappend" 现在扩展已有的 first recipe，让它在 build task 前先运行一个 patch 函数。为做对比，将对应的 recipe 和 append 文件放到 meta-two/recipes-base/first 目录。meta-two/recipes-base/first/first_0.1.bbappend：12345python do_patch () &#123; bb.note ("first:do_patch")&#125; addtask patch before do_build 此时若列出 first recipe 的 task 列表，可以看到 patch task。运行 bitbake first 可看到运行了 patch 和 build。 添加前：12345678910sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake -c listtasks firstParsing recipes: 100% |################################################################################| Time: 00:00:00Parsing of 3 .bb files complete (0 cached, 3 parsed). 3 targets, 0 skipped, 0 masked, 0 errors.NOTE: Resolving any missing task queue dependenciesNOTE: Preparing RunQueueNOTE: Executing RunQueue Tasksdo_showdatado_builddo_listtasksNOTE: Tasks Summary: Attempted 1 tasks of which 0 didn't need to be rerun and all succeeded. 添加 append 文件后：1234567891011sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake -c listtasks firstParsing recipes: 100% |################################################################################| Time: 00:00:00Parsing of 3 .bb files complete (0 cached, 3 parsed). 3 targets, 0 skipped, 0 masked, 0 errors.NOTE: Resolving any missing task queue dependenciesNOTE: Preparing RunQueueNOTE: Executing RunQueue Tasksdo_showdatado_builddo_listtasksdo_patchNOTE: Tasks Summary: Attempted 1 tasks of which 0 didn't need to be rerun and all succeeded. 运行 bitbake first 结果：123456789101112131415161718sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake firstParsing recipes: 100% |################################################################################| Time: 00:00:00Parsing of 3 .bb files complete (0 cached, 3 parsed). 3 targets, 0 skipped, 0 masked, 0 errors.NOTE: Resolving any missing task queue dependenciesNOTE: Preparing RunQueueNOTE: Executing RunQueue TasksNOTE: Tasks Summary: Attempted 2 tasks of which 0 didn't need to be rerun and all succeeded.sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/first-0.1-r1/temp/log.do_build log.do_listtasks.20111 run.do_build run.do_listtasks.20111log.do_build.20152 log.do_patch run.do_build.20152 run.do_patchlog.do_listtasks log.do_patch.20151 run.do_listtasks run.do_patch.20151log.do_listtasks.20001 log.task_order run.do_listtasks.20001 sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/first-0.1-r1/temp/log.task_order do_listtasks (20001): log.do_listtasks.20001do_listtasks (20111): log.do_listtasks.20111do_patch (20151): log.do_patch.20151do_build (20152): log.do_build.20152sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ 提示：如果你愿意，现在就可以构建一个 recipe，使用 confbuild class 和一个 append 文件，运行 patch、configure 和 build 任务。 8.3 include 文件BitBake 有两种指令引用文件： include filename，这是一种可选引用，如果 filename 找不到，不会有 error 产生； require filename，如果 filename 没找到，会产生 error。 值得一提的是，include 和 require 都是在 BBPATH 中指定的目录查找 filename。 8.3.1 添加 local.conf 用于引用文件BitBake 工程通常使用 bitbake.conf 引用一个位于 build 目录内的 local.conf 文件。local.conf 文件可能包含一些当前构建目标相关的特殊设置。典型的样例是 Yocto 的设置。 这里模仿 local.conf 的典型应用，让 bitbake.conf require 引用 local.conf，添加以下内容到 meta-tutorial/conf/bitbake.conf：12require local.confinclude conf/might_exist.conf 如果此时执行构建命令，BitBake 会产生类似以下的错误信息：12345678910111213141516171819sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake worldERROR: Traceback (most recent call last): File "/home/sunyongfeng/ops-build.test/yocto/poky/bitbake/lib/bb/cookerdata.py", line 175, in wrapped return func(fn, *args) File "/home/sunyongfeng/ops-build.test/yocto/poky/bitbake/lib/bb/cookerdata.py", line 185, in parse_config_file return bb.parse.handle(fn, data, include) File "/home/sunyongfeng/ops-build.test/yocto/poky/bitbake/lib/bb/parse/__init__.py", line 107, in handle return h['handle'](fn, data, include) File "/home/sunyongfeng/ops-build.test/yocto/poky/bitbake/lib/bb/parse/parse_py/ConfHandler.py", line 148, in handle statements.eval(data) File "/home/sunyongfeng/ops-build.test/yocto/poky/bitbake/lib/bb/parse/ast.py", line 39, in eval statement.eval(data) File "/home/sunyongfeng/ops-build.test/yocto/poky/bitbake/lib/bb/parse/ast.py", line 61, in eval bb.parse.ConfHandler.include(self.filename, s, self.lineno, data, "include required") File "/home/sunyongfeng/ops-build.test/yocto/poky/bitbake/lib/bb/parse/parse_py/ConfHandler.py", line 98, in include raise ParseError("Could not %(error_out)s file %(fn)s" % vars(), parentfn, lineno)ParseError: ParseError at /home/sunyongfeng/workshop/test/tutorial/build/../meta-tutorial/conf/bitbake.conf:53: Could not include required file local.confERROR: Unable to parse conf/bitbake.conf: ParseError at /home/sunyongfeng/workshop/test/tutorial/build/../meta-tutorial/conf/bitbake.conf:53: Could not include required file local.conf 添加一个 local.conf 文件到 build 目录可解决此问题。注意 include 语句包含的文件可有可无。 使用变量 可定义变量并在 recipes 中使用，让 BitBake 具有很强的灵活性。可将可配置部分使用变量的方式编写 recipe，这种 recipe 的用户可以给出那些将由 recipe 使用的变量值。一个典型的例子是给 recipe 传递额外的配置或标志。通过正确使用变量，不需要编辑和更改 recipe，因为某些函数只需要一些特殊的参数。 9.1 全局变量全局变量可以通过使用者设置，recipe 可以使用。 9.1.1 定义全局变量刚才已经创建一个空的 local.conf，现在在这个文件加一些变量。比如添加一行：1MYVAR="hello from MYVAR" 9.1.2 访问全局变量可以在 recipes 或 classes 中访问 MYVAR 变量。这里创建一个新的 recipes 组 recipes-vars，及一个 recipe myvar。meta-two/recipes-vars/myvar/myvar_0.1.bb：123456789101112DESCRIPTION = "Show access to global MYVAR"PR = "r1" do_build()&#123; echo "myvar_sh: $&#123;MYVAR&#125;" (1)&#125; python do_myvar_py () &#123; print "myvar_py:" + d.getVar('MYVAR', True) (2)&#125; addtask myvar_py before do_build 在类 bash 语法中访问变量； 通过全局数据存储访问变量。 现在运行 bitbake myvar，检查 tmp 目录的输出，则可以看到我们确实访问了全局 MYVAR 变量。 12345678910111213141516171819sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake myvarParsing recipes: 100% |################################################################################| Time: 00:00:00Parsing of 4 .bb files complete (0 cached, 4 parsed). 4 targets, 0 skipped, 0 masked, 0 errors.NOTE: Resolving any missing task queue dependenciesNOTE: Preparing RunQueueNOTE: Executing RunQueue TasksNOTE: Tasks Summary: Attempted 2 tasks of which 0 didn't need to be rerun and all succeeded.sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/myvar-0.1-r1/temp/log.task_order do_myvar_py (4595): log.do_myvar_py.4595do_build (4596): log.do_build.4596sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/myvar-0.1-r1/temp/log.do_myvar_pyDEBUG: Executing python function do_myvar_pymyvar_py:hello from MYVARDEBUG: Python function do_myvar_py finishedsunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/myvar-0.1-r1/temp/log.do_buildDEBUG: Executing shell function do_buildmyvar_sh: hello from MYVARDEBUG: Shell function do_build finished 9.2 本地变量典型的 recipe 只包含一些本地变量，这些变量用于其继承的 classes 中的函数设置。 先创建 meta-two/classes/varbuild.bbclass：1234567varbuild_do_build () &#123; echo "build with args: $&#123;BUILDARGS&#125;"&#125; addtask build EXPORT_FUNCTIONS do_build 然后在 meta-two/recipes-vars/varbuld/varbuild_0.1.bb 中使用：1234567DESCRIPTION = "Demonstrate variable usage \ for setting up a class task"PR = "r1" BUILDARGS = "my build arguments" inherit varbuild 运行 bitbake varbuild，输出的 log 显示 build 任务使用了 recipe 设置的变量值。 1234567891011121314sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ bitbake varbuildParsing recipes: 100% |################################################################################| Time: 00:00:00Parsing of 5 .bb files complete (0 cached, 5 parsed). 5 targets, 0 skipped, 0 masked, 0 errors.NOTE: Resolving any missing task queue dependenciesNOTE: Preparing RunQueueNOTE: Executing RunQueue TasksNOTE: Tasks Summary: Attempted 1 tasks of which 0 didn't need to be rerun and all succeeded.sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/varbuild-0.1-r1/temp/log.task_order do_build (4760): log.do_build.4760sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ cat tmp/work/varbuild-0.1-r1/temp/log.do_buildDEBUG: Executing shell function do_buildbuild with args: my build argumentsDEBUG: Shell function do_build finishedsunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial/build$ 这是使用 BitBake的典型方法。通用 task 由 class 定义，比如下载源代码、configure、make 和其他操作，recipe 设置这些 task 所需要的变量。 附目录树 12345678910111213141516171819202122232425262728293031323334353637sunyongfeng@openswitch-OptiPlex-380:~/workshop/test/tutorial$ tree ./*./build├── bitbake.lock├── conf│ └── bblayers.conf└── local.conf./meta-tutorial├── classes│ ├── base.bbclass│ └── mybuild.bbclass├── conf│ ├── bitbake.conf│ └── layer.conf└── recipes-tutorial ├── first │ └── first_0.1.bb └── second └── second_1.0.bb./meta-two├── classes│ ├── confbuild.bbclass│ └── varbuild.bbclass├── conf│ ├── bitbake.conf│ └── layer.conf├── recipes-base│ ├── first│ │ └── first_0.1.bbappend│ └── third│ └── third_01.bb└── recipes-vars ├── myvar │ └── myvar_0.1.bb └── varbuild └── varbuild_0.1.bb14 directories, 17 files 总结 以上是本教程的所有内容，感谢你一直看到这里，希望你喜欢。学习完教程，你应该对 BitBake 的基本概念有基本理解。本教程涉及的内容有： BitBake 是一个执行 python 和 shell 脚本的引擎； 常见的 BitBake 工程设计与一些默认文件的位置； BitBake 使用的 5 种文件类型（.bb，.bbclass，.bbappend，.conf 和 include 文件）； BitBake 函数和 task，说明如何组织、分组和调用它们； BitBake 变量及其基本使用方法 。 熟悉这些内容后，希望你可以开始使用类似 Yocto 的工程，并继续深入理解。]]></content>
      <categories>
        <category>yocto</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>yocto</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rpm使用记录]]></title>
    <url>%2F201610%2Ftools%2Frpm.html</url>
    <content type="text"><![CDATA[列出rpm包的内容：1rpm -qpl *.rpm 解压rpm包的内容：（没有安装，就像解压tgz包一样rpm包）1rpm2cpio *.rpm | cpio -div]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coredump文件简易指南]]></title>
    <url>%2F201609%2Fprogrammer%2Ftools%2Fcoredump.html</url>
    <content type="text"><![CDATA[coredump简介通常情况下，coredump（亦称为core文件）文件包含程序运行时的内存信息，含寄存器状态、堆栈指针、内存管理信息、操作系统flags及其他信息，可以理解为把程序工作的当前状态存储成一个文件。Coredump文件通常于程序异常终止（crashed）时自动生成，常用于辅助分析和解决bug，可通过 coredump 文件进行栈回溯和反汇编。 Coredump文件在不同的操作系统上文件类型不一，在目前的Unix-like操作系统中，使用ELF类型保存coredump文件，如下所示。目前常见阅读coredump文件的工具有BFD（GNU Binutils Binary File Descriptor library），以及使用这个库的GDB（GNU Debugger）和objdump。下文使用GDB阅读coredump文件。12rj@rj:~/test/coredump$ file core-cd_test-1359224646core-cd_test-1359224646: ELF 32-bit LSB core file Intel 80386, version 1 (SYSV), SVR4-style, from './cd_test' 产生原因产生coredump文件的原因有很多，主要为低级bug中的内存访问越界、使用空指针、堆栈溢出等。用coredump文件来查找此类bug效率极高。 coredump相关系统设置以Ubuntu 12.04为例。 系统是否允许产生coredump文件Coredump也是类似消息队列，属于系统资源。使用“ulimit –a”查看系统资源限制，如图1所示。对于coredump文件，使用“ulimit -c”查看其限制，如果为0，表示系统不会产生coredump文件。 Ubuntu系统可查看/etc/security/limits.conf查看系统资源限制相关的单位。如下所示，可在这进行长久的设置，因其他系统资源项也是平时我们需要注意的，因此在此把整个limits.conf文件copy过来。可用“ulimit -c your-size”进行临时设置，不过重启后无效。12345678910111213141516171819sunnogo@R04220:~$ uname -aLinux R04220 4.4.0-36-generic #55-Ubuntu SMP Thu Aug 11 18:01:55 UTC 2016 x86_64 x86_64 x86_64 GNU/Linuxsunnogo@R04220:~$ ulimit -acore file size (blocks, -c) 0data seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 15232max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 15232virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 配置文件limits.conf：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758sunnogo@R04220:~$ cat /etc/security/limits.conf# /etc/security/limits.conf##Each line describes a limit for a user in the form:##&lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt;##Where:#&lt;domain&gt; can be:# - a user name# - a group name, with @group syntax# - the wildcard *, for default entry# - the wildcard %, can be also used with %group syntax,# for maxlogin limit# - NOTE: group and wildcard limits are not applied to root.# To apply a limit to the root user, &lt;domain&gt; must be# the literal username root.##&lt;type&gt; can have the two values:# - "soft" for enforcing the soft limits# - "hard" for enforcing hard limits##&lt;item&gt; can be one of the following:# - core - limits the core file size (KB)# - data - max data size (KB)# - fsize - maximum filesize (KB)# - memlock - max locked-in-memory address space (KB)# - nofile - max number of open files# - rss - max resident set size (KB)# - stack - max stack size (KB)# - cpu - max CPU time (MIN)# - nproc - max number of processes# - as - address space limit (KB)# - maxlogins - max number of logins for this user# - maxsyslogins - max number of logins on the system# - priority - the priority to run user process with# - locks - max number of file locks the user can hold# - sigpending - max number of pending signals# - msgqueue - max memory used by POSIX message queues (bytes)# - nice - max nice priority allowed to raise to values: [-20, 19]# - rtprio - max realtime priority# - chroot - change root to directory (Debian-specific)##&lt;domain&gt; &lt;type&gt; &lt;item&gt; &lt;value&gt;##* soft core 0#root hard core 100000#* hard rss 10000#@student hard nproc 20#@faculty soft nproc 20#@faculty hard nproc 50#ftp hard nproc 0#ftp - chroot /ftp#@student - maxlogins 4# End of filesunnogo@R04220:~$ coredump文件的保存路径和文件名格式本节内容完全来自这里。 查看正在使用的core文件路径和格式【more /proc/sys/kernel/core_pattern】。自动添加pid的配置是在【more /proc/sys/kernel/core_uses_pid】里面配置的，如果为1就是自动添加。 修改/etc/sysctl.conf文件【vi /etc/sysctl.conf】，添加需要保存的路径【kernel.core_pattern = /tmp/corefile/core.%e.%t】，需要注意的是该路径必须应用有写的权限，不然core文件是不会生成的。再执行命令【sysctl -p】即可生效。关于core_users_pid默认在sysctl文件里面已经存在，不需要更改，pid还是很重要的信息。 附上core文件支持的格式列表：1234567%p – insert pid into filename 【pid】%u – insert current uid into filename 【uid】%g – insert current gid into filename 【gid】%s – insert signal that caused the coredump into the filename 【core信号】%t – insert UNIX time that the coredump occurred into filename 【core文件生成时的unix时间】%h – insert hostname where the coredump happened into filename 【主机名】%e – insert coredumping executable name into filename 【应用的名字】 可自己写个除0或者访问NULL指针的程序来验证coredump设置OK。 如何“阅读”coredump文件这章是这个指南的核心所在。编译时的Gcc选项会影响coredump文件，目前知道的有“-g”选项（用于调试，能够在gdb中看到所有的symbol，即函数、变量等）和“-fomit-frame-pointer”（用于优化栈顶指针，将不会保留ebp的信息）。 【Tips】gdb命令也可用tab键补全。 以如下程序为例：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758cd_test.c：static int g_t1;static int g_t2 = 2;int div(int div_i, int div_j)&#123; int a4, b4; char *c4; a4 = div_i + 3; b4 = div_j + 3; c4 = "divf"; return (div_i / div_j);&#125;int sub(int sub_i, int sub_j)&#123; int a3, b3; char *c3; a3 = sub_i + 2; b3 = sub_j + 2; c3 = "subf"; div(a3, 0); // 这里通过除0让程序运行时挂掉 return (sub_i - sub_j);&#125;int add(int add_i, int add_j)&#123; int a2, b2; char *c2; a2 = add_i + 1; b2 = add_j + 1; c2 = "addf"; sub(a2, b2); return (add_i + add_j);&#125;int main(int argc, char *argv[])&#123; int a1, b1; char *c1; static int u1; static int x1 = 1; a1 = 1; b1 = 0; c1 = "main function"; add(a1, b1); return 0;&#125; 编译，执行。下文会涉及到三种gcc编译选项：默认的“gcc –g”，不带“-g”选项，“gcc -g -fomit-frame-pointer”。123rj@rj:~/test/coredump$ gcc -g -o cd_test cd_test.crj@rj:~/test/coredump$ ./cd_test浮点数例外 (核心已转储) 提示产生coredump文件 运行gdb阅读core文件，命令为“gdb 程序 对应coredump文件”，这时就进入gdb的提示符“(gdb)”。 12345678910111213141516171819rj@rj:~/test/coredump$ gdb cd_test core-cd_test-1359266323GNU gdb (Ubuntu/Linaro 7.4-2012.04-0ubuntu2) 7.4-2012.04Copyright (C) 2012 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "i686-linux-gnu".For bug reporting instructions, please see:&lt;http://bugs.launchpad.net/gdb-linaro/&gt;...Reading symbols from /home/rj/test/coredump/cd_test...done.[New LWP 28375]warning: Can't read pathname for load map: 输入/输出错误.Core was generated by `./cd_test'.Program terminated with signal 8, Arithmetic exception.#0 0x080483eb in div (div_i=4, div_j=0) at cd_test.c:1313 return (div_i / div_j);(gdb) 执行“backtrace”或其缩写“bt”进入栈回溯。如下所示，函数调用的顺序是从#n中数值高的往低的。比如这些是main()add()sub()div()，#0表示跑飞的地方。英文用frame表示一个调用层次，下文所说的各种信息对应某个指定frame。 12345(gdb) bt#0 0x080483eb in div (div_i=4, div_j=0) at cd_test.c:13#1 0x08048422 in sub (sub_i=2, sub_j=1) at cd_test.c:24#2 0x08048461 in add (add_i=1, add_j=0) at cd_test.c:37#3 0x08048498 in main (argc=1, argv=0xbfba3264) at cd_test.c:53 若编译时没有-g选项，则结果是：12345678Core was generated by `./cd_test'.Program terminated with signal 8, Arithmetic exception.#0 0x080483eb in div ()(gdb) bt#0 0x080483eb in div () 对比带-g选项的少了些什么？#1 0x08048422 in sub ()#2 0x08048461 in add ()#3 0x08048498 in main () 执行“frame n”进入对应调用层次。以frame 3为例。123(gdb) frame 3#3 0x08048498 in main (argc=1, argv=0xbfba3264) at cd_test.c:5353 add(a1, b1); 没带-g选项的：12(gdb) frame 3#3 0x08048498 in main () 少了很多信息 执行“info frame”查看本层调用的栈信息123456789(gdb) info frameStack level 3, frame at 0xbfba31d0: eip = 0x8048498 in main (cd_test.c:53); saved eip 0xb75d24d3 caller of frame at 0xbfba31b0 source language c. Arglist at 0xbfba31c8, args: argc=1, argv=0xbfba3264 Locals at 0xbfba31c8, Previous frame's sp is 0xbfba31d0 Saved registers: ebp at 0xbfba31c8, eip at 0xbfba31cc 带-fomit-frame-pointer选项：123456789(gdb) info frameStack level 3, frame at 0xbffa57c0: eip = 0x80484af in main (cd_test.c:53); saved eip 0xb753d4d3 caller of frame at 0xbffa57a4 source language c. Arglist at unknown address. Locals at unknown address, Previous frame's sp is 0xbffa57c0 Saved registers: eip at 0xbffa57bc 没有ebp 不带-g选项：12345678(gdb) info frameStack level 3, frame at 0xbfca4a90: eip = 0x8048498 in main; saved eip 0xb75e74d3 caller of frame at 0xbfca4a70 Arglist at 0xbfca4a88, args: Locals at 0xbfca4a88, Previous frame's sp is 0xbfca4a90 Saved registers: ebp at 0xbfca4a88, eip at 0xbfca4a8c 使用“info args”查看参数信息123(gdb) info argsargc = 1argv = 0xbfba3264 带-fomit-frame-pointer同上。不带-g选项：12(gdb) info argsNo symbol table info available. 使用“info locals”查看所有局部变量信息123456(gdb) info localsa1 = 1b1 = 0c1 = 0x804857f "main function"u1 = 0x1 = 1 带-fomit-frame-pointer同上。不带-g选项依旧是“No symbol table info available”。 使用“print 变量名”查看变量信息，比如查看全局变量。实验结果显示，不管带不带-g或-fomit-pointer-frame选项，全局变量都能查看得到。 12(gdb) print g_t1$1 = 0 使用“info registers”查看寄存器信息，三个选项结果一样。info all-registers会打印更多寄存器信息。 1234567891011121314151617(gdb) info registerseax 0x4 4ecx 0xbfba3264 -1078316444edx 0x0 0ebx 0xb775eff4 -1217007628esp 0xbfba31b0 0xbfba31b0ebp 0xbfba31c8 0xbfba31c8esi 0x0 0edi 0x0 0eip 0x8048498 0x8048498 &lt;main+45&gt;eflags 0x10246 [ PF ZF IF RF ]cs 0x73 115ss 0x7b 123ds 0x7b 123es 0x7b 123fs 0x0 0gs 0x33 51 使用“info threads”查看线程信息，多线程的暂未实验。 123(gdb) info threads Id Target Id Frame* 1 LWP 28375 0x08048498 in main (argc=1, argv=0xbfba3264) at cd_test.c:53 无-g选项的信息会少一些。123(gdb) info threads Id Target Id Frame* 1 LWP 28229 0x08048498 in main () 使用“info macro”查看宏，暂未实验。 使用“disassemble”反汇编。还可以通过“disassemble 函数名”对指定函数进行反汇编。1234567891011121314151617(gdb) disassembleDump of assembler code for function main: 0x0804846b &lt;+0&gt;: push %ebp 0x0804846c &lt;+1&gt;: mov %esp,%ebp 0x0804846e &lt;+3&gt;: sub $0x18,%esp 0x08048471 &lt;+6&gt;: movl $0x1,-0xc(%ebp) 0x08048478 &lt;+13&gt;: movl $0x0,-0x8(%ebp) 0x0804847f &lt;+20&gt;: movl $0x804857f,-0x4(%ebp) 0x08048486 &lt;+27&gt;: mov -0x8(%ebp),%eax 0x08048489 &lt;+30&gt;: mov %eax,0x4(%esp) 0x0804848d &lt;+34&gt;: mov -0xc(%ebp),%eax 0x08048490 &lt;+37&gt;: mov %eax,(%esp) 0x08048493 &lt;+40&gt;: call 0x8048430 &lt;add&gt;=&gt; 0x08048498 &lt;+45&gt;: mov $0x0,%eax 标识在哪挂掉 0x0804849d &lt;+50&gt;: leave 0x0804849e &lt;+51&gt;: retEnd of assembler dump. 不带-g选项的同上。带-fomit-frame-pointer：123456789101112131415(gdb) disassembleDump of assembler code for function main: 没有ebp了 0x08048480 &lt;+0&gt;: sub $0x18,%esp 0x08048483 &lt;+3&gt;: movl $0x1,0xc(%esp) 0x0804848b &lt;+11&gt;: movl $0x0,0x10(%esp) 0x08048493 &lt;+19&gt;: movl $0x804859f,0x14(%esp) 0x0804849b &lt;+27&gt;: mov 0x10(%esp),%eax 0x0804849f &lt;+31&gt;: mov %eax,0x4(%esp) 0x080484a3 &lt;+35&gt;: mov 0xc(%esp),%eax 0x080484a7 &lt;+39&gt;: mov %eax,(%esp) 0x080484aa &lt;+42&gt;: call 0x804843d &lt;add&gt;=&gt; 0x080484af &lt;+47&gt;: mov $0x0,%eax 0x080484b4 &lt;+52&gt;: add $0x18,%esp 0x080484b7 &lt;+55&gt;: retEnd of assembler dump. Gdb中使用Linux命令：shell 你的命令。123456789101112(gdb) shell ls -al /usr总用量 164drwxr-xr-x 10 root root 4096 4月 23 2012 .drwxr-xr-x 23 root root 4096 1月 27 01:25 ..drwxr-xr-x 2 root root 61440 1月 19 02:45 bindrwxr-xr-x 2 root root 4096 9月 5 19:53 gamesdrwxr-xr-x 37 root root 20480 11月 28 14:20 includedrwxr-xr-x 194 root root 36864 1月 8 19:31 libdrwxr-xr-x 11 root root 4096 6月 1 2012 localdrwxr-xr-x 2 root root 12288 1月 22 12:29 sbindrwxr-xr-x 316 root root 12288 1月 22 12:29 sharedrwxr-xr-x 10 root root 4096 12月 11 20:32 src 其他GDB的功能远不止于此，本文档只是个简易的coredump文件阅读指南。 另外，关于-fomit-frame-pointer选项，在gdb官方说明文档： Some compilers provide a way to compile functions so that they operate without stack frames. (For example, the gcc option `-fomit-frame-pointer’ generates functions without a frame.) This is occasionally done with heavily used library functions to save the frame setup time. gdb has limited facilities for dealing with these function invocations. If the innermost function invocation has no stack frame, gdb nevertheless regards it as though it had a separate frame, which is numbered zero as usual, allowing correct tracing of the function call chain. However, gdb has no provision for frameless functions elsewhere in the stack. 上面的黑体字说明-fomit-frame-pointer会造成编译器有时会把函数编译成无stack frame，即有可能在backtrace的出现各种“?? ()”， 如下所示。12345678(gdb) bt#0 0x080483eb in div (div_i=134513698, div_j=4) at cd_test.c:13#1 0xbfec16a8 in ?? ()#2 0x08048422 in sub (sub_i=134513761, sub_j=2) at cd_test.c:24#3 0xbfec16c8 in ?? ()#4 0x08048461 in add (add_i=134513816, add_j=1) at cd_test.c:37#5 0xbfec16e8 in ?? ()#6 0x08048498 in main (argc=-1218612013, argv=0x1) at cd_test.c:51]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>coredump</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ARM 平台 abort 退出后堆栈打不全]]></title>
    <url>%2F201609%2Fprogrammer%2Flinux%2Farm_abort.html</url>
    <content type="text"><![CDATA[ARM 平台 assert 退出后堆栈打不出来的原因是：调用了abort()函数，abort是一个没有返回的函数，只会被调用一次，运行时不会去保存相关的寄存器值。 改进方向： 追踪邮件列表发现08年后的abort()函数可能有优化。这是一个方向，优化abort函数，以使得调用abort函数的源能打出来。 改 assert 函数，让它以其他 signal 退出，比如通过改写 0 地址内容产生 signal 11 退出。 链接：http://comments.gmane.org/gmane.comp.gdb.devel/24018 Your implementation of abort does not save a return address, so GDBcan’t display it. I believe tehis is a known limitation of the ARMGCC port. GCC should really not do this. People are almost guaranteed to wantto be able to see a backtrace from abort(3). I suppose it optimizes away the instructions to save the returnaddress, because abort() is marked with __attribute__(noreturn). Butthat means there is very little point in actually doing thatoptimization since __attribute__(noreturn) implies that the functionwill only be called once! I suppose there are some space savings butare they really significant? Joe&gt; There are several effects from “noreturn”. We would want some Joe&gt; of these effects for “abort”, but not others, to get debuggable Joe&gt; code without degrading compile-time warnings. So the issue is that two unrelated features are currently combined ina single attribute: This function doesn’t return, do the right thing with warnings inthe caller of this function. Don’t bother saving registers when calling this function because itwon’t return so the registers aren’t needed afterwards. The issue is that #2 doesn’t apply to “abort” because the registersARE needed afterwards – at debug time.]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>arm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新技术点记录]]></title>
    <url>%2F201608%2Fprogrammer%2FnewTech%2Fwork.html</url>
    <content type="text"><![CDATA[郭子，Upgrade on fly，类似 Nginx，热升级时，业务不中断。20160824。]]></content>
      <categories>
        <category>newTech</category>
      </categories>
      <tags>
        <tag>新技术点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行 - diff 和 patch]]></title>
    <url>%2F201608%2Fshell%2Fdiff_patch.html</url>
    <content type="text"><![CDATA[生成 patchdiff -ruN xxx_src xxx_dst &gt; xxx.patch 参数： -u，合并相同内容。如果两个文件相似度很高，那么上下文格式的diff，将显示大量重复的内容，很浪费空间。1990年，GNU diff率先推出了”合并格式”的diff，将f1和f2的上下文合并在一起显示。 -r，或–recursive，递归比较，比较子目录中的文件。 -N，或–new-file，文件A仅出现在某个目录中，预设会显示：Only in目录；文件A若使用-N参数，则diff会将文件A与一个空白的文件比较。 应用 patchpatch [参数] &lt;patchfile&gt; 参数： -p Num 忽略几层文件夹 -E 选项说明如果发现了空文件，那么就删除它 -R 取消打过的补丁。 如果使用参数-p0，表示从当前目录找打补丁的目标文件夹，再对该目录中的文件执行patch操作。 而使用参数-p1，表示忽略第一层目录，从当前目录寻找目标文件夹中的子目录和文件，进行patch操作。 产生补丁1diff -uN f1 f2 &gt; file.patch 打补丁1patch -p0 &lt; file.patch 或者1patch f1 file.patch 取消补丁1patch -RE -p0 &lt; file.patch 或者1patch -RE f1 file.patch 参考文献参考： http://812lcl.com/blog/2014/04/03/linuxming-ling-xue-xi-(1)%3Adiffhe-patch/ http://linux-wiki.cn/wiki/%E8%A1%A5%E4%B8%81(patch)%E7%9A%84%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%BA%94%E7%94%A8 http://www.ruanyifeng.com/blog/2012/08/how_to_read_diff.html]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>programmer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Kernel 工具 perf 交叉编译]]></title>
    <url>%2F201608%2Fprogrammer%2Ftools%2Fperf_compile.html</url>
    <content type="text"><![CDATA[以下译自 en.wikipedia) perf （有时亦称为 “Perf Events” 或 perf 工具，原始名称为 “Performance Counters for linux”, PCL），是一个 Linux 性能分析工具，从 Linux 内核版本 2.6.31 导入。用户空间控制工具名为 perf，在命令行使用，提供一系列子命令，适用于整个系统（包含用户空间、内核空间代码）的 profiling 数据统计（即性能剖析数据统计）。 perf 支持硬件性能计数器、tracepoints、软件性能计数器（如 hrtimer），和动态 probes （比如 kprobes 或uprobes）。IBM 在 2012 年将 perf 与 Oprofile 评为两个最常用的 linux performance counter profiling tools。 内核选项12345* General setup ---&gt; + [*] Profiling support + Kernel Performance Events And Counters ---&gt; - [*] Kernel performance events and counters - [*] Debug: use vmalloc to back perf mmap() buffers 体现在配置文件上的配置项： ARM Cortex a9： CONFIG_HAVE_PERF_EVENTS=y CONFIG_PERF_USE_VMALLOC=y CONFIG_PERF_EVENTS=y CONFIG_DEBUG_PERF_USE_VMALLOC=y CONFIG_VM_EVENT_COUNTERS=y CONFIG_PROFILING=y MIPS OCTEON II： CONFIG_CAVIUM_OCTEON_PERF=y CONFIG_HAVE_PERF_EVENTS=y CONFIG_PERF_USE_VMALLOC=y CONFIG_PERF_EVENTS=y CONFIG_DEBUG_PERF_USE_VMALLOC=y CONFIG_VM_EVENT_COUNTERS=y CONFIG_PROFILING=y CONFIG_HAVE_PERF_REGS=y CONFIG_HAVE_PERF_USER_STACK_DUMP=y X86_64ubuntu 16.04 上： 安装 linux-tools-generic、linux-cloud-tools-generic、perf-tools-unstable 如果 perf 工具支持的内核不是当前默认启机的内核，则启机后，通过 grub 菜单选择对应的内核后，perf 才能使用。 实测可用。 MIPS OCTEON II截止 2016年8月24日，MIPS 平台的 perf 还不支持用户空间 callchain，即 perf 使用时无法识别用户空间的函数。 来自 arch/mips/kernel/perf_events.c:123423 /* 24 * Leave userspace callchain empty for now. When we find a way to trace 25 * the user stack callchains, we will add it here. 26 */ 实测不支持用户空间 callchains。 1234567891011121314151617181920212223242526272829303132333435363738394041424344# perf version : 3.9.9.g3b9f02# arch : mips64# nrcpus online : 4# nrcpus avail : 4# cpudesc : Cavium Octeon II V0.1# total memory : 4093516 kB# cmdline : /bin/perf record -g -e cpu-clock ./t1 # event : name = cpu-clock, type = 1, config = 0x0, config1 = 0x0, config2 = 0x0, excl_usr = 0, excl_kern = 0, excl_host = 0, excl_guest = 1, precise_ip = 0# HEADER_CPU_TOPOLOGY info available, use -I to display# pmu mappings: software = 1, uncore_l2c = 7, uncore_tad = 8, uncore_mc = 6# ========## Samples: 6K of event 'cpu-clock'# Event count (approx.): 1560000000## Overhead Command Shared Object# ........ ....... .................# 99.92% t1 t1 （用户空间程序） 0.06% t1 [kernel.kallsyms] | |--25.00%--kmem_cache_alloc | anon_vma_prepare | handle_pte_fault | __do_page_fault | ret_from_exception | |--25.00%--__update_tlb | __do_fault | handle_pte_fault | __do_page_fault | ret_from_exception | |--25.00%-- unlock_page | __do_fault | handle_pte_fault | __do_page_fault | ret_from_exception | --25.00%--release_pages pagevec_lru_move_fn lru_add_drain_cpu/data2 # ARM Cortex a9实测perf stat 时 counter 无计数，perf record 亦无数据，还不清楚问题在哪。 12345678910111213141516171819202122~ # perf stat lsbin etc mnt rgos sysboot home perf.data root tmpbootloader include perf.data.old rootfs usrdata lib proc sbin vardev linuxrc rg_cfg share Performance counter stats for 'ls': &lt;not counted&gt; task-clock &lt;not counted&gt; context-switches &lt;not counted&gt; cpu-migrations &lt;not counted&gt; page-faults &lt;not supported&gt; cycles &lt;not supported&gt; stalled-cycles-frontend &lt;not supported&gt; stalled-cycles-backend &lt;not supported&gt; instructions &lt;not supported&gt; branches &lt;not supported&gt; branch-misses 0.003733662 seconds time elapsed~ # 以下为编译记录： 交叉编译记录参考，丫凡的博文《交叉编译 perf for arm》。 内核版本：3.10.18 arm 交叉编译工具链：arm-cortex_a9-linux-gnueabi-gcc 依赖：zlib、elfutils zlibzlib 因公司的交叉编译环境已支持，不用重新编译，略过。 elfutils 交叉编译记录 版本，0.150，官方下载地址。 如果直接以 ./configure --host=arm-cotex_a9-linux-gnueabi --prefix=/home/sunnogo/workshop; make，会编译不过，挂在： 12345678910111213arm-cortex_a9-linux-gnueabi-gcc -std=gnu99 -Wall -Wshadow -Werror -Wunused -Wextra -Wformat=2 -fpic -fdollars-in-identifiers -I/home/sunnogo/workshop/rgosm-build/public/include -I/home/sunnogo/workshop/rgosm-build/prj_s6000e/images/header -D_LITTLE_ENDIAN -L/home/sunnogo/workshop/rgosm-build/prj_s6000e/images/lib -L/home/sunnogo/workshop/rgosm-build/prj_s6000e/images/rootfs/lib -o i386_gendis i386_gendis.o i386_lex.o i386_parse.o ../lib/libeu.a -lm ./i386_gendis i386_defs &gt; i386_dis.h/bin/bash: ./i386_gendis: cannot execute binary file: 可执行文件格式错误Makefile:535: recipe for target 'i386_dis.h' failedmake[2]: *** [i386_dis.h] Error 126rm i386_defsmake[2]: Leaving directory '/home/sunyongfeng/workshop/elfutils-0.150/libcpu'Makefile:348: recipe for target 'all-recursive' failedmake[1]: *** [all-recursive] Error 1make[1]: Leaving directory '/home/sunyongfeng/workshop/elfutils-0.150'Makefile:262: recipe for target 'all' failedmake: *** [all] Error 2sunnogo@R04220:~/workshop/elfutils-0.150$ 配置 aclocal autoheader autoconf automake –add-missing ./configure –host=arm-cotex_a9-linux-gnueabi –prefix=/home/sunnogo/workshop 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071sunnogo@R04220:~/workshop/elfutils-0.150$ aclocalconfigure.ac:66: warning: AC_LANG_CONFTEST: no AC_LANG_SOURCE call detected in body../../lib/autoconf/lang.m4:193: AC_LANG_CONFTEST is expanded from...../../lib/autoconf/general.m4:2601: _AC_COMPILE_IFELSE is expanded from...../../lib/autoconf/general.m4:2617: AC_COMPILE_IFELSE is expanded from...../../lib/m4sugar/m4sh.m4:639: AS_IF is expanded from...../../lib/autoconf/general.m4:2042: AC_CACHE_VAL is expanded from...../../lib/autoconf/general.m4:2063: AC_CACHE_CHECK is expanded from...configure.ac:66: the top levelconfigure.ac:66: warning: AC_LANG_CONFTEST: no AC_LANG_SOURCE call detected in body../../lib/autoconf/lang.m4:193: AC_LANG_CONFTEST is expanded from...../../lib/autoconf/general.m4:2601: _AC_COMPILE_IFELSE is expanded from...../../lib/autoconf/general.m4:2617: AC_COMPILE_IFELSE is expanded from...../../lib/m4sugar/m4sh.m4:639: AS_IF is expanded from...../../lib/autoconf/general.m4:2042: AC_CACHE_VAL is expanded from...../../lib/autoconf/general.m4:2063: AC_CACHE_CHECK is expanded from...configure.ac:66: the top levelsunnogo@R04220:~/workshop/elfutils-0.150$ sunnogo@R04220:~/workshop/elfutils-0.150$ autoheader configure.ac:66: warning: AC_LANG_CONFTEST: no AC_LANG_SOURCE call detected in body../../lib/autoconf/lang.m4:193: AC_LANG_CONFTEST is expanded from...../../lib/autoconf/general.m4:2601: _AC_COMPILE_IFELSE is expanded from...../../lib/autoconf/general.m4:2617: AC_COMPILE_IFELSE is expanded from...../../lib/m4sugar/m4sh.m4:639: AS_IF is expanded from...../../lib/autoconf/general.m4:2042: AC_CACHE_VAL is expanded from...../../lib/autoconf/general.m4:2063: AC_CACHE_CHECK is expanded from...configure.ac:66: the top levelsunnogo@R04220:~/workshop/elfutils-0.150$ autoconf configure.ac:66: warning: AC_LANG_CONFTEST: no AC_LANG_SOURCE call detected in body../../lib/autoconf/lang.m4:193: AC_LANG_CONFTEST is expanded from...../../lib/autoconf/general.m4:2601: _AC_COMPILE_IFELSE is expanded from...../../lib/autoconf/general.m4:2617: AC_COMPILE_IFELSE is expanded from...../../lib/m4sugar/m4sh.m4:639: AS_IF is expanded from...../../lib/autoconf/general.m4:2042: AC_CACHE_VAL is expanded from...../../lib/autoconf/general.m4:2063: AC_CACHE_CHECK is expanded from...configure.ac:66: the top levelsunnogo@R04220:~/workshop/elfutils-0.150$ automake --add-missing configure.ac:66: warning: AC_LANG_CONFTEST: no AC_LANG_SOURCE call detected in body../../lib/autoconf/lang.m4:193: AC_LANG_CONFTEST is expanded from...../../lib/autoconf/general.m4:2601: _AC_COMPILE_IFELSE is expanded from...../../lib/autoconf/general.m4:2617: AC_COMPILE_IFELSE is expanded from...../../lib/m4sugar/m4sh.m4:639: AS_IF is expanded from...../../lib/autoconf/general.m4:2042: AC_CACHE_VAL is expanded from...../../lib/autoconf/general.m4:2063: AC_CACHE_CHECK is expanded from...configure.ac:66: the top levelconfigure.ac:242: warning: The 'AM_PROG_MKDIR_P' macro is deprecated, and its use is discouraged.configure.ac:242: You should use the Autoconf-provided 'AC_PROG_MKDIR_P' macro instead,configure.ac:242: and use '$(MKDIR_P)' instead of '$(mkdir_p)'in your Makefile.am files.configure.ac:61: installing 'config/compile'config/eu.am:29: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')backends/Makefile.am:27: 'config/eu.am' included from hereconfig/eu.am:29: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')lib/Makefile.am:27: 'config/eu.am' included from hereconfig/eu.am:29: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')libasm/Makefile.am:27: 'config/eu.am' included from hereconfig/eu.am:29: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')libcpu/Makefile.am:27: 'config/eu.am' included from hereconfig/eu.am:29: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')libdw/Makefile.am:27: 'config/eu.am' included from hereconfig/eu.am:29: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')libdwfl/Makefile.am:29: 'config/eu.am' included from hereconfig/eu.am:29: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')libebl/Makefile.am:27: 'config/eu.am' included from hereconfig/eu.am:29: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')libelf/Makefile.am:27: 'config/eu.am' included from hereconfig/eu.am:29: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')src/Makefile.am:27: 'config/eu.am' included from hereconfig/eu.am:29: warning: 'INCLUDES' is the old name for 'AM_CPPFLAGS' (or '*_CPPFLAGS')tests/Makefile.am:27: 'config/eu.am' included from hereparallel-tests: installing 'config/test-driver'sunnogo@R04220:~/workshop/elfutils-0.150$ 修改 Makefile 删除根目录 Makefile 中的 libcpu 删除 backends/Makefile 中的 libebl_i386.a and libebl_x86_64.a 相关内容 (这里把所有 i386 和 x86_64 字眼所在行全部注释) test 代码依赖 libz patch 如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234diff -uNr elfutils-0.150/backends/Makefile elfutils-0.150.change_makefile/backends/Makefile--- elfutils-0.150/backends/Makefile 2016-08-24 14:28:43.122364093 +0800+++ elfutils-0.150.change_makefile/backends/Makefile 2016-08-24 10:44:13.750042768 +0800@@ -123,13 +123,13 @@ arm_regs.$(OBJEXT) arm_corenote.$(OBJEXT) arm_auxv.$(OBJEXT) \ arm_attrs.$(OBJEXT) arm_retval.$(OBJEXT) libebl_arm_pic_a_OBJECTS = $(am_libebl_arm_pic_a_OBJECTS)-libebl_i386_pic_a_AR = $(AR) $(ARFLAGS)-libebl_i386_pic_a_LIBADD =-am__objects_3 = i386_init.$(OBJEXT) i386_symbol.$(OBJEXT) \+#libebl_i386_pic_a_AR = $(AR) $(ARFLAGS)+#libebl_i386_pic_a_LIBADD =+#am__objects_3 = i386_init.$(OBJEXT) i386_symbol.$(OBJEXT) \ i386_corenote.$(OBJEXT) i386_cfi.$(OBJEXT) \ i386_retval.$(OBJEXT) i386_regs.$(OBJEXT) i386_auxv.$(OBJEXT) \ i386_syscall.$(OBJEXT)-libebl_i386_pic_a_OBJECTS = $(am_libebl_i386_pic_a_OBJECTS)+#libebl_i386_pic_a_OBJECTS = $(am_libebl_i386_pic_a_OBJECTS) libebl_ia64_pic_a_AR = $(AR) $(ARFLAGS) libebl_ia64_pic_a_LIBADD = am__objects_4 = ia64_init.$(OBJEXT) ia64_symbol.$(OBJEXT) \@@ -165,13 +165,13 @@ sparc_corenote.$(OBJEXT) sparc64_corenote.$(OBJEXT) \ sparc_auxv.$(OBJEXT) libebl_sparc_pic_a_OBJECTS = $(am_libebl_sparc_pic_a_OBJECTS)-libebl_x86_64_pic_a_AR = $(AR) $(ARFLAGS)-libebl_x86_64_pic_a_LIBADD =-am__objects_10 = x86_64_init.$(OBJEXT) x86_64_symbol.$(OBJEXT) \+#libebl_x86_64_pic_a_AR = $(AR) $(ARFLAGS)+#libebl_x86_64_pic_a_LIBADD =+#am__objects_10 = x86_64_init.$(OBJEXT) x86_64_symbol.$(OBJEXT) \ x86_64_corenote.$(OBJEXT) x86_64_cfi.$(OBJEXT) \ x86_64_retval.$(OBJEXT) x86_64_regs.$(OBJEXT) \ i386_auxv.$(OBJEXT) x86_64_syscall.$(OBJEXT)-libebl_x86_64_pic_a_OBJECTS = $(am_libebl_x86_64_pic_a_OBJECTS)+#libebl_x86_64_pic_a_OBJECTS = $(am_libebl_x86_64_pic_a_OBJECTS) AM_V_P = $(am__v_P_$(V)) am__v_P_ = $(am__v_P_$(AM_DEFAULT_VERBOSITY)) am__v_P_0 = false@@ -201,16 +201,15 @@ am__v_CCLD_0 = @echo " CCLD " $@; am__v_CCLD_1 = SOURCES = $(libebl_alpha_pic_a_SOURCES) $(libebl_arm_pic_a_SOURCES) \- $(libebl_i386_pic_a_SOURCES) $(libebl_ia64_pic_a_SOURCES) \+ $(libebl_ia64_pic_a_SOURCES) \ $(libebl_ppc64_pic_a_SOURCES) $(libebl_ppc_pic_a_SOURCES) \ $(libebl_s390_pic_a_SOURCES) $(libebl_sh_pic_a_SOURCES) \- $(libebl_sparc_pic_a_SOURCES) $(libebl_x86_64_pic_a_SOURCES)+ $(libebl_sparc_pic_a_SOURCES) DIST_SOURCES = $(libebl_alpha_pic_a_SOURCES) \- $(libebl_arm_pic_a_SOURCES) $(libebl_i386_pic_a_SOURCES) \+ $(libebl_arm_pic_a_SOURCES) \ $(libebl_ia64_pic_a_SOURCES) $(libebl_ppc64_pic_a_SOURCES) \ $(libebl_ppc_pic_a_SOURCES) $(libebl_s390_pic_a_SOURCES) \- $(libebl_sh_pic_a_SOURCES) $(libebl_sparc_pic_a_SOURCES) \- $(libebl_x86_64_pic_a_SOURCES)+ $(libebl_sh_pic_a_SOURCES) $(libebl_sparc_pic_a_SOURCES) am__can_run_installinfo = \ case $$AM_UPDATE_INFO_DIR in \ n|no|NO) false;; \@@ -278,7 +277,7 @@ MAINT = # MAKEINFO = makeinfo MKDIR_P = /bin/mkdir -p-MODVERSION = Build on R04220 2016-08-24T14:28:41+0800+MODVERSION = Build on R04220 2016-08-24T10:35:18+0800 MSGFMT = /usr/bin/msgfmt MSGFMT_015 = /usr/bin/msgfmt MSGMERGE = /usr/bin/msgmerge@@ -372,8 +371,8 @@ CLEANFILES = *.gcno *.gcda $(foreach m,$(modules), libebl_$(m).map \ libebl_$(m).so $(am_libebl_$(m)_pic_a_OBJECTS)) textrel_check = if readelf -d $@ | fgrep -q TEXTREL; then exit 1; fi-modules = i386 sh x86_64 ia64 alpha arm sparc ppc ppc64 s390-libebl_pic = libebl_i386_pic.a libebl_sh_pic.a libebl_x86_64_pic.a \+modules = sh ia64 alpha arm sparc ppc ppc64 s390+libebl_pic = libebl_sh_pic.a \ libebl_ia64_pic.a libebl_alpha_pic.a libebl_arm_pic.a \ libebl_sparc_pic.a libebl_ppc_pic.a libebl_ppc64_pic.a \ libebl_s390_pic.a@@ -384,21 +383,21 @@ #libelf = ../libelf/libelf.a libdw = ../libdw/libdw.so #libdw = ../libdw/libdw.a-i386_SRCS = i386_init.c i386_symbol.c i386_corenote.c i386_cfi.c \+#i386_SRCS = i386_init.c i386_symbol.c i386_corenote.c i386_cfi.c \ i386_retval.c i386_regs.c i386_auxv.c i386_syscall.c -cpu_i386 = ../libcpu/libcpu_i386.a-libebl_i386_pic_a_SOURCES = $(i386_SRCS)-am_libebl_i386_pic_a_OBJECTS = $(i386_SRCS:.c=.os)+#cpu_i386 = ../libcpu/libcpu_i386.a+#libebl_i386_pic_a_SOURCES = $(i386_SRCS)+#am_libebl_i386_pic_a_OBJECTS = $(i386_SRCS:.c=.os) sh_SRCS = sh_init.c sh_symbol.c sh_corenote.c sh_regs.c sh_retval.c libebl_sh_pic_a_SOURCES = $(sh_SRCS) am_libebl_sh_pic_a_OBJECTS = $(sh_SRCS:.c=.os)-x86_64_SRCS = x86_64_init.c x86_64_symbol.c x86_64_corenote.c x86_64_cfi.c \+#x86_64_SRCS = x86_64_init.c x86_64_symbol.c x86_64_corenote.c x86_64_cfi.c \ x86_64_retval.c x86_64_regs.c i386_auxv.c x86_64_syscall.c -cpu_x86_64 = ../libcpu/libcpu_x86_64.a-libebl_x86_64_pic_a_SOURCES = $(x86_64_SRCS)-am_libebl_x86_64_pic_a_OBJECTS = $(x86_64_SRCS:.c=.os)+#cpu_x86_64 = ../libcpu/libcpu_x86_64.a+#libebl_x86_64_pic_a_SOURCES = $(x86_64_SRCS)+#am_libebl_x86_64_pic_a_OBJECTS = $(x86_64_SRCS:.c=.os) ia64_SRCS = ia64_init.c ia64_symbol.c ia64_regs.c ia64_retval.c libebl_ia64_pic_a_SOURCES = $(ia64_SRCS) am_libebl_ia64_pic_a_OBJECTS = $(ia64_SRCS:.c=.os)@@ -480,10 +479,10 @@ $(AM_V_AR)$(libebl_arm_pic_a_AR) libebl_arm_pic.a $(libebl_arm_pic_a_OBJECTS) $(libebl_arm_pic_a_LIBADD) $(AM_V_at)$(RANLIB) libebl_arm_pic.a -libebl_i386_pic.a: $(libebl_i386_pic_a_OBJECTS) $(libebl_i386_pic_a_DEPENDENCIES) $(EXTRA_libebl_i386_pic_a_DEPENDENCIES) - $(AM_V_at)-rm -f libebl_i386_pic.a- $(AM_V_AR)$(libebl_i386_pic_a_AR) libebl_i386_pic.a $(libebl_i386_pic_a_OBJECTS) $(libebl_i386_pic_a_LIBADD)- $(AM_V_at)$(RANLIB) libebl_i386_pic.a+#libebl_i386_pic.a: $(libebl_i386_pic_a_OBJECTS) $(libebl_i386_pic_a_DEPENDENCIES) $(EXTRA_libebl_i386_pic_a_DEPENDENCIES) +# $(AM_V_at)-rm -f libebl_i386_pic.a+# $(AM_V_AR)$(libebl_i386_pic_a_AR) libebl_i386_pic.a $(libebl_i386_pic_a_OBJECTS) $(libebl_i386_pic_a_LIBADD)+# $(AM_V_at)$(RANLIB) libebl_i386_pic.a libebl_ia64_pic.a: $(libebl_ia64_pic_a_OBJECTS) $(libebl_ia64_pic_a_DEPENDENCIES) $(EXTRA_libebl_ia64_pic_a_DEPENDENCIES) $(AM_V_at)-rm -f libebl_ia64_pic.a@@ -515,10 +514,10 @@ $(AM_V_AR)$(libebl_sparc_pic_a_AR) libebl_sparc_pic.a $(libebl_sparc_pic_a_OBJECTS) $(libebl_sparc_pic_a_LIBADD) $(AM_V_at)$(RANLIB) libebl_sparc_pic.a -libebl_x86_64_pic.a: $(libebl_x86_64_pic_a_OBJECTS) $(libebl_x86_64_pic_a_DEPENDENCIES) $(EXTRA_libebl_x86_64_pic_a_DEPENDENCIES) - $(AM_V_at)-rm -f libebl_x86_64_pic.a- $(AM_V_AR)$(libebl_x86_64_pic_a_AR) libebl_x86_64_pic.a $(libebl_x86_64_pic_a_OBJECTS) $(libebl_x86_64_pic_a_LIBADD)- $(AM_V_at)$(RANLIB) libebl_x86_64_pic.a+#libebl_x86_64_pic.a: $(libebl_x86_64_pic_a_OBJECTS) $(libebl_x86_64_pic_a_DEPENDENCIES) $(EXTRA_libebl_x86_64_pic_a_DEPENDENCIES) +# $(AM_V_at)-rm -f libebl_x86_64_pic.a+# $(AM_V_AR)$(libebl_x86_64_pic_a_AR) libebl_x86_64_pic.a $(libebl_x86_64_pic_a_OBJECTS) $(libebl_x86_64_pic_a_LIBADD)+# $(AM_V_at)$(RANLIB) libebl_x86_64_pic.a mostlyclean-compile: -rm -f *.$(OBJEXT)@@ -539,14 +538,14 @@ include ./$(DEPDIR)/arm_regs.Po include ./$(DEPDIR)/arm_retval.Po include ./$(DEPDIR)/arm_symbol.Po-include ./$(DEPDIR)/i386_auxv.Po-include ./$(DEPDIR)/i386_cfi.Po-include ./$(DEPDIR)/i386_corenote.Po-include ./$(DEPDIR)/i386_init.Po-include ./$(DEPDIR)/i386_regs.Po-include ./$(DEPDIR)/i386_retval.Po-include ./$(DEPDIR)/i386_symbol.Po-include ./$(DEPDIR)/i386_syscall.Po+#include ./$(DEPDIR)/i386_auxv.Po+#include ./$(DEPDIR)/i386_cfi.Po+#include ./$(DEPDIR)/i386_corenote.Po+#include ./$(DEPDIR)/i386_init.Po+#include ./$(DEPDIR)/i386_regs.Po+#include ./$(DEPDIR)/i386_retval.Po+#include ./$(DEPDIR)/i386_symbol.Po+#include ./$(DEPDIR)/i386_syscall.Po include ./$(DEPDIR)/ia64_init.Po include ./$(DEPDIR)/ia64_regs.Po include ./$(DEPDIR)/ia64_retval.Po@@ -579,13 +578,6 @@ include ./$(DEPDIR)/sparc_regs.Po include ./$(DEPDIR)/sparc_retval.Po include ./$(DEPDIR)/sparc_symbol.Po-include ./$(DEPDIR)/x86_64_cfi.Po-include ./$(DEPDIR)/x86_64_corenote.Po-include ./$(DEPDIR)/x86_64_init.Po-include ./$(DEPDIR)/x86_64_regs.Po-include ./$(DEPDIR)/x86_64_retval.Po-include ./$(DEPDIR)/x86_64_symbol.Po-include ./$(DEPDIR)/x86_64_syscall.Po .c.o: $(AM_V_CC)$(COMPILE) -MT $@ -MD -MP -MF $(DEPDIR)/$*.Tpo -c -o $@ $&lt;@@ -822,8 +814,8 @@ -Wl,-z,defs -Wl,--as-needed $(libelf) $(libdw) $(libmudflap) $(textrel_check) -libebl_i386.so: $(cpu_i386)-libebl_x86_64.so: $(cpu_x86_64)+#libebl_i386.so: $(cpu_i386)+#libebl_x86_64.so: $(cpu_x86_64) install: install-am install-ebl-modules install-ebl-modules:diff -uNr elfutils-0.150/Makefile elfutils-0.150.change_makefile/Makefile--- elfutils-0.150/Makefile 2016-08-24 14:28:43.006363730 +0800+++ elfutils-0.150.change_makefile/Makefile 2016-08-24 10:35:45.771545207 +0800@@ -358,7 +358,7 @@ pkginclude_HEADERS = version.h # Add doc back when we have some real content.-SUBDIRS = config m4 lib libelf libebl libdwfl libdw libcpu libasm backends \+SUBDIRS = config m4 lib libelf libebl libdwfl libdw libasm backends \ src po tests EXTRA_DIST = elfutils.spec GPG-KEY NOTES EXCEPTIONdiff -uNr elfutils-0.150/src/Makefile elfutils-0.150.change_makefile/src/Makefile--- elfutils-0.150/src/Makefile 2016-08-24 14:28:43.134364130 +0800+++ elfutils-0.150.change_makefile/src/Makefile 2016-08-24 10:50:27.408937610 +0800@@ -352,12 +352,12 @@ LEX_OUTPUT_ROOT = lex.yy LIBEBL_SUBDIR = elfutils LIBOBJS = -LIBS = +LIBS = -lz LTLIBOBJS = MAINT = # MAKEINFO = makeinfo MKDIR_P = /bin/mkdir -p MODVERSION = Build on R04220 2016-08-24T10:35:18+0800 MSGFMT = /usr/bin/msgfmt MSGFMT_015 = /usr/bin/msgfmt MSGMERGE = /usr/bin/msgmergediff -uNr elfutils-0.150/tests/Makefile elfutils-0.150.change_makefile/tests/Makefile--- elfutils-0.150/tests/Makefile 2016-08-24 14:28:43.158364205 +0800+++ elfutils-0.150.change_makefile/tests/Makefile 2016-08-24 10:51:48.828696796 +0800@@ -678,12 +678,12 @@ LEX_OUTPUT_ROOT = lex.yy LIBEBL_SUBDIR = elfutils LIBOBJS = -LIBS = +LIBS = -lz LTLIBOBJS = MAINT = # MAKEINFO = makeinfo MKDIR_P = /bin/mkdir -p MODVERSION = Build on R04220 2016-08-24T14:28:41+0800 MSGFMT = /usr/bin/msgfmt MSGFMT_015 = /usr/bin/msgfmt MSGMERGE = /usr/bin/msgmerge perf arm 交叉编译记录 Makefile 添加外部库路径、外部头文件路径、依赖的库 patch 如下：1234567891011121314151617181920212223242526272829diff --git a/tools/perf/Makefile b/tools/perf/Makefileindex b0f164b..5e88839 100644--- a/tools/perf/Makefile+++ b/tools/perf/Makefile@@ -30,11 +30,13 @@ include config/utilities.mak # Define LDFLAGS=-static to build a static binary. # # Define EXTRA_CFLAGS=-m64 or EXTRA_CFLAGS=-m32 as appropriate for cross-builds.-#+EXTRA_CFLAGS=-I/home/sunnogo/workshop/rgosm-build/public/include -I/home/sunnogo/workshop/prj/images/header -D_LITTLE_ENDIAN -L/home/sunnogo/workshop/prj/images/lib -L/home/sunnogo/workshop/prj/images/rootfs/lib+ # Define NO_DWARF if you do not want debug-info analysis feature at all. # # Define WERROR=0 to disable treating any warnings as errors.-#+WERROR=0+ # Define NO_NEWT if you do not want TUI support. (deprecated) # # Define NO_SLANG if you do not want TUI support.@@ -111,7 +113,7 @@ ifdef NO_NEWT endif CFLAGS = -fno-omit-frame-pointer -ggdb3 -funwind-tables -Wall -Wextra -std=gnu99 $(CFLAGS_WERROR) $(CFLAGS_OPTIMIZE) $(EXTRA_WARNINGS) $(EXTRA_CFLAGS) $(PARSER_DEBUG_CFLAGS)-EXTLIBS = -lpthread -lrt -lelf -lm+EXTLIBS = -lpthread -lrt -lelf -lm -lebl -lz -ldl ALL_CFLAGS = $(CFLAGS) -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE ALL_LDFLAGS = $(LDFLAGS) STRIP ?= strip]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>perf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C程序异常提示“stack smashing detected”]]></title>
    <url>%2F201606%2Fprogrammer%2Fc%2Fstack_smashing_detected.html</url>
    <content type="text"><![CDATA[如题，在程序运行中出现： 123*** stack smashing detected ***: /home/sunyongfeng/workshop/test/sredis.x86/x.elf terminatedProgram received signal SIGABRT, Aborted. 原因： 操作溢出。我的问题是 memcpy 拷贝超过预期长度的内存。 详见 stackoverflow 的 sud03r 回答。以下引用该回答。 Stack Smashing here is actually caused due to a protection mechanism used by gcc to detect buffer overflow errors. For example in the following snippet: 123456789101112#include &lt;stdio.h&gt;&gt;&gt;void func()&#123; char array[10]; gets(array);&#125;&gt;int main(int argc, char **argv)&#123; func();&#125; The compiler, (in this case gcc) adds protection variables (called canaries) which have known values. An input string of size greater than 10 causes corruption of this variable resulting in SIGABRT to terminate the program. To get some insight, you can try disabling this protection of gcc using option -fno-stack-protector while compiling. In that case you will get a different error, most likely a segmentation fault as you are trying to access an illegal memory location. Note that -fstack-protector should always be turned on for release builds as it is a security feature. You can get some information about the point of overflow by running the program with a debugger. Valgrind doesn’t work well with stack-related errors, but like a debugger, it may help you pin-point the location and reason for the crash.]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 订阅发布]]></title>
    <url>%2F201606%2Fprogrammer%2Fredis%2Fsubpub.html</url>
    <content type="text"><![CDATA[订阅配置redis 配置文件，EVENT NOTIFICATION 一节，配置监听响应哪种事件。这里配置为 notify-keyspace-events &quot;KA&quot;。 123456789101112131415161718192021222324252627282930313233343536373839404142434445############################# EVENT NOTIFICATION ############################### Redis can notify Pub/Sub clients about events happening in the key space.# This feature is documented at http://redis.io/topics/notifications## For instance if keyspace events notification is enabled, and a client# performs a DEL operation on key "foo" stored in the Database 0, two# messages will be published via Pub/Sub:## PUBLISH __keyspace@0__:foo del# PUBLISH __keyevent@0__:del foo## It is possible to select the events that Redis will notify among a set# of classes. Every class is identified by a single character:## K Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.# E Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.# g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...# $ String commands# l List commands# s Set commands# h Hash commands# z Sorted set commands# x Expired events (events generated every time a key expires)# e Evicted events (events generated when a key is evicted for maxmemory)# A Alias for g$lshzxe, so that the "AKE" string means all the events.## The "notify-keyspace-events" takes as argument a string that is composed# of zero or multiple characters. The empty string means that notifications# are disabled.## Example: to enable list and generic events, from the point of view of the# event name, use:## notify-keyspace-events Elg## Example 2: to get the stream of the expired keys subscribing to channel# name __keyevent@0__:expired use:## notify-keyspace-events Ex## By default all notifications are disabled because most users don't need# this feature and the feature has some overhead. Note that if you don't# specify at least one of K or E, no events will be delivered.notify-keyspace-events "KA" CLI 1 进行订阅操作：123456sunnogo@R04220:~/workshop/redis_new$ redis-cli 127.0.0.1:6379&gt; PSUBSCRIBE __keyspace@0__:/RT/*Reading messages... (press Ctrl-C to quit)1) "psubscribe"2) "__keyspace@0__:/RT/*"3) (integer) 1 CLI 2 进行发布操作：12127.0.0.1:6379&gt; HSET /RT/1.1.1.1 nexthop 2.2.2.2(integer) 1 CLI 1 中的响应：12341) "pmessage"2) "__keyspace@0__:/RT/*"3) "__keyspace@0__:/RT/1.1.1.1"4) "hset"]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fcitx 在 WPS for Linux 中无法使用]]></title>
    <url>%2F201605%2Flinux%2Fwps_fcitx_fail.html</url>
    <content type="text"><![CDATA[问题： fcitx 在 WPS for Linux 中调不出来，在 Linux 的其他应用中可以正常使用。原因：环境变量未正确设置。解决： Google 搜索，来自 Linux 教程： 在 /usr/bin/wps （word）、/usr/bin/wpp （powerpoint）、/usr/bin/et （excel）脚本的开始，加入 export XMODIFIERS=&quot;@im=fcitx&quot; 和 export QT_IM_MODULE=&quot;fcitx&quot;。以 wps 为例： 123456789$ sudo vi /usr/bin/wps#!/bin/bashexport XMODIFIERS="@im=fcitx"export QT_IM_MODULE="fcitx"gOpt=#gOptExt=-multiplygTemplateExt=("wpt" "dot" "dotx")]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>wps</tag>
        <tag>fcitx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 链接库使用记录]]></title>
    <url>%2F201605%2Fprogrammer%2Ftools%2Flinux_library.html</url>
    <content type="text"><![CDATA[本文记录 Linux 静态、动态链接库的一些常用使用方法。 查看符号 nm 命令，nm -A libxxx.so 2&gt;/dev/null | grep &quot;your_symbol&quot;]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>lib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VIM 配置文件]]></title>
    <url>%2F201605%2Fprogrammer%2Ftools%2Fvimrc.html</url>
    <content type="text"><![CDATA[已更新在 gist。 以下已过时。 这是我的个人 vim 配置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142" 1. Install bundle" git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundle"" 2. Powerline font creator" a. sudo apt-get install python-fontforge" b. /path/to/fontpatcher MyFontFile.ttf" c. cp MyFontFile-Powerline.otf ~/.fonts" d. sudo fc-cache -vf" e. Change your console font. Bingo!set nocompatible " be iMprovedfiletype off " required!set rtp+=~/.vim/bundle/vundle/call vundle#rc()" let Vundle manage Vundle" required! Bundle 'gmarik/vundle'"Bundle 'Valloric/YouCompleteMe'"Bundle 'rdnetto/YCM-Generator'Bundle 'scrooloose/nerdtree'Bundle 'fholgado/minibufexpl.vim'Bundle 'vim-scripts/taglist.vim'Bundle 'kien/ctrlp.vim'"Bundle 'brookhong/cscope.vim'"Bundle 'mbbill/echofunc'Bundle 'vim-scripts/winmanager'Bundle 'vim-scripts/CRefVim'"Bundle 'vim-scripts/AutoComplPop'"Bundle 'vim-scripts/EasyColour'"Bundle 'vim-scripts/clibs.vim'"Bundle 'vim-scripts/OmniCppComplete'Bundle 'plasticboy/vim-markdown'"Bundle 'ervandew/supertab'Bundle 'Lokaltog/vim-powerline'" Search"Bundle 'ggreer/the_silver_searcher'"Bundle 'rking/ag.vim'Bundle 'dyng/ctrlsf.vim'Bundle 'vim-scripts/a.vim'"Bundle 'vim-scripts/cream-statusline-prototype'"Bundle 'xolox/vim-easytags'"Bundle 'tpope/vim-vividchalk'"Bundle 'xolox/vim-misc'"Bundle 'wesleyche/SrcExpl'"Bundle 'vim-scripts/indexer.tar.gz'"Bundle 'vim-scripts/vimprj'"Bundle 'vim-scripts/DfrankUtil'" My Bundles here:filetype plugin onfiletype plugin indent on " required!colorscheme elflord"" Brief help" :BundleList - list configured bundles" :BundleInstall(!) - install(update) bundles" :BundleSearch(!) foo - search(or refresh cache first) for foo" :BundleClean(!) - confirm(or auto-approve) removal of unused bundles"" see :h vundle for more details or wiki for FAQ" NOTE: comments after Bundle command are not allowed..let g:syntastic_ignore_files=[".*\.py$"]let g:ycm_global_ycm_extra_conf = '~/.vim/bundle/YouCompleteMe/third_party/ycmd/cpp/ycm/.ycm_extra_conf.py'set nocp" set MiniBufExplorerlet g:miniBufExplMapWindowNavVim = 1 let g:miniBufExplMapWindowNavArrows = 1 let g:miniBufExplMapCTabSwitchBufs = 1 let g:miniBufExplModSelTarget = 1let g:miniBufExplMoreThanOne=0" set winmanager" Caution: current version of winmanager has a problem" need to modify ~/.vim/plugin/winmanager.vim" function ToggleWindowsManager()下的call" s:StartWindowsManager()的下一行加一句exe 'q'let g:NERDTree_title="[NERDTree]"let g:winManagerWindowLayout="MiniBufExplorer,NERDTree|TagList""let g:winManagerWindowLayout="MiniBufExplorer,TagList"function! NERDTree_Start() exec 'NERDTree'endfunctionfunction! NERDTree_IsValid() return 1endfunctionnmap wm :WMToggle&lt;CR&gt;" set clib.vimlet c_hi_identifiers = 'all'let c_hi_libs = ['*']set hlsearchset nuset cc=100set ts=4set shiftwidth =4set expandtabset autoindentset cindentset smartindentset softtabstop=4" 关闭omnicpp预览窗口set completeopt=menulet OmniCpp_ShowPrototypeInAbbr = 1 " show function prototype in popup windowlet g:vim_markdown_folding_disabled=1" powerline的设置let g:Powerline_symbols = 'fancy'set fillchars+=stl:\ ,stlnc:\set t_Co=256set laststatus=2 " Always show the statuslinelet mapleader=','" 使用 ctrlsf.vim插件在工程内全局查找光标所在关键字，设置快捷键。快捷键速记法：search in projectnnoremap &lt;Leader&gt;sf :CtrlSF&lt;CR&gt;" Encoding" Recognition GBK encoding firstset encoding=utf-8set fenc=cp936set fileencodings=cp936,ucs-bom,utf-8" Avoid menu garbled charactersif v:lang =~? '^\(zh\)\|\(ja\)\|\(ko\)' set ambiwidth=doubleendifset nobomb]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 下使用 RTX]]></title>
    <url>%2F201605%2Flinux%2Fwine_rtx.html</url>
    <content type="text"><![CDATA[本文记录 Ubuntu 16.04 64 位下 wine RTX 的过程。最终验证 wine 后的 RTX 字体 OK 无方块，截图正常，可发送截图、文件。 什么是 RTX简单的，RTX 是 QQ 的企业版，亦有人称之为 BQQ。如果没有听过这个名称，这篇文章亦可做为 Linux 下 Wine 其他 windows 工具的参考。 腾讯通 RTX（Real Time eXchange）是腾讯公司推出的企业级即时通信平台。企业员工可以轻松地通过服务器所配置的组织架构查找需要进行通讯的人员，并采用丰富的沟通方式进行实时沟通。文本消息、文件传输、直接语音会话或者视频的形式满足不同办公环境下的沟通需求。 安装最新版 wine详见 Ubuntu wine wiki。 ubuntu 官方有自带 wine ，但是推荐用 winehq 官方提供的最新版本 wine ，新版本解决很多以前旧版本的问题。 PPA地址：https://launchpad.net/~wine/+archive/ubuntu/wine-builds 123sudo add-apt-repository ppa:wine/wine-buildssudo apt-get updatesudo apt-get install wine-devel 要注意，若 apt-get install wine 安装的是稳定版（版本一般比较旧）；若 apt-get install wine-devel 则安装的是较新的开发版本 ，开发版本经常有不少优化和修正。 如果愿意安装比 devel 稍微更 devel 的 staging 版本的话，可试试 wine-staging。 下载最新 winetricks最新的 winetricks 解决许多下载失败等问题，直接从 github 上下载。链接。 winetricks 下载慢或则失败，可按 winetricks 脚本中写的文件名到 google 搜索、寻找其他下载源。若出现下载的程序版本与 winetricks 要求的版本不一致导致 sha 检测不通过，可通过改 winetricks 中的检测值解决。 安装依赖为防止 32 位、64 位可能出现不兼容，执行命令的时候配置 WINEARCH 为 win32。 1WINEARCH=win32 WINEPREFIX=~/.wine winetricks msxml3 gdiplus riched20 riched30 ie6 vcrun6 vcrun2005sp1 allfonts 安装 rtx2015rtx 官方下载页面。 1WINEARCH=win32 WINEPREFIX=~/.wine wine Downloads/rtxclient2015formal.exe 安装完后，直接可用。字体、截图及发送、文件发送皆正常。不会出现离线后再上线就登不上的问题。 问题 为防止字体的方块问题，建议将系统的默认语言调整为汉语。如果默认为英语，则某些地方的汉字会显示成方块； 不清楚是 WINE 的问题还是 RTX 窗口开太多，RTX 的 CPU 常维持在 20% 左右； RTX 可能出现假死，即导致整个 Unity 界面挂住，过一小会儿后才 OK。据说在 Xfce 界面中也会出现此问题。 RTX 运行久了之后，可能出现系统状态栏的图标点不了。 RTX 可能在运行过程中出现中文输入法无法调出。本文用的输入法是 fcitx。 截图 RTX 界面与菜单 界面： 菜单： 聊天界面 界面1： 界面2：（含图片发送） 消息管理器之会话消息 消息管理器之多人会话（含图片） 消息管理器之文件接收 消息管理器之导出会话将会话导出为 RTF 文件，以下为在 word 中打开的 RTF 文件截图。 RTX 设置 RTX 退出界面注意，如果系统默认语言不是中文，退出界面将的中文显示为方块。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
        <tag>wine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[交叉编译 python]]></title>
    <url>%2F201605%2Fprogrammer%2Fpython%2Fcross_compile.html</url>
    <content type="text"><![CDATA[下载、解压 python 源代码从 python.org 下载。 导入交叉编译 patch参考自 python-2.7-001-support-for-build.patch，2.7.11 的修改地方有稍微变化，详见如下 patch。 Python 虽然使用 autoconf，但是事实上代码中已经包含 configure 文件，因此下文代码给出的是修改 configure.ac 并执行 autoconf 后生成的 configure 文件。 patch 的使用方法，在 python 源代码根目录下执行： 1patch -p1 &lt; ../0001-cross-compile.patch python 2.7.11 交叉编译 patch： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374diff --git a/Makefile.pre.in b/Makefile.pre.inindex ee73edd..730db7e 100644--- a/Makefile.pre.in+++ b/Makefile.pre.in@@ -237,7 +237,8 @@ LIBFFI_INCLUDEDIR= @LIBFFI_INCLUDEDIR@ ########################################################################## # Parser-PGEN= Parser/pgen$(EXE)+BUILDPGEN= Parser/pgen$(EXE)+PGEN_FOR_BUILD= @PGEN_FOR_BUILD@ PSRCS= \ Parser/acceler.c \@@ -635,14 +636,14 @@ Modules/pwdmodule.o: $(srcdir)/Modules/pwdmodule.c $(srcdir)/Modules/posixmodule $(GRAMMAR_H): $(GRAMMAR_INPUT) $(PGENSRCS) @$(MKDIR_P) Include- $(MAKE) $(PGEN)- $(PGEN) $(GRAMMAR_INPUT) $(GRAMMAR_H) $(GRAMMAR_C)+ $(MAKE) $(BUILDPGEN)+ $(PGEN_FOR_BUILD) $(GRAMMAR_INPUT) $(GRAMMAR_H) $(GRAMMAR_C) $(GRAMMAR_C): $(GRAMMAR_H) $(GRAMMAR_INPUT) $(PGENSRCS) $(MAKE) $(GRAMMAR_H) touch $(GRAMMAR_C) -$(PGEN): $(PGENOBJS)- $(CC) $(OPT) $(LDFLAGS) $(PGENOBJS) $(LIBS) -o $(PGEN)+$(BUILDPGEN): $(PGENOBJS)+ $(CC) $(OPT) $(LDFLAGS) $(PGENOBJS) $(LIBS) -o $(BUILDPGEN) Parser/grammar.o: $(srcdir)/Parser/grammar.c \ $(srcdir)/Include/token.h \diff --git a/configure b/configureindex 7dab897..bf16c0e 100755--- a/configure+++ b/configure@@ -734,6 +734,7 @@ UNIVERSALSDK CONFIG_ARGS SOVERSION VERSION+PGEN_FOR_BUILD PYTHON_FOR_BUILD host_os host_vendor@@ -2911,6 +2912,13 @@ else fi +if test "$cross_compiling" = yes; then+ PGEN_FOR_BUILD="$&#123;PGEN_FOR_BUILD&#125;"+else+ PGEN_FOR_BUILD='$(BUILDPGEN)'+fi++ if test "$prefix" != "/"; then prefix=`echo "$prefix" | sed -e 's/\/$//g'`@@ -6334,6 +6342,12 @@ fi # Enable PGO flags.++++++ # Extract the first word of "llvm-profdata", so it can be a program name with args. set dummy llvm-profdata; ac_word=$2 &#123; $as_echo "$as_me:$&#123;as_lineno-$LINENO&#125;: checking for $ac_word" &gt;&amp;5-- 1.9.1 创建 build 目录在 python 源代码下创建 build-pc 和 build-mips 目录，分别用于编译 PC pgen（交叉编译时用到）与交叉编译 mips python。该目录做 configure、make、make install，编译时用于保存临时生成的文件，保证 python 源代码干净。 编译本地 Python 与 pgen用于生成 grammar 所需要文件用。 12345cd build-pc../configure CC=gcc CXX=g++ AR=ar RANLIB=ranlib LDFLAGS="-L/usr/lib -L/usr/lib64 -L/usr/local/lib -L/usr/local/lib64" CFLAGS="-I/usr/include -I/usr/local/include" make python Parser/pgen 配置配置交叉编译环境变量比如 CC、CFLAGS、LDFLAGS 等。 configure 配置配置命令如下：configure 的 prefix 只支持绝对路径。 123cd build-mips../configure --host=mips64-octeon-linux-gnu --build=x86_64-linux-gnu --prefix=/home/sunyongfeng/python-install --disable-ipv6 ac_cv_file__dev_ptmx=no ac_cv_file__dev_ptc=no ac_cv_have_long_long_format=yes PGEN_FOR_BUILD=../build-pc/Parse/pgen 问题： --enable-FEATURE，不清楚有哪些 features ，怎么配置； --enable-PACKAGE，不清楚有哪些 package，怎么配置。 配置完了之后，在 Modules 目录会生成 Setup 文件。x86 的默认编译会编译到必须的模块，而 mips64 的交叉编译很多模块没有编译下，如 socket 等。修改 Modules/Setup 文件，定制想编译的内置模块。以下是基础模块，目前还不清楚如果不想内置的话要如何编译。定制内置模块，参见这篇博文 《定制 Python 嵌入 C++: (四) 定制 Python 内建模块》，讲述各个内置模块的功能。 123456789101112131415161718192021# Modules that should always be present (non UNIX dependent): array arraymodule.c # array objects cmath cmathmodule.c _math.c # -lm # complex math library functions math mathmodule.c _math.c # -lm # math library functions, e.g. sin() _struct _struct.c # binary structure packing/unpacking time timemodule.c # -lm # time operations and variables operator operator.c # operator.add() and similar goodies _testcapi _testcapimodule.c # Python C API test module _random _randommodule.c # Random number generator _collections _collectionsmodule.c # Container types _heapq _heapqmodule.c # Heapq type itertools itertoolsmodule.c # Functions creating iterators for efficient looping strop stropmodule.c # String manipulations _functools _functoolsmodule.c # Tools for working with functions and callable objects _elementtree -I$(srcdir)/Modules/expat -DHAVE_EXPAT_CONFIG_H -DUSE_PYEXPAT_CAPI _elementtree.c # elementtree accelerator#_pickle _pickle.c # pickle accelerator datetime datetimemodule.c # date/time type _bisect _bisectmodule.c # Bisection algorithms unicodedata unicodedata.c # static Unicode character database 编译简单的 make 命令即可。 安装命令 make install -i，安装 bin、lib、share、man 等目录至 ./configure 中配置的 prefix 目录。 1234567891011121314151617181920212223242526272829303132333435363738sunyongfeng@R04220:~/python-install$ lsbin include lib sharesunyongfeng@R04220:~/python-install$ ls -al *bin:总用量 9612drwxr-xr-x 2 sunyongfeng sunyongfeng 4096 5月 13 16:51 .drwxr-xr-x 6 sunyongfeng sunyongfeng 4096 5月 15 10:58 ..-rwxrwxr-x 1 sunyongfeng sunyongfeng 123 5月 13 16:38 2to3-rwxrwxr-x 1 sunyongfeng sunyongfeng 121 5月 13 16:38 idle-rwxrwxr-x 1 sunyongfeng sunyongfeng 106 5月 13 16:38 pydoclrwxrwxrwx 1 sunyongfeng sunyongfeng 7 5月 13 16:51 python -&gt; python2lrwxrwxrwx 1 sunyongfeng sunyongfeng 9 5月 13 16:51 python2 -&gt; python2.7-rwxr-xr-x 1 sunyongfeng sunyongfeng 9793952 5月 13 16:51 python2.7-rwxr-xr-x 1 sunyongfeng sunyongfeng 1709 5月 13 16:51 python2.7-configlrwxrwxrwx 1 sunyongfeng sunyongfeng 16 5月 13 16:51 python2-config -&gt; python2.7-configlrwxrwxrwx 1 sunyongfeng sunyongfeng 14 5月 13 16:51 python-config -&gt; python2-config-rwxrwxr-x 1 sunyongfeng sunyongfeng 18569 5月 13 16:38 smtpd.pyinclude:总用量 12drwxr-xr-x 3 sunyongfeng sunyongfeng 4096 5月 13 16:51 .drwxr-xr-x 6 sunyongfeng sunyongfeng 4096 5月 15 10:58 ..drwxr-xr-x 2 sunyongfeng sunyongfeng 4096 5月 13 16:51 python2.7lib:总用量 16312drwxr-xr-x 4 sunyongfeng sunyongfeng 4096 5月 13 16:51 .drwxr-xr-x 6 sunyongfeng sunyongfeng 4096 5月 15 10:58 ..-r-xr-xr-x 1 sunyongfeng sunyongfeng 16670684 5月 13 16:51 libpython2.7.adrwxr-xr-x 2 sunyongfeng sunyongfeng 4096 5月 13 16:51 pkgconfigdrwxr-xr-x 28 sunyongfeng sunyongfeng 20480 5月 13 16:51 python2.7share:总用量 12drwxr-xr-x 3 sunyongfeng sunyongfeng 4096 5月 13 16:51 .drwxr-xr-x 6 sunyongfeng sunyongfeng 4096 5月 15 10:58 ..drwxr-xr-x 3 sunyongfeng sunyongfeng 4096 5月 13 16:51 mansunyongfeng@R04220:~/python-install$ 打包放到目标机上，配置目标机的 PATH，加上 python 的 bin 目录。 问题编译依赖交叉编译的时候，如果没有配置好 CFLAGS、LDFLAGS 之类的变量，可能找不到 python 编译所依赖的头文件或库文件。最终体现在编译的结果（此处可能因不同的变量配置而不同）： 12345678Python build finished, but the necessary bits to build these modules were not found:_bsddb _curses _curses_panel _sqlite3 _ssl _tkinter bsddb185 bz2 dbm dl gdbm imageop linuxaudiodev ossaudiodev readline sunaudiodev zlib To find the necessary bits, look in setup.py in detect_modules() for the module's name. sqlite3 依赖配置修改 python 源码根目录下的 setup.py 文件，在 detect_modules 函数下，找到 sqlite3 的头文件配置，添加上交叉编译下的 sqlite3 头文件目录。 123456789101112sqlite_inc_paths = [ '/usr/include', '/usr/include/sqlite', '/usr/include/sqlite3', '/usr/local/include', '/usr/local/include/sqlite', '/usr/local/include/sqlite3', ] if cross_compiling: sqlite_inc_paths = [ '/home/sunyongfeng/workshop/prj/images/header/', '/home/sunyongfeng/workshop/prj/images/header/sqlite', '/home/sunyongfeng/workshop/prj/images/header/sqlite3', ] ssl 依赖配置类似 sqlite3，在 setup.py 文件的 detect_modules 函数下，找到 ssl 相关的头文件与库文件配置，添加上交叉编译下的 ssl 头文件与库文件目录。 12345678910111213141516171819# Detect SSL support for the socket module (via _ssl) search_for_ssl_incs_in = [ '/usr/local/ssl/include', '/usr/contrib/ssl/include/', '/home/sunyongfeng/workshop/prj/images/header/', ] ssl_incs = find_file('openssl/ssl.h', inc_dirs, search_for_ssl_incs_in ) if ssl_incs is not None: krb5_h = find_file('krb5.h', inc_dirs, ['/usr/kerberos/include']) if krb5_h: ssl_incs += krb5_h ssl_libs = find_library_file(self.compiler, 'ssl',lib_dirs, ['/usr/local/ssl/lib', '/usr/contrib/ssl/lib/', '/home/sunyongfeng/workshop/prj/images/rootfs/lib64' ] ) ncurses 维基百科 ncurses（new curses）是一个程序库，它提供了API，可以允许程序员编写独立于终端的基于文本的用户界面。它是一个虚拟终端中的“类GUI”应用软件工具箱。它还优化了屏幕刷新方法，以减少使用远程shell时遇到的延迟。 readline如果 readline 模块编译失败，会导致退格键、方向键等不可用。下面错误中”^”位置是退格键。交叉编译 python 前需要先编译好 libreadline ，并将头文件和库文件放到默认可索引到的路径。 123456&gt;&gt;&gt; print "abc" File "&lt;stdin&gt;", line 1 print "abc" ^SyntaxError: invalid syntax&gt;&gt;&gt; 环境变量目前还不清楚为何 export $PATH 后，运行 python 命令找不到 python lib 库，而且找不到 site 模块。而使用绝对路径访问 python 没有问题。 1234567891011/tmp/bin # pythonCould not find platform independent libraries &lt;prefix&gt;Could not find platform dependent libraries &lt;exec_prefix&gt;Consider setting $PYTHONHOME to &lt;prefix&gt;[:&lt;exec_prefix&gt;]ImportError: No module named site/tmp/bin # /tmp/bin/pythonPython 2.7.11 (default, May 16 2016, 17:11:59) [GCC 4.3.3] on linux2Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; 通过配置环境变量解决：123export PYTHONHOME=/usr/lib/python2.7export PYTHONPATH=.:$PYTHONHOME:$PYTHONHOME/site-packagesexport PATH=$PATH:$PYTHONHOME:$PYTHONPATH 裁剪考虑 lib/libpython2.7.a, 16M lib/test, 30M 附一：Python 内建模块功能说明直接引自 定制 Python 嵌入 C++: (四) 定制 Python 内建模块，内容可能已过时，不过有参考价值。 array (Modules/arraymodule.c) (http://docs.python.org/library/array.html) 一个可以存放基本类型的高效数组, 提供了和序列类似的操作. 使用放法类似于 a = array.array(‘b’, [10, 20, 30]), 不常使用, 可以考虑去除. _ast (Python/Python-ast.c) (http://docs.python.org/library/ast.html) 抽象语法树, 供 Python 程序解析处理 Python 语法相关的库, 这个模块的源代码是由脚本自动生成的. 由于 Python-ast.c 本身还会被解释器的其它地方引用, 不能删除, 所以, 如果是为了压缩解释器大小, 保留这个库也没关系. 如果是为了定制 python 的功能, 也可以屏蔽这个库, 但是源代码需要保留, 不能从工程中删掉. audioop (Modules/audioop.c) (http://docs.python.org/library/audioop.html) 一个音频处理的库, 仅 Win32 平台有效. binascii (Modules/binascii.c) (http://docs.python.org/library/binascii.html) 提供二进制和 ASCII 码的转换, 会被 uu, base64, binhex 这些库引用. 建议保留. cmath (Modules/cmathmodule.c) (http://docs.python.org/library/cmath.html) 提供复数操作的函数 errno (Modules/errnomodule.c) (http://docs.python.org/library/errno.html) 提供标准的错误码定义, 在很多地方中都会使用, 需要保留. future_builtins (Modules/future_builtins.c) (http://docs.python.org/library/future_builtins.html) 对那些在 Python2.x 和 Python3 中都有但是意义不一样的函数提供的包装. 使用这里面的函数可以保证调用了正确的版本的函数. gc (Modules/gcmodule.c) (http://docs.python.org/library/gc.html) Python 的垃圾收集接口. 当然保留. imageop (Modules/imageop.c) (http://docs.python.org/library/imageop.html) 一些图像处理的函数. math (Modules/mathmodule.c) (http://docs.python.org/library/math.html) 提供了 C 标准库中的那些数学函数. _md5 (Modules/md5module.c) 提供了 MD5 算法. nt (Modules/posixmodule.c) 一些操作系统习惯的函数, 比如打开文件等等. operator (Modules/operator.c) (http://docs.python.org/library/operator.html) 提供了操作符的等价函数 signal (Modules/signalmodule.c) (http://docs.python.org/library/signal.html) 信号机制, 提供异步事件的回调. _sha, _sha256, _sha512 三种 SHA 的加密算法模块. strop (Modules/stropmodule.c) 提供了一些优化的字符串操作.17.time (Modules/timemodule.c) (http://docs.python.org/library/time.html) 时间操作库. thread (Modules/threadmodule.c) Python 线程的底层模块, threading 会使用 thread 库. cStringIO (Modules/cStringIO.c) (http://docs.python.org/library/stringio.html) StringIO 的高效版本. cPickle (Modules/cPickle.c) (http://docs.python.org/library/pickle.html) Python 的序列化模块. msvcrt (PC/msvcrtmodule.c) (http://docs.python.org/library/msvcrt.html) VC 运行时库的包装, 包括一些文件和屏幕操作函数. _locale (Modules/_localemodule.c) 提供本地化支持的模块. _subprocess (PC/_subprocess.c) (http://docs.python.org/library/subprocess.html) 操作子进程的库, 平台相关的. _codecs (Modules/_codecsmodule.c) (http://docs.python.org/library/codecs.html) 定义了 Python 的编码器相关接口. _weakref (Modules/_weakref.c) (http://docs.python.org/library/weakref.html) 创建对象的弱引用. _hotshot (Modules/_hotshot.c) (http://docs.python.org/library/hotshot.html) 类似于 Profiler 模块, 而且将来可能被移除, 现在把它去掉也不错. _random (Modules/_randommodule.c) 随机数模块. _bisect (Modules/_bisectmodule.c) (http://docs.python.org/library/bisect.html) 一个基于二分算法, 可以让插入一个数据岛排序的序列后序列仍然有序的库. _heapq (Modules/_heapqmodule.c) (http://docs.python.org/library/heapq.html) 实现堆栈数据结构算法的库. _lsprof (Modules/_lsprof.c) (http://docs.python.org/library/profile.html) Profiler 模块, 统计程序执行的性能. itertools (Modules/itertoolsmodule.c) (http://docs.python.org/library/itertools.html) 一些迭代器操作的模块. _collections (Modules/_collectionsmodule.c) (http://docs.python.org/library/collections.html) 提供了几个高级的容器类. _symtable (Modules/symtablemodule.c) (http://docs.python.org/library/symtable.html) 符号表管理模块. mmap (Modules/mmapmodule.c) (http://docs.python.org/library/mmap.html) 文件内存映射支持模块. _csv (Modules/_csv.c) (http://docs.python.org/library/csv.html) 为 CSV 模块的内部支持. CSV 模块提供了读写 CSV 文件的功能. _sre (Modules/_sre.c) 正则表达式的匹配引擎. parser (Modules/parsermodule.c) (http://docs.python.org/library/parser.html) 操作 Python 语法树的模块. _winreg (PC/_winreg.c) Windows 注册表操作模块. _struct (Modules/_struct.c) 提供在 Python 和 C 之间转换数据类型的功能. datetime (Modules/datetimemodule.c) (http://docs.python.org/library/datetime.html) 日期时间操作函数. _functools (Modules/_functoolsmodule.c) (http://docs.python.org/library/functools.html) 函数相关操作模块. _json (Modules/_json.c) (http://docs.python.org/library/json.html) JSON 数据格式操作模块. xxsubtype (Modules/xxsubtype.c) 这是一个测试相关的模块. 运行 test_descr.py 时会用到. zipimport (Modules/zipimport.c) 这个模块主要用于从 zip 文件中导入 Python 的模块. zlib (Modules/zlibmodule.c) 这个模块提供了 zip 压缩和解压功能, 基于 GNU zip 实现. _multibytecodec, _codecs_cn, _codecs_hk, _codecs_iso2022, _codecs_jp, _codecs_kr, _codecs_tw (Modules/cjkcodecs/*) 这些模块提供了 CJK(中日韩统一表意文字) 的编码和解码. 去掉这部分可以减小 python 解释器 600 多 K. marshal (Python/marshal.c) (http://docs.python.org/library/marshal.html) 为 Python 对象提供序列化的模块. imp (Python/import.c) (http://docs.python.org/library/imp.html) 这个模块提供了 Python 里的 import 语句的实现. main, builtin, sys, exceptions, _warnings 这部分模块在 config.c 设置里只是一个名字占位符. _io (Modules/_iomodule.c) (http://docs.python.org/library/io.html) 新版本的 Python 输入输出模块, 在 Python 3 中为默认的输入输出处理方法. 附二：Python 最佳编译依赖直接译自 Python Deployment。 键入如下命令自动安装一些依赖：1$ sudo apt-get build-dep python2.7 确认安装如下列下的其他 -dev 包。 python-dev libncurses5-dev libsqlite3-dev libbz2-dev libreadline-dev libdb4.8-dev tcl8.5-dev,tk8.5-dev 下面这个包在 ubuntu 早期版本（如 10.04）并没有自动安装，需确认一下。 libssl-dev libexpat1-dev libreadline6-dev libgtk2.0-dev 如果想支持 xml 相关： libxml2-dev libxslt1-dev 如果想支持 MySQLdb （在 pypi 中实际命令为 MySQL-python）： libmysqlclient-dev 最终的 make 结果（编译结果）如能如下： 1234Python build finished, but the necessary bits to build these modules were not found:_tkinter bsddb185 dlgdbm imageop sunaudiodevTo find the necessary bits, look in setup.py in detect_modules() for the module's name. 这个编译 log 提示哪些模块没有被编译到，注意其中有一些并不是必需的或过时的： bsddb185: Older version of Oracle Berkeley DB. Undocumented. Install version 4.8 instead. dl: For 32-bit machines. Deprecated. Use ctypes instead. imageop: For 32-bit machines. Deprecated. Use PIL instead. sunaudiodev: For Sun hardware. Deprecated. _tkinter: For tkinter graphy library, unnecessary if you don’t develop tkinter programs. 参考文献 定制 Python 嵌入 C++: (四) 定制 Python 内建模块 build python 2.7.11 for mips Python Deployment How to cross compile python for MIPS python-2.7-001-support-for-build.patch]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
        <tag>python</tag>
        <tag>交叉编译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于研究]]></title>
    <url>%2F201605%2Flife%2Ftalk_about_research.html</url>
    <content type="text"><![CDATA[关于研究领导谈招人的期待： 本科生，能按 list 逐步执行清单； 研究生，给一个目标，可以自行完成； 博士生，自已选一个题（一个方向），我给资源；]]></content>
      <categories>
        <category>思考</category>
      </categories>
      <tags>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 命令集]]></title>
    <url>%2F201605%2Fprogrammer%2Fredis%2Fcmd.html</url>
    <content type="text"><![CDATA[查看所有 key：KEYS * 查看数据库大小：DBSIZE 查看数据库基本信息：INFO 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111redis /tmp/redis.sock&gt; info# Serverredis_version:3.2.1redis_git_sha1:ce18ff58redis_git_dirty:0redis_build_id:2de158ec05fb50c4redis_mode:standaloneos:Linux 2.6.32.13-Cavium-Octeon mips64arch_bits:64multiplexing_api:epollgcc_version:4.3.3process_id:2877run_id:91d28ac8ed2ab0f4ceb592d472a79ffcb10a1049tcp_port:16904192uptime_in_seconds:17846uptime_in_days:0hz:10lru_clock:11220343executable:/redis-serverconfig_file:/etc/redis/redis_ce_global.conf# Clientsconnected_clients:25client_longest_output_list:0client_biggest_input_buf:0blocked_clients:0# Memoryused_memory:2230112used_memory_human:2.13Mused_memory_rss:3670016used_memory_rss_human:3.50Mused_memory_peak:2296768used_memory_peak_human:2.19Mtotal_system_memory:4111892480total_system_memory_human:3.83Gused_memory_lua:37888used_memory_lua_human:37.00Kmaxmemory:0maxmemory_human:0Bmaxmemory_policy:noevictionmem_fragmentation_ratio:1.65mem_allocator:libc# Persistenceloading:0rdb_changes_since_last_save:0rdb_bgsave_in_progress:0rdb_last_save_time:1470820590rdb_last_bgsave_status:okrdb_last_bgsave_time_sec:0rdb_current_bgsave_time_sec:-1aof_enabled:1aof_rewrite_in_progress:0aof_rewrite_scheduled:0aof_last_rewrite_time_sec:-1aof_current_rewrite_time_sec:-1aof_last_bgrewrite_status:okaof_last_write_status:okaof_current_size:623151aof_base_size:0aof_pending_rewrite:0aof_buffer_length:0aof_rewrite_buffer_length:0aof_pending_bio_fsync:0aof_delayed_fsync:0aof_file_cmd_num:3936aof_buf_cmd_num:0aof_is_shadowfile:0# Statstotal_connections_received:25total_commands_processed:4483instantaneous_ops_per_sec:0total_net_input_bytes:655148total_net_output_bytes:6071473instantaneous_input_kbps:0.00instantaneous_output_kbps:0.00rejected_connections:0sync_full:0sync_partial_ok:0sync_partial_err:0expired_keys:0evicted_keys:0keyspace_hits:528keyspace_misses:2pubsub_channels:0pubsub_patterns:11latest_fork_usec:494migrate_cached_sockets:0# Replicationrole:masterconnected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0# CPUused_cpu_sys:0.73used_cpu_user:0.61used_cpu_sys_children:0.01used_cpu_user_children:0.05# Clustercluster_enabled:0# Keyspacedb0:keys=3073,expires=0,avg_ttl=0 MONITOR，监控数据库使用情况，CTRL C 退出。 123456789[0809-09:49:06:833] ~ # redis-cli -s /tmp/redis/redis_de_global.sock [0809-09:49:08:744] redis /tmp/redis/redis_de_global.sock&gt; MONITOR[0809-09:49:08:753] OK[0809-09:49:10:853] [0809-09:49:14:849] 1470735840.255050 [0 unix:/tmp/redis/redis_de_global.sock] "HMSET" "/SS/NHOP/TBL/7623" "INTFID" "1" "VLAN" "100" "MAC" "0000.0000.0003" "PHYID" "07001b0b" "ACTION" "2" "FLOWID" "0" "FLAG" "00000000" "CTRL_FLAG" "00000000" "ENCAPID" "0"[0809-09:49:14:870] 1470735840.256824 [0 unix:/tmp/redis/redis_de_global.sock] "HMSET" "/SS/UC/RT/TBL/0/0/2.2.2.3/32/0" "VID" "0" "URPF" "0" "ACTION" "2" "NH_TYPE" "0" "NH_SIZE" "1" "ECMPGRP_ID" "0" "NHBASE_ID" "7623" "ENCAP_ID" "0" "CLASSID" "0" "INTFID" "0" "PHYID" "00000000" "MAC" "0001.0203.0405"[0809-09:49:14:894] 1470735840.261173 [0 unix:/tmp/redis/redis_de_global.sock] "HMSET" "/SS/NHOP/TBL/7624" "INTFID" "1" "VLAN" "100" "MAC" "0000.0000.0004" "PHYID" "07001b0b" "ACTION" "2" "FLOWID" "0" "FLAG" "00000000" "CTRL_FLAG" "00000000" "ENCAPID" "0"[0809-09:53:05:655] 1470735856.464859 [0 unix:/tmp/redis/redis_de_global.sock] "HMSET" "/SS/NHOP/TBL/12699" "INTFID" "1" "VLAN" "100" "MAC" "0000.0000.13d7" "PHYID" "07001b0b" "ACTION" "2" "FLOWID" "0" "FLAG" ""/SS/NHOP/TBL/12700" "INTFID" "1" "VLAN" "100" "MAC" "0000.0000.13d8" "PHYID" "07001b0b" "ACTION" "2" "FLOWID" "0" "FLAG" "00000000" "CTRL_FL[0809-09:54:52:443] ~ #]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux C 语言时间相关处理]]></title>
    <url>%2F201604%2Fprogrammer%2Fc%2Ftime.html</url>
    <content type="text"><![CDATA[time gettimeofday jeffies clock_gettime，多种类型 定时器 信号 条件锁 time()以下是 man 2 time： 12345678910111213141516171819202122SYNOPSIS #include &lt;time.h&gt; time_t time(time_t *t);DESCRIPTION time() returns the time as the number of seconds since the Epoch, 1970-01-01 00:00:00 +0000 (UTC). If t is non-NULL, the return value is also stored in the memory pointed to by t.RETURN VALUE On success, the value of time in seconds since the Epoch is returned. On error, ((time_t) -1) is returned, and errno is set appropriately.ERRORS EFAULT t points outside your accessible address space.CONFORMING TO SVr4, 4.3BSD, C89, C99, POSIX.1-2001. POSIX does not specify any error conditions.]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C 语言字符串与整型相互转换]]></title>
    <url>%2F201604%2Fprogrammer%2Fc%2Fstring_int_convert.html</url>
    <content type="text"><![CDATA[string to int可参考 stackoverflow 回答。 atoi / atol strtol，可用于多种进制转换 sscanf int to string itoa sprintf / snprintf MAC to string本节来自 stackoverflow： On a C99-conformant implementation, this should work 123unsigned char mac[6];sscanf(macStr, "%hhx:%hhx:%hhx:%hhx:%hhx:%hhx", &amp;mac[0], &amp;mac[1], &amp;mac[2], &amp;mac[3], &amp;mac[4], &amp;mac[5]); Otherwise, you’ll need: 1234567unsigned int iMac[6];unsigned char mac[6];int i;sscanf(macStr, "%x:%x:%x:%x:%x:%x", &amp;iMac[0], &amp;iMac[1], &amp;iMac[2], &amp;iMac[3], &amp;iMac[4], &amp;iMac[5]);for(i=0;i&lt;6;i++) mac[i] = (unsigned char)iMac[i];]]></content>
      <categories>
        <category>c</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thinkpad E420 无法上电]]></title>
    <url>%2F201604%2Fmisc%2Fthinkpad_e420_cannot_power_on.html</url>
    <content type="text"><![CDATA[2016.04.16 问题Thinkpad E420 （2012 年 3 月购，已使用 4 年，无任何异常）在前一天还正常使用的情况下，今天突然无法上电。表现为按电源键无法开机，插电源线电源指示灯不亮。 解决来自百度知道的答案： 尊敬的联想用户您好！ 您好，您的机器的情况您可以试下复位操作，请您将电源、电池以及其他外接设备从电脑上拔掉(确保完全断电)；然后按住开机键大约十几秒的时间；松开几秒，之后按十几秒，最后将电源、电池接到机器上，然后开机。无效的话可能是机器的硬件故障的，建议您将机器送到服务站进行检测服务站地址查询。 您也可以通过如下链接获取更多ThinPad资料: http://think.lenovo.com.cn/support/knowledge/knowledgehome.aspx?intcmp=thinkbd 期待您满意的评价，感谢您对联想的支持，祝您生活愉快！ 后记搜索一番，发现 Thinkpad E420 的问题很普遍，主要包括像本文的无法上电或主板烧坏等。]]></content>
      <categories>
        <category>misc</category>
      </categories>
      <tags>
        <tag>misc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[makefile 学习记录]]></title>
    <url>%2F201604%2Fprogrammer%2Ftools%2Fmakefile.html</url>
    <content type="text"><![CDATA[特殊规则或变量.DEFAULT_GOAL默认目标，即执行不带参数的 make 命令，例如 .DEFAULT_GOAL := all。只能配置一条规则，否则报错。 .INTERMEDIATE.ONESHELLMakefile 样例: 12345678910.ONESHELL:test: @if [ ! -d abc ]; then @ mkdir abc @ echo "abc not found" @else @ echo "abc found" @fi 运行结果: 12345jeromesun@km:~/workshop/hello$ rmdir abcjeromesun@km:~/workshop/hello$ make testabc not foundjeromesun@km:~/workshop/hello$ make test abc found 删除 .ONESHELL，运行结果: 1234jeromesun@km:~/workshop/hello$ make test /bin/sh: 1: Syntax error: end of file unexpectedMakefile:10: recipe for target 'test' failedmake: *** [test] Error 2 .SECONDEXPANSION函数自定义和使用函数Makefile 样例如下，函数内的代码行不需要以 tab 开始。不以 @开头，在调用时也不会打印出 shell 语句。通过 define 和 endef 围起来。 1234567891011121314.ONESHELL:define func_test @echo "func_test parameters: 0:$0, 1:$1, 2:$2" @if [ ! -d abc ]; then @ mkdir abc @ echo "abc not found" @else @ echo "abc found" @fiendeftest: @$(call func_test, one, two) 运行结果: 1234567jeromesun@km:~/workshop/hello$ rmdir abc jeromesun@km:~/workshop/hello$ make test func_test parameters: 0:func_test, 1: one, 2: twoabc not foundjeromesun@km:~/workshop/hello$ make test func_test parameters: 0:func_test, 1: one, 2: twoabc found 使用 eval 在 makefile 规则中赋值123$(eval IMAGE_TIME_STAMP=$(shell date +%Y%m%d%H%M%S))$(eval IMAGE_NAME_SIMPLE=$@)$(eval IMAGE_NAME=$(shell echo $(IMAGE_NAME_SIMPLE) | sed 's/.bin/.$(IMAGE_TIME_STAMP).bin/g')) foreach 遍历call 调用函数注意: Call 调用函数时，注意参数和逗号间不要有空格，否则参数分有带空格和没带空格之分 和 foreach 一起使用的时候，注意 call 的自定义函数最后一行要加 ; call 参数没空格样例: 1234567891011121314151617181920212223jeromesun@km:~/workshop/hello.test$ cat mkfiles/func_test.mk .ONESHELL:define func_test echo "func_test parameters: 0:$0, 1:$1, 2:$2" if [ ! -d abc ]; then mkdir abc echo "abc not found" else echo "abc found" fiendefjeromesun@km:~/workshop/hello.test$ cat Makefile .ONESHELL:-include mkfiles/*.mktest: @$(call func_test,one,two)jeromesun@km:~/workshop/hello.test$ make test func_test parameters: 0:func_test, 1:one, 2:twoabc found call 参数有空格样例: 12345678910jeromesun@km:~/workshop/hello.test$ cat Makefile .ONESHELL:-include mkfiles/*.mktest: @$(call func_test, one, two)jeromesun@km:~/workshop/hello.test$ make func_test parameters: 0:func_test, 1: one, 2: twoabc found miscellaneous判断 32 位还是 64 位来自 stackoverflow 的答案: 123456ARCH := $(shell getconf LONG_BIT)CPP_FLAGS_32 := -D32_BIT ... Some 32 specific compiler flags ...CPP_FLAGS_64 := -D64_BITCPP_FLAGS := $(CPP_FLAGS_$(ARCH)) ... all the other flags ... 清除某个 CFLAGS 编译选项来自 stackoverflow 的答案： 1CFLAGS := $(filter-out -Werror,$(CFLAGS)) 在规则中等待输入123456789101112reset : @echo &amp;&amp; echo -n "Warning! All local changes will be lost. Proceed? [y/N]: " @read ans &amp;&amp; \ if [ $$ans == y ]; then \ git clean -xfdf; \ git reset --hard; \ git submodule foreach --recursive git clean -xfdf; \ git submodule foreach --recursive git reset --hard; \ git submodule update --init --recursive;\ else \ echo "Reset aborted"; \ fi 【已淘汰】在规则中使用 shell 函数这种写法很挫，不够优雅。用 .ONESHELL + 自定义 Makefile 函数替换。 1234567891011121314151617181920212223242526272829303132# $(1) path# $(2) fetch cmd# $(3) fetch url# $(4) fetch branch# $(5) fetch commit idfetch_source = \ echo "Download Source 'path $1' 'cmd $2' 'url $3' 'branch $4' 'commit id $5'"; \ if [ ! -d $(SOURCE_REAL)/$1 ]; then \ mkdir -p $(SOURCE_REAL)/$1; \ if [ "$2"i == "git"i ]; then \ if [ -n "$4" ]; then \ git clone -b $4 $3 $(SOURCE_REAL)/$1; \ else \ git clone $3 $(SOURCE_REAL)/$1; \ fi; \ pushd $(SOURCE_REAL)/$1 ; git checkout $5 ; git submodule update --init --recursive; popd; \ elif [ "$2"i == "svn"i ]; then \ svn chekcout $3 -r $5 $1; \ elif [ "$2"i == "wget"i ]; then \ wget $3 `basename $3` -P $(SOURCE_REAL)/$1; \ pushd $(SOURCE_REAL)/$1; tar xvf `basename $3`; popd; \ fi; \ if [[ $1 =~ "platform/" ]]; then \ ln -sf ../../$(SOURCE_REAL)/$1 $1; \ else \ ln -sf ../$(SOURCE_REAL)/$1 $1; \ fi; \ fi;download : $(foreach target,$(SONIC_DOWNLOAD_SOURCE),$(call fetch_source,$($(target)_SRC_PATH),$($(target)_FETCH_CMD),$($(target)_FETCH_URL),$($(target)_FETCH_BRANCH),$($(target)_FETCH_COMMITID))) 执行 shell 命令例如 PWD := $(shell pwd)]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>makefile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Excel 使用记录]]></title>
    <url>%2F201604%2Ftools%2Fexcel.html</url>
    <content type="text"><![CDATA[数据透视图/表“插入” -&gt; “数据透视图/表”，功能很强大，可对选定内容进行智能统计、求和、求方差等，免下以下“统计单元格数目”一节的烦杂。 如何快速自动统计数据 选择选区 插入选项卡，选择 数据透视表 或 推荐的数据透视表 选择右上角 数据透视表字段 中要添加到报表的字段，并拖动要统计的字段到右下角的“值” 如何快速统计以’;’号间隔的文本和自出现的次数 先分列，数据选项卡，按分号 分列 选择新的区域，通过 countif 计算，或者操作到同一列上，然后删除空白行，再通过数据透视表 统计。 统计单元格数目 统计列满足条件的单元格个数，COUNTIF 函数 统计列满足多条件的单元格个数，COUNTIFS 函数 样例： 统计 “total” 标签所有 H 列，值等于 A12 的单元格个数 1COUNTIF(total!H:H,A12)， 统计 “total” 标签所有 H 列，值为 “abc” 的单元格个数 1COUNTIF(total!H:H,"abc") 统计 “total” 标签所有 H 列，非空单元格个数 1COUNTIF(total!H:H,"&lt;&gt;") 统计 “total” 标签所有 H 列，空单元格个数 1COUNTIF(total!H:H,"") 统计 “total” 标签所有 A 列值为 *2015 （此处 * 为通配符）且 “total” 标签 I 列值为空的单元格个数 1COUNTIFS(total!A:A,"*2015",total!I:I,"") 删除重复数据数据 选项卡 -&gt; 数据工具 选项组中的 删除重复项，按提示操作。 删除空白单元格 选择选区 开始 选项卡，查找和选择 中间的三角形，下拉点击 定位条件 在弹出的窗口中选择 空值 右击被选择的单元格，按行或列删除 按日期算周数类似 =CEILING((&quot;2011-3-14&quot;-&quot;2011-2-10&quot;)/7,1)，可以把日期改成按日期格式填写内容的单元格 饼图数字百分比到小数点后面右击饼图中的数字，选择设置数据标签格式，选择第二个大类 数据 -&gt; 类别 -&gt; 百分比，小数点位数 为你所需要的。 如何删除文本前的空白字符trim(A1)]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openswitch 编译记录]]></title>
    <url>%2F201603%2Fnetworks%2Fopenswitch-build.html</url>
    <content type="text"><![CDATA[From link。OVS is feature rich with different configuration commands, but the majority of your configuration and troubleshooting can be accomplished with the following 4 commands: ovs-vsctl : Used for configuring the ovs-vswitchd configuration database (known as ovs-db) ovs-ofctl : A command line tool for monitoring and administering OpenFlow switches ovs-dpctl : Used to administer Open vSwitch datapaths ovs−appctl : Used for querying and controlling Open vSwitch daemons 编译步骤 安装依赖软件包，在 Ubuntu 14.04 上的依赖软件包有： screen chrpath device_tree_compiler gawk makeinfo，软件包名字是 texinfo 1sudo apt-get install screen chrpath device_tree_compiler gawk texinfo 下载 ops-build 12git clone https://git.openswitch.net/openswitch/ops-build [&lt;directory&gt;]cd &lt;directory&gt; 配置 openswitch 产品 1make configure genericx86-64 编译产品注意需要编译较长时间。 1make 部署产品XXX: todo]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>NOS</tag>
        <tag>openswitch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pktgen]]></title>
    <url>%2F201603%2Fnetworks%2Fpktgen.html</url>
    <content type="text"><![CDATA[什么是 pktgenpktgen 是一款 Linux 发包工具，可在内核高速发包。 Linux packet generator is a tool to generate packets at very high speed in the kernel. 使能 pktgen内核配置文件开启 CONFIG_NET_PKTGEN，通过查看是否有 /proc/net/pktgen/ 目录确认是否编译 OK。 使用 pktgen 发包 添加设备 1echo "add_device eth3" &gt; /proc/net/pktgen/kpktgend_0 配置报文配置方法，样例仅给出部分配置123echo "pkt_size 64" &gt; /proc/net/pktgen/eth3echo "count 1000000" &gt; /proc/net/pktgen/eth3echo "dst_mac aa:bb:cc:dd:ee:ff" &gt; /proc/net/pktgen/eth3 查看配置结果：1cat /proc/net/pktgen/eth3 发送报文 1echo "start" &gt; /proc/net/pktgen/pgctrl 查看发送结果：1cat /proc/net/pktgen/eth3 发包样例12345678910111213141516171819202122232425[1209-20:29:14:517] root@ubuntu:/proc/net/pktgen# echo "pkt_size 1500" &gt; /proc/net/pktgen/eth3 [1209-20:29:26:980] root@ubuntu:/proc/net/pktgen# echo "count 1000000" &gt; /proc/net/pktgen/eth3 [1209-20:29:29:862] root@ubuntu:/proc/net/pktgen# echo "start" &gt; /proc/net/pktgen/pgctrl [1209-20:29:48:407] root@ubuntu:/proc/net/pktgen# cat /proc/net/pktgen/eth3 [1209-20:29:48:430] Params: count 1000000 min_pkt_size: 1500 max_pkt_size: 1500[1209-20:29:48:435] frags: 0 delay: 0 clone_skb: 0 ifname: eth3[1209-20:29:48:437] flows: 0 flowlen: 0[1209-20:29:48:441] queue_map_min: 0 queue_map_max: 0[1209-20:29:48:444] dst_min: dst_max: [1209-20:29:48:447] src_min: src_max: [1209-20:29:48:452] src_mac: 02:10:18:2c:f8:0e dst_mac: 00:00:00:00:00:00[1209-20:29:48:458] udp_src_min: 9 udp_src_max: 9 udp_dst_min: 9 udp_dst_max: 9[1209-20:29:48:460] src_mac_count: 0 dst_mac_count: 0[1209-20:29:48:464] Flags: [1209-20:29:48:464] Current:[1209-20:29:48:467] pkts-sofar: 1000000 errors: 0[1209-20:29:48:472] started: 3219370012us stopped: 3233111900us idle: 299798us[1209-20:29:48:477] seq_num: 1000001 cur_dst_mac_offset: 0 cur_src_mac_offset: 0[1209-20:29:48:481] cur_saddr: 192.168.2.1 cur_daddr: 0.0.0.0[1209-20:29:48:486] cur_udp_dst: 9 cur_udp_src: 9[1209-20:29:48:490] cur_queue_map: 0[1209-20:29:48:491] flows: 0[1209-20:29:48:496] Result: OK: 13741888(c13442090+d299798) usec, 1000000 (1500byte,0frags)[1209-20:29:48:499] 72770pps 873Mb/sec (873240000bps) errors: 0[1209-20:30:05:839] root@ubuntu:/proc/net/pktgen# 完整说明 From linuxfoundation.org pktgen： SetupEnable CONFIG_NET_PKTGEN to compile and build pktgen.o either in kernel or as module. Module is preferred. insmod pktgen if needed. Once running pktgen creates a thread on each CPU where each thread has affinty it’s CPU. Monitoring and controlling is done via /proc. Easiest to select a suitable a sample script and configure. On a dual CPU: 123ps aux | grep pktroot 129 0.3 0.0 0 0 ? SW 2003 523:20 [pktgen/0]root 130 0.3 0.0 0 0 ? SW 2003 509:50 [pktgen/1] For montoring and control pktgen creates: /proc/net/pktgen/pgctrl /proc/net/pktgen/kpktgend_X12345# cat /proc/net/pktgen/kpktgend_0 Name: kpktgend_0 max_before_softirq: 10000Running: Stopped: eth1 Result: OK: max_before_softirq=10000 Most important the devices assigned to thread. Note! A device can only belong to one thread.*/proc/net/pktgen/ethXParam section holds configured info. Current hold running stats. Result is printed after run or after interruption. Example:12345678910111213141516171819# cat /proc/net/pktgen/eth1Params: count 10000000 min_pkt_size: 60 max_pkt_size: 60 frags: 0 delay: 0 clone_skb: 1000000 ifname: eth1 flows: 0 flowlen: 0 dst_min: 10.10.11.2 dst_max: src_min: src_max: src_mac: 00:00:00:00:00:00 dst_mac: 00:04:23:AC:FD:82 udp_src_min: 9 udp_src_max: 9 udp_dst_min: 9 udp_dst_max: 9 src_mac_count: 0 dst_mac_count: 0 Flags: Current: pkts-sofar: 10000000 errors: 39664 started: 1103053986245187us stopped: 1103053999346329us idle: 880401us seq_num: 10000011 cur_dst_mac_offset: 0 cur_src_mac_offset: 0 cur_saddr: 0x10a0a0a cur_daddr: 0x20b0a0a cur_udp_dst: 9 cur_udp_src: 9 flows: 0Result: OK: 13101142(c12220741+d880401) usec, 10000000 (60byte,0frags) 763292pps 390Mb/sec (390805504bps) errors: 39664 ConfguringThis is done via the /proc interface easiest done via pgset in the scripts Examples:1234567891011121314151617181920212223242526272829303132pgset "clone_skb 1" sets the number of copies of the same packetpgset "clone_skb 0" use single SKB for all transmitspgset "pkt_size 9014" sets packet size to 9014pgset "frags 5" packet will consist of 5 fragmentspgset "count 200000" sets number of packets to send, set to zero for continious sends untill explicitl stopped.pgset "delay 5000" adds delay to hard_start_xmit(). nanosecondspgset "dst 10.0.0.1" sets IP destination addres (BEWARE! This generator is very aggressive!)pgset "dst_min 10.0.0.1" Same as dstpgset "dst_max 10.0.0.254" Set the maximum destination IP.pgset "src_min 10.0.0.1" Set the minimum (or only) source IP.pgset "src_max 10.0.0.254" Set the maximum source IP.pgset "dst6 fec0::1" IPV6 destination addresspgset "src6 fec0::2" IPV6 source addresspgset "dstmac 00:00:00:00:00:00" sets MAC destination addresspgset "srcmac 00:00:00:00:00:00" sets MAC source addresspgset "src_mac_count 1" Sets the number of MACs we'll range through. The 'minimum' MAC is what you set with srcmac.pgset "dst_mac_count 1" Sets the number of MACs we'll range through. The 'minimum' MAC is what you set with dstmac.pgset "flag [name]" Set a flag to determine behaviour. Current flags are: IPSRC_RND #IP Source is random (between min/max), IPDST_RND, UDPSRC_RND, UDPDST_RND, MACSRC_RND, MACDST_RND pgset "udp_src_min 9" set UDP source port min, If &lt; udp_src_max, then cycle through the port range. pgset "udp_src_max 9" set UDP source port max. pgset "udp_dst_min 9" set UDP destination port min, If &lt; udp_dst_max, then cycle through the port range. pgset "udp_dst_max 9" set UDP destination port max. pgset stop aborts injection. Also, ^C aborts generator. ExamplesA collection of small tutorial scripts for pktgen is in expamples dir. pktgen.conf-1-1 # 1 CPU 1 dev pktgen.conf-1-2 # 1 CPU 2 dev pktgen.conf-2-1 # 2 CPU’s 1 dev pktgen.conf-2-2 # 2 CPU’s 2 dev pktgen.conf-1-1-rdos # 1 CPU 1 dev w. route DoS pktgen.conf-1-1-ip6 # 1 CPU 1 dev ipv6 pktgen.conf-1-1-ip6-rdos # 1 CPU 1 dev ipv6 w. route DoS pktgen.conf-1-1-flows # 1 CPU 1 dev multiple flows.Run in shell: ./pktgen.conf-X-Y It does all the setup including sending. Interrupt affinityNote when adding devices to a specific CPU there good idea to also assign /proc/irq/XX/smp_affinity so the TX-interrupts gets bound to the same CPU. as this reduces cache bouncing when freeing skb’s. CommandsPgcontrol commands: start stopThread commands: add_device rem_device_all max_before_softirqDevice commands: count clone_skb debug frags delay src_mac_count dst_mac_count pkt_size min_pkt_size max_pkt_size udp_src_min udp_src_max udp_dst_min udp_dst_max flag IPSRC_RND TXSIZE_RND IPDST_RND UDPSRC_RND UDPDST_RND MACSRC_RND MACDST_RND dst_min dst_max src_min src_max dst_mac src_mac clear_counters dst6 src6 flows flowlen]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>网络测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 搭站备忘]]></title>
    <url>%2F201603%2Ftools%2Fhexo.html</url>
    <content type="text"><![CDATA[安装 hexo 安装 git 安装 nodejs，debian / ubuntu 类的环境：sudo apt-get install npm nodejs-legacy如果安装的是 node 包，则安装 hexo 时可能出现下文的 error 。 12345678910npm http GET https://registry.npm.taobao.org/inherits&gt; spawn-sync@1.0.15 postinstall /usr/local/lib/node_modules/hexo-cli/node_modules/hexo-util/node_modules/cross-spawn/node_modules/spawn-sync&gt; node postinstallnpm WARN This failure might be due to the use of legacy binary "node"npm WARN For further explanations, please read/usr/share/doc/nodejs/README.Debiannpm ERR! weird error 1 安装 hexo，sudo npm install -g hexo-cli，如果想用淘宝的源：npm install -g hexo-cli --registry=https://registry.npm.taobao.org。实测官方源没有问题。 配置 npm 的默认源为淘宝源：npm config set registry https://registry.npm.taobao.org/ 安装插件 RSS: npm install hexo-generator-feed sitmap: npm install hexo-generator-sitemap deploy-git: npm install hexo-deployer-git --save，hexo 3.0 后必须。 next 主题next 主题 tags 页和 categories 页的设置与其他主题的不一样，会导致 tags 页和 categories 页没有内容。 以 tags 页为例： 123456---title: tagslayout: tags &lt;-- 这个是之前的设置方式，不知道是不是 hexo 版本变化发生变化了。type: "tags" &lt;-- 这个是当前 next 主题的配置方式。date: 2016-03-18 00:32:32---]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VIM 使用记录]]></title>
    <url>%2F201603%2Fprogrammer%2Ftools%2Fvim.html</url>
    <content type="text"><![CDATA[替换选区内的字符串v 选中区域后键入 :，会自动选中选区 :&#39;&lt;,&#39;&gt;，之后像在全局操作那样 %s/str/substr/g，替换“str”为“substr”。 替换 windows 的回车换行单文件替换 基于 DOS/Windows 的文本文件在每一行末尾有一个 CR（回车）和 LF（换行），而 UNIX 文本只有一个换行,即win每行结尾为\r\n，而linux只有一个\n如果win下的文档上传到linux，每行的结尾都会出现一个^M，(^M是ctrl+v,ctrl+m)如果是单个文档的话，可以用vi打开，执行 :%s/^M//g 来去掉^M, 作者：小幕链接：https://www.zhihu.com/question/22130727/answer/33814375来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 批量文件替换 方法 1: 用 dos2unix 工具把win文档转换成linux下文档find ./ -type f -print0 | xargs -0 dos2unix 如果想把linux下的文档转换成win下的:find ./ -type f -print0 | xargs -0 unix2dos 方法2: 用 sed 命令把win文档转换成linux下文档:find ./ -type f print0 | xargs -0 sed -i &#39;s/^M$//&#39; 把linux下的文档转换成win下的fild ./ -type f print0 | xargs -0 sed -i &#39;s/$/^M/&#39; 作者：小幕链接：https://www.zhihu.com/question/22130727/answer/33814375来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 行列太小，看文字很累12:set columns=200:set lines=45 统计匹配次数这里最后带 n 表示统计，不是真正替换。 1:%s/xxx//gn 统计报告样例： 12 NORMAL  /home/jeromesun/.vimrc  vim  utf-8[unix]  0% ☰ 1/488  : 1  ☲ [6]trailing [458]mixed-indent [371:13]mix-indent-file 76 matches on 76 lines]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用软件备忘]]></title>
    <url>%2F201603%2Ftools%2Fapp.html</url>
    <content type="text"><![CDATA[常用软件Android KingRoot，预装卸载 Windows virgo，虚拟桌面工具 ALT + 1..4 -&gt; 切换 1 .. 4 个桌面 CTRL + 1..4 -&gt; 发送当前窗口到 1 .. 4 某个桌面 ALT + CTRL + SHIFT + Q -&gt; 退出程序 total commander 文件查找 Launchy everything Listray，类似 Launchy，但是感觉比 Launchy 好用 录屏 apowersoft Open Boradcaster Software ScreenToGif 开机自启动 打开文件夹 “开始” -&gt; “所有程序” -&gt; “启动” 创建快捷方式到待自启动的程序到 “启动” 文件夹 重启，即可生效。 terminal 终端类工具 windows 平台 ConEmu，轻量级，超好用！ putty Mobaxterm linux 平台 guake tmux powerline-shell，装逼利器 跨平台 secureCRT, 商用 web diigo，网页标注或网页上的 pdf 标注 stackedit.io，Markdown 编辑器 web 版始祖 draw.io，画图工具 编程PlantUML官网，编程画 UML 图，sublime、atom、eclipse 等都有提供插件。 远程桌面 teamviewer vncviewer / vnc4server]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>app</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shadowsocks 记录]]></title>
    <url>%2F201602%2Ftools%2Fshadowsocks.html</url>
    <content type="text"><![CDATA[shadowsocks in linux install, pip install shadowsocks start shadowsocks, sslocal -d start -p server_port -k your_password -s server_url(or server_ip) -m aes-256-cfb -l local_port proxychains install, sudo apt-get install proxychains configure, sudo vi /etc/proxychains.conf, add line socks5 127.0.0.1 1080 to tail use proxy for app, sudo proxychains your_app chromium 无法使用 proxychains，有个 issue。 switchyOmega可在 Profiles 下的 auto switch 以 rule list 的形式加入自动切换的列表，在 Rule List Config 下填入 rule list 的链接即可。这是一个 gfwlist。 socks5 转 http 代理详见 http://xuhehuan.com/2119.html。 使用 polipo，用 apt-get 可安装，配置如下：123456789101112131415161718# This file only needs to list configuration variables that deviate# from the default values. See /usr/share/doc/polipo/examples/config.sample# and "polipo -v" for variables you can tweak and further information.logSyslog = falselogFile = "/var/log/polipo/polipo.log"socksParentProxy = "127.0.0.1:1080"socksProxyType = socks5chunkHighMark = 50331648objectHighMark = 16384serverMaxSlots = 64serverSlots = 16serverSlots1 = 32proxyAddress = "0.0.0.0"proxyPort = 8123 重启 polipo，sudo service polipo restart 验证 sock5 转 http 是否 ok： 12export http_proxy="http://127.0.0.1:8123/"curl www.google.com ok 的话返回网页抓取结果：123456789101112131415161718192021222324252627~$ curl www.google.com.hk &lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Proxy error: 502 Read from server failed: Connection reset by peer.&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;502 Read from server failed: Connection reset by peer&lt;/h1&gt;&lt;p&gt;The following error occurred while trying to access &lt;strong&gt;http://www.google.com.hk/&lt;/strong&gt;:&lt;br&gt;&lt;br&gt;&lt;strong&gt;502 Read from server failed: Connection reset by peer&lt;/strong&gt;&lt;/p&gt;&lt;hr&gt;Generated Tue, 08 Nov 2016 15:53:18 CST by Polipo on &lt;em&gt;openswitch-OptiPlex-380:10080&lt;/em&gt;.&lt;/body&gt;&lt;/html&gt;sunyongfeng@openswitch-OptiPlex-380:~$ sunyongfeng@openswitch-OptiPlex-380:~$ curl www.google.com.hk&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Proxy error: 502 Read from server failed: Connection reset by peer.&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;502 Read from server failed: Connection reset by peer&lt;/h1&gt;&lt;p&gt;The following error occurred while trying to access &lt;strong&gt;http://www.google.com.hk/&lt;/strong&gt;:&lt;br&gt;&lt;br&gt;&lt;strong&gt;502 Read from server failed: Connection reset by peer&lt;/strong&gt;&lt;/p&gt;&lt;hr&gt;Generated Tue, 08 Nov 2016 15:55:03 CST by Polipo on &lt;em&gt;openswitch-OptiPlex-380:10080&lt;/em&gt;.&lt;/body&gt;&lt;/html&gt;sunyongfeng@openswitch-OptiPlex-380:~$ curl www.google.com.hk&lt;!doctype html&gt;&lt;html itemscope="" itemtype="http://schema.org/WebPage" lang="zh-HK"&gt;&lt;head&gt;&lt;meta content="text/html; charset=UTF-8" http-equiv="Content-Type"&gt;&lt;meta content="/images/branding/googleg/1x/googleg_standard_color_128dp.png" itemprop="image"&gt;&lt;title&gt;Google&lt;/title&gt;&lt;script&gt;(function()&#123;window.google=&#123;kEI:'PoUhWJLcI4nW0gLCrrCoCQ',kEXPI:'750722,1351828,1351903,1352148,3700062,3700245,4026241,4028875,4029815,4031109,4032677,4036527,4038012,4039268,4043491,4045841,4048347,4065786,4067860,4068550,4069839,4069841,4071842,4072289,4072364,4072602,4072705,4072775,4073405,4073415,4073486,4073498,4073959,4074684,4076095,4076542,4076931,4076999,4078241,4078407,4078430,4078438,4078454,4078456,4078607,4079105,4079553,4079624,4079870,4080115,4080161,4080165,4080815,4081037,4081038,4081128,4081263,4081278,4081497,4082112,4082219,4082290,4082310,4082441,4082618,4082638,4082778,4083064,4083115,4083281,4083353,4084066,4084258,4084259,4084277,4084325,4084343,4084366,4084402,4084676,4084691,4084956,4085014,4085057,4085066,4085181,4085628,4085917,8300272,8502184,8503585,8504846,8504935,8505150,8505152,8505259,8506255,8506340,8506477,8506615,8507098,8507361,8507381,8507842,8507846,8508176,8508241,8508317,10200083',authuser:0,kscs:'c9c918f0_24'&#125;;google.kHL='zh-HK';&#125;)();(function()&#123;google.lc=[];google.li=0;google.getEI=function(a)&#123;for(var b;a&amp;&amp;(!a.getAttribute||!(b=a.getAttribute("eid")));)a=a.parentNode;return b||google.kEI&#125;;google.getLEI=function(a)&#123;for(var b=null;a&amp;&amp;(!a.getAttribute||!(b=a.getAttribute("leid")));)a=a.parentNode;return b&#125;;google.https=function()&#123;return"https:"==window.location.protocol&#125;;google.ml=function()&#123;return null&#125;;google.wl=function(a,b)&#123;try&#123;google.ml(Error(a),!1,b)&#125;catch(c)&#123;&#125;&#125;;google.time=function()&#123;return(new Date).getTime()&#125;;google.log=function(a,b,c,e,g)&#123;a=google.logUrl(a,b,c,e,g);if(""!=a)&#123;b=new Image;var d=google.lc,f=google.li;d[f]=b;b.onerror=b.onload=b.onabort=function()&#123;delete d[f]&#125;;window.google&amp;&amp;window.google.vel&amp;&amp;window.google.vel.lu&amp;&amp;window.google.vel.lu(a);b.src=a;google.li=f+1&#125;&#125;;google.logUrl=function(a,b,c,e,g)&#123;var d="",f=google.ls||"";if(!c&amp;&amp;-1==b.search("&amp;ei="))&#123;var h=google.getEI(e),d="&amp;ei="+h;-1==b.search("&amp;lei=")&amp;&amp;((e=google.getLEI(e))?d+="&amp;lei="+e:h!=google.kEI&amp;&amp;(d+="&amp;lei="+google.kEI))&#125;a=c||"/"+(g||"gen_204")+"?atyp=i&amp;ct="+a+"&amp;cad="+b+d+f+"&amp;zx="+google.time();/^http:/i.test(a)&amp;&amp;google.https()&amp;&amp;(google.ml(Error("a"),!1,&#123;src:a,glmm:1&#125;),a="");return a&#125;;google.y=&#123;&#125;;google.x=function(a,b)&#123;google.y[a.id]=[a,b];return!1&#125;;google.lq=[];google.load=function(a,b,c)&#123;google.lq.push([[a],b,c])&#125;;google.loadAll=function(a,b)&#123;google.lq.push([a,b])&#125;;&#125;)();var a=window.location,b=a.href.indexOf("#");if(0&lt;=b)&#123;var c=a.href.substring(b+1);/(^|&amp;)q=/.test(c)&amp;&amp;-1==c.indexOf("#")&amp;&amp;a.replace("/search?"+c.replace(/(^|&amp;)fp=[^&amp;]*/g,"")+"&amp;cad=h")&#125;;&lt;/script&gt;&lt;style&gt;#gbar,#guser&#123;font-size:13px;padding-top:1px !important;&#125;#gbar&#123;height:22px&#125;#guser&#123;padding-bottom:7px !important;text-align:right&#125;.gbh,.gbd&#123;border-top:1px solid #c9d7f1;font-size:1px&#125;.gbh&#123;height:0;position:absolute;top:24px;width:100%&#125;@media all&#123;.gb1&#123;height:22px;margin-right:.5em;vertical-align:top&#125;#gbar&#123;float:left&#125;&#125;a.gb1,a.gb4&#123;text-decoration:underline !important&#125;a.gb1,a.gb4&#123;color:#00c !important&#125;.gbi .gb4&#123;color:#dd8e27 !important&#125;.gbf .gb4&#123;color:#900 !important&#125;&lt;/style&gt;&lt;style&gt;body,td,a,p,.h&#123;font-family:arial,sans-serif&#125;body&#123;margin:0;overflow-y:scroll&#125;#gog&#123;padding:3px 8px 0&#125;td&#123;line-height:.8em&#125;.gac_m td&#123;line-height:17px&#125;form&#123;margin-bottom:20px&#125;.h&#123;color:#36c&#125;.q&#123;color:#00c&#125;.ts td&#123;padding:0&#125;.ts&#123;border-collapse:collapse&#125;em&#123;color:#c03;font-style:normal;font-weight:normal&#125;a em&#123;text-decoration:underline&#125;.lst&#123;height:25px;width:496px&#125;.gsfi,.lst&#123;font:18px arial,sans-serif&#125;.gsfs&#123;font:17px arial,sans-serif&#125;.ds&#123;display:inline-box;display:inline-block;margin:3px 0 4px;margin-left:4px&#125;input&#123;font-family:inherit&#125;a.gb1,a.gb2,a.gb3,a.gb4&#123;color:#11c !important&#125;body&#123;background:#fff;color:black&#125;a&#123;color:#11c;text-decoration:none&#125;a:hover,a:active&#123;text-decoration:underline&#125;.fl a&#123;color:#36c&#125;a:visited&#123;color:#551a8b&#125;a.gb1,a.gb4&#123;text-decoration:underline&#125;a.gb3:hover&#123;text-decoration:none&#125;#ghead a.gb2:hover&#123;color:#fff !important&#125;.sblc&#123;padding-top:5px&#125;.sblc a&#123;display:block;margin:2px 0;margin-left:13px;font-size:11px&#125;.lsbb&#123;background:#eee;border:solid 1px;border-color:#ccc #999 #999 #ccc;height:30px&#125;.lsbb&#123;display:block&#125;.ftl,#fll a&#123;display:inline-block;margin:0 12px&#125;.lsb&#123;background:url(/images/nav_logo229.png) 0 -261px repeat-x;border:none;color:#000;cursor:pointer;height:30px;margin:0;outline:0;font:15px arial,sans-serif;vertical-align:top&#125;.lsb:active&#123;background:#ccc&#125;.lst:focus&#123;outline:none&#125;&lt;/style&gt;&lt;script&gt;&lt;/script&gt;&lt;link href="/images/branding/product/ico/googleg_lodp.ico" rel="shortcut icon"&gt;&lt;/head&gt;&lt;body bgcolor="#fff"&gt;&lt;script&gt;(function()&#123;var src='/images/nav_logo229.png';var iesg=false;document.body.onload = function()&#123;window.n &amp;&amp; window.n();if (document.images)&#123;new Image().src=src;&#125;if (!iesg)&#123;document.f&amp;&amp;document.f.q.focus();document.gbqf&amp;&amp;document.gbqf.q.focus();&#125;&#125;&#125;)();&lt;/script&gt;&lt;div id="mngb"&gt; &lt;div id=gbar&gt;&lt;nobr&gt;&lt;b class=gb1&gt;&lt;/b&gt; &lt;a class=gb1 href="http://www.google.com.hk/imghp?hl=zh-TW&amp;tab=wi"&gt;&lt;/a&gt; &lt;a class=gb1 href="http://maps.google.com.hk/maps?hl=zh-TW&amp;tab=wl"&gt;&lt;/a&gt; &lt;a class=gb1 href="https://play.google.com/?hl=zh-TW&amp;tab=w8"&gt;Play&lt;/a&gt; &lt;a class=gb1 href="http://www.youtube.com/?gl=HK&amp;tab=w1"&gt;YouTube&lt;/a&gt; &lt;a class=gb1 href="http://news.google.com.hk/nwshp?hl=zh-TW&amp;tab=wn"&gt;&lt;/a&gt; &lt;a class=gb1 href="https://mail.google.com/mail/?tab=wm"&gt;Gmail&lt;/a&gt; &lt;a class=gb1 href="https://drive.google.com/?tab=wo"&gt;&lt;/a&gt; &lt;a class=gb1 style="text-decoration:none" href="https://www.google.com.hk/intl/zh-TW/options/"&gt;&lt;u&gt;&lt;/u&gt; &amp;raquo;&lt;/a&gt;&lt;/nobr&gt;&lt;/div&gt;&lt;div id=guser width=100%&gt;&lt;nobr&gt;&lt;span id=gbn class=gbi&gt;&lt;/span&gt;&lt;span id=gbf class=gbf&gt;&lt;/span&gt;&lt;span id=gbe&gt;&lt;/span&gt;&lt;a href="http://www.google.com.hk/history/optout?hl=zh-TW" class=gb4&gt;&lt;/a&gt; | &lt;a href="/preferences?hl=zh-TW" class=gb4&gt;&lt;/a&gt; | &lt;a target=_top id=gb_70 href="https://accounts.google.com/ServiceLogin?hl=zh-TW&amp;passive=true&amp;continue=http://www.google.com.hk/" class=gb4&gt;&lt;/a&gt;&lt;/nobr&gt;&lt;/div&gt;&lt;div class=gbh style=left:0&gt;&lt;/div&gt;&lt;div class=gbh style=right:0&gt;&lt;/div&gt; &lt;/div&gt;&lt;center&gt;&lt;br clear="all" id="lgpd"&gt;&lt;div id="lga"&gt;&lt;div style="padding:28px 0 3px"&gt;&lt;div style="height:110px;width:276px;background:url(/images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png) no-repeat" title="Google" align="left" id="hplogo" onload="window.lol&amp;&amp;lol()"&gt;&lt;div style="color:#777;font-size:16px;font-weight:bold;position:relative;top:70px;left:218px" nowrap=""&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;form action="/search" name="f"&gt;&lt;table cellpadding="0" cellspacing="0"&gt;&lt;tr valign="top"&gt;&lt;td width="25%"&gt;&amp;nbsp;&lt;/td&gt;&lt;td align="center" nowrap=""&gt;&lt;input name="ie" value="Big5" type="hidden"&gt;&lt;input value="zh-HK" name="hl" type="hidden"&gt;&lt;input name="source" type="hidden" value="hp"&gt;&lt;input name="biw" type="hidden"&gt;&lt;input name="bih" type="hidden"&gt;&lt;div class="ds" style="height:32px;margin:4px 0"&gt;&lt;input style="color:#000;margin:0;padding:5px 8px 0 6px;vertical-align:top" autocomplete="off" class="lst" value="" title="Google " maxlength="2048" name="q" size="57"&gt;&lt;/div&gt;&lt;br style="line-height:0"&gt;&lt;span class="ds"&gt;&lt;span class="lsbb"&gt;&lt;input class="lsb" value="Google " name="btnG" type="submit"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="ds"&gt;&lt;span class="lsbb"&gt;&lt;input class="lsb" value="name="btnI" onclick="if(this.form.q.value)this.checked=1; else top.location='/doodles/'" type="submit"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/td&gt;&lt;td class="fl sblc" align="left" nowrap="" width="25%"&gt;&lt;a href="/advanced_search?hl=zh-HK&amp;amp;authuser=0"&gt;&lt;/a&gt;&lt;a href="/language_tools?hl=zh-HK&amp;amp;authuser=0"&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;input id="gbv" name="gbv" type="hidden" value="1"&gt;&lt;/form&gt;&lt;div id="gac_scont"&gt;&lt;/div&gt;&lt;div style="font-size:83%;min-height:3.5em"&gt;&lt;br&gt;&lt;div id="als"&gt;&lt;style&gt;#als&#123;font-size:small;margin-bottom:24px&#125;#_eEe&#123;display:inline-block;line-height:28px;&#125;#_eEe a&#123;padding:0 3px;&#125;._lEe&#123;display:inline-block;margin:0 2px;white-space:nowrap&#125;._PEe&#123;display:inline-block;margin:0 2px&#125;&lt;/style&gt;&lt;div id="_eEe"&gt;Google.com.hk &lt;a href="http://www.google.com.hk/setprefs?sig=0_rRVcKKfvrZgCB_A43UF1XQ9TPmw%3D&amp;amp;hl=zh-CN&amp;amp;source=homepage" data-ved="0ahUKEwiS85jb15jQAhUJq1QKHUIXDJUQ2ZgBCAU"&gt;(&amp;#31616;/a&gt; &lt;a href="http://www.google.com.hk/setprefs?sig=0_rRVcKKfvrZgCB_A43UF1XQ9TPmw%3D&amp;amp;hl=en&amp;amp;source=homepage" data-ved="0ahUKEwiS85jb15jQAhUJq1QKHUIXDJUQ2ZgBCAY"&gt;English&lt;/a&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;span id="footer"&gt;&lt;div style="font-size:10pt"&gt;&lt;div style="margin:19px auto;text-align:center" id="fll"&gt;&lt;a href="/intl/zh-TW/ads/"&gt;&lt;/a&gt;&lt;a href="/intl/zh-TW/about.html"&gt;Google &lt;/a&gt;&lt;a href="http://www.google.com.hk/setprefdomain?prefdom=US&amp;amp;sig=__A6fXbQceC3SkqMu_FRt85xzWjWI%3D" id="fehl"&gt;Google.com&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;p style="color:#767676;font-size:8pt"&gt;&amp;copy; 2016 - &lt;a href="/intl/zh-TW/policies/privacy/"&gt;a&gt; - &lt;a href="/intl/zh-TW/policies/terms/"&gt;&lt;/a&gt;&lt;/p&gt;&lt;/span&gt;&lt;/center&gt;&lt;script&gt;(function()&#123;window.google.cdo=&#123;height:0,width:0&#125;;(function()&#123;var a=window.innerWidth,b=window.innerHeight;if(!a||!b)var c=window.document,d="CSS1Compat"==c.compatMode?c.documentElement:c.body,a=d.clientWidth,b=d.clientHeight;a&amp;&amp;b&amp;&amp;(a!=google.cdo.width||b!=google.cdo.height)&amp;&amp;google.log("","","/client_204?&amp;atyp=i&amp;biw="+a+"&amp;bih="+b+"&amp;ei="+google.kEI);&#125;)();&#125;)();&lt;/script&gt;&lt;div id="xjsd"&gt;&lt;/div&gt;&lt;div id="xjsi"&gt;&lt;script&gt;(function()&#123;function c(b)&#123;window.setTimeout(function()&#123;var a=document.createElement("script");a.src=b;document.getElementById("xjsd").appendChild(a)&#125;,0)&#125;google.dljp=function(b,a)&#123;google.xjsu=b;c(a)&#125;;google.dlj=c;&#125;)();(function()&#123;window.google.xjsrm=[];&#125;)();if(google.y)google.y.first=[];if(!google.xjs)&#123;window._=window._||&#123;&#125;;window._._DumpException=function(e)&#123;throw e&#125;;if(google.timers&amp;&amp;google.timers.load.t)&#123;google.timers.load.t.xjsls=new Date().getTime();&#125;google.dljp('/xjs/_/js/k\x3dxjs.hp.en_US.HHTiPh8WO1g.O/m\x3dsb_he,d/rt\x3dj/d\x3d1/t\x3dzcms/rs\x3dACT90oFyHK2p3Cq9BefJNT1WLwsFHb2Nvg','/xjs/_/js/k\x3dxjs.hp.en_US.HHTiPh8WO1g.O/m\x3dsb_he,d/rt\x3dj/d\x3d1/t\x3dzcms/rs\x3dACT90oFyHK2p3Cq9BefJNT1WLwsFHb2Nvg');google.xjs=1;&#125;google.pmc=&#123;"sb_he":&#123;"agen":true,"cgen":true,"client":"heirloom-hp","dh":true,"dhqt":true,"ds":"","fl":true,"host":"google.com.hk","isbh":28,"jam":0,"msgs":&#123;"cibl":"","dym":""lcky":""lml":"","oskt":"","psrc":"003Ca href=\"/history\"\u003E\u003C/a\u003E","psrl":"","sbit":"","srch":"Google "&#125;,"nds":true,"ovr":&#123;&#125;,"pq":"","refpd":true,"refspre":true,"rfs":[],"scd":10,"sce":5,"stok":"ahSc6O6Rc51lCmCOKZYjJdw8hyI"&#125;,"d":&#123;&#125;&#125;;google.y.first.push(function()&#123;if(google.med)&#123;google.med('init');google.initHistory();google.med('history');&#125;&#125;);if(google.j&amp;&amp;google.j.en&amp;&amp;google.j.xi)&#123;window.setTimeout(google.j.xi,0);&#125;]]></content>
      <categories>
        <category>tools, administrator</category>
      </categories>
      <tags>
        <tag>administrator</tag>
        <tag>外面的世界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GCC 问题记录]]></title>
    <url>%2F201602%2Fprogrammer%2Ftools%2Fgcc_issues.html</url>
    <content type="text"><![CDATA[errorserror: dereferencing pointer to incomplete type原因：使用 typedef struct {} xxx_t 定义类型 xxx_t，定义变量时，使用 struct xxx_t ，应为 xxx_t。 1234567891011typedef struct xxx_s &#123; int a; int b;&#125; xxx_t;int func(void)&#123; struct xxx_t st; st.a = 1; // &lt;---- 这里会报错。&#125; 找不到 libz.so.1交叉编译时，找不到 libz.so.1，但是 sudo apt-get install zlib1g 相关的所有包都已安装。 1/home/sunyongfeng/workshop/rgosm-build/.toolchain-arm-cortex_a9/arm-cortex_a9/arm-cortex_a9-linux-gnueabi/bin/../lib/gcc/arm-cortex_a9-linux-gnueabi/4.4.6/../../../../arm-cortex_a9-linux-gnueabi/bin/as: error while loading shared libraries: libz.so.1: cannot open shared object file: No such file or directory 原因：交叉编译 target 为 arm 32 bit，host 为 x64。解决：来自 stackoverflow，安装 zlib1g:386 版本，sudo apt-get install zlib1g:i386 快速解决 -Werror 选项出错带 -Werror 选项，一有 warning 就出错，有时不同架构间移值代码很容易出现。1cc1: warnings being treated as errors 快速解决的方法：添加选项 -Wno-error。 -Werror 选项不生效-Wno-error 一定要在 -Werror 之后，从实际运行看，放在后面的 option 生效。源代码：12345sunyongfeng@openswitch-OptiPlex-380:~/workshop/test$ cat abc.cint main()&#123; printf("sv\n");&#125; 正常编译：1234567sunyongfeng@openswitch-OptiPlex-380:~/workshop/test$ gcc -o abc abc.cabc.c: In function ‘main’:abc.c:3:5: warning: implicit declaration of function ‘printf’ [-Wimplicit-function-declaration] printf("sv\n"); ^abc.c:3:5: warning: incompatible implicit declaration of built-in function ‘printf’abc.c:3:5: note: include ‘&lt;stdio.h&gt;’ or provide a declaration of ‘printf’ 如果 -Werror 在 -Wno-errno 之后，则 warning 还是当 error。12345678910111213141516sunyongfeng@openswitch-OptiPlex-380:~/workshop/test$ gcc -o abc abc.c -Wno-error -Werrorabc.c: In function ‘main’:abc.c:3:5: error: implicit declaration of function ‘printf’ [-Werror=implicit-function-declaration] printf("sv\n"); ^abc.c:3:5: error: incompatible implicit declaration of built-in function ‘printf’ [-Werror]abc.c:3:5: note: include ‘&lt;stdio.h&gt;’ or provide a declaration of ‘printf’cc1: all warnings being treated as errorssunyongfeng@openswitch-OptiPlex-380:~/workshop/test$ gcc -o abc abc.c -Wno-error -Werror -Wno-errorabc.c: In function ‘main’:abc.c:3:5: warning: implicit declaration of function ‘printf’ [-Wimplicit-function-declaration] printf("sv\n"); ^abc.c:3:5: warning: incompatible implicit declaration of built-in function ‘printf’abc.c:3:5: note: include ‘&lt;stdio.h&gt;’ or provide a declaration of ‘printf’sunyongfeng@openswitch-OptiPlex-380:~/workshop/test$ 库可以被找到，但是编译时还是提示 undefined reference to &#39;Py_Initialize&#39;stackoverflow 链接。 问题：编译 gcc -lpython2.7 $(BUILD_CFLAGS) -o $(ELF) $^ -lxxx，libxxx.a 使用 libpython2.7.so，编译时提示找不到 python 的 symbol。 原因：-lxxx 写在 -lpython2.7 之后。 the linker doesn’t yet know that Py_Initialize is a required symbol when it loads libpython2.7.a, so it tosses it away. And then it gets to p.o and throws a fit about the missing symbol. Ordering it this way will let the linker look for the missing symbol in subsequent inputs. See: http://gcc.gnu.org/onlinedocs/gcc/Link-Options.html It makes a difference where in the command you write this option; the linker searches and processes libraries and object files in the order they are specified. Thus, foo.o -lz bar.o’ searches libraryz’ after file foo.o but before bar.o. If bar.o refers to functions in `z’, those functions may not be loaded. 解决：把 -lpython2.7 写在 -lxxx 之后。像这种库中依赖库的地方需要注意。 relocation R_X86_64_32 against `xxx’ can not be used when making a shared object; recompile with -fPIC sub.o: could not read symbols: Bad value123456x86_64-unknown-linux-gnu-gcc -fPIC -shared -D_LITTLE_ENDIAN -g -Wno-error=deprecated-declarations -Wall -D_GNU_SOURCE -lpthread/home/sunyongfeng/workshop/../build/sub.o /home/sunyongfeng/workshop/../build/undef.o /home/sunyongfeng/workshop/../build/libxy.so/home/sunyongfeng/workshop/toolchain/toolchain-x86_64/x86_64/bin/../lib/gcc/x86_64-unknown-linux-gnu/4.2.4/../../../../x86_64-unknown-linux-gnu/bin/ld: /home/sunyongfeng/workshop/../build/libproxy/policy/sub.o: relocation R_X86_64_32 against `g_lock' can not be used when making a shared object; recompile with -fPIC/home/sunyongfeng/workshop/../build/libproxy/policy/sub.o: could not read symbols: Bad valuecollect2: ld returned 1 exit statusmakefile:69: recipe for target 'build' failed 源代码编译也添加 -fPIC 选项，在 ARM / MIPS 平台都没此问题，在 x86 才有。]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>gcc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 问题记录]]></title>
    <url>%2F201602%2Ftools%2Fgit_issues.html</url>
    <content type="text"><![CDATA[git push 相关error: RPC failed; result=22, HTTP code = 504 Why am I getting a 504 error when accessing Git over HTTP?If you’re getting a message of the form: error: RPC failed; result=22, HTTP code = 504 When attempting to clone your Git repository over HTTP, it probably means that there’s a size issue. Git is not designed to perform well over HTTP with repositories larger than about 1 GB. Over HTTP, Git has to be served using FastCGI and so the FastCGI process can sometimes time out before the command can return results. To your team, this looks like intermittent failure and some issue with our servers, but it’s actually Git’s inability to send the amounts of data in question fast enough. To work around this, if you need to have a large Git repository, we recommend accessing it via SSH using the instructions at: How Do I Connect To My Git Repository? You can email us as well at support [at] to open a support ticket and request that we run garbage collection on your server, which sometimes can free up enough space to make a difference. Alternatively, we do offer Subversion, which is great for hosting large artifact repositories for your team as well, and because it’s not distributed, doesn’t have as many issues with copying large amounts of data. git status 提示某个子模块 fatal: git status --porcelain failed详见，https://stackoverflow.com/questions/5456683/why-do-i-get-fatal-git-status-porcelain-failed。解决，到对应子模块，git init 一下即可。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>版本控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 10 在 thinkpad E420 启机慢]]></title>
    <url>%2F201601%2Fwindows%2FWin10_startup_very_slow_on_thinkpad_E420.html</url>
    <content type="text"><![CDATA[启动慢现象启动过后，黑屏大概 1 分半钟才进入登陆界面。总的启动时间 2 分钟以上。 解决win10开机黑屏很久（amd双显卡），可能是 AMD HD7400 显卡特有问题。禁用 ULPS （Ultra Low Power State），注册表如下。ULPS 用于节能。 1234567Windows Registry Editor Version 5.00[HKEY_LOCAL_MACHINE\SYSTEM\ControlSet001\Control\Class\&#123;4D36E968-E325-11CE-BFC1-08002BE10318&#125;\0000]"EnableULPS"=dword:00000000[HKEY_LOCAL_MACHINE\SYSTEM\ControlSet001\Control\Class\&#123;4D36E968-E325-11CE-BFC1-08002BE10318&#125;\0001]"EnableULPS"=dword:00000000 磁盘使用率高很可能是误报，因为刚装完机可能在后台安装更新。优化可参照：Win10磁盘占用率100%的原因及解决方法]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Wireshark Usage]]></title>
    <url>%2F201512%2Fnetworks%2Fwireshark.html</url>
    <content type="text"><![CDATA[Linux中非ROOT用户使用wireshark抓包原理没细看，详见《Sniffing with Wireshark as a Non-Root User》。 步骤： 安装setcap 创建wireshark组（可选） 配置抓包能力 logout再重新登录生效。 123456789101112131415161. sudo apt-get install libcap2-bin2. sudo groupadd wiresharksudo usermod -a -G wireshark your_user_namesudo newgrp wireshark（会切成root用户）chgrp wireshark /usr/bin/dumpcapchmod 750 /usr/bin/dumpcap3. setcap cap_net_raw,cap_net_admin=eip /usr/bin/dumpcap确认是否配置成功：# getcap /usr/bin/dumpcap/usr/bin/dumpcap = cap_net_admin,cap_net_raw+eip]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用软件备忘]]></title>
    <url>%2F201511%2Ftools%2Fvlc.html</url>
    <content type="text"><![CDATA[“媒体” -&gt; “流”，弹出“打开媒体窗口”。 选择“文件”标签，“Add”一个视频源，再选择“串流”按钮，进入“流输出”窗口。 在“来源”界面，直接点下一步。 在“Destination setup”的“New destination”点击下拉菜单选择“RTSP”协议，再点击旁边的“添加”按钮。 在“RTSP”标签下改端口号（默认8554）和路径，以路径“test”为例，点击下一步。 在“Transcoding Options”中，选择一种，我选的是“Video - H.264 + MP3(MP4)”，点击右侧紧靠的按钮，选择封装，我的视频是MKV，我直接就点MKV了，点击保存。 点击下一步，点击“STREAM”按钮即可。 访问地址为：rtsp://your_ip:8554/test]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>vlc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PC模拟WAN报文时延与丢包率]]></title>
    <url>%2F201510%2Fnetworks%2FPC-simulate-WAN-loss-latency.html</url>
    <content type="text"><![CDATA[使用PC模拟WAN报文时延与丢包率的思路为： 报文进入PC，在PC中进行软件转发。 在PC的软件转发策略中，加入时延与丢包率。 测试方法： 多网卡，可简单控制某端口入、某端口出。一般可基于端口、流进行配置。 单网卡，PC机内部使用多虚拟网卡中转模拟WAN，在外部交换机进行PBR策略，对报文入口是PC的走另一条路由。 工具：（这里只介绍两种） netem + tc，目前大多数Linux发行版天然支持，命令行使用上有学习成本。netem为内核上的功能，用户空间命令tc最终使用netem提供的服务。 WANem，一个Linux版本，需要安装新系统。可通过网页进行配置。 测试须知： 由于PC的软件处理能力有限，测试时尽可能避免大流量软件转发，造成PC处理能力不足而引起的丢包、时延不准确。 netem + tc样例： 配置路由，sudo ip route add xxx.xxx.xxx.xxx/mask -i ethx 使能PC进行IP报文转发， sudo sysctl net.ipv4.ip_forward=1 查看端口收发包，sudo tcpdump -i ethx 使用tc进行时延/丢包率配置，sudo tc qdisc add dev eth0 root netem delay 100ms]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>网络测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scapy简述]]></title>
    <url>%2F201509%2Fnetworks%2FScapy.html</url>
    <content type="text"><![CDATA[scapy常用接口get_if_list() 获取接口列表支持自动被全函数集的功能。12&gt;&gt;&gt; get_if_list()['lo', 'eth0', 'eth1', 'eth2'] help() 获取帮助1234567&gt;&gt;&gt; help(sendp)Help on function sendp in module scapy.sendrecv:sendp(x, inter=0, loop=0, iface=None, iface_hint=None, count=None, verbose=None, realtime=None, *args, **kargs) Send packets at layer 2 sendp(packets, [inter=0], [loop=0], [verbose=conf.verb]) -&gt; None(END) 发送/接收接口 只发不收 send()，三层发包 sendp()，二层发包 发且收 sr()，sr1()， srloop()，三层发包 srp()，srp1()，srploop，二层发包 The send and receive functions family will not only send stimuli and sniff responses but also match sent stimuli with received responses. Function sr(),sr1(),and srloop() all work at layer 3. Sr() is for sending and receiving packets,it returns a couple of packet and answers,and the unanswered packets.but sr1() only receive the first answer.srloop() is for sending a packet in loop and print the answer each time 常用操作发送pcap格式的报文 读取pcap文件 以二层的形式发包。 1234from scapy.all import *buffer=rdpcap("/home/sunyongfeng/test/1029.pcap")sendp(buffer, iface="eth2",inter=0.001, loop=1, count=1000000000000)sendp(ETHER()/IP(dst="1.1.1.1")/TCP()/"You are offline.", iface="eth2",inter=0.001, loop=1, count=1000000000000) 发送 raw 报文使用 Raw 类。 1234567891011$ sudo scapy INFO: Can't import python gnuplot wrapper . Won't be able to plot.INFO: Can't import PyX. Won't be able to use psdump() or pdfdump().WARNING: No route found for IPv6 destination :: (no default route?)INFO: Can't import python Crypto lib. Won't be able to decrypt WEP.INFO: Can't import python Crypto lib. Disabled certificate manipulation toolsWelcome to Scapy (2.2.0)&gt;&gt;&gt; pkt = Raw('\x00\xe0\xec\x5a\x68\x34\x00\xe0\xec\x83\xb4\x78\x08\x00\x45\xc0\x00\x3c\x38\xe7\x40\x00\x01\x06\x18\x13\x14\x00\x00\x01\x14\x00\x00\x02\x8d\x49\x00\xb3\xe6\x7e\x5f\xfa\x00\x00\x00\x00\xa0\x02\x72\x10\x53\x43\x00\x00\x02\x04\x05\xb4\x04\x02\x08\x0a\x00\xc4\x85\x70\x00\x00\x00\x00\x01\x03\x03\x07')&gt;&gt;&gt; sendp(pkt, iface="Ethernet52", inter=1, loop=1, count=10) ..........Sent 10 packets. 发送特定长度报文使用 RandString(size=xxx)。 12&gt;&gt;&gt; a=IP(dst="76.200.0.2",ttl=1)/TCP(sport=176)/Raw(RandString(size=8000)) &gt;&gt;&gt; send(a, iface="Ethernet76", inter=0.001, loop=1, count=1000) 发送 ARP 报文op 还有 is-at。 12from scapy.all import *sendp(Ether(src="00:00:00:00:00:AA", dst="ff:ff:ff:ff:ff:ff")/ARP(pdst="192.168.3.4", psrc="192.168.3.1",op="who-has"), iface="enp132s0f1", inter=0.1, loop=1, count=1) 抓包并基于该包构造、发送新包以下样例抓特定接口 ARP 请求报文，并返回 ARP 响应报文，类似 proxy ARP 功能。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556from scapy.all import *import threadingdef fakeResponse(packet): for pkt in packet: smac = pkt[Ether].src sip = pkt[ARP].psrc tip = pkt[ARP].pdst hwsrc = pkt[ARP].hwsrc # 1 REQUEST, 2 REPLY op = pkt[ARP].op if op != 1: return #print "### RECV PACKET START ###" #pkt.show() #print "### RECV PACKET END ###" reply = Ether(dst=smac)/ARP(op="is-at", psrc=tip, pdst=sip, hwdst=hwsrc)/Raw(RandString(size=48)) #print "### SEND PACKET START ###" #reply.show() #print "### SEND PACKET END ###" global lock global pkts global thd pkts_tmp = [] with lock: pkts.append(reply) if len(pkts) &gt;= thd: pkts_tmp = copy.copy(pkts) pkts = [] if len(pkts_tmp) != 0: sendp(pkts_tmp, iface='eth4', verbose=0, inter=0.005)def timer_handler(): global lock global pkts global thd pkts_tmp = [] with lock: pkts_tmp = copy.copy(pkts) pkts = [] if len(pkts_tmp) != 0: sendp(pkts_tmp, iface='eth4', verbose=0, inter=0.005) global timer timer = threading.Timer(0.5, timer_handler) timer.start()pkts = []thd = 50lock = threading.Lock()timer = threading.Timer(0.5, timer_handler)timer.start()sniff(iface='eth4', filter="arp", prn=fakeResponse) 查看报文见 https://thepacketgeek.com/scapy-p-04-looking-at-packets/: 1234567891011121314151617pkts[0].summary()pkts.summary()pkts[3].show()packet.haslayer(ICMP)packet.getlayer(ICMP).code&gt;&gt;&gt; pkts[3]&lt;Ether dst=00:00:16:aa:bb:cc src=00:24:97:2e:d6:c0 type=0x800 |\&lt;IP version=4L ihl=5L tos=0x20 len=84 id=47340 flags= frag=0L ttl=57 proto=icmp chksum=0x3826 src=4.2.2.1 dst=192.168.201.203 options=[] |\&lt;ICMP type=echo-reply code=0 chksum=0xcfbf id=0x3060 seq=0x1 |&lt;Raw |&gt;&gt;&gt;&gt;&gt;&gt;&gt; pkts[3][Ether].src'00:24:97:2e:d6:c0'&gt;&gt;&gt; pkts[3][IP].ttl57&gt;&gt;&gt; pkts[3][IP].proto1&gt;&gt;&gt; pkts[3][ICMP].type0 常见问题发包慢 一个一个发包，比按 pkts list 发包慢很多，原因为一个一个发，会一直在 bind socket。 使用 send 发送三层报文提示 MAC 未解析使用 send 发送三层报文的时候，Ethernet 的信息由 PF_PACKET 自行解析，不需要提供，否则会提示 WARNING: Mac address to reach destination not found. Using broadcast.。 1234567891011121314151617181920212223$ sudo scapy3k WARNING: No route found for IPv6 destination :: (no default route?). This affects only IPv6INFO: Please, report issues to https://github.com/phaethon/scapyINFO: Can't import python cryptography lib. Won't be able to decrypt WEP.INFO: Can't import python cryptography lib. Disabled IPsec encryption/authentication.INFO: Can't import python cryptography. Disabled certificate manipulation toolsWARNING: IPython not available. Using standard Python shell instead.Welcome to Scapy (3.0.0)&gt;&gt;&gt; a=Ether(dst="00:e0:ec:b1:b6:92")/IP(dst="76.200.0.2",ttl=2)/TCP() &gt;&gt;&gt; send(a, iface="Ethernet76", inter=0.001, loop=1, count=1000)WARNING: Mac address to reach destination not found. Using broadcast..WARNING: Mac address to reach destination not found. Using broadcast..WARNING: more Mac address to reach destination not found. Using broadcast...........................................................................................................................................^CSent 141 packets.&gt;&gt;&gt; a=IP(dst="76.200.0.2",ttl=2)/TCP() &gt;&gt;&gt; send(a, iface="Ethernet76") .Sent 1 packets.&gt;&gt;&gt; send(a, iface="Ethernet76", inter=0.001, loop=1, count=1000)........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Sent 1000 packets.&gt;&gt;&gt;]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>网络测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux开发环境配置记录]]></title>
    <url>%2F201509%2Flinux%2Fdev-conf.html</url>
    <content type="text"><![CDATA[远程登录windowsremmina安装包： remmina remmina-plugin-rdp 配置： Protocol，选择“RDP - Remote Desktop Protocol” Basic标签 Server，windows的IP User name Password Advanced标签 Security，选择“Negotiate” SSH标签 去掉Enable SSH tunnel freerdp本人倾向使用freerdp，简单易用。 安装包：freerdp。命令：（将username / password / 1.1.1.1替换成自己的内容）xfreerdp -u username -p &quot;password&quot; -g 1024x768 -x l --plugin cliprdr --plugin rdpsnd 1.1.1.1 因为版本不同，可能命令参数不一样：xfreerdp --sec rdp -u username -p &quot;password&quot; -g 1440x790 -x l --plugin cliprdr --plugin rdpsnd 1.1.1.1 跨系统拷贝粘贴失败问题注意，windows 7有bug，导致clipboard有问题。即windows与Linux的copy、paste无法共用。解决方法见链接，其中mike 1504的做法，通过任务管理器杀掉rdpclip.exe再重启rdpclip.exe进程规避本问题。 This is an old problem. It has been around since pre2004, and microsoft is well aware of it. The cause is tied to MS Office as well as the OS. It usually occurs during Remote desktop sessions, and the problem is on the remote machine. The best solution I have found is to pull up task man, end the process rdpclip.exe, and then restart it by first changing focus from task manager to another program and back to task manager, choose file&gt;new task (run) and then typing in rdpclip.exe and hit enter. The remote clip service will restart, and usually the copy you wanted to paste immediately becomes available.If you fail to change focus from Task Manager to another program and back you may find the remote session locks up. If so, don’t panic, simply end the remote session and begin a new one. In case you don’t know how to access task manager on the remote machine (CTRL ALT DELETE is always to the local machine), simply right click on the task bar and choose it from the context menu.I would have thought by win7 this would have been fixed, but I am running Win7 enterprise trial right now and having the problem there. ssh远程登录Linux安装包：openssh-server客户端登录：ssh username@hostIP 串口PAC Manager安装包： PAC Manager，不在Ubuntu仓库中，Sourceforge链接。 cu 需要把/dev/ttyUSB0的用户切换成cu的uucp才能被cu使用。使用cu时需要用sudo还没有明白remote-tty怎么用。 kermit安装包： ckermit lrzsz，用于xmodem传输 不改权限的话，只有用超级用户才能正常用kermit访问串口。123456789101112sudo kermitset line /dev/ttyUSB0set speed 115200set carrier-watch offset handshake noneset flow-control nonerobust set receive packet-length 9024set send packekt-length 9024set protocol xmodem 在ckermit命令提示符下： connect，连接串口； ?，查看所有命令，前面的配置命令在此都可以看到； send /path/to/file，传输文件，支持相对路径； 在串口控制台下，通过ctrl + \，再敲c，返回ckermit控制台。 Ser2net共享串口（SerialPort），提供telnet服务。 配置文件/etc/ser2net.conf，类似下面的配置依葫芦画瓢就可以了。 2001，端口号 telnet，用telnet访问串口 /dev/ttyUSB1，表示实际串口 9600，波特率 8DATABITS NONE 1STOPBIT，常见的8N1 600，port timeout，如果在超时时间间隔内没有对串口进行任何操作，ser2net会自动退出。 可以将所有的波特率的配置都添加进去，注意使用不同的端口号。 122001:telnet:600:/dev/ttyUSB1:9600 8DATABITS NONE 1STOPBIT -XONXOFF -RTSCTS banner 3001:telnet:600:/dev/ttyUSB1:115200 8DATABITS NONE 1STOPBIT -XONXOFF -RTSCTS banner Windows下，可使用Comfoolery共享串口，功能更加强大。 wine连接不上串口来源链接。步骤： 映射/dev/ttyUSB0成windows中的概念com1 1ln -s /dev/ttyUSB0 ~/.wine/dosdevices/com1 查看/dev/ttyUSB0的用户组，如下，用户组为dialout 12ls -l /dev/ttyUSB0crw-rw---T 1 root dialout 4, 6 Nov 18 20:34 ttyUSB0 将当前用户加入用户组dialout 123456sudo vi /etc/group修改dialout:x:20:为dialout:x:20:your_user_name 文件共享samba安装包：samba 配置： 修改配置文件/etc/samba/smb.conf，确认要共享的目录。sudo service samba restart生效。配置样例如下。 创建samba用户：sudo smbpasswd -a user_name，user_name填成自己想要的名称。 12345[linuxMint] comment = linux path = /home/sunyongfeng/ writeable = yes valid users = sunyongfeng 其中，linuxMint是共享目录显示给使用者的名称。path是实际共享的目录，valid users是合法的用户。 windows 7 如何清除自动登录的凭据控制面板 -&gt; 用户账户 -&gt; 管理您的凭据，然后单击要清除的那个凭据，点击从保管库中删除，重启生效。 解决Ubuntu用户名变动后，无法从win7 登录 samba。 Linux 访问 Windows 共享目录 在 windows 设置好共享目录； 使用 smbclient 访问共享目录（可测试共享目录是否可用）： smbclient //IP/share_dir -U your_username ； 挂载共享目录到 linux： sudo mount -t cifs -o username=your_username,password=your_passwd //IP/share_dir /mnt 亦可直接在文件管理器中直接输入smb://IP，按提示输入用户名密码，即可从 Linux 文件管理器中直接查看 windows 的共享目录。 smbclient 访问 log： 1234567891011121314sunyongfeng@sunnogo:~$ smbclient //IP/share_dir -U your_nameEnter oa's password:Domain=[sunnogo] OS=[Windows 7 Ultimate 7601 Service Pack 1] Server=[Windows 7 Ultimate 6.1]smb: \&gt; ls . D 0 Thu Mar 10 19:24:05 2016 .. D 0 Thu Mar 10 19:24:05 2016 asic D 0 Thu Mar 10 18:58:41 2016 linux D 0 Thu Mar 10 18:58:43 2016 python D 0 Thu Mar 10 18:59:04 2016 工具 D 0 Thu Mar 10 19:06:10 2016 项目 D 0 Thu Mar 10 20:08:25 2016 40960 blocks of size 4194304. 33262 blocks availablesmb: \&gt; mount挂载 log：123456789sunyongfeng@sunnogo:~$ sudo mount -t cifs -o username=your_username,password=your_passwd //IP/share_dir /mntsunyongfeng@sunnogo:~$ ls -al /mnt/总用量 3244drwxr-xr-x 2 root root 4096 3月 10 19:24 .drwxr-xr-x 3 root root 4096 3月 11 09:35 ..drwxr-xr-x 2 root root 0 3月 10 18:58 linuxdrwxr-xr-x 2 root root 0 3月 10 18:59 pythondrwxr-xr-x 2 root root 0 3月 10 19:06 工具drwxr-xr-x 2 root root 0 3月 10 20:08 项目 tftp安装包：tftpd-hpa 配置： 修改配置文件/etc/default/tftpd-hpa，样例如下。 需要chmod 777 /home/sunyongfeng/tftpboot，否则可能出现权限问题，TFTP error: &#39;Permission denied&#39; (0)。tftpboot为tftp共享的主目录。 12345678# /etc/default/tftpd-hpa TFTP_USERNAME="tftp"#TFTP_DIRECTORY="/var/lib/tftpboot"TFTP_DIRECTORY="/home/sunyongfeng/tftpboot"TFTP_ADDRESS="[::]:69"#TFTP_OPTIONS="--secure" TFTP_OPTIONS="-l -c -s" 异常： 如果一直timeout，可能是网卡出问题了，sudo service networking restart，或者重启电脑。 有时不清楚为何启机之后，tftpd-hpa在，但是tftp无法下载。sudo service tftpd-hpa restart可解决此问题。没有看系统log细究原因。 atftpd另一款tftp服务器。 安装包：atftpd配置： 修改/etc/default/atftpd，样例如下。 把/etc/inet.conf中的tftp注释掉，不然会出现“atftpd: cannot bind port: 69/udp”。 限制：最大文件有限制，32M。 1234#/etc/default/atftpdUSE_INETD=false OPTIONS="--tftpd-timeout 300 --retry-timeout 5 --mcast-port 1758 --mcast-addr 239.239.239.0-255 --mcast-ttl 1 --maxthread 100 --verbose=7 /home/sunyongfeng/tftpboot" 安装linaro gcc交叉编译器123sudo add-apt-repository ppa:linaro-maintainers/toolchainsudo apt-get updatesudo apt-get install gcc-arm-linux-gnueabi 终端（Terminal）guakefbtermscreen screen -S sessionName，为 screen 会话取名字 screen -list，查看当前有哪些会话 screen -r sessionName，Reattach 到 sessionName 会话 ctrl + a + d，detach 当前会话 script启机进入命令行 /etc/default/grub, change this lineRUB_CMDLINE_LINUX_DEFAULT=&quot;splash quiet&quot; toGRUB_CMDLINE_LINUX_DEFAULT=&quot;text&quot;Run sudo update-grub when done. This is easily reversed too if you need to change back.]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
        <tag>远程登录</tag>
        <tag>串口</tag>
        <tag>文件共享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux使用记录]]></title>
    <url>%2F201509%2Flinux%2Fpersonal-faq.html</url>
    <content type="text"><![CDATA[善用/var/log该目录存放系统日志，很多异常，比如进不了GUI、服务器连不上等问题，都可通过此目录内的log排查。 比如samba连不上，可通过cat /var/log/auth.log | grep samba查看samba失败的原因。 服务重启很多服务如samba、tftp如果配置文件改了之后，需要通过sudo service smbd/tftp restart来重启服务。 硬件相关网卡相关以Ubuntu server 14.04为例。 没有 ifconfig 命令sudo apt-get install net-tools 静态IP配置配置文件：/etc/network/interfaces，如eth0的配置。 1234567891011121314sunnogo@sunyongfeng:~/Downloads$ cat /etc/network/interfaces# This file describes the network interfaces available on your system# and how to activate them. For more information, see interfaces(5).# The loopback network interfaceauto loiface lo inet loopback# eth0, Realtek Fast Ethernet NICauto eth0iface eth0 inet static address 192.168.204.148netmask 255.255.255.0gateway 192.168.204.1 以上配置相当于命令：12ifconfig eth0 192.168.204.148 netmask 255.255.255.0route add default gw 192.168.204.1 DNS配置配置文件：/etc/resolvconf/resolv.conf.d/base 123sunnogo@sunyongfeng:~/Downloads$ cat /etc/resolvconf/resolv.conf.d/base nameserver 8.8.8.8nameserver 114.114.114.114 禁用IPv6禁用的原因：ubuntu源默认使用IPv6，详见链接。 修订文件/etc/sysctl.conf，在该文件最后加上：1234# IPv6 disablednet.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1net.ipv6.conf.lo.disable_ipv6 = 1 保存关闭，并执行1$ sudo sysctl -p 即时生效，可通过ifconfig检查。重启有效。 显示相关屏幕分辨率问题处理elementary OS时的操作 123sudo xrandr --newmode "1440x900" 106.50 1440 1528 1672 1904 900 903 909 934 -hsync +vsyncsudo xrandr --addmode VGA1 1440x900sudo xrandr --output VGA1 --mode 1440x900 日常使用apt配置源 安装ubuntu的图形工具update-manager，通过Software &amp; Updates，在“Ubuntu Software”标签页，点“Download from:”旁边的复选框，选择http://mirrors.yun-idc.com/ubuntu，这个源在福州的速度不错。 亦可通过更改/etc/apt/source.list的内容实现源配置。 debian可以通过apt-spy实现类似功能。 更新cacheapt-get update 以关键字查找包apt-cache search your-keyword 强制使用IPv4更新默认使用IPv6源更新，不过国内目前还未全力推广IPv6。通过Software &amp; Updates图形界面配置中文源后，无此问题。 强制使用IPv4更新的方法，说明详见链接。 使用apt-get install时，加入选项 -o Acquire::ForceIPv4=true。 添加一个配置文件/etc/apt/apt.conf.d/99force-ipv4，在配置文件中写入Acquire::ForceIPv4 &quot;true&quot;;。 安装失败出现如下错误： 123456sunyongfeng@R04220 ~/smoking/ci $ sudo apt-get install npm[sudo] password for sunyongfeng: 正在读取软件包列表... 有错误！ E: Encountered a section with no Package: headerE: Problem with MergeList /var/lib/apt/lists/packages.linuxmint.com_dists_rebecca_import_i18n_Translation-en E: 无法解析或打开软件包的列表或是状态文件。 解决，简单粗暴地删除cache，再更新一下。12sudo rm /var/lib/apt/lists/* -vfsudo apt-get update 中文支持Ubuntu server 14.04中文支持默认使用English，之后装gdm，想在英文环境中显示中文。 安装的包： 中文支持 gnome中文支持包： language-pack-zh-han* language-pack-gnome-zh-han* 中文字体 ttf-wqy-microhei ttf-wqy-zenhei ttf-ubuntu-font-family，这个不是中文字体，只是装一下而已。 fonts-arphic-uming，个人很喜欢的一个中文字体，不过其英文显示有点难看。 输入法使用经典的fcitx。 Ubuntu server 14.04 fcitx 安装的包 fcitx fcitx-config-gtk2，图形配置工具 fcitx-table-wbpy，五笔拼音输出法 fcitx-module-*，有dbus、kimpanel等 fcitx-frontend-*，在gdm中，不需要装这个。为fbterm准备。 配置 卸载ibus，apt-get remove ibus，5M多；原理不明。 通过fcitx-config-gtk2，点击“Input Method”标签页左下方的“+”号，搜索出WubiPinyin，添加即可。 fcitx旧安装方式记录12345sudo apt-get install fcitx fcitx-frontend-qt5 fcitx-table-wbpy fcitx-ui-classic fcitx-config-gtk3sudo apt-get remove ibusps -e | grep ibus, kill掉带ibus_daemon的那条进程sudo apt-get install im-switchin-switch -s fcitx fcitx-table-xxx，这里用的wbpy是五笔拼音，其他输入法如拼音由使用者自己选择。执行：fcitx-autostart可开机自启动打开fcitx。 浏览器安装的包：（安装完后，默认的中文字体意外地显示得很好AR PL UMing CN和Monospace） chromium-browser pepperflashplugin-nonfree 文件管理器（File Manager）注意与窗口管理器（Window Manager）的概念不一样。 安装包： gnome，nautilus kde，dolphin 文本编辑器安装包： gnome，gdeit kde，kate 引导失败一般是先装Linux再装Windows出现。解决方法： 用Docker吧，不用再装Windows了。 通过Linux USB启动盘进入U盘中的Linux，通过grub一般都能修复，然后替换掉windows的引导，先通过grub引导。 update-grub或update-grub2 grub-install 通过EasyBCD配置，重启后进入Linux，然后再进行grub修复。 键鼠提示CapsLock键大写提示工具：indicators-keylock，先导入源，再安装。 12sudo add-apt-repository ppa:tsbarnes/indicator-keylock &amp;&amp; sudo apt-get updatesudo apt-get install indicator-keylock 禁用触摸板Ubuntu配置禁用触摸板wiki。 命令：synclient touchpadoff=1。 可以使用工具GPointingDeviceSettings。 用户管理Add user and add to sudoers groupFrom How can I add a new user as sudoer using the command line?, ændrük’s answer.From RootSudo#Allowing_other_users_to_run_sudo: Allowing other users to run sudo To add a new user to sudo, open the Users and Groups tool from System-&gt;Administration menu. First click Unlock, then you can select a user from the list and hit Properties. Choose the User Privileges tab and check Administer the system. In the terminal (for Precise Pangolin, 12.04), this would be: sudo adduser &lt;username&gt; sudo where you replace with the name of the user (without the &lt;&gt;). In previous version of Ubuntu sudo adduser &lt;username&gt; admin would have been appropriate, but the admin group has been deprecated and no longer exists in Ubuntu 12.04. 添加用户命令： useradd, 如果想类似 adduser 那样默认创建用户 home 目录，命令样例为 useradd -m -d /home/newuser -p yourPaSsWoRd newuser，又如 useradd -G sudo,docker jeromesun -m -s /bin/bash usermod userdel adduser, user adduser can default add a /home/username directory. 批量创建大量用户： 123456789101112131415161718#!/bin/bashGRP=("aaa""bbb""ccc")for i in $&#123;GRP[@]&#125; ; do short=$&#123;i:0:2&#125; pass="XX.$&#123;short&#125;.123" echo "add $i passwd $&#123;pass&#125;" # centos wheel group has sudo permission useradd -G wheel $&#123;i&#125; -m -s /bin/bash -p `openssl passwd -1 $&#123;pass&#125;` #userdel $&#123;i&#125; #rm -rf /home/$&#123;i&#125;done 修改密码命令：passwd username 修改root密码ubuntu的默认root密码随机，通过sudo passwd root修改 添加sudo用户如果用户不是sudo用户，且使用sudo命令，则会提示“xxx is not in the sudoers file. This incident will be reported”。解决方法： 拿到root权限，添加文件/etc/sudoers读权限 修改/etc/sudoers，在User privilege specification下，类似root那样，添加一行usernamexxxx ALL=(ALL:ALL) ALL 123# User privilege specificationroot ALL=(ALL:ALL) ALLusernamexxxx ALL=(ALL:ALL) ALL 添加 sudo 用户的另一种简易方法详见：How To Create a Sudo User on Ubuntu [Quickstart]。 以 root 用户登陆你的设备 1ssh root@server_ip_address 使用 adduser 命令创建新用户。以下内容请替换 username 为你想创建的用户名。 1adduser username 设置和确认新用户的密码。 1234Set password prompts:Enter new UNIX password:Retype new UNIX password:passwd: password updated successfully 接下来提示设置用户信息，可以全部不填，直接敲回车键。 123456789User information prompts:Changing the user information for usernameEnter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []:Is the information correct? [Y/n] 使用 usermod 命令添加用户到 sudo 组。 1usermod -aG sudo username Ubuntu 上 sudo 组的成员默认拥有 sudo 权限。 测试新用户账号的 sudo 权限。使用 su 命令切换到新用户。 1su - username 在你的命令前加 sudo 尝试新用户权限： 1sudo command_to_run 例如，查看 /root 目录的内容： 1sudo ls -la /root 如果是本会话中第一次使用 sudo，将系统会提示你输入密码。 12345678910sunyongfeng@ubuntu:~$ sudo ls -al /root[sudo] password for sunyongfeng: total 3308drwx------ 4 root root 4096 Nov 28 14:22 .drwxr-xr-x 22 root root 4096 Nov 4 14:52 ..-rw------- 1 root root 92 Nov 28 10:01 .bash_history-rw-r--r-- 1 root root 3106 Feb 20 2014 .bashrcdrwx------ 2 root root 4096 Nov 4 15:25 .cache-rw-r--r-- 1 root root 140 Feb 20 2014 .profile-rw------- 1 root root 2024 Nov 28 14:22 .viminfo 配置字体 拷贝字体 配置字体 刷新字体 123sudo cp -a msfonts /usr/share/fonts/msfontssudo fc-cache -f -vfc-cache -f -s -v sshssh 远程登陆后很久才提示输入密码原因：配置 GSSAPIAuthentication 为 yes 了。默认情况下该配置并未开启，详见 /etc/ssh/sshd_config 123# GSSAPI options#GSSAPIAuthentication no#GSSAPICleanupCredentials yes 详见 SSH 中的 GSSAPI 相关选项]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
        <tag>apt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【解决】Win7虚拟机ubuntu安装vm-tools的问题]]></title>
    <url>%2F201507%2Fwindows%2FVmplayer-ubuntu-install-vmtools.html</url>
    <content type="text"><![CDATA[win7 vmplayer中安装ubuntu，在安装vm-tools的时候出现找不到“the location of the directory of C header files that match your running kernel?”。 一般kernel header files安装在/usr/src/`uname -r`/include。没有的话自己apt-get install linux-header-`uname -r`。不过发现有了之后还是会出现前面的问题。查了下，发现原因是旧版本的vm-tools会去linux/version.h中找一个宏定义UTS_VERSION，以前这个宏定义放在linux/version.h，但是现在放在generated/utsrelease.h，把这个宏定义拷过去就好了。 有可能会说找不到linux/autoconf.h，也同样在generated目录中，拷出来就可以了。]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【解决】thinkpad没有break键 & win7远程桌面全屏与退出]]></title>
    <url>%2F201507%2Fwindows%2Fquit-mstsc-full-screen.html</url>
    <content type="text"><![CDATA[使用win7远程公司的电脑，但是全屏之后看不到中间那个最大化最小化的小条条了，不知道要怎么退出全屏的远程桌面。经查，有几个解决方法： 最简单粗暴的方法，能过QQ或其他办法让主机弹窗。 进入mstsc远程前，配置一下远程桌面的参数。选项-&gt;本地资源-&gt;键盘-&gt;选择应用Windows组合键在这台计算机上，这样进入远程桌面之后想切出来就可以直接用alt + ctrl或者其他各种方式。 使用快捷键ctrl + alt + break切换远程桌面全屏与退出。问题是，我的笔记本上没有break/pause键！搜了好久，才发现：thinkpad下（e420试验没错），Fn + p = pause, Fn + b = break。 玩dota的同学应该可以用warkey设一个break键出来； 像网上某些蛋疼的回答：搞个外接键盘，标准键盘都有。。 另外远程桌面默认不是全屏的，在mstsc远程前，配置选项-&gt;显示配置，把全屏滑动条拉到最右边就可以了。]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>远程登录</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【解决】Ubuntu 12.04启机到登陆界面后，在登陆界面死循环]]></title>
    <url>%2F201507%2Flinux%2Fubuntu-endless-loop-at-startup-greeter.html</url>
    <content type="text"><![CDATA[到登录界面后，即使密码正确输入之后，会直接返回登陆界面让你再输入密码，一直这样死循环，没有进入图形界面。 查看/var/log/upstart/lightdm.log有下面的提示： 123(process:1231): WARNING: Error reading existing Xauthority: Error opening file: Permission deniedError writing X authority: Error opening file '/home/xx/.Xauthority': Permission denied 原因是/home/xx/.Xauthority的owner和group都是root，把.Xauthority的这两个属性改成自己的用户名就可以了。 要养成出问题之后，多看/var下的记录的好习惯！]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MAC地址]]></title>
    <url>%2F201507%2Fnetworks%2Fmac.html</url>
    <content type="text"><![CDATA[概述MAC Address，Media Access Control Address，亦称为EHA（Ethernet Hardware Address）、硬件地址、物理地址（Physical Address）。在OSI节层模型中，属于第二层链路层概念。一个MAC地址唯一指定一台设备，全球唯一，并且通常烧写在固件中。 MAC地址由IEEE（Institute of Electrical and Electronics Engineers）定义，有三种：MAC-48、EUI-48、EUI-64。EUI， Extended Unique Identifier。 MAC-48，地址空间48比特，支持2^48即281,474,976,710,656个MAC地址。MAC-48的设计目标是一百年内够用。常以16进制数表示MAC地址，通用表示方法有三种格式，如01-23-45-67-89-ab、01:23:45:67:89:ab和0123.4567.89ab。 组成MAC地址如下图所示，其前3字节表示OUI（Organizationally Unique Identifier），由IEEE的注册管理机构给不同厂家分配的代码，区分不同的厂家，附IEEE当前OUI分配。后3字节由厂家自行分配。 MAC地址最高字节（MSB）的低第二位（LSb）表示这个MAC地址是全局的还是本地的，即U/L（Universal/Local）位，如果为0，表示是全局地址。所有的OUI这一位都是0。 MAC地址最高字节（MSB）的低第一位(LSb），表示这个MAC地址是单播还是多播。0表示单播。 MAC-48、EUI-48与EUI-64的关系疑问： EUI-48 MA-L、MA-M、MA-S有没有可能冲突？ EUI-48的MA-M/MA-S的应用？ EUI-48IEEE的《Guidelines for 48-Bit Global Identifier (EUI-48)》对EUI-48标识符的使用范围进行定义： 用为IEEE 802或类IEEE 802网络设备的硬件地址。 用为特定硬件设备的标识，不需要为网络设备。 EUI-48有三种格式： 前24位由IEEE Registration Authority (IEEE RA) 分配，后24位由MA-L（MAC Address Block Large）的厂商或组织分配。这种格式即MAC-48。 前28位由IEEE RA分配，后20位由MA-M（MAC Address Block Medium）的厂商或组织分配。 前36位由IEEE RA分配，后12位由MA-S（MAC Address Block Small）分配。 EUI-64待整理 应用（来自wikipedia） ###MAC-48### Ethernet 802.11 wireless networks Bluetooth IEEE 802.5 token ring most other IEEE 802 networks Fiber Distributed Data Interface (FDDI) Asynchronous Transfer Mode (ATM), switched virtual connections only, as part of an NSAP address Fibre Channel and Serial Attached SCSI (as part of a World Wide Name) The ITU-T G.hn standard, which provides a way to create a high-speed (up to 1 gigabit/s) local area network using existing home wiring (power lines, phone lines and coaxial cables). The G.hn Application Protocol Convergence (APC) layer accepts Ethernet frames that use the MAC-48 format and encapsulates them into G.hn Medium Access Control Service Data Units (MSDUs). EUI-64 FireWire IPv6 (Modified EUI-64 as the least-significant 64 bits of a unicast network address or link-local address when stateless autoconfiguration is used) ZigBee / 802.15.4 / 6LoWPAN wireless personal-area networks 特殊MAC地址###广播地址###全F，在本VLAN内泛洪。 ###IANA注册###详见ethernet-numbers，此处仅截取常见地址。 ####单播地址####以00-00-5e开头： 00-01-00 to 00-01-FF VRRP (Virtual Router Redundancy Protocol) [RFC5798] 00-02-00 to 00-02-FF VRRP IPv6 (Virtual Router Redundancy Protocol IPv6) [RFC5798] 90-01-00 TRILL OAM [RFC7455] ####组播地址####以01-00-5e开头： 00-00-00 to 7F-FF-FF IPv4 Multicast [RFC1112] 80-00-00 to 8F-FF-FF MPLS Multicast [RFC5332] 90-00-00 MPLS-TP p2p [RFC7213] 90-00-01 Bidirectional Forwarding Detection (BFD) on Link Aggregation Group (LAG) Interfaces [RFC7130] 90-01-00 TRILL OAM [RFC7455] 映射组播IP为组播MAC地址转换如下图（来自微软）所示，IPv4组播MAC地址为IANA定义，前25位固定。而组播IP为D类IP地址，其前4位固定为1110b。将组播IP的低23位直接映射到MAC地址的低23位，即可与前面固定的25位组成一个48位的MAC地址。 由于组播IP还有5位没有映射到MAC地址中，因此组播MAC地址与组播IP不是一一映射，而是一对多的关系，一个组播MAC地址对应32位组播IP地址。 Written with StackEdit.]]></content>
      <categories>
        <category>networks</category>
      </categories>
      <tags>
        <tag>L2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GDB使用记录]]></title>
    <url>%2F201506%2Fprogrammer%2Ftools%2Fgdb.html</url>
    <content type="text"><![CDATA[简介GDB，GNU Debugger，特性如下： GDB具备各种调试功效，可对计算机程序的运行进行追踪、警告。使用者可以监控及修改程序内部变量的值，甚至可在程序的正常运行之外调用函数。 GDB支持多数处理器架构 持续开发中 支持远程调试 支持内核调试，KGDB 从事嵌入式软件开发两年来，主要在以下几方面使用GDB： 查看、修改运行时变量； 多线程调试，查看当前线程运行状态（以确定当前线程是不是因为等锁等原因挂起）； 查看coredump文件； 碰到难缠的内存非法改写问题，用GDB的断点、物理watch功能查看内存变化以定位改写者； 引用公司一个技术牛人的话：在大型的项目中，使用GDB的单步调试、软件watch是不现实的，因为会运行得实在太慢。 命令小记： 123456789101112131415161718192021222324linux提示符1. GDB进入正在运行的进程 gdb 可执行文件 core文件 gdb -p pid GDB提示符1. 查看调用栈信息 bt / backtrace / bt full frame n info locals info args2. 查看、设置变量 p 变量 p 变量 = 新值 set 变量 = 新值 3. 查看内存 x/&lt;n/f/u&gt; &lt;addr&gt;4. 线程调试 info thread thread n thread apply all bt full 启动GDBGCC选项想用GDB调试，则在GCC编译的时候要加上-g选项。 启动GDB启动GDB的方法主要有以下几种： gdb gdb executable_file gdb executable_file corefile：查看coredump文件信息，定位coredump产生原因、触发源。 gdb attach pid：调度运行时的进程或线程，同gdb -p pid。 善用help在GDB提示符下输入help或help 命令，能够查看命令的帮助说明。 123456789101112131415161718192021(gdb) helpList of classes of commands:aliases -- Aliases of other commandsbreakpoints -- Making program stop at certain pointsdata -- Examining datafiles -- Specifying and examining filesinternals -- Maintenance commandsobscure -- Obscure featuresrunning -- Running the programstack -- Examining the stackstatus -- Status inquiriessupport -- Support facilitiestracepoints -- Tracing of program execution without stopping the programuser-defined -- User-defined commandsType "help" followed by a class name for a list of commands in that class.Type "help all" for the list of all commands.Type "help" followed by command name for full documentation.Type "apropos word" to search for commands related to "word".Command name abbreviations are allowed if unambiguous. 查看调用栈写一个简单的例子（仅为样例，并不严谨）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;stdbool.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include &lt;assert.h&gt;#include &lt;sys/prctl.h&gt;typedef struct &#123; int member_a; int member_b;&#125; test_t;int g_int;bool g_bool;char *g_str[] = &#123; "Hello, GDB!", "It's funny."&#125;;void stay_here(int arg, test_t *test)&#123; int local; local = 100; while (true) &#123; local++; if (local % 200 == 0) &#123; local = 0; &#125; sleep(1); &#125; return;&#125;void *thread_process(void *arg)&#123; int in; char name[64]; in = (int)arg; (void)snprintf(name, 64, "test-%d", in + 1); prctl(PR_SET_NAME, (unsigned long)name); /* set thread name */ while (true) &#123; sleep(2); &#125; return NULL;&#125;void create_thread(void)&#123; int i, rv; pthread_t tid; for (i = 0; i &lt; 5; i++) &#123; rv = pthread_create(&amp;tid, NULL, thread_process, (void *)i); assert(rv == 0); &#125;&#125;int main(int argc, char **argv)&#123; int local; test_t test; local = 999; test.member_a = 10; test.member_b = 11; create_thread(); stay_here(local, &amp;test); return 0;&#125; 编译并运行起来，注意gcc的-g选项，这里使用&amp;让程序运行到后台，[1] 8043指刚刚这个程序运行时的进程号，也可用ps命令查看。 123456789sunnogo@a3e420:~/test/gdb$ gcc -o prt_mod_var prt_mod_var.c -g -Wall -lpthreadsunnogo@a3e420:~/test/gdb$ sunnogo@a3e420:~/test/gdb$ lsprt_mod_var prt_mod_var.csunnogo@a3e420:~/test/gdb$ ./prt_mod_var &amp;[1] 8043sunnogo@a3e420:~/test/gdb$ sunnogo@a3e420:~/test/gdb$ ps -e | grep prt_mod_var 8043 pts/1 00:00:00 prt_mod_var 接下来使用gdb -p 8043连入正在运行的进程中。还不明白为什么我的计算机中要求使用root权限才能让GDB attach到对应进程。 12345678910111213141516sunnogo@a3e420:~/test/gdb$ gdb -p 8043GNU gdb (GDB) 7.5-ubuntuCopyright (C) 2012 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "i686-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Attaching to process 8043Could not attach to process. If your uid matches the uid of the targetprocess, check the setting of /proc/sys/kernel/yama/ptrace_scope, or tryagain as the root user. For more details, see /etc/sysctl.d/10-ptrace.confptrace: Operation not permitted.(gdb) quit 重新sudo gdb -p pid进入进程。 使用bt查看当前调用栈信息（call stack，即函数调用层次信息），当前进程的是由main() -&gt; sleep() -&gt; nanosleep() -&gt; __kernel_vsyscall()一层一层调入。注意“#数字”，在GDB中这叫stack frames，或直接称为frame，运行栈由一个或多个连续的frame组成，数字越小代表调用层次越深。 使用bt full查看详细调用栈信息，会把各个frame的入参和局部变量信息显示出来。这里bt是backtrace的缩写，GDB的全命令经常有其简短的写法。 注意：GDB中，按回车默认是执行上一次命令。先MARK下面的“No symbol table info available.” 123456789101112131415161718192021222324252627282930313233343536sunnogo@a3e420:~/test/gdb$ sudo gdb -p 8043[sudo] password for sunnogo: GNU gdb (GDB) 7.5-ubuntuCopyright (C) 2012 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "i686-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Attaching to process 8043Reading symbols from /home/sunnogo/test/gdb/prt_mod_var...done.Reading symbols from /lib/i386-linux-gnu/libc.so.6...(no debugging symbols found)...done.Loaded symbols for /lib/i386-linux-gnu/libc.so.6Reading symbols from /lib/ld-linux.so.2...(no debugging symbols found)...done.Loaded symbols for /lib/ld-linux.so.20xb7751424 in __kernel_vsyscall ()(gdb) bt #0 0xb7751424 in __kernel_vsyscall ()#1 0xb7640ce0 in nanosleep () from /lib/i386-linux-gnu/libc.so.6#2 0xb7640aff in sleep () from /lib/i386-linux-gnu/libc.so.6#3 0x0804845b in stay_here (arg=999, test=0xbf8e5118) at prt_mod_var.c:26#4 0x08048492 in main (argc=1, argv=0xbf8e51c4) at prt_mod_var.c:41(gdb) bt full#0 0xb7751424 in __kernel_vsyscall ()No symbol table info available.#1 0xb7640ce0 in nanosleep () from /lib/i386-linux-gnu/libc.so.6No symbol table info available.#2 0xb7640aff in sleep () from /lib/i386-linux-gnu/libc.so.6No symbol table info available.#3 0x0804845b in stay_here (arg=999, test=0xbf8e5118) at prt_mod_var.c:26 local = 113#4 0x08048492 in main (argc=1, argv=0xbf8e51c4) at prt_mod_var.c:41 local = 999 test = &#123;member_a = 10, member_b = 11&#125; 使用frame n进入“#n”的frame。默认显示当前函数名、函数入参、当前运行处所在源文件的代码行位置，并显示当前行代码。 使用info命令查看frame详细信息，info命令不是全命令，后面还有子命令。info有很多子命令，除本frame外，还可以查看本进程信息、系统信息，这里仅仅是冰山一角。 info frame 显示当前frame信息 info args 显示入参信息 info local 显示局部变量信息 123456789101112131415161718(gdb) frame 3#3 0x0804845b in stay_here (arg=999, test=0xbf8e5118) at prt_mod_var.c:2626 sleep(1);(gdb) info frameStack level 3, frame at 0xbf8e5100: eip = 0x804845b in stay_here (prt_mod_var.c:26); saved eip 0x8048492 called by frame at 0xbf8e5130, caller of frame at 0xbf8e50d0 source language c. Arglist at 0xbf8e50f8, args: arg=999, test=0xbf8e5118 Locals at 0xbf8e50f8, Previous frame's sp is 0xbf8e5100 Saved registers: ebx at 0xbf8e50f4, ebp at 0xbf8e50f8, eip at 0xbf8e50fc(gdb) info argsarg = 999test = 0xbf8e5118(gdb) info locallocal = 113(gdb) 查看、修改变量p var查看变量信息，p是print的缩写。 p var p *(指针类型)地址 p *结构体指针 p 数组名 1234567891011121314151617181920212223242526# 打印变量 (gdb) p g_int$3 = 0(gdb) p g_bool$4 = false# 打印特定类型指针(gdb) info locallocal = 113(gdb) p &amp;local$11 = (int *) 0xbf8e50ec(gdb) p *(int *) 0xbf8e50ec$12 = 113(gdb) # 打印结构体指针(gdb) p test$1 = (test_t *) 0xbf8e5118(gdb) p *test$2 = &#123;member_a = 10, member_b = 11&#125;# 打印数组名(gdb) p g_str$5 = &#123;0x8048538 "Hello, GDB!", 0x8048544 "It's funny."&#125;(gdb) p g_str[0]$6 = 0x8048538 "Hello, GDB!" print不仅可以用来查看变量，还可用于设置变量。print var=value。设置变量值的命令还有set，set var=value。 123456789101112131415161718192021222324252627# set int(gdb) print local$1 = 109(gdb) print local=20$2 = 20(gdb) print local$3 = 20(gdb) set local=30(gdb) print local$4 = 30# set bool(gdb) print g_bool$5 = false(gdb) set g_bool=trueNo symbol "true" in current context.(gdb) set g_bool=1(gdb) print g_bool$6 = true# set pointer(gdb) print g_str$7 = &#123;0x8048538 "Hello, GDB!", 0x8048544 "It's funny."&#125;(gdb) set g_str[0]="SETTING VAR"(gdb) print g_str$8 = &#123;0x8e05008 "SETTING VAR", 0x8048544 "It's funny."&#125;(gdb) 查看内存examine查看内存，缩写是x。命令格式： 1x/&lt;n/f/u&gt; &lt;addr&gt; n、f、u是可选参数，说明如下： 12345678910111213(gdb) help xExamine memory: x/FMT ADDRESS.ADDRESS is an expression for the memory address to examine.FMT is a repeat count followed by a format letter and a size letter.Format letters are o(octal), x(hex), d(decimal), u(unsigned decimal), t(binary), f(float), a(address), i(instruction), c(char) and s(string).Size letters are b(byte), h(halfword), w(word), g(giant, 8 bytes).The specified number of objects of the specified size are printedaccording to the format.Defaults for format and size letters are those previously used.Default count is 1. Default address is following last thing printedwith this command or "print". n表示要打印的多少个单位的内存，默认是1，单位由u定义； f表示打印的格式，格式有： o，octal，八进制； x，hex，十六进制； d，decimal，十进制； u，unsigned decimal，无符号十进制； t，binary，二进制； f，float； a，address； i，instruction，指令； c，char，字符； s，string，字符串。 u定义单位，b表示1字节，h表示2字节，w表示4字节，g表示8字节。 123456789101112131415161718192021222324252627282930313233343536373839404142# 当前CPU是intel i3，小端# 以十进制形式打印(gdb) x/8db test0xbf8e5118: 10 0 0 0 11 0 0 0(gdb) x/4dh test0xbf8e5118: 10 0 11 0(gdb) x/2dw test0xbf8e5118: 10 11(gdb) x/2d test0xbf8e5118: 10 11(gdb) x/1dg test0xbf8e5118: 47244640266 # 注意和x/1xg test的结果比较# 以二进制形式打印(gdb) x/1tg test0xbf8e5118: 0000000000000000000000000000101100000000000000000000000000001010(gdb) x/2tw test0xbf8e5118: 00000000000000000000000000001010 00000000000000000000000000001011(gdb) x/4th test0xbf8e5118: 0000000000001010 0000000000000000 0000000000001011 0000000000000000(gdb) x/8tb test0xbf8e5118: 00001010 00000000 00000000 00000000 00001011 0000000000000000 00000000# 以十六进制形式打印(gdb) x/8xb test0xbf8e5118: 0x0a 0x00 0x00 0x00 0x0b 0x00 0x00 0x00(gdb) x/4xh test0xbf8e5118: 0x000a 0x0000 0x000b 0x0000(gdb) x/2xw test0xbf8e5118: 0x0000000a 0x0000000b(gdb) x/1xg test0xbf8e5118: 0x0000000b0000000a# 打印字符或字符串(gdb) x/30cb g_str[0]0x8048538: 72 'H' 101 'e' 108 'l' 108 'l' 111 'o' 44 ',' 32 ' ' 71 'G'0x8048540: 68 'D' 66 'B' 33 '!' 0 '\000' 73 'I' 116 't' 39 '\'' 115 's'0x8048548: 32 ' ' 102 'f' 117 'u' 110 'n' 110 'n' 121 'y' 46 '.' 0 '\000'0x8048550: 1 '\001' 27 '\033' 3 '\003' 59 ';' 56 '8' 0 '\000'(gdb) x/s g_str[0]0x8048538: "Hello, GDB!" 查看线程信息有两种方法可以进入线程调试： 设置线程名，用ps查看母进程的线程信息，获取tid，再启动GDB进入； 直接启动GDB调试母进程，info thread查看所有线程信息，获取到想要的线程的GDB内部编号n，thread n进入线程的调用栈。 直接获取、调试线程上面样例中创建5条线程，并使用prctl函数为每条线程命名为”test-n”。这样可以通过ps -eL | grep test（或者test进程的pid）来查看刚创建的线程的tid。然后gdb -p tid进入线程调度。这里进入编号为4的线程。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748sunnogo@a3e420:~/test/gdb$ gcc -o test test.c -g -Wall -lpthreadsunnogo@a3e420:~/test/gdb$ ./test &amp;[2] 16427sunnogo@a3e420:~/test/gdb$ ps -eL | grep test16427 16427 pts/1 00:00:00 test16427 16428 pts/1 00:00:00 test-116427 16429 pts/1 00:00:00 test-216427 16430 pts/1 00:00:00 test-316427 16431 pts/1 00:00:00 test-416427 16432 pts/1 00:00:00 test-5sunnogo@a3e420:~/test/gdb$ sudo gdb -p 16431GNU gdb (GDB) 7.5-ubuntuCopyright (C) 2012 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "i686-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Attaching to process 16431warning: process 16431 is a cloned processReading symbols from /home/sunnogo/test/gdb/test...done.Reading symbols from /lib/i386-linux-gnu/libpthread.so.0...(no debugging symbols found)...done.[Thread debugging using libthread_db enabled]Using host libthread_db library "/lib/i386-linux-gnu/libthread_db.so.1".Loaded symbols for /lib/i386-linux-gnu/libpthread.so.0Reading symbols from /lib/i386-linux-gnu/libc.so.6...(no debugging symbols found)...done.Loaded symbols for /lib/i386-linux-gnu/libc.so.6Reading symbols from /lib/ld-linux.so.2...(no debugging symbols found)...done.Loaded symbols for /lib/ld-linux.so.20xb774f424 in __kernel_vsyscall ()(gdb) bt full#0 0xb774f424 in __kernel_vsyscall ()No symbol table info available.#1 0xb7623d06 in nanosleep () from /lib/i386-linux-gnu/libc.so.6No symbol table info available.#2 0xb7623aff in sleep () from /lib/i386-linux-gnu/libc.so.6No symbol table info available.#3 0x080485ee in thread_process (arg=0x3) at test.c:46 in = 3 name = "test-4", '\000' &lt;repeats 57 times&gt;#4 0xb771cd4c in start_thread () from /lib/i386-linux-gnu/libpthread.so.0No symbol table info available.#5 0xb765abae in clone () from /lib/i386-linux-gnu/libc.so.6No symbol table info available.(gdb) 间接获取、调试线程注意和上一种方法的对比，相比起来，第一种方法要方便得多。也从侧面看出为每个线程命名的重要性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162sunnogo@a3e420:~/test/gdb$ nnogo@a3e420:~/test/gdb$ sudo gdb attach 16427GNU gdb (GDB) 7.5-ubuntuCopyright (C) 2012 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "i686-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...attach: No such file or directory.Attaching to process 16427Reading symbols from /home/sunnogo/test/gdb/test...done.Reading symbols from /lib/i386-linux-gnu/libpthread.so.0...(no debugging symbols found)...done.[New LWP 16432][New LWP 16431][New LWP 16430][New LWP 16429][New LWP 16428][Thread debugging using libthread_db enabled]Using host libthread_db library "/lib/i386-linux-gnu/libthread_db.so.1".Loaded symbols for /lib/i386-linux-gnu/libpthread.so.0Reading symbols from /lib/i386-linux-gnu/libc.so.6...(no debugging symbols found)...done.Loaded symbols for /lib/i386-linux-gnu/libc.so.6Reading symbols from /lib/ld-linux.so.2...(no debugging symbols found)...done.Loaded symbols for /lib/ld-linux.so.20xb774f424 in __kernel_vsyscall ()(gdb) info thread Id Target Id Frame 6 Thread 0xb7568b40 (LWP 16428) "test-1" 0xb774f424 in __kernel_vsyscall () 5 Thread 0xb6d67b40 (LWP 16429) "test-2" 0xb774f424 in __kernel_vsyscall () 4 Thread 0xb6566b40 (LWP 16430) "test-3" 0xb774f424 in __kernel_vsyscall () 3 Thread 0xb5d65b40 (LWP 16431) "test-4" 0xb774f424 in __kernel_vsyscall () 2 Thread 0xb5564b40 (LWP 16432) "test-5" 0xb774f424 in __kernel_vsyscall ()* 1 Thread 0xb75696c0 (LWP 16427) "test" 0xb774f424 in __kernel_vsyscall ()(gdb) thread 3[Switching to thread 3 (Thread 0xb5d65b40 (LWP 16431))]#0 0xb774f424 in __kernel_vsyscall ()(gdb) bt full#0 0xb774f424 in __kernel_vsyscall ()No symbol table info available.#1 0xb7623d06 in nanosleep () from /lib/i386-linux-gnu/libc.so.6No symbol table info available.#2 0xb7623aff in sleep () from /lib/i386-linux-gnu/libc.so.6No symbol table info available.#3 0x080485ee in thread_process (arg=0x3) at test.c:46 in = 3 name = "test-4", '\000' &lt;repeats 57 times&gt;#4 0xb771cd4c in start_thread () from /lib/i386-linux-gnu/libpthread.so.0No symbol table info available.#5 0xb765abae in clone () from /lib/i386-linux-gnu/libc.so.6No symbol table info available.(gdb) qA debugging session is active. Inferior 1 [process 16427] will be detached.Quit anyway? (y or n) yDetaching from program: /home/sunnogo/test/gdb/test, process 16427sunnogo@a3e420:~/test/gdb$ sunnogo@a3e420:~/test/gdb$ 查看所有线程堆栈使用 thread apply all bt full，查看所有线程的堆栈，如果线程多，可能会产生短暂刷屏。 gdb中调用调用函数call func_name(param1, param2, ...)，目前还没有明白如果参数是结构体要怎么整。注意，只能在进程上下文中才能使用，coredump中无法使用。 gdb中申请内存p malloc(size)，结果会返回一个指针，即可正常使用这个指针。注意，只能在进程上下文中才能使用，coredump中无法使用。如下例： 1234(gdb) p malloc(4)[New Thread 0x693ff460 (LWP 2033)][Switching to Thread 0xb6101000 (LWP 1456)]$1 = (void *) 0xb58d01e0 &lt;----使用这个返回的指针。 查看寄存器信息to-do GDB反汇编to-do 断点设置to-do 内存监控to-do GCC选项对GDB的影响GCC -g选项的影响注意上面的，如果gcc编译的时候不加-g选项，那么frame 3也会显示“No symbol table info available.”，无符号表信息可用，全局变量g_str也打不出来。 12345678910111213141516(gdb) bt full#0 0xb77a3424 in __kernel_vsyscall ()No symbol table info available.#1 0xb7692ce0 in nanosleep () from /lib/i386-linux-gnu/libc.so.6No symbol table info available.#2 0xb7692aff in sleep () from /lib/i386-linux-gnu/libc.so.6No symbol table info available.#3 0x08048462 in main ()No symbol table info available.(gdb) p g_str$1 = 134513928(gdb) p g_str[0]cannot subscript something of type `&lt;data variable, no debug info&gt;'(gdb) p g_bool$2 = 0(gdb) GCC -fomit-frame-pointer选项的影响]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>调试</tag>
        <tag>GDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git quick start]]></title>
    <url>%2F201504%2Ftools%2Fgit-quick-start.html</url>
    <content type="text"><![CDATA[git - the stupid content tracker 这里讲GIT命令行客户端工具如何使用，不涉及GIT服务器如何部署。 入门操作本节内容完全引用自《git - 简易指南》，作者：罗杰·杜德勒。如该文一开始所述：“助你开始使用 git 的简易指南，木有高深内容，;)”。 这个网站很酷炫，建议直接点进去看。 下载代码（检出仓库）执行如下命令以创建一个本地仓库的克隆版本：1git clone /path/to/repository 如果是远端服务器上的仓库，你的命令会是这个样子：1git clone username@host:/path/to/repository 工作流你的本地仓库由 git 维护的三棵“树”组成。第一个是你的 工作目录，它持有实际文件；第二个是 缓存区（Index），它像个缓存区域，临时保存你的改动；最后是 HEAD，指向你最近一次提交后的结果。 添加与提交你可以计划改动（把它们添加到缓存区），使用如下命令：12git add &lt;filename&gt;git add * 这是 git 基本工作流程的第一步；使用如下命令以实际提交改动：1git commit -m "代码提交信息" 现在，你的改动已经提交到了 HEAD，但是还没到你的远端仓库。 推送改动推送改动你的改动现在已经在本地仓库的 HEAD 中了。执行如下命令以将这些改动提交到远端仓库：1git push origin master 可以把 master 换成你想要推送的任何分支。 如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加：1git remote add origin &lt;server&gt; 如此你就能够将你的改动推送到所添加的服务器上去了。 分支分支是用来将特性开发绝缘开来的。在你创建仓库的时候，master 是“默认的”。在其他分支上进行开发，完成后再将它们合并到主分支上。 创建一个叫做“feature_x”的分支，并切换过去：1git checkout -b feature_x 切换回主分支：1git checkout master 再把新建的分支删掉：1git branch -d feature_x 除非你将分支推送到远端仓库，不然该分支就是 不为他人所见的：1git push origin &lt;branch&gt; 更新与合并要更新你的本地仓库至最新改动，执行：1git pull 以在你的工作目录中 获取（fetch） 并 合并（merge） 远端的改动。要合并其他分支到你的当前分支（例如 master），执行：1git merge &lt;branch&gt; 两种情况下，git 都会尝试去自动合并改动。不幸的是，自动合并并非次次都能成功，并可能导致 冲突（conflicts）。 这时候就需要你修改这些文件来人肉合并这些 冲突（conflicts） 了。改完之后，你需要执行如下命令以将它们标记为合并成功：1git add &lt;filename&gt; 在合并改动之前，也可以使用如下命令查看：1git diff &lt;source_branch&gt; &lt;target_branch&gt; 标签在软件发布时创建标签，是被推荐的。这是个旧有概念，在 SVN 中也有。可以执行如下命令以创建一个叫做 1.0.0 的标签：1git tag 1.0.0 1b2e1d63ff 1b2e1d63ff 是你想要标记的提交 ID 的前 10 位字符。使用如下命令获取提交 ID：1git log 你也可以用该提交 ID 的少一些的前几位，只要它是唯一的。 替换本地改动替换本地改动假如你做错事（自然，这是不可能的），你可以使用如下命令替换掉本地改动：1git checkout -- &lt;filename&gt; 此命令会使用 HEAD 中的最新内容替换掉你的工作目录中的文件。已添加到缓存区的改动，以及新文件，都不受影响。 假如你想要丢弃你所有的本地改动与提交，可以到服务器上获取最新的版本并将你本地主分支指向到它：12git fetch origingit reset --hard origin/master GIT与SVN的差异本节大部分内容引用自《GIT和SVN之间的五个基本区别》： 仓库管理方式GIT是分布式的，SVN是集中式的。GIT代码clone下来之后，就是一个完整的仓库，本地不管在线或离线，都可以提交修订（到本地仓库）、查看历史版本、创建分支等。而SVN是集中式管理，如果离线，则几乎无法进行任何工作，不能查看历史版本、不能查看log、不能提交修订… 现在还不理解这段话 同样，这种分布式的操作模式对于开源软件社区的开发来说也是个巨大的恩赐，你不必再像以前那样做出补丁包，通过email方式发送出去，你只需要创建一个分支，向项目团队发送一个推请求。这能让你的代码保持最新，而且不会在传输过程中丢失。GitHub.com就是一个这样的优秀案例。 内容存储方式GIT把内容按元数据方式存储，而SVN是按文件。 什么是元数据（metadata, data about data）？可通过计算机中的文件来理解，如本文，存储为git.md，其真实数据就是展现在各位面前的内容。而在系统中，为方便文件系统管理，会为该文件生成一些元数据，使用stat命令查看git.md的元数据，包含文件名、inode、文件大小、文件实际占用的block数、相关时间参数等。 元数据最大的好处是，它使信息的描述和分类可以实现格式化，从而为机器处理创造了可能。By startwithdp from csdn.net 12345678910111213141516sunnogo@a3e420:~/github/hexo/source/_posts/tools$ stat git.md File: ‘git.md’ Size: 8491 Blocks: 24 IO Block: 4096 regular fileDevice: 805h/2053d Inode: 8654069 Links: 1Access: (0664/-rw-rw-r--) Uid: ( 1000/ sunnogo) Gid: ( 1000/ sunnogo)Access: 2015-04-27 21:51:35.120007595 +0800Modify: 2015-04-27 21:51:34.120007554 +0800Change: 2015-04-27 21:51:34.164007556 +0800 Birth: -sunnogo@a3e420:~/github/hexo/source/_posts/tools$ stat -f git.md File: "git.md" ID: 212ada8747b1ce3b Namelen: 255 Type: ext2/ext3Block size: 4096 Fundamental block size: 4096Blocks: Total: 48028567 Free: 23741023 Available: 21295532Inodes: Total: 12214272 Free: 11218615 这段话也还不理解： 所有的资源控制系统都是把文件的元信息隐藏在一个类似.svn、.cvs等的文件夹里。如果你把.git目录的 体积大小跟.svn比较，你会发现它们差距很大。因为.git目录是处于你的机器上的一个克隆版的版本库，它拥有中心版本库上所有的东西，例如标签、分支、版本记录等。 分支SVN的分支看着相对简单，就是版本库中的另一个目录。 目前公司的SVN、GIT版本策略不是严格的branch/trunk/tags，分支太散太多，碎片太多，合代码相对难。有用过svn merge同步分支代码，但是还未用过直接整分支修订同步的命令，也不清楚有没有类似命令。 你需要手工运行像这样的命令svn propget svn:mergeinfo，来确认代码是否被合并。所以，经常会发生有些分支被遗漏的情况。 然而，处理GIT的分支却是相当的简单和有趣。你可以从同一个工作目录下快速的在几个分支间切换。你很容易发现未被合并的分支，你能简单而快捷的合并这些文件。 版本号SVN采用递增的全局版本号，GIT使用SHA-1来唯一标识一个代码快照。SVN的版本号很好理解，一次提交，本仓库的版本号就加1。 SVN从原始文件开始，每次记录有哪些文件作了更新，以及更新了哪些行的内容。GIT不一样，GIT不保存这些前后变化的差异数据，更像是把变化的文件作快照后，记录在一个微型的文件系统中。每次提交更新时，它会纵览一遍所有文件的指纹信息并对文件作一快照，然后保存一个指向这次快照的索引。为提高性能，若文件没有变化，GIT不会再次保存，而只对上次保存的快照作一链接。问题：GIT快照是基于单一文件的，还是基于整个分支的？ 数据完整性GIT的SHA-1校验，能保证仓库的完整性。所有保存在GIT数据库中的东西都是使用此哈希值来作索引，而不是靠文件名。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>版本控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行查看当前内存使用情况 - free]]></title>
    <url>%2F201504%2Fshell%2Ffree.html</url>
    <content type="text"><![CDATA[free - Display amount of free and used memory in the system. 常见选项和样例 -h，即--human-readable，显示的单位为大家熟悉的K/M/G等。 -s second，持续显示内存使用情况，每隔second秒输出一次。 -c count，与-s同时使用，表示持续输出的次数。 123456789101112131415161718192021222324252627282930313233343536373839401) 不带参数时，输出的单位是byte。sunnogo@a3e420:~$ free total used free shared buffers cachedMem: 4039288 2005376 2033912 71920 353564 980252-/+ buffers/cache: 671560 3367728Swap: 7811068 0 78110682) -h参数sunnogo@a3e420:~$ free -h total used free shared buffers cachedMem: 3.9G 1.9G 1.9G 70M 345M 957M-/+ buffers/cache: 655M 3.2GSwap: 7.4G 0B 7.4G3) 持续输出，这里的样例输出两次直接手动ctrl + c退出。sunnogo@a3e420:~$free -hs 3 total used free shared buffers cachedMem: 3.9G 1.9G 1.9G 70M 345M 957M-/+ buffers/cache: 655M 3.2GSwap: 7.4G 0B 7.4G total used free shared buffers cachedMem: 3.9G 1.9G 1.9G 70M 345M 957M-/+ buffers/cache: 655M 3.2GSwap: 7.4G 0B 7.4G^C4) 带输出次数的持续输出。sunnogo@a3e420:~$ free -hs 3 -c 2 total used free shared buffers cachedMem: 3.9G 1.9G 1.9G 70M 345M 957M-/+ buffers/cache: 655M 3.2GSwap: 7.4G 0B 7.4G total used free shared buffers cachedMem: 3.9G 1.9G 1.9G 70M 345M 957M-/+ buffers/cache: 656M 3.2GSwap: 7.4G 0B 7.4Gsunnogo@a3e420:~/github/hexo/source/_posts/shell$ 命令含义free命令显示结果的含义，该命令读自/proc/meminfo，这里只简解free命令用到的内容，待后续再进行补充说明。 total，即所有可用内存，值为物理内存扣掉一些保留的比特位（多少？）及解压后放到内存中的内核。 used（“Mem:”行），扣除空闲内存（free）后的内存容量。 free（“Mem:”行），LowFree和HighFree之和，系统当前未使用的内存总量。 HighFree，该区域不是直接映射到内核空间。内核必须使用不同的手法使用该段内存。(Starting with Linux 2.6.19, CONFIG_HIGHMEM is required.) Total amount of highmem. Highmem is all memory above ~860MB of physical memory. Highmem areas are for use by user-space programs, or for the page cache. The kernel must use tricks to access this memory, making it slower to access than lowmem. LowFree，低位可以达到高位内存一样的作用，而且它还能够被内核用来记录一些自己的数据结构。(Starting with Linux 2.6.19, CONFIG_HIGHMEM is required.) Total amount of lowmem. Lowmem is memory which can be used for everything that highmem can be used for, but it is also available for the kernel’s use for its own data structures. Among many other things, it is where everything from Slab is allocated. Bad things happen when you’re out of lowmem. shared，仅共享内存？还是所有进程间通信资源的总和？ buffers，用来给文件做缓冲大小。 Relatively temporary storage for raw disk blocks that shouldn’t get tremendously large (20MB or so). cached，被高速缓冲存储器（cache memory）用的内存的大小（等于diskcache minus SwapCache）. swap，swap分区的使用情况，swap分区在磁盘分区时确定。被高速缓冲存储器（cache memory）用的交换空间的大小已经被交换出来的内存，但仍然被存放在swapfile中。用来在需要的时候很快被替换而不需要再次打开I/O端口。Memory that once was swapped out, is swapped back in but still also is in the swap file. (If memory pressure is high, these pages don’t need to be swapped out again because they are already in the swap file. This saves I/O.)。 used（“-/+ buffers/cache:”行），used[2] = used[1] - buffers - cached free（“-/+ buffers/cache:”行），free[2] = free[1] + buffers + cached 如何清 cached 和 buffers ？1$ sudo sysctl -w vm.drop_caches=3 drop_caches 的含义，见 man proc： 1234567891011121314151617181920/proc/sys/vm/drop_caches (since Linux 2.6.16) Writing to this file causes the kernel to drop clean caches, dentries, and inodes from memory, causing that memory to become free. This can be useful for memory management testing and performing reproducible filesystem benchmarks. Because writing to this file causes the benefits of caching to be lost, it can degrade overall system performance. To free pagecache, use: echo 1 &gt; /proc/sys/vm/drop_caches To free dentries and inodes, use: echo 2 &gt; /proc/sys/vm/drop_caches To free pagecache, dentries and inodes, use: echo 3 &gt; /proc/sys/vm/drop_caches Because writing to this file is a nondestructive operation and dirty objects are not freeable, the user should run sync(1) first.]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>内存管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2015春节以来的一些思考]]></title>
    <url>%2F201503%2Flife%2Ftoughts-after-2015-spring-festival.html</url>
    <content type="text"><![CDATA[春节那天晚上，去发小家喝完酒回来，躺床上时，回顾自己毕业三年来的工作、生活，越想越不爽，最后竟禁不住地蒙住被子嚎啕大哭（据小妹统计，肖了半个来小时），后来发了那条“我TMD是个Fucking loser”的朋友圈。 现在静下心来，回顾一下自己毕业三年来成为一名loser的根本原因。 没有详尽的职业生涯规划，不知道自己真正想做什么，而有想法时却从未去实现过。到目前为止，还没有为自己定下方向。最近已经在思考，希望两个月内能给自己一个满意的答复。 对金钱一点概念没有，在看完《小狗钱钱》和《富爸爸穷爸爸》之后，有了少许的概念，但是还远远不够。 不敢冒险，不思改变。怕自己出去就找不到和现在这份工作相当报酬的活，而事实上是根本就没怎么找过。 什么事都过于认真。对波波和土豆说的“嬉笑怒骂、游戏人生”一点都不理解，一点都不洒脱。今年春节喝酒high够了才领略了那么一点点。 对职场还远远不够成熟，导致因为加薪啥的各种不爽。节前在厦门听老舍的一句话之后恍然大悟，“你想要多少工资，就要先干出对应工资的绩效”。这话太精辟了，想加薪想疯了吧，赶紧干活！ 春节以来自己有一些明显的进步： 做事情迅速，不拖延。 坚持健身，我也要拥有八块腹肌^_^！ 敢想。敢做。 没那么纠结了。 2014的目标没一个实现的（换工作到厦门、买单车、找个女朋友），好好设定一下2015年的目标： 不管换不换工作，一定要做好自己的职业规划，并考虑好三年内的计划。 不管怎么样，该相亲相亲去。 单车在4月份前买好，至少要骑满福建的所有地级市，可踢除现已实现的福州、莆田。 至少参与一个开源项目。 学车。 感谢1号节日里那一番推心置腹的谈话，我也会找到一条路，一条属于自己的、即使失败也不会说自己是loser的路。最后，还是给自己敲个：Good luck &amp; have fun!]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVN基础用法]]></title>
    <url>%2F201501%2Ftools%2Fsvn.html</url>
    <content type="text"><![CDATA[svn - Subversion command line client tool 这里讲SVN命令行客户端工具如何使用，不涉及SVN服务器如何部署。 创建新分支1svn copy src_url [-r version] dst_url [-m "message"] [--username your_name --password your_password] 如果不带-r version，则默认使用src_url的最新版本。version为数字，版本号。建议所有含提交功能的命令都要带-m message，这样才能通过log直接明了地看出这个版本提交了什么修订。 下载代码1svn checkout url -r version 从服务器仓库下载代码到本地，成为本地工作副本。 升级到新版本1svn update -r version 查看工作副本状态1svn status 第一列表示文件的状态： ，没有修订 A，添加 C，冲突，需要解决冲突状态，才能正常提交代码。 D，删除 I，忽略 M，有修改 ?，没有版本控制，在工作副本添加文件或目录之后，需要使用svn add your_path才能加该文件加到版本控制。 !，文件丢失，如果不是使用svn delete删除文件或目录，会产生此状态。 添加新文件或目录到版本控制12svn add file1 file2 ...svn add dir ... 使用Linux命令或在窗口下添加文件或目录后，需要使用本命令，才能将添加的文件或目录加入版本控制，svn提交时才能将该文件或目录提交到服务器。 删除文件或目录1svn delete your_path 如果仅仅是手动使用rm命令或窗口下删除工作副本内的文件或目录，该删除并不会记录svn的状态。可能会导致提交代码时，遗漏了删除文件或目录。因此建议删除svn工作副本内的文件或目录时，使用本命令进行操作。 重命名文件或目录1svn move src dst 问题：svn move重命名文件之后，再用svn diff打patch会发现只能打进删除文件的补丁，没有新增文件的内容，目前还不清楚svn move要如何打patch。例如： 12345678910111213141516171819202122sunnogo@a3e420:~/src/test$ svn statussunnogo@a3e420:~/src/test$ svn mv my.spec tmp.specA tmp.specD my.specsunnogo@a3e420:~/src/test$ svn statusD my.spec &gt; moved to tmp.specA + tmp.spec &gt; moved from my.specsunnogo@a3e420:~/src/test$ svn diffIndex: my.spec===================================================================--- my.spec (revision 11706)+++ my.spec (working copy)@@ -1,27 +0,0 @@-#ʹ����ȷ�������滻�ļ��а����ַ�'X'�ĵط�--Summary: my packages- 此处省略N行。-%attr(755,root,root)-/*sunnogo@a3e420:~/src/test$ 查看工作副本信息1svn info 能够查看到本工作副本的url、版本等信息。 生成patch1svn diff [file_list] 将工作副本的修订以patch的形式输出，常使用svn diff &gt; your_patch.patch输出patch。 打某个版本的patch1svn diff -r ver1:ver2 [file_list] 查看某两个版本中的修订，如果ver1大于ver2，则所输出的diff是回退代码的patch；如果ver2大于ver1，则所输出的patch是合并代码的patch。 应用补丁1svn patch your_patch.patch 提交代码1svn commit [-m message] [file_list] 如果没有带文件列表，则把工作副本的所有修订都提交，如果有带文件列表，则只提交文件列表中对应文件的修订。 合并代码1svn merge -r ver1:ver2 src_url working_copy_path 可将任意版本的任意修订合并到工作副本中。如果ver1小于ver2，表示合并src_url分支ver1到ver2的修订到本地工作副本；如果ver1大于ver2，表示回退修订。 另外也可以操作服务器仓库，把working_copy_path直接换成目的分支的url即可，但是这种做法比较危险，不建议新手直接使用。 注意，svn merge后的commit需要user同时拥有源分支和目的分支的权限才能提交。 回退工作副本的修订12svn revert file1 file2 ...svn revert -R dir 查看log1svn log [OPTIONS] [FILE_LIST] 会默认输出所有的log，不实用，需要使用参数过滤才能得到我们想要的内容。默认只查看工作副本及以前版本的log。 常用参数 -l n，只输出n个log信息； -v，显示修订的文件，默认不显示； -r ver，显示特定版本的log； -r ver1:ver2，显示版本ver1到ver2之间所有提交的log； -r {2013-01-01}:{2013-01-11}，显示日期间所有提交的log，-r选项的版本号和日期可以混用； --diff，除显示log信息外，还直接输出修订的内容； --search，根据当前输出的log信息，按关键字过滤log，该关键字可以匹配输出信息的任意字符串，比如可匹配到提交者、提交的log信息，如果带-v选项还可以匹配到修订的文件等。 --stop-on-copy，只显示当前分支的修订的log，不会回溯源基线分支修订的log。比如分支branch基于tags分支版本100创建，此时branch分支的svn log会默认显示tags分支版本100以前所有修订的log，而如果带上本选项，则只会显示branch分支自己修订的log。 svn版本信息导入execl表方法来自stackoverflow Use the following Subversion command to create an xml file out of the repository’s log: svn log -v --xml &gt; repository_log.xml，还可以根据需求配搭其他的svn log选项。 Import the xml file into an Excel spreadsheet (not sure if it will work with LibreOffice/OpenOffice). You can then save it as a spreadsheet. 问题汇总提示 svn: Can’t convert string from ‘UTF-8’ to native encoding:处理：(来自 https://blog.csdn.net/ssergsw/article/details/14169987)，在环境变量中添加 export LC_ALL=zh_CN.UTF-8。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>版本控制</tag>
        <tag>svn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行查看文件结尾的内容 - tail]]></title>
    <url>%2F201501%2Fshell%2Ftail.html</url>
    <content type="text"><![CDATA[tail - output the last part of files，用于输出文件结尾的内容。tail命令的参数与head命令类似，支持显示结尾连续n行的内容或c字节的内容。 查看文件结尾若干行的内容使用-n lines选项显示文件结尾的前lines行。 12345678910111213141516sunnogo@a3e420:~/test/hello$ cat hello.c -n 1 #include &lt;stdio.h&gt; 2 /* just a comment */ 3 int main(void) 4 &#123; 5 printf("Hello world!\n"); 6 7 return 0; 8 &#125;sunnogo@a3e420:~/test/hello$ tail hello.c -n 5&#123; printf("Hello world!\n"); return 0;&#125;sunnogo@a3e420:~/test/hello$ 另一种使用方法： 1234567sunnogo@a3e420:~/test/hello$ cat hello.c -n | tail -n 5 4 &#123; 5 printf("Hello world!\n"); 6 7 return 0; 8 &#125;sunnogo@a3e420:~/test/hello$ 查看文件结尾若干字节的内容使用-c bytes显示文件前bytes字节的内容 123sunnogo@a3e420:~/test/hello$ tail -c 5 hello.c 0;&#125; 输出文件结尾内容的同时显示文件名使用-v选项显示文件名： 12345678sunnogo@a3e420:~/test/hello$ tail -vn 5 hello.c ==&gt; hello.c &lt;==&#123; printf("Hello world!\n"); return 0;&#125;sunnogo@a3e420:~/test/hello$ 使用tail命令监控文件的实时状态 -f选项，让tail命令一直保持活动状态，如果有新的内容加到文件的末尾就显示出来； --pid=PID选项，和-f参数一起使用，跟踪一个文件直到进程ID为PID的进程结束； -s sec选项，和-f参数一起使用，在每次循环输出之间休眠sec秒。 样例待后续补充。]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>字符流操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行查看文件开头的内容 - head]]></title>
    <url>%2F201501%2Fshell%2Fhead.html</url>
    <content type="text"><![CDATA[head - output the first part of files，用于输出文件开头的内容。 查看文件开头若干行的内容使用-n lines选项显示文件开头的前lines行。 123456789101112131415sunnogo@a3e420:~/test/hello$ cat hello.c -n 1 #include &lt;stdio.h&gt; 2 /* just a comment */ 3 int main(void) 4 &#123; 5 printf("Hello world!\n"); 6 7 return 0; 8 &#125;sunnogo@a3e420:~/test/hello$ head hello.c -n 5#include &lt;stdio.h&gt;/* just a comment */int main(void)&#123; printf("Hello world!\n"); 另一种head命令的使用方法： 1234567sunnogo@a3e420:~/test/hello$ cat hello.c -n | head -n 5 1 #include &lt;stdio.h&gt; 2 /* just a comment */ 3 int main(void) 4 &#123; 5 printf("Hello world!\n");sunnogo@a3e420:~/test/hello$ 查看文件开头若干字节的内容使用-c bytes显示文件前bytes字节的内容 123sunnogo@a3e420:~/test/hello$ head -c 5 hello.c #inclsunnogo@a3e420:~/test/hello$ 输出文件开头内容的同时显示文件名使用-v选项显示文件名： 1234567sunnogo@a3e420:~/test/hello$ head -vn 5 hello.c ==&gt; hello.c &lt;==#include &lt;stdio.h&gt;/* just a comment */int main(void)&#123; printf("Hello world!\n");]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>字符流操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行浏览文件内容 - cat]]></title>
    <url>%2F201412%2Fshell%2Fcat.html</url>
    <content type="text"><![CDATA[cat - concatenate files and print on the standard output，用来连接文件并显示出来。 基础用法cat file1 file2 ... 如果文件很大，使用cat输出时会刷屏，甚至刷个不停。此时有多种处理方法： 如果只看前几行，使用head命令，cat filename | head -n 行数 如果只看后几行，使用tail命令，cat filename | tail -n 行数 如果要查看中间部分，使用less命令，cat filename | less，再使用less命令的快捷键查看内容。 例1：查看hello.c文件的内容123456789sunnogo@a3e420:~/test/hello$ cat hello.c #include &lt;stdio.h&gt;/* just a comment */int main(void)&#123; printf("Hello world!\n"); return 0;&#125; 例2：查看readme.txt文件的内容12345678sunnogo@a3e420:~/test/hello$ cat readme.txt This is a Hello world source file in C language.Compile: gcc -o hello hello.c Run: ./hello 例3：同时查看hello.c和readme.txt的内容12345678910111213141516sunnogo@a3e420:~/test/hello$ cat hello.c readme.txt #include &lt;stdio.h&gt;/* just a comment */int main(void)&#123; printf("Hello world!\n"); return 0;&#125;This is a Hello world source file in C language.Compile: gcc -o hello hello.cRun: ./hello 进阶使用显示行号-n选项，显示行号，-b选项可在显示行号时忽略空行。 例4：显示行号输出hello.c的内容123456789sunnogo@a3e420:~/test/hello$ cat -n hello.c 1 #include &lt;stdio.h&gt; 2 /* just a comment */ 3 int main(void) 4 &#123; 5 printf("Hello world!\n"); 6 7 return 0; 8 &#125; 例5：显示行号输出hello.c的内容，计算行号时忽略空行。12345678910sunnogo@a3e420:~/test/hello$ cat -nb hello.c 1 #include &lt;stdio.h&gt; 2 /* just a comment */ 3 int main(void) 4 &#123; 5 printf("Hello world!\n"); 6 return 0; 7 &#125;sunnogo@a3e420:~/test/hello$ 显示特殊字符 -T显示TAB为^I，-t等于-vT -E在行尾显示$，-e等于-vE -v显示windows的换行^M -A等于-vET 例6：显示windows式的换行12345678sunnogo@a3e420:~/test/hello$ cat -v readme.txt This is a Hello world source file in C language.Compile: gcc -o hello hello.c^MRun: ./hello 例7：显示行尾，并同时显示windows式的换行123456789sunnogo@a3e420:~/test/hello$ cat -vE readme.txt This is a Hello world source file in C language.$$Compile:$ gcc -o hello hello.c^M$$Run:$ ./hello$$ 例8：显示TAB键、显示行尾并同时显示windows式的换行12345678910sunnogo@a3e420:~/test/hello$ cat -vET readme.txt This is a Hello world source file in C language.$$Compile:$^Igcc -o hello hello.c^M$$Run:$ ./hello$$sunnogo@a3e420:~/test/hello$]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行查看磁盘空间使用情况 - df]]></title>
    <url>%2F201412%2Fshell%2Fdf.html</url>
    <content type="text"><![CDATA[df - report file system disk space usage，用于查看磁盘空间使用情况。 基本使用方法：df -h，以human readable的形式直观显示磁盘空间使用情况。 12345678910sunnogo@a3e420:~/github/hexo$ df -hFilesystem Size Used Avail Use% Mounted on/dev/sda1 92G 19G 69G 22% /none 4.0K 0 4.0K 0% /sys/fs/cgroupudev 2.0G 4.0K 2.0G 1% /devtmpfs 395M 1.4M 394M 1% /runnone 5.0M 0 5.0M 0% /run/locknone 2.0G 25M 2.0G 2% /run/shmnone 100M 20K 100M 1% /run/user/dev/sda5 184G 60G 115G 35% /home 还可以通过df -i查看inode使用情况。 12345678910sunnogo@a3e420:~/github/hexo$ df -iFilesystem Inodes IUsed IFree IUse% Mounted on/dev/sda1 6111232 362844 5748388 6% /none 212221 2 212219 1% /sys/fs/cgroupudev 205558 531 205027 1% /devtmpfs 212221 581 211640 1% /runnone 212221 3 212218 1% /run/locknone 212221 51 212170 1% /run/shmnone 212221 17 212204 1% /run/user/dev/sda5 12214272 738413 11475859 7% /home]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>磁盘管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行查找文件 - find]]></title>
    <url>%2F201412%2Fshell%2Ffind.html</url>
    <content type="text"><![CDATA[find - search for files in a directory hierarchy按照目录等级搜索文件。 基本命令格式： 1find [path...] [expression] 基础用法查找本目录下特定名称find . -name filename可用于查找本目录下一个特定名称的文件。.表示当前路径，filename表示待查找的文件。下文几乎所有的例子的path都使用当前路径。 123查找特定文件hello.csunnogo@a3e420:~/test$ find . -name hello.c./hello/hello.c 查找特定后缀的文件上述filename支持通配符，因此可简单实现按类型查找文件等功能。1234567查找后缀为.c的文件sunnogo@a3e420:~/test$ find . -name *.c./script/prof.c./hello/hello.c./tdef/test.c./cmd_line/config_file/parse_conf.c./config_file/parse_conf.c 查找模糊文件名的文件在使用过程中，大家可能不记得某个文件的全名，但是大概记得文件名的某一段关键字符。这时通配符就又被派上用场了：123456查找名字带parse的文件sunnogo@a3e420:~/test$ find . -name *parse*./cmd_line/config_file/parse_conf./cmd_line/config_file/parse_conf.c./config_file/parse_conf./config_file/parse_conf.c 进阶用法如果find命令的参数后接的数值，则有如下几种表示方式： +n，表示大于n -n，表示小于n n，表示等于n 按大小查找文件find . [-name filename] -size [+|-]n[b|c|w|k|M|G]其中： -size，表示只输出文件大小大于/小于/等于特定值n的文件 大小的单位如下，注意此处单位的大小写，k是小写的。 b表示512字节的块 c表示字节 w表示双字节 k表示1024字节 M表示1024kB G表示1024MB 例子中用到的-ls参数是非posix标准参数，这里只是为了更好展示查找结果才使用。 12345678910111213141516171819202122232425262728查找当前目录及子目录中，所有文件大小大于4KB的文件sunnogo@a3e420:~/test$ find . -size +4k -ls8127133 8 -rwxrwxr-x 1 sunnogo sunnogo 7292 Dec 20 22:00 ./hello/hello8130650 20 -rw-rw-r-- 1 sunnogo sunnogo 17967 Jul 26 2013 ./hello/hello.i7219878 12 -rw-r--r-- 1 sunnogo sunnogo 12288 Jul 24 2013 ./.hello.c.swp7209916 8 -rwxrwxr-x 1 sunnogo sunnogo 7122 Jan 17 2013 ./tdef/test7340928 8 -rwxrwxr-x 1 sunnogo sunnogo 7702 Mar 19 2013 ./cmd_line/config_file/parse_conf7996916 8 -rwxrwxr-x 1 sunnogo sunnogo 7702 Mar 19 2013 ./config_file/parse_conf查找当前目录及子目录中，所有文件大小小于4KB的文件sunnogo@a3e420:~/test$ find . -size -4k -ls7340612 4 -rwxrwxr-x 3 sunnogo sunnogo 94 Jun 21 2013 ./script/link.sh7340612 4 -rwxrwxr-x 3 sunnogo sunnogo 94 Jun 21 2013 ./script/if.sh7340612 4 -rwxrwxr-x 3 sunnogo sunnogo 94 Jun 21 2013 ./script/lnlink.sh7340881 0 lrwxrwxrwx 1 sunnogo sunnogo 5 Feb 23 2014 ./script/symbol.sh -&gt; if.sh7340895 0 lrwxrwxrwx 1 sunnogo sunnogo 5 Feb 23 2014 ./script/lnsymbol.sh -&gt; if.sh7340899 4 -rw-rw-r-- 1 sunnogo sunnogo 519 Nov 12 2013 ./script/prof.c...查找当前目录及子目录文件中，所有文件大小等于4KB的文件。sunnogo@a3e420:~/test$ find . -size 4k -ls7209663 4 drwxrwxr-x 11 sunnogo sunnogo 4096 Dec 26 00:22 .7340537 4 drwxrwxr-x 2 sunnogo sunnogo 4096 Feb 23 2014 ./script8130648 4 drwxrwxr-x 2 sunnogo sunnogo 4096 Dec 20 22:00 ./hello7342618 4 drwxr-xr-x 3 sunnogo sunnogo 4096 Feb 23 2014 ./mv7342622 4 drwxr-xr-x 2 sunnogo sunnogo 4096 Feb 23 2014 ./mv/dir7341100 4 drwxr-xr-x 2 sunnogo sunnogo 4096 Feb 23 2014 ./touch... 按权限查找文件Linux文件权限的格式有两种，这在ls一文的“查看文件权限信息”中有详细说明。每个文件供给三种用户使用（owner、group、other），每种用户有可读（readable）、可写（writable）、可执行（executable）三种权限。因此一个文件有九种基本权限。 数值格式。假设有个文件的权限是“751”，则“7”表示文件的owner可读、可写、可执行，“5”表示文件所属group可读、可执行，“1”表示other用户可执行。 符号格式，以r表示可读、w表示可写、x表示可执行。一般配以o表示owner、g表示group、o表示other。 find命令按文件权限查找文件有两种格式： find -perm -mode，All of the permission bits mode are set for the file，即目标文件的权限要匹配到mode中所有允许的权限，但未涉及的权限可有可无； find -perm /mode，Any of the permission bits mode are set for the file，即查找到的文件只要匹配到mode中允许的一种权限即可； 如下例中的find . -perm -700表示查找权限至少是owner可读、可写、可执行的文件。如ls显示的结果，只有文件hello满足此条件。注意文件hello还包含group可读、可写可执行权限以及other的可读、可执行权限。find . -perm /700的结果与find . -perm -700的结果就有明显差异，几乎把本目录中的所有文件都打出来了。 12345678910111213141516171819202122232425262728sunnogo@a3e420:~/test/hello$ ls -altotal 48drwxrwxr-x 2 sunnogo sunnogo 4096 Dec 20 22:00 .drwxrwxr-x 11 sunnogo sunnogo 4096 Dec 26 00:22 ..-rwxrwxr-x 1 sunnogo sunnogo 7292 Dec 20 22:00 hello-rw-rw-r-- 1 sunnogo sunnogo 104 Jul 24 2013 hello.c-rw-rw-r-- 1 sunnogo sunnogo 0 Dec 20 22:00 .hello.hide-rw-rw-r-- 1 sunnogo sunnogo 17967 Jul 26 2013 hello.i-rw-rw-rw- 1 sunnogo sunnogo 1028 Jul 26 2013 hello.o-rw-rw-r-- 1 sunnogo sunnogo 491 Jul 26 2013 hello.ssunnogo@a3e420:~/test/hello$ find . -perm -700 -ls 8130648 4 drwxrwxr-x 2 sunnogo sunnogo 4096 Dec 20 22:00 .8127133 8 -rwxrwxr-x 1 sunnogo sunnogo 7292 Dec 20 22:00 ./hellosunnogo@a3e420:~/test/hello$ find . -perm /700 -ls 8130648 4 drwxrwxr-x 2 sunnogo sunnogo 4096 Dec 20 22:00 .8127133 8 -rwxrwxr-x 1 sunnogo sunnogo 7292 Dec 20 22:00 ./hello8127134 0 -rw-rw-r-- 1 sunnogo sunnogo 0 Dec 20 22:00 ./.hello.hide8131706 4 -rw-rw-rw- 1 sunnogo sunnogo 1028 Jul 26 2013 ./hello.o8130651 4 -rw-rw-r-- 1 sunnogo sunnogo 491 Jul 26 2013 ./hello.s7219321 4 -rw-rw-r-- 1 sunnogo sunnogo 104 Jul 24 2013 ./hello.c8130650 20 -rw-rw-r-- 1 sunnogo sunnogo 17967 Jul 26 2013 ./hello.isunnogo@a3e420:~/test/hello$ find . -perm /003 -ls8130648 4 drwxrwxr-x 2 sunnogo sunnogo 4096 Dec 20 22:00 .8127133 8 -rwxrwxr-x 1 sunnogo sunnogo 7292 Dec 20 22:00 ./hello8131706 4 -rw-rw-rw- 1 sunnogo sunnogo 1028 Jul 26 2013 ./hello.o mode也可以使用符号格式，如下例子使用符号格式实现find . -perm -700与find . -perm /003。 12345678910等同“find . -perm -700”sunnogo@a3e420:~/test/hello$ find . -perm -u+r,u+w,u+x -ls8130648 4 drwxrwxr-x 2 sunnogo sunnogo 4096 Dec 20 22:00 .8127133 8 -rwxrwxr-x 1 sunnogo sunnogo 7292 Dec 20 22:00 ./hello等同“find . -perm /003”sunnogo@a3e420:~/test/hello$ find . -perm /o+w,o+x -ls8130648 4 drwxrwxr-x 2 sunnogo sunnogo 4096 Dec 20 22:00 .8127133 8 -rwxrwxr-x 1 sunnogo sunnogo 7292 Dec 20 22:00 ./hello8131706 4 -rw-rw-rw- 1 sunnogo sunnogo 1028 Jul 26 2013 ./hello.o 按时间查找文件Linux文件相关时间属性详见ls一文中“常见文件属性信息汇总”小节的描述。 按访问时间查找（access time，atime） -amin n，查找在此前第[n - 1, n]分钟的期间被访问的文件（当n不等于0时为如上结论，如果n等于0，默认无输出，该文件的access time是否在未来的时间）。 -anewer file，查找access time比文件file晚的文件 -atime n，查找在此前第[(n - 1)× 24, n × 24]小时的期间被访问的文件 注意本章一开头对find的数值参数n的描述，+n表示大于n的情况，-n表示小于n的情况，同样适合于本小节所描述的参数。用于实现查找某个时间点被访问以前或之后的文件，这才是我们最想要的用途。注意此时的时间不再是个区间，而就是个时间点。具体用法如下例所述。 上述的时间期间可能不好理解，详见本文后面的小节“理解按时间查找文件中时间期间的含义”。 123456789101112sunnogo@a3e420:~/test/hello$ touch -at 12262300 hello.isunnogo@a3e420:~/test/hello$ stat hello.i | grep "Access: 2014"Access: 2014-12-26 23:00:00.000000000 +0800sunnogo@a3e420:~/test/hello$ dateFri Dec 26 23:14:08 CST 2014sunnogo@a3e420:~/test/hello$ find . -amin 15./hello.isunnogo@a3e420:~/test/hello$ find . -amin -14sunnogo@a3e420:~/test/hello$ find . -amin -15./hello.i 按状态变动时间查找（change time，ctime），命令与access time类似 -cmin n -cnewer file -ctime n 按修改时间查找（modify time，mtime） -mmin n -mnewer file，-newer file看似功能与本选项一致。 -mtime n 按文件类型查找文件Linux文件相关时间属性详见ls一文中“常见文件属性信息汇总”小节的描述。 find PATH -type file_type，文件类型file_type包含如下几种： b，块设备文件 c，字符设备文件 d，目录文件 p，有名管道文件 f，普通文件 l，符号链接文件 s，socket文件 以下是样例：123456789sunnogo@a3e420:~/test$ find . -type d -ls7209663 4 drwxrwxr-x 11 sunnogo sunnogo 4096 Dec 26 00:22 .7340537 4 drwxrwxr-x 2 sunnogo sunnogo 4096 Feb 23 2014 ./script8130648 4 drwxrwxr-x 2 sunnogo sunnogo 4096 Dec 20 22:00 ./hello...sunnogo@a3e420:~/test$ find . -type l -ls7340881 0 lrwxrwxrwx 1 sunnogo sunnogo 5 Feb 23 2014 ./script/symbol.sh -&gt; if.sh7340895 0 lrwxrwxrwx 1 sunnogo sunnogo 5 Feb 23 2014 ./script/lnsymbol.sh -&gt; if.sh 多条件查找find命令支持运算符，允许多个expression进行计算。主要运算符有： ()，和四则运算一样，表示优先执行括号内的表达式； ! expr，类似逻辑运算的not，表示对表达式expr的结果取反； expr1 -a expr2，类似逻辑运算的and，表示expr1和expr2进行与运算。类似C语言的短路求值(short-circuit evalution)，若expr1为假，就不会计算expr2； expr1 -o expr2，类似逻辑运算的or，表示expr1和expr2进行或运行。同样使用短路求值，若expr1为真，则不会计算expr2 事实上find命令也有-not、-and、-or选项等同于上述三种运算符，但是这三种运算符是非POSIX兼容的，使用时需要注意。 12345678910111213141516171819202122232425262728293031sunnogo@a3e420:~/test$ ls -al hello/total 48drwxrwxr-x 2 sunnogo sunnogo 4096 Dec 20 22:00 .drwxrwxr-x 12 sunnogo sunnogo 4096 Dec 26 23:27 ..-rwxrwxr-x 1 sunnogo sunnogo 7292 Dec 20 22:00 hello-rw-rw-r-- 1 sunnogo sunnogo 104 Jul 24 2013 hello.c-rw-rw-r-- 1 sunnogo sunnogo 0 Dec 20 22:00 .hello.hide-rw-rw-r-- 1 sunnogo sunnogo 17967 Dec 26 23:02 hello.i-rw-rw-rw- 1 sunnogo sunnogo 1028 Jul 26 2013 hello.o-rw-rw-r-- 1 sunnogo sunnogo 491 Jul 26 2013 hello.s查找文件名为"hello"开头、且至少有一种用户有写权限的文件sunnogo@a3e420:~/test$ find . -name "hello*" -a -perm /a+w -ls8130648 4 drwxrwxr-x 2 sunnogo sunnogo 4096 Dec 20 22:00 ./hello8127133 8 -rwxrwxr-x 1 sunnogo sunnogo 7292 Dec 20 22:00 ./hello/hello8131706 4 -rw-rw-rw- 1 sunnogo sunnogo 1028 Jul 26 2013 ./hello/hello.o8130651 4 -rw-rw-r-- 1 sunnogo sunnogo 491 Jul 26 2013 ./hello/hello.s7219321 4 -rw-rw-r-- 1 sunnogo sunnogo 104 Jul 24 2013 ./hello/hello.c8130650 20 -rw-rw-r-- 1 sunnogo sunnogo 17967 Dec 26 23:02 ./hello/hello.i查找文件名为"hello"开头、且所有用户都有写权限的文件sunnogo@a3e420:~/test$ find . -name "hello*" -a -perm -a+w -ls8131706 4 -rw-rw-rw- 1 sunnogo sunnogo 1028 Jul 26 2013 ./hello/hello.o查找文件名为"hello"开头、且不是所有用户都有写权限的文件sunnogo@a3e420:~/test$ find . -name "hello*" -a ! -perm -a+w -ls8130648 4 drwxrwxr-x 2 sunnogo sunnogo 4096 Dec 20 22:00 ./hello8127133 8 -rwxrwxr-x 1 sunnogo sunnogo 7292 Dec 20 22:00 ./hello/hello8130651 4 -rw-rw-r-- 1 sunnogo sunnogo 491 Jul 26 2013 ./hello/hello.s7219321 4 -rw-rw-r-- 1 sunnogo sunnogo 104 Jul 24 2013 ./hello/hello.c8130650 20 -rw-rw-r-- 1 sunnogo sunnogo 17967 Dec 26 23:02 ./hello/hello.i 对查找结果进行处理即对查找的结果作为参数输入给其他命令。有以下四种形式的格式，\只是个转义字符，为防止符号;或+在shell中有不同的含义。 -exec command &quot;{}&quot; \; -exec command &quot;{}&quot; \+ -execdir command &quot;{}&quot; \; -execdir command &quot;{}&quot; \+ 目前尚不需理解命令参数结束符;与+的差异以及exec与execdir的差异。 123456789101112131415161718192021sunnogo@a3e420:~/test$ mkdir execsunnogo@a3e420:~/test$ cd execsunnogo@a3e420:~/test/exec$ echo "abcdefg" &gt; abc.txtsunnogo@a3e420:~/test/exec$ echo "xyzabc" &gt; xyz.txtsunnogo@a3e420:~/test/exec$ echo "bcdefgh" &gt; bcd.txtsunnogo@a3e420:~/test/exec$ mkdir exec_subsunnogo@a3e420:~/test/exec$ cd exec_abc/sunnogo@a3e420:~/test/exec/exec_abc$ echo "abcdefghijkl" &gt; bck.txtsunnogo@a3e420:~/test/exec/exec_abc$ cd ..sunnogo@a3e420:~/test/exec$ find . -name "*bc*" ./bcd.txt./exec_abc./exec_abc/bck.txt./abc.txtsunnogo@a3e420:~/test/exec$ find . -name "*bc*" -exec cat "&#123;&#125;" \+ bcdefghcat: ./exec_abc: Is a directoryabcdefghijklabcdefg 按格式输出查找结果使用print、fprint参数实现，相对的内容较多但是不重要，在此不详细，需要的同学使用man find看一下。 使用正则表达式匹配文件名-regex pattern文件名可以用正则表达式匹配，这里不详述。 其他参数还可以根据硬连接数、inode信息、owner信息等查找文件 理解按时间查找文件中时间期间的含义“查找在此前第[n-1, n]分钟的期间被访问的文件”，不好理解，先看下面的例子： 首先，查看文件hello.i的属性信息，发现access time是22:32:52 123456789sunnogo@a3e420:~/test/hello$ stat hello.i File: ‘hello.i’ Size: 17967 Blocks: 40 IO Block: 4096 regular fileDevice: 805h/2053d Inode: 8130650 Links: 1Access: (0664/-rw-rw-r--) Uid: ( 1000/ sunnogo) Gid: ( 1000/ sunnogo)Access: 2014-12-26 22:32:52.248847993 +0800Modify: 2014-12-26 22:32:50.072847903 +0800Change: 2014-12-26 22:32:50.072847903 +0800 Birth: - 其次，查看当前时间点，现在是22:57:38，距离hello.i的atime为24分钟46秒。 12sunnogo@a3e420:~/test/hello$ dateFri Dec 26 22:57:38 CST 2014 第三，看n值为24、25、26时find . -amin n的结果。 1234sunnogo@a3e420:~/test/hello$ find . -amin 25./hello.isunnogo@a3e420:~/test/hello$ find . -amin 24sunnogo@a3e420:~/test/hello$ find . -amin 26 接下来看看find . -amin 0会不会显示未来时间。实际上最科学的方法是去查找find命令的代码实现，这里仅仅是玩一玩，验证自己觉得可能比较有趣的情况，无需较真。 123456789sunnogo@a3e420:~/test/hello$ dateFri Dec 26 23:06:55 CST 2014sunnogo@a3e420:~/test/hello$ touch -at 12300000 hello.i sunnogo@a3e420:~/test/hello$ stat hello.i | grep "Access: 2014"Access: 2014-12-30 00:00:00.000000000 +0800sunnogo@a3e420:~/test/hello$ find . -amin 0sunnogo@a3e420:~/test/hello$ Written with StackEdit.]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行查看目录及子目录大小 - du]]></title>
    <url>%2F201412%2Fshell%2Fdu.html</url>
    <content type="text"><![CDATA[在ls命令中，可通过ls -alh查看文件的大小，但是此时看到的目录文件大小是Linux目录文件实际的大小，一般是4KB，而不是一般意义的目录总大小，命令du可用于查看目录的总大小。 12du - estimate file space usage Summarize disk usage of each FILE, recursively for directories. du命令默认递归把本目录以下的所有目录及文件的大小都输出到控制台。如果各目录层次下的文件太多，会导致控制台输出的内容太多。 一般情况下会使用-d N参数或者--max-depth=N来控制du命令递归输出的目录层次数。N表示递归输出到第几级目录。-h参数是让输出的文件大小值使用Human readable的形式表示，即以KB/MB/GB的形式出现，默认以KB为单位输出。 查看本目录总大小使用0级目录即可。注意与ls -alh的结果对比，ls的结果也有个total总计，但是这个total并不递归累加每个子目录下各个文件的大小，而是把本目录下的子目录当成4KB的普通文件。 12345678910111213141516171819sunnogo@a3e420:~/github/hexo$ du -d 0 -h181M .sunnogo@a3e420:~/github/hexo$ ls -alhtotal 163Mdrwxrwxr-x 8 sunnogo sunnogo 4.0K Dec 24 23:09 .drwxrwxr-x 6 sunnogo sunnogo 4.0K Dec 12 22:41 ..-rw-rw-r-- 1 sunnogo sunnogo 2.0K Dec 20 23:13 _config.yml-rw-rw-r-- 1 sunnogo sunnogo 105K Dec 24 00:49 db.json-rw-rw-r-- 1 sunnogo sunnogo 7.3K Dec 13 19:38 debug.logdrwxrwxr-x 13 sunnogo sunnogo 4.0K Dec 24 00:49 .deploy-rw-rw-r-- 1 sunnogo sunnogo 68 Dec 12 22:41 .gitignoredrwxr-xr-x 5 sunnogo sunnogo 4.0K Dec 12 22:42 node_modules-rw-rw-r-- 1 sunnogo sunnogo 186 Dec 12 22:47 package.jsondrwxrwxr-x 12 sunnogo sunnogo 4.0K Dec 20 23:19 publicdrwxrwxr-x 2 sunnogo sunnogo 4.0K Dec 12 22:41 scaffoldsdrwxrwxr-x 5 sunnogo sunnogo 4.0K Dec 20 22:47 sourcedrwxrwxr-x 4 sunnogo sunnogo 4.0K Dec 12 22:46 themes-rw-rw-r-- 1 sunnogo sunnogo 163M Dec 24 23:08 veryLargeFile.txt 查看本目录下各个子目录的总大小使用一级目录递归输出即可。注意，一级递归输出并没有输出本目录下的普通文件，但是大小已经统计在内。 12345678sunnogo@a3e420:~/github/hexo$ du -d 1 -h2.5M ./public20K ./scaffolds6.3M ./node_modules4.5M ./themes32K ./source5.2M ./.deploy181M . 对输出的结果进行排序简单地，du命令可与sort命令配合按大小或文件名输出结果。亦可再配合head或tail命令只显示排序前几或倒数前几的结果。 12345678910111213sunnogo@a3e420:~/github/hexo$ du -d 1 | sort -nr 185104 .6376 ./node_modules5324 ./.deploy4592 ./themes2560 ./public32 ./source20 ./scaffoldssunnogo@a3e420:~/github/hexo$ du -d 1 | sort -nr | head -n 3185104 .6376 ./node_modules5324 ./.deploy sort的-n选项表示按数值排序，-r表示反向排序即从大到小排序，sort默认使用。 注意符号|，在linux shell中这是一个很重要的概念，名为管道，即将前道工序输出的结果做为后一道工序的输入。 head命令显示输入的前n行，tail命令则相反。 只输出大小大于某个特定值的文件通过-t SIZE或--threshold=SIZE实现本功能，注意 Size的单位是Byte。12345sunnogo@a3e420:~/github/hexo$ du -d 1 -h -t 45000006.3M ./node_modules4.5M ./themes5.2M ./.deploy181M . 忽略统计某些特定类型或匹配文件的大小通过-X PATTERN或--exclude=PATTERN实现本功能。注意PATTERN是支持通配符，并不支持正则表达式。 一般用于过滤特定后缀的文件。如果想一次过滤多种PATTERN的文件，可通过多次使用-X或--exclude实现。 12345678910111213141516sunnogo@a3e420:~/github/hexo$ du -hd 1 --exclude '*.js'2.3M ./public20K ./scaffolds2.4M ./node_modules4.2M ./themes32K ./source5.0M ./.deploy177M .sunnogo@a3e420:~/github/hexo$ du -hd 1 --exclude '*.js' --exclude '*.txt'2.3M ./public20K ./scaffolds2.4M ./node_modules4.2M ./themes32K ./source5.0M ./.deploy14M . Written with StackEdit.]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行剪切、重命名文件 - mv]]></title>
    <url>%2F201402%2Fshell%2Fmv.html</url>
    <content type="text"><![CDATA[mv - move (rename) files常用方式： 重命名，mv dir1/file1 dir2/file2，如果已有dir2/file2的存在，则就像cp命令那样，有覆盖提示（-i）、更新（-u）、强制覆盖（-f）等一样的选项。 移动单个文件/目录（即剪切），mv file1 dir1 移动多个文件/目录到同一个目录，mv -t dest_dir file1 file2... 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051521. 创建三个文件sunnogo@a3e420:~/test/mv$ echo "first file" &gt; file1&lt;----创建文件的方式有很多种，touch只是其中一种。sunnogo@a3e420:~/test/mv$ cat file1 first filesunnogo@a3e420:~/test/mv$ lsfile1sunnogo@a3e420:~/test/mv$ echo "second file" &gt; file2sunnogo@a3e420:~/test/mv$ echo "third file" &gt; file3sunnogo@a3e420:~/test/mv$ lsfile1 file2 file32. 重命名文件没有覆盖的情况：sunnogo@a3e420:~/test/mv$ mv file1 file4sunnogo@a3e420:~/test/mv$ cat file4 first filesunnogo@a3e420:~/test/mv$ lsfile2 file3 file4有覆盖的情况：sunnogo@a3e420:~/test/mv$ mv file4 file1sunnogo@a3e420:~/test/mv$ mv file1 file2sunnogo@a3e420:~/test/mv$ lsfile2 file3sunnogo@a3e420:~/test/mv$ cat file2first file有覆盖提示的情况：sunnogo@a3e420:~/test/mv$ mv -i file2 file3mv: overwrite ‘file3’? ysunnogo@a3e420:~/test/mv$ sunnogo@a3e420:~/test/mv$ lsfile3sunnogo@a3e420:~/test/mv$ cat file3 first filesunnogo@a3e420:~/test/mv$ 3. 移动多个文件到同一个目录sunnogo@a3e420:~/test/mv$ mv file3 file1sunnogo@a3e420:~/test/mv$ echo "second file" &gt; file2sunnogo@a3e420:~/test/mv$ echo "third file" &gt; file3sunnogo@a3e420:~/test/mv$ sunnogo@a3e420:~/test/mv$ lsfile1 file2 file3sunnogo@a3e420:~/test/mv$ mkdir dirsunnogo@a3e420:~/test/mv$ mv -t dir/ file1 file2 file3 sunnogo@a3e420:~/test/mv$ lsdirsunnogo@a3e420:~/test/mv$ ls dir/file1 file2 file3sunnogo@a3e420:~/test/mv$ Written with StackEdit.]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行浏览文件 - ls]]></title>
    <url>%2F201402%2Fshell%2Fls.html</url>
    <content type="text"><![CDATA[ls - list directory content，用来查看文件属性信息。以下简要说明ls的常见使用方法。 常见文件属性信息汇总ls命令主要用于查看文件的属性信息。Linux文件有以下几种主要属性。 文件名 文件类型，如普通文件、目录文件、软链接文件、字符设备文件、设设备文件、socket文件等。 文件大小，单位可以是Byte、KByte、MByte、GByte或者block。 是否隐藏文件，linux的隐藏文件的定义较为简单，文件名以“.”的文件都叫隐藏文件。ls命令默认不会输出隐藏文件的信息。 文件权限，每三种用户类型：所属者（owner）、所属组（group）、其他人（other），每种用户有三种权限：可读、可写、可执行，可使用3 × 3 bits表示某种类型用户的某种权限。 owner信息，一般是名称或用户编号。 group信息，一般是名称或组编号。 时间属性，含Access time、modify time、change time，分别以atime、mtime、ctime表示。 access time，访问时间，读一次这个文件的内容，这个时间就会更新。比如对这个文件运用 more、cat等命令。ls、stat命令都不会修改文件的访问时间。 modify time，修改时间是文件内容最后一次被修改时间。比如：vi后保存文件。ls -l列出的时间就是这个时间。 change time，状态改动时间。是该文件的i节点最后一次被修改的时间，通过chmod、chown命令修改一次文件属性，这个时间就会更新。inode的概念将于《inode学习》一文详述。 注意：Linux中什么都是文件，目录也只是一种文件。这个观点始终贯穿Linux操作系统。 ls命令基础查看文件名直接敲一下ls命令就能看到当前目录下的所有非隐藏文件。12sunnogo@a3e420:~/test/hello$ lshello hello.c hello.i hello.o hello.s 查看隐藏文件带-a参数，可查看列出隐藏文件。如以下的.hello.hide文件。 注意.和..，Linux中使用.表示当前目录，使用..表示上一级目录。看看ls -a、ls -a .和ls -a ..三者有什么差异。 123456sunnogo@a3e420:~/test/hello$ ls -a. .. hello hello.c .hello.hide hello.i hello.o hello.ssunnogo@a3e420:~/test/hello$ ls -a .. .. hello hello.c .hello.hide hello.i hello.o hello.ssunnogo@a3e420:~/test/hello$ ls -a ... .. cmd_line .config config_file .git .gitignore hello .hello.c.swp mkdir mv rm script tdef touch 查看文件大小ls命令使用-s参数查看文件大小，默认以block为单位。使用-h参数将文件大小的单位转换为human readable的单位，即常见的KB、MB、GB等。 ls的-l参数，即long list formating，把大多数的文件属性信息都显示出来，因此一般只记-l参数，而无需去记类似-s这样的参数。注意-l参数默认不显示隐藏文件，默认的文件大小以Byte为单位。12345678910111213141516sunnogo@a3e420:~/test/hello$ ls -stotal 40 8 hello 4 hello.c 20 hello.i 4 hello.o 4 hello.ssunnogo@a3e420:~/test/hello$ ls -shtotal 40K8.0K hello 4.0K hello.c 20K hello.i 4.0K hello.o 4.0K hello.ssunnogo@a3e420:~/test/hello$ ls -alhtotal 48Kdrwxrwxr-x 2 sunnogo sunnogo 4.0K Dec 20 22:00 .drwxrwxr-x 14 sunnogo sunnogo 4.0K Apr 20 2014 ..-rwxrwxr-x 1 sunnogo sunnogo 7.2K Dec 20 22:00 hello-rw-rw-r-- 1 sunnogo sunnogo 104 Jul 24 2013 hello.c-rw-rw-r-- 1 sunnogo sunnogo 0 Dec 20 22:00 .hello.hide-rw-rw-r-- 1 sunnogo sunnogo 18K Jul 26 2013 hello.i-rw-rw-r-- 1 sunnogo sunnogo 1.1K Jul 26 2013 hello.o-rw-rw-r-- 1 sunnogo sunnogo 491 Jul 26 2013 hello.s 查看文件权限信息如上所示，-l参数的第一列显示文件权限信息，第一位表示文件类型，后九位表示文件权限。以文件hello为例，其权限信息rwxrwxr-x表示： 第1到3位rwx，对象是文件所属者，所属者对该文件有可读、可写、可执行三种权限； 第4到6位rwx，对象是文件所属组，组是多用户组成的，所属组对该文件有可读、可写、可执行三种权限。 第7到9位r-x，对象是其他用户，其他用户对该文件有可读、可执行两种权限，没有权限运行该文件。 对文件的属性Linux系统上还有另一种用数值表示的方法，即通过3个bit来表示一种用户的权限，r是最高位，w是第二位，x是最低位，对应位置为1表示用户拥有对应的权限，0表示无此权限。例如，数字6（即110）表示可读、可写两种权限，数字5（即101）表示可读、可执行两种权限。这种表示方法在chmod命令中经常使用。 查看文件类型-l参数即可查看文件类型，第一位的第一位表示文件类型，含目录（d），文件（-），字符型文件（c），块文件（b），软链接文件（l）等。 查看文件时间属性可用stat命令查看文的三种时间属性。ls命令也可查看时间属性，默认输出mtime，-c参数表示ctime，-u参数表示atime。 查看ctime，ls -lc filename 查看atime，ls -lu filename 查看mtime，ls -l filename 排序相关参数-t，以文件的时间排序，默认是最后修改时间，如果有-u选项，则是以上次访问时间排序。-S，大写S，以文件大小排序输出，注意，目录文件的大小始终是4KB，不会去统计目录内部文件的总大小。-u，小写u，输出文件的最后访问时间，而非最后修改时间。-X，大写X，按文件扩展名排序输出。 其他参数 -R，即--recursive，递归列出子目录内容。这个参数在其他命令中也很常见，表示递归处理子目录。 -B，即--ignore-backups，不显示以波浪线结尾的条目，波浪线是用来表示备份的副本，如果有用过gedit或kate，对这波浪线肯定深有体会。 -i，即--inode，显示每个文件的索引值。这个在学操作系统时可能能用上。 -n，即--numeric-uid-gid，显示数字类型的userid和groupid来替代名字。 TIPs： 命令行参数一般有单字母参数和全字参数两种形式，比如ls -a和ls --all。单字母通常由英文破折号开始，全字参数则更容易看懂，通常以双英文破折号开始。许多参数都有单字母和全字两种版本，而有些则只有一种。 ls命令支持标准通配符，问号代表一个字符，星号代表零或多个字符。 如果不知道某个命令怎么使用，要学会使用man手册，即Linux的帮助手册。通过命令man your_command即可查看对应命令的使用方法、参数说明等。 Written with StackEdit.]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行创建目录 - mkdir]]></title>
    <url>%2F201402%2Fshell%2Fmkdir.html</url>
    <content type="text"><![CDATA[mkdir - make directories常用参数：-p，--parents，如果要创建的目录存在，也不会提示error，如果父目录不存在，则一并创建父目录。 12345678910111213141516171819202122232425sunnogo@a3e420:~/test/mkdir$ ls sunnogo@a3e420:~/test/mkdir$ sunnogo@a3e420:~/test/mkdir$ mkdir first_dirsunnogo@a3e420:~/test/mkdir$ ls -altotal 12drwxr-xr-x 3 sunnogo sunnogo 4096 2月 23 22:09 .drwxrwxr-x 12 sunnogo sunnogo 4096 2月 23 22:09 ..drwxr-xr-x 2 sunnogo sunnogo 4096 2月 23 22:09 first_dirsunnogo@a3e420:~/test/mkdir$ sunnogo@a3e420:~/test/mkdir$ mkdir second_dir/21dirmkdir: cannot create directory ‘second_dir/21dir’: No such file or directory&lt;----创建多级目录如果不加-p选项且有父目录不存在，就会提示错误sunnogo@a3e420:~/test/mkdir$ sunnogo@a3e420:~/test/mkdir$ mkdir -p second_dir/21dirsunnogo@a3e420:~/test/mkdir$ ls -ltotal 8drwxr-xr-x 2 sunnogo sunnogo 4096 2月 23 22:09 first_dirdrwxr-xr-x 3 sunnogo sunnogo 4096 2月 23 22:10 second_dirsunnogo@a3e420:~/test/mkdir$ ls -l *first_dir:total 0second_dir:total 4drwxr-xr-x 2 sunnogo sunnogo 4096 2月 23 22:10 21dir Written with StackEdit.]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行拷贝文件 - cp]]></title>
    <url>%2F201402%2Fshell%2Fcp.html</url>
    <content type="text"><![CDATA[cp - copy files and directories命令语法：cp [option] source destination 基本参数cp的参数较多，一般使用-a参数即可完成大多数的拷贝操作需求。个人亦喜欢使用-aux参数查看文件的更新情况。 -a，等于-dpR，归档文件，并保留它们的属性。即整个目录保留属性复制。 -u，update，仅在源文件比目标文件新的情况下复制（相当于更新）。 -v，verbose，详细模式，解释到底发生了什么。这个参数在其他命令中也很常见。 123sunnogo@a3e420:~/test/script$ cp -auv ../prof.c .‘../prof.c’ -&gt; ‘./prof.c’sunnogo@a3e420:~/test/script$ 其他常见参数： -f，force，强制覆盖已存在的目标文件，不提示。这个参数在其他命令中也很常见。 -l，hard link，创建文件链接，而非复制。 -s，symbolic link，创建一个符号链接而非复制文件。 -p，preserve，保存属性信息，如owership、timestamp等。 -R，recursive，递归复制，复制目录需要加上这个选项。 -x，仅限于当前文件系统的复制。 -T, –no-target-directory. treat DEST as a normal file。我用来拷贝隐藏文件。详见 https://superuser.com/a/970185. 12345678910111213141516171819sunnogo@a3e420:~/test/script$ ls -litotal 47340612 -rwxrwxr-x 1 sunnogo sunnogo 94 6月 21 2013 if.shsunnogo@a3e420:~/test/script$ sunnogo@a3e420:~/test/script$ cp -l if.sh link.shsunnogo@a3e420:~/test/script$ ls -litotal 87340612 -rwxrwxr-x 2 sunnogo sunnogo 94 6月 21 2013 if.sh7340612 -rwxrwxr-x 2 sunnogo sunnogo 94 6月 21 2013 link.shsunnogo@a3e420:~/test/script$ sunnogo@a3e420:~/test/script$ cp -s if.sh symbol.shsunnogo@a3e420:~/test/script$ ls -litotal 87340612 -rwxrwxr-x 2 sunnogo sunnogo 94 6月 21 2013 if.sh7340612 -rwxrwxr-x 2 sunnogo sunnogo 94 6月 21 2013 link.sh7340881 lrwxrwxrwx 1 sunnogo sunnogo 5 2月 23 21:16 symbol.sh -&gt; if.shcp -rT /etc/skel /home/user 注意cp -l和cp -s的差异，体现在ls -li中显示的inode是否一致和文件的硬链接总数。关于软、硬链接，在《Linux命令行创建“快捷方式” - ln》一文描述。 Written with StackEdit.]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行创建文件、修改文件时间戳 - touch]]></title>
    <url>%2F201402%2Fshell%2Ftouch.html</url>
    <content type="text"><![CDATA[touch - change file timestampstouch常用于Linux命令行创建空文件，而从man touch的结果看来，touch主要用于修改时间戳，创建文件只是兼职工作。 常用方式： touch file，如果当前目录内无该文件，则以当前时间创建空文件；如果当前目录内有该文件，则以当前时间修改文件时间戳（访问时间和修改时间）； touch -t YearMonthDateHourMinute file，指定时间修改文件时间戳，时间方式如201402232200。 touch -a file，只修改访问时间（access timestamp） touch -m file，只修改修改时间（modify timestamp） find . -name &quot;*&quot; -print0 | xargs -0 -I &#39;{}&#39; touch -r &#39;{}&#39; -d &#39;-3 month&#39; &#39;{}&#39;，对查找的所有文件，修改时间戳，减 3 个月 123456789101112131415161718sunnogo@a3e420:~/test/touch$ sunnogo@a3e420:~/test/touch$ touch firstsunnogo@a3e420:~/test/touch$ ls -l first -rw-r--r-- 1 sunnogo sunnogo 0 2月 23 21:56 firstsunnogo@a3e420:~/test/touch$ ls -lu first -rw-r--r-- 1 sunnogo sunnogo 0 2月 23 21:56 firstsunnogo@a3e420:~/test/touch$ sunnogo@a3e420:~/test/touch$ touch -at 201110101200 first sunnogo@a3e420:~/test/touch$ ls -l first -rw-r--r-- 1 sunnogo sunnogo 0 2月 23 21:56 first &lt;----修改时间戳不变sunnogo@a3e420:~/test/touch$ ls -lu first -rw-r--r-- 1 sunnogo sunnogo 0 10月 10 2011 first &lt;----访问时间戳改变sunnogo@a3e420:~/test/touch$ sunnogo@a3e420:~/test/touch$ touch -mt 201110101200 first sunnogo@a3e420:~/test/touch$ ls -l first -rw-r--r-- 1 sunnogo sunnogo 0 10月 10 2012 first &lt;----修改时间戳改变sunnogo@a3e420:~/test/touch$ ls -lu first -rw-r--r-- 1 sunnogo sunnogo 0 10月 10 2011 first Written with StackEdit.]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行删除文件 - rm]]></title>
    <url>%2F201402%2Fshell%2Frm.html</url>
    <content type="text"><![CDATA[rm - remove files or directories命令语法：rm [option] file常见参数：-f，--force，不提示直接删除。有风险，须谨慎。-i，删除每个文件前，先提示一把。如果批量删除多个文件的话，略显麻烦。-I，避免删除多个文件时，像-i那么麻烦。如果删除三个或以上文件，只会提醒一次。-r，删除目录以及递归删除目录下的文件和子目录。 本人较喜欢使用rm -rf dir的形式删除文件，也曾因此丢失重要数据，不过吃一堑长一智，也因此学会即时备份重要数据。 123456789101112131415161718192021222324252627282930313233343536sunnogo@a3e420:~/test/rm$ lssunnogo@a3e420:~/test/rm$ touch asunnogo@a3e420:~/test/rm$ rm a&lt;----普通删除不提示，直接删除，对比下面的-i删除sunnogo@a3e420:~/test/rm$ lssunnogo@a3e420:~/test/rm$ touch bsunnogo@a3e420:~/test/rm$ rm -i brm: remove regular empty file ‘b’? ysunnogo@a3e420:~/test/rm$ lssunnogo@a3e420:~/test/rm$ mkdir -p dir1/dir1_1/dir1_1_1sunnogo@a3e420:~/test/rm$ touch dir1/aa dir1/bb dir1/cc dir1/ddsunnogo@a3e420:~/test/rm$ rm -ri dir1/rm: descend into directory ‘dir1/’? yrm: remove regular empty file ‘dir1/dd’? yrm: remove regular empty file ‘dir1/bb’? yrm: remove regular empty file ‘dir1/cc’? yrm: descend into directory ‘dir1/dir1_1’? yrm: remove directory ‘dir1/dir1_1/dir1_1_1’? yrm: remove directory ‘dir1/dir1_1’? yrm: remove regular empty file ‘dir1/aa’? yrm: remove directory ‘dir1/’? y&lt;----批量删除的-i选项太麻烦了。sunnogo@a3e420:~/test/rm$ sunnogo@a3e420:~/test/rm$ mkdir -p dir1/dir1_1/dir1_1_1sunnogo@a3e420:~/test/rm$ touch dir1/aa dir1/bb dir1/cc dir1/ddsunnogo@a3e420:~/test/rm$ rm -rI dir1/rm: remove all arguments recursively? y&lt;----大写的-I选项轻松多了sunnogo@a3e420:~/test/rm$ sunnogo@a3e420:~/test/rm$ mkdir -p dir1/dir1_1/dir1_1_1sunnogo@a3e420:~/test/rm$ touch dir1/aa dir1/bb dir1/cc dir1/ddsunnogo@a3e420:~/test/rm$ rm -rf dir1/&lt;----数据无价，强制删除需谨慎。 还有一个专门删除目录的命令rmdir，man手册中rmdir的说明是“rmdir - remove empty directories”，只能删除空目录，有rm的存在，rmdir看着有点鸡肋，不详述。 Written with StackEdit.]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令行创建“快捷方式” - ln]]></title>
    <url>%2F201402%2Fshell%2Fln.html</url>
    <content type="text"><![CDATA[将ln命令说成创建“快捷方式”只是用于比喻，实际上ln命令与Linux文件系统的特性悉悉相关。 基础知识简述文件都有文件名与数据，数据在Linux上被分成两个部分：用户数据（user data）与元数据（metadata）。用户数据，即文件数据块（data block），数据块是记录文件真实内容的地方；而元数据则是文件的附加属性，如文件大小、创建时间、所有者等信息。在Linux中，元数据中的inode号（inode 是文件元数据的一部分但其并不包含文件名，inode号即索引节点号）才是文件的唯一标识而非文件名。文件名仅是为了方便人们的记忆和使用，系统或程序通过文件名索引到inode号再去寻找正确的文件数据块。 为解决文件的共享使用，Linux系统引入了两种链接：硬链接（hard link）与软链接（又称符号链接，即soft link或symbolic link）。链接为Linux 系统解决了文件的共享使用，还带来了隐藏文件路径、增加权限安全及节省存储等好处。 若一个inode号对应多个文件名，则称这些文件为硬链接。换言之，硬链接就是同一个文件使用了多个别名。创建一个硬链接之后，inode不变，但是硬连接总数（也称为引用计数）有增加，当删除文件时，只有硬连接总数为0时，系统才会真正删除文件。 软链接与硬链接不同，若文件用户数据块中存放的内容是另一文件的路径名的指向，则该文件就是软连接。软链接就是一个普通文件，只是数据块内容有点特殊。软链接有着自己的inode号以及用户数据块，即有新文件生成，这个新文件（如上symbol.sh）指向旧文件（if.sh）。这个有点像Windows中的快捷方式。快捷方式指向的文件被删除了，则快捷方式无效；如果把快捷方式删除了，也不影响原来的文件。 （以上关于软、硬链接的说明摘抄自IBM文档《理解 Linux 的硬链接与软链接》） ln命令说明ln - make links between files常用格式：ln [OPTION] TARGET LINK_NAMEln target link_name等同于cp -l target link_nameln -s target link_name等同于cp -s target link_name-f，覆盖已有的link。 TIPs: Linux文件复制命令 - cp也有创建链接的功能。使用-s表示创建符号链接，-l表示创建硬链接。 注意：windows默认文件系统不支持软链接，如果将含软链接的压缩包在windows文件系统中，软链接将失效。 1234567891011121314151617sunnogo@a3e420:~/test/script$ ln if.sh lnlink.shsunnogo@a3e420:~/test/script$ ls -litotal 167340612 -rwxrwxr-x 3 sunnogo sunnogo 94 6月 21 2013 if.sh7340612 -rwxrwxr-x 3 sunnogo sunnogo 94 6月 21 2013 link.sh7340612 -rwxrwxr-x 3 sunnogo sunnogo 94 6月 21 2013 lnlink.sh7340899 -rw-rw-r-- 1 sunnogo sunnogo 519 11月 12 00:33 prof.c7340881 lrwxrwxrwx 1 sunnogo sunnogo 5 2月 23 21:16 symbol.sh -&gt; if.shsunnogo@a3e420:~/test/script$ ln -s if.sh lnsymbol.shsunnogo@a3e420:~/test/script$ ls -litotal 167340612 -rwxrwxr-x 3 sunnogo sunnogo 94 6月 21 2013 if.sh7340612 -rwxrwxr-x 3 sunnogo sunnogo 94 6月 21 2013 link.sh7340612 -rwxrwxr-x 3 sunnogo sunnogo 94 6月 21 2013 lnlink.sh7340895 lrwxrwxrwx 1 sunnogo sunnogo 5 2月 23 21:26 lnsymbol.sh -&gt; if.sh7340899 -rw-rw-r-- 1 sunnogo sunnogo 519 11月 12 00:33 prof.c7340881 lrwxrwxrwx 1 sunnogo sunnogo 5 2月 23 21:16 symbol.sh -&gt; if.sh Written with StackEdit.]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SecureCRT python 脚本记录]]></title>
    <url>%2F201311%2Fprogrammer%2Ftools%2Fscrt_python.html</url>
    <content type="text"><![CDATA[SecureCRT 从 7.0 版本开始支持 python。 SecureCRT 脚本发送 ctrl c 或其他特殊字符python 脚本不支持 SendKeys，之前不知道怎么发送 ctrl c，瞎写了一个 vb 脚本用 SendKeys 发送。 123456789101112#$language = "VBScript"#$interface = "1.0"Sub Main()crt.Screen.ClearWhile 1 crt.screen.sendkeys("^C") crt.sleep(200)WendEnd Sub Google 一下，发现 python 本身就可以发送控制码，在 stackoverflow 中，IIRC, Ctrl-C is etx. Thus send \x03。再看 ascii 码，所有的这些控制码都有对应的 ascii 码。python 版的一直发 ctrl + c： 123456# $language = "python"# $interface = "1.0"while True: crt.Screen.Send("\x03") crt.Sleep(200)]]></content>
      <categories>
        <category>programmer</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>SecureCRT</tag>
      </tags>
  </entry>
</search>
